

#### ['MDS in a box - Monte Carlo simulation of the NBA  @爱可可-爱生活](https://weibo.com/1402400261/MmTePEi6J)

Note: 'MDS in a box - Monte Carlo simulation of the NBA season, leveraging meltano, dbt, duckdb and superset' Jacob Matson GitHub: github.com/matsonj/nba-monte-carlo  

Picture: [5396ee05ly1h9sr3wo569j221b11f7m8.jpg](https://weibo.cn//mblog/pic/MmTePEi6J?rl=1)

Github: [github.com/matsonj/nba-monte-carlo](https://github.com/matsonj/nba-monte-carlo)

#### [【fastplotlib：Python快速绘图库】’fastplotlib - A fast plo @爱可可-爱生活](https://weibo.com/1402400261/MmT6y2dxc)

Note: 【fastplotlib：Python快速绘图库】’fastplotlib - A fast plotting library' by Kushal Kolar GitHub: github.com/kushalkolar/fastplotlib  

Picture: [5396ee05ly1h9sqij5rj3j21ai0hgdnu.jpg](https://weibo.cn//mblog/pic/MmT6y2dxc?rl=1)

Github: [github.com/kushalkolar/fastplotlib](https://github.com/kushalkolar/fastplotlib)

#### [《Competitive Programmer’s Handbook》 by Antti Laaks @爱可可-爱生活](https://weibo.com/1402400261/MnneblxAj)

Note: 《Competitive Programmer’s Handbook》 by Antti Laaksonen (2017)  

Picture: [5396ee05ly1frbqjgz4f4j20x01bqn4n.jpg](https://weibo.cn//mblog/pic/GgIZVyvGS?rl=1)

#### [【Transformers Tasks：集成了基于 transformers 库实现的多种 NLP  @爱可可-爱生活](https://weibo.com/1402400261/Mo6LQfYKs)

Note: 【Transformers Tasks：集成了基于 transformers 库实现的多种 NLP 任务】'transformers_tasks - NLP Algorithms with transformers lib. Supporting Text-Classification, Text-Generation, Information-Extraction, Text-Matching, RLHF etc.' HarderThenHarder GitHub: github.com/HarderThenHarder/transformers_tasks 

Picture: [5396ee05ly1ha20k4xgh9j21c131gb29.jpg](https://weibo.cn//mblog/pic/Mo6LQfYKs?rl=1)

Github: [github.com/HarderThenHarder/transformers_tasks](https://github.com/HarderThenHarder/transformers_tasks)

#### [【Yark：YouTube的本地归档和离线浏览工具】’Yark - YouTube archivin @爱可可-爱生活](https://weibo.com/1402400261/Mn2gk3AlG)

Note: 【Yark：YouTube的本地归档和离线浏览工具】’Yark - YouTube archiving made simple' Owen Griffiths GitHub: github.com/Owez/yark  

Picture: [5396ee05ly1h9tuxhzgwxj219c0janjr.jpg](https://weibo.cn//mblog/pic/Mn2gk3AlG?rl=1)

Github: [github.com/Owez/yark](https://github.com/Owez/yark)

#### [CRN：2022年最热的半导体创业公司CRN：The 10 Hottest Semiconducto @WinnieS的微博](https://weibo.com/2144454703/MnF52azBF)

Note: CRN：2022年最热的半导体创业公司CRN：The 10 Hottest Semiconductor Startup Companies Of 20221，Alif Semiconductor ：多功能高性能低功耗带AI功能MCU，ARM和RISC-V都有2，Astera Labs ： Leo  CXL Memory Connectivity Platform 提供高速chip-2-memory互联3，Atomica Corp.：MEMS4，Axelera AI：  in-memory computing的AI5，Cron AI ：英国的公司，做3D data edge inference 6，Eliyan ：基于UCIe的chiplet互联方案7，Lightelligence ：光电系统的，之前上过hotchip8，Luminous Computing：AI supercomputer9，Quadric：可以跑ML算法也能跑C/C++的GPGPU，这种混合架构在特定场合应该有能效优势10，Syntiant Corp.：ML NPU，号称出了 2千万片这10家公司，看名字，印度裔CEO的比例很高回复:就是人多… …印度裔公司高管占比高的现象到底是啥原因感觉不少都是等着别人收购赚一波

Picture: [7fd1c82fgy1h9yk1osy9rj21vy0toe81.jpg](https://weibo.cn//mblog/pic/MnF52azBF?rl=1)

#### [【I wrote a WebAssembly Interpreter and Toolkit in  @网路冷眼](https://weibo.com/1715118170/MovEFbW2Y)

Note: 【I wrote a WebAssembly Interpreter and Toolkit in C】https:///github.com/FastVM/Web49 我用 C 写了一个 WebAssembly 解释器和工具包。 

Picture: [663aa05aly1h9yqqt8grdj20hs0dct8z.jpg](https://weibo.cn//mblog/pic/MovEFbW2Y?rl=1)

Github: [github.com/FastVM/Web49](https://github.com/FastVM/Web49)

#### ['Template ("Golden Master") - arc42 - the template @爱可可-爱生活](https://weibo.com/1402400261/MpM9PEu3y)

Note: 'Template ("Golden Master") - arc42 - the template for software architecture documentation and communication' GitHub: github.com/arc42/arc42-template  

Picture: [5396ee05ly1haeozxo149j21c613ekbz.jpg](https://weibo.cn//mblog/pic/MpM9PEu3y?rl=1)

Github: [github.com/arc42/arc42-template](https://github.com/arc42/arc42-template)

#### [【PyTorch Vulkan Back End User Workflow】 PyTorch Vu @网路冷眼](https://weibo.com/1715118170/Mq7OWfkVp)

Note: 【PyTorch Vulkan Back End User Workflow】 PyTorch Vulkan 后端用户工作流程。 

#### [使用wireshark进行恶意流量分析，主要涉及知识点包括IOC，键盘记录器木马，ftp协议等。   @蚁工厂](https://weibo.com/2194035935/MqHaDbDxO)

Note: 使用wireshark进行恶意流量分析，主要涉及知识点包括IOC，键盘记录器木马，ftp协议等。  

#### [电子书《Rust by Example》英文版：中文版：《通过例子学 Rust》（Rust By E @蚁工厂](https://weibo.com/2194035935/MqJ24B5ep)

Note: 电子书《Rust by Example》英文版：中文版：《通过例子学 Rust》（Rust By Example, RBE）内容由一系列可在线运行的实例组成，通过这些例子阐明了各种 Rust 的概念和基本库。 

Picture: [82c654dfly1halfako391j20dt1kojw6.jpg](https://weibo.cn//mblog/pic/MqJ24B5ep?rl=1)

#### [电子书《Learn-Vim(the Smart Way)》 中文翻译地址：github.com/ws @敖天羽](https://weibo.com/1888981347/MrhDA3pu7)

Note: 电子书《Learn-Vim(the Smart Way)》 中文翻译地址：github.com/wsdjeg/Learn-Vim_zh_cn本指南同时为初学者和高级Vim用户撰写。它从宽泛而简单的概念开始讲，最后落在特殊的、进阶的技巧上。 

Picture: [82c654dfly1gyvqo3kjmuj20ju1hr0yg.jpg](https://weibo.cn//mblog/pic/LdJHA184j?rl=1)

Github: [github.com/wsdjeg/Learn-Vim_zh_cn](https://github.com/wsdjeg/Learn-Vim_zh_cn)

#### [恶意流量分析第三集来了[成人礼]   @蚁工厂](https://weibo.com/2194035935/Mr7TLsWn6)

Note: 恶意流量分析第三集来了[成人礼]  

#### [  @AINLP](https://weibo.com/2703427641/Mr9Qh1eMM)

#### [上海交通大学并行与分布式系统研究所的新人培训视频第一讲：Shell第二讲：CMake第三讲：Git第 @蚁工厂](https://weibo.com/2194035935/MrivB4gQb)

Note: 上海交通大学并行与分布式系统研究所的新人培训视频第一讲：Shell第二讲：CMake第三讲：Git第四讲：Vim第七讲：内核调试第八讲：科研数据管理 （缺5、6讲） 分布式讲了一堆运维的东西回复:业余时间可以自己研究，脱离分布式重点了这些不会工作没法开展分布式讲了一堆运维的东西

#### [程序调试宣言 总结了作者在调试过程中的经验教训。如在修改bug前先要搞明白发生了什么，不要觉得底层操 @敖天羽](https://weibo.com/1888981347/MrinP8vB7)

Note: 程序调试宣言 总结了作者在调试过程中的经验教训。如在修改bug前先要搞明白发生了什么，不要觉得底层操作系统一定不会出错等等 

Picture: [82c654dfly1haq8azakt8j20vw1dmdxk.jpg](https://weibo.cn//mblog/pic/MrigaD4LA?rl=1)

#### [Git 系列文章，是作者 决定结合之前在 Code.fun 建立的 Git 规范，和分享过的常见操作 @蚁工厂](https://weibo.com/2194035935/MrkBxmWLG)

Note: Git 系列文章，是作者 决定结合之前在 Code.fun 建立的 Git 规范，和分享过的常见操作整理出来，作为虎年兔年承上启下的文章，贡献给大家。（一）：常用团队规范，包含Git 使用原则、分支设计、单线分支原则、开发规范（二）：常见问题解决，包含处理 hotfix、git rebase dev -i、git reset –hard COMMIT（三）：Git推荐配置与小技巧，包含我也来转一发。这套规范在传统git flow的基础上强调了git rebase的重要性。后两篇以及分享了一些解决问题的经验，和方向性的讨论。希望对大家有帮助。

#### ['FAY - 一个完整的数字人项目，包含Python内核及UE数字人模型，可以用于做数字助理及抖音自 @爱可可-爱生活](https://weibo.com/1402400261/MrrJsBmjf)

Note: 'FAY - 一个完整的数字人项目，包含Python内核及UE数字人模型，可以用于做数字助理及抖音自动直播' TheRamU GitHub: github.com/TheRamU/Fay  Mark

Picture: [5396ee05ly1hare5gf2tvj20le0bsqat.jpg](https://weibo.cn//mblog/pic/MrrJsBmjf?rl=1)

Github: [github.com/TheRamU/Fay](https://github.com/TheRamU/Fay)

#### [CaskDB - 使用 Go语言构建你自己的基于磁盘的 KV 存储 地址：github.com/av @蚁工厂](https://weibo.com/2194035935/MrA6jkTUR)

Note: CaskDB - 使用 Go语言构建你自己的基于磁盘的 KV 存储 地址：github.com/avinassh/go-caskdb其基本原理是由basho的bitcask论文所设计的key-value存储引擎，是一种底层格式为日志模样的 kv 存储。该项目更多的是用于教学，旨在帮助任何人，甚至是数据库初学者，在几个小时内建立一个持久的数据库。 没有外部依赖； 只有 Go 标准库就足够了。感觉这些年kv发明的太多了

Picture: [82c654dfly1hase1kopaqj20qr0giq7c.jpg](https://weibo.cn//mblog/pic/MrA6jkTUR?rl=1)

Github: [github.com/avinassh/go-caskdb](https://github.com/avinassh/go-caskdb)

#### [通用图形处理器设计- GPGPU编程模型与架构原理（景乃峰，柯晶，梁晓峣）第三章GPGPU的控制核心 @WinnieS的微博](https://weibo.com/2144454703/Msgk4nkhC)

Note: 通用图形处理器设计- GPGPU编程模型与架构原理（景乃峰，柯晶，梁晓峣）第三章GPGPU的控制核心架构（下）3.3 线程分支SIMT模型，按照线程束（warp）的粒度进行取指，译码和执行，这时如果遇到了if else，就要处理线程分支/分叉概念1： 谓词（Predicate）寄存器 ：为每个执行通道配备的1比特寄存器           向量处理器，SIMD，SIMT等架构常用GPGPU用显式的谓语寄存器来支持线程分支          显式：就是软件可见 （配合例程代码3-1 和图3-5理解）线程分支是GPGPU性能损失的一个重要因素    （因此CPU要做分支预测，而且预测准确率很高）概念2: SIMT堆栈（SIMT stack）根据每个线程的谓语寄存器形成线程束的活跃掩码（active mask）帮助调度器确定哪些线程应该开启或关闭，从而实现分支线程的管理谓语寄存器是软件可见，活跃掩码就是硬件使用概念3:分叉点（devergent point）和重聚点（reconvergent point）识别分叉点和重聚点就是管理活跃掩码的关键SIMT堆栈实现了对活跃掩码的管理。   堆栈中的每个条目包括三个字段：分支重聚点的PC（Reconvergence PC，RPC），下一条PC（next PC，NPC），活跃掩码（Active Mask）结合图3-5和图3-6，就知道，借助Active Mask和SIMT堆栈，所有的线程都执行了ABCDEFGA的全路径，只是部分线程在一些时间并不执行代码。 也就是实现了分支SIMT堆栈方式简单高效，但是在原子操作的情况下，有死锁问题。 概念4:分支屏障和Yield指令， 可以解死锁问题优化分支设计的两个角度：    1.寻找更早的分支重聚点（缩短分支么）    2.积极实施分支线程的动态重组和合并（这往往需要微架构支持）这部分属于高级设计部分了，有志于从事SM核设计的，好好看看，其它人可略3.4 线程束调度线程束调度器，跟CPU指令流水中的调度器一样， 从就绪的线程束中挑选一个或者多个线程束发送给空闲的执行单元。 就绪的线程束：避免了下列8个原因的线程束，就是可发射的      1，pipeline busy， 就是指令运行所需的功能单元正忙      2，Texture单元正忙      3，Constant缓存缺失， 第一次访问会缺失      4，Instruction Fetch 指令缓存缺失 ，也是一般第一次运行访问时容易缺失      5，memory throttle， 大量存储访问操作尚未完成      6， memory Dependency ， 由于请求支援不可用或者满载导致load/store无法执行      7，synchronization  线程束在等待同步指令      8，execution dependency 输入依赖线程束调度器的条目：   ID（线程块ID，线程束ID，线程ID） PC， 解码后的指令，Ready， Valid解码完成， Valid置位检查看是否可以发射，如果可以就Ready置位线程束 发射指令之后，调度器清除表项，并通知取指单元加载新的指令 线程束调度器的调度策略，常见的有RR（Round- Robin）和GTO（Greedy-then-oldest） 线程束调度策略优化：数据访存延时是影响性能的主要因素，因此发掘数据的局部性是有效手段。局部性包含了时间和空间的两种局部性。优化策略永远是存在”更好更快“的方法的，有兴趣者可以深入。 3.5 记分牌记分牌是用来解决数据相关带来的竞争和冒险。概念：数据相关性，写后读（Read after Write， RAW），真数据相关，写后写（Write After Write， WAW），名词相关，读后写（Write After Read，WAR），反相关。 都是跟CPU一样的概念。GPGPU，顺序执行，因此简单的记分牌设计即可，重点避免RAW和WAW记分牌方案简单，但是GPGPU的寄存器数量庞大，如果给每个寄存器都分牌1bit标识，记分牌将占据大量空间；其次待发射的线程束指令在调度时需要一直查询记分牌，直到所依赖的指令执行完毕，更新寄存器对应的标识之后，才能发射。 这些都是需要优化的。 1，基于寄存器编号索引的记分牌设计2，基于读写屏障的软件记分牌设计3.6 线程块分配与调度线程块是一个或者多个线程束， 是CUDA或者OpenCL将任务分配给SM/CU的基本单元线程块之间应该相互独立，不存在依赖（CUDA/OpenCL编程模型保证）首先，线程块如何分配到SM/CU上线程块的调度器（图3-2）就负责管理所有线程块的分配。当调度器可以在一个SM/CU上分配一个线程块所需的所有资源的时候，就会创建一个线程块。 线程块是个大单位， 其中的一个线程束（基本的调度粒度）的执行情况是线程块的局部执行状况。 线程块的最常用分配策略是轮询策略。 线程块调度器按轮询方式，为每个SM分配至少一个线程块，如果第一轮分配结束之后，SM上仍然有空闲未分配的智勇（包括寄存器，共享存储器，线程块分配槽等），则进行第二轮分配，如此反复，直到所有的SM上的资源分配完为止。 尚未分配的线程块，需要等待已分配的线程块执行完毕并释放资源，才可以分配到有资源的SM/CU上去。 GPGPU一般不允许任务的强占和迁移。 Nvidia的GPGPU中，线程块的分配由千兆线程引擎（giga thread engine）来完成，大体遵循轮询策略，但并不是朴素的轮询。线程块的调度策略和线程束的调度策略由很高的关联性，两者都对GPGPU的执行性能有重要影响，但是调度粒度不同（线程块大）线程块的调度与线程块的分配策略也密切相关，分配方式也会影响到调度的质量。 线程块分配与调度策略优化主要是围绕SIMT线程地址所展现出来的连续性，进而在缓存和DRAM的局部性上寻求更优化的访存操作及在线程块分配进行限流等方面提高GPGPU的资源利用率。    1，感知空间局部性的调度策略：感知L1缓存局部性的块级线程块调度， 感知DRAM板块的线程块协同调度  2，感知时间局部性的强占调度策略   3，限制线程块数量的怠惰分配和调度策略   4，利用线程块重聚类感知局部性的软件调度策略回复:美国禁令，无论如何都得自己做win大，nv已经在大搞tensor core和transformer engine了，国内gpgpu能做出性能收益嘛，不会到最后还得依靠信创吧

Picture: [7fd1c82fgy1haxlmcsuc9j22c03404qq.jpg](https://weibo.cn//mblog/pic/Msgk4nkhC?rl=1)

#### [这个页面收集了技术面试中最后可以反问面试官的话github.com/yifeikong/revers @蚁工厂](https://weibo.com/2194035935/MstN40seG)

Note: 这个页面收集了技术面试中最后可以反问面试官的话github.com/yifeikong/reverse-interview-zh比如职责、技术、团队、休假时间等。摘录部分：    公司常用的技术栈是什么？    你们怎么使用源码控制系统？    你们怎么测试代码？    不同的意见如何处理？    如果被退回了会怎样？（“这个在预计的时间内做不完”）    当团队有压力并且在超负荷工作的时候怎么处理？    我可以为开源项目做贡献吗？是否需要审批？    你认为公司未来五年或者十年会发展成什么样子？

Github: [github.com/yifeikong/reverse-interview-zh](https://github.com/yifeikong/reverse-interview-zh)

#### [《Rust 编码规范》发了一个新的小版本0.2地址：rust-coding-guidelines.g @蚁工厂](https://weibo.com/2194035935/Msuswf4f1)

Note: 《Rust 编码规范》发了一个新的小版本0.2地址：rust-coding-guidelines.github.io/rust-coding-guidelines-zh/本规范致力于成为统一的 Rust 编码规范，各大公司可以依赖本规范，结合自己的业务领域和团队习惯，形成自己的编码规范，并可以在日常实践中反哺本规范，让本规范更加完善。包含代码风格和 编码实践两部分

Picture: [82c654dfly1gz9a4i23vej20j81klgoi.jpg](https://weibo.cn//mblog/pic/LeWjFlK77?rl=1)

#### [【Shell GPT：基于 OpenAI 的 text-davinci-003 模型的自然语言指令执 @爱可可-爱生活](https://weibo.com/1402400261/Msvrs9hjN)

Note: 【Shell GPT：基于 OpenAI 的 text-davinci-003 模型的自然语言指令执行命令行工具】’Shell GPT - A command-line interface (CLI) productivity tool powered by OpenAI's text-davinci-003 model, will help you accomplish your tasks faster and more efficiently.' Farkhod Sadykov GitHub: github.com/TheR1D/shell_gpt  no more shell真的很nb啊，是我想做的东西了

Github: [github.com/TheR1D/shell_gpt](https://github.com/TheR1D/shell_gpt)

#### [【CUDA 编程手册(中文版)】’CUDA 编程手册 - This is a Chinese tra @爱可可-爱生活](https://weibo.com/1402400261/MsvQ4yhIW)

Note: 【CUDA 编程手册(中文版)】’CUDA 编程手册 - This is a Chinese translation of the CUDA programming guide' NVIDIA-Ken GitHub: github.com/HeKun-NVIDIA/CUDA-Programming-Guide-in-Chinese  

Picture: [5396ee05ly1hazi3l2e5sj218g1b8h4u.jpg](https://weibo.cn//mblog/pic/MsvQ4yhIW?rl=1)

Github: [github.com/HeKun-NVIDIA/CUDA-Programming-Guide-in-Chinese](https://github.com/HeKun-NVIDIA/CUDA-Programming-Guide-in-Chinese)

#### [【QCVM: Bite-sized QuakeC VM written in C】https:/// @网路冷眼](https://weibo.com/1715118170/MsEWzBGzu)

Note: 【QCVM: Bite-sized QuakeC VM written in C】https:///github.com/JaycieErysdren/QCVM QCVM：用 C 语言编写的小型 QuakeC VM 。 

Github: [github.com/JaycieErysdren/QCVM](https://github.com/JaycieErysdren/QCVM)

#### [美国的好大学常常能与时俱进，开出前沿研究领域和最新技术的相关课程。这是斯坦福大学上学期开设的人工智能 @蚁工厂](https://weibo.com/2194035935/MrIACx9mM)

Note: 美国的好大学常常能与时俱进，开出前沿研究领域和最新技术的相关课程。这是斯坦福大学上学期开设的人工智能大语言模型课程：CS324 - Large Language Models，包括课程讲义。stanford-cs324.github.io/winter2022 (由于微博不允许这个链接，自己在URL前面加上https://) 

Picture: [007C1uJCgy1hatbnl7zzij30zo1y7tnm.jpg](https://weibo.cn//mblog/pic/MrHrJm4Oj?rl=1)

#### [【《编写高效程序的艺术》随书代码】’The Art of Writing Efficient Pro @爱可可-爱生活](https://weibo.com/1402400261/MrKPVrd1G)

Note: 【《编写高效程序的艺术》随书代码】’The Art of Writing Efficient Programs - The Art of Writing Efficient Programs, published by Packt' sanonymous GitHub: github.com/PacktPublishing/The-Art-of-Writing-Efficient-Programs  

Picture: [5396ee05ly1hatqkpdu06j206y08l0tv.jpg](https://weibo.cn//mblog/pic/MrKPVrd1G?rl=1)

Github: [github.com/PacktPublishing/The-Art-of-Writing-Efficient-Programs](https://github.com/PacktPublishing/The-Art-of-Writing-Efficient-Programs)

#### [【Paper QA：基于 OpenAI API 的文档问答引擎】’Paper QA - LLM Ch @爱可可-爱生活](https://weibo.com/1402400261/MrU37jCo1)

Note: 【Paper QA：基于 OpenAI API 的文档问答引擎】’Paper QA - LLM Chain for answering questions from documents with citations' Andrew White GitHub: github.com/whitead/paper-qa  

Picture: [5396ee05ly1hauv9kii0hj219i0ii0zd.jpg](https://weibo.cn//mblog/pic/MrU37jCo1?rl=1)

Github: [github.com/whitead/paper-qa](https://github.com/whitead/paper-qa)

#### [【Researchers at Stanford Introduce Parsel: An Arti @网路冷眼](https://weibo.com/1715118170/Ms2E2kANU)

Note: 【Researchers at Stanford Introduce Parsel: An Artificial Intelligence AI Framework That Enables Automatic Implementation And Validation of Complex Algorithms With Code Large Language Models LLMs】 斯坦福大学的研究人员介绍了 Parsel：一种人工智能 AI 框架，可以使用代码大型语言模型 LLM 自动实施和验证复杂算法。

Picture: [663aa05aly1hapia9tzucj208c06yq3h.jpg](https://weibo.cn//mblog/pic/Ms2E2kANU?rl=1)

#### [Netflix纪录片《诈.骗.王.》2小时完整版___()  @宝玉xp](https://weibo.com/1727858283/MsMiCD9UZ)

Note: Netflix纪录片《诈.骗.王.》2小时完整版___() 

#### [Git飞行规则(Flight Rules)github.com/k88hudson/git-flig @蚁工厂](https://weibo.com/2194035935/MsMNpfrjE)

Note: Git飞行规则(Flight Rules)github.com/k88hudson/git-flight-rules/blob/master/README_zh-CN.md这是一篇给宇航员（这里就是指使用Git的程序员们）的指南，用来指导问题出现后的应对之法。中英文都有。 

Picture: [82c654dfly1gzbt1p1051j20u00xzwnj.jpg](https://weibo.cn//mblog/pic/LfgUryzk4?rl=1)

Github: [github.com/k88hudson/git-flight-rules/blob/master/README_zh-CN.md](https://github.com/k88hudson/git-flight-rules/blob/master/README_zh-CN.md)

#### [【ChatGPTPapers：ChatGPTP 必读文献列表】’ChatGPTPapers - Mu @爱可可-爱生活](https://weibo.com/1402400261/MsXMr0ioJ)

Note: 【ChatGPTPapers：ChatGPTP 必读文献列表】’ChatGPTPapers - Must-read papers, related blogs and API tools on the pre-training and tuning methods for ChatGPT.' shizhediao GitHub: github.com/shizhediao/ChatGPTPapers  

Picture: [5396ee05ly1hb2xgisdouj21bk18ex2g.jpg](https://weibo.cn//mblog/pic/MsXMr0ioJ?rl=1)

Github: [github.com/shizhediao/ChatGPTPapers](https://github.com/shizhediao/ChatGPTPapers)

#### [【Chroma：面向LLM等应用的嵌入式开源向量存储检索数据库】’Chroma - the open @爱可可-爱生活](https://weibo.com/1402400261/MsXPaALD9)

Note: 【Chroma：面向LLM等应用的嵌入式开源向量存储检索数据库】’Chroma - the open source embedding database' GitHub: github.com/chroma-core/chroma  

Picture: [5396ee05ly1hb2xmalb8jj21b2190aoq.jpg](https://weibo.cn//mblog/pic/MsXPaALD9?rl=1)

Github: [github.com/chroma-core/chroma](https://github.com/chroma-core/chroma)

#### [为什么 GPT-3 的所有公开复制都失败了？我们应该在哪些任务中使用 GPT-3.5/ChatGPT @蚁工厂](https://weibo.com/2194035935/MsZvlEQtX)

Note: 为什么 GPT-3 的所有公开复制都失败了？我们应该在哪些任务中使用 GPT-3.5/ChatGPT？地址：jingfengyang.github.io/gpt作者Jingfeng Yang，亚马逊NLP研究科学家 

Picture: [82c654dfgy1hb352clwn8j216w0v8dqh.jpg](https://weibo.cn//mblog/pic/MsZvlEQtX?rl=1)

#### [《设计数据密集型应用 - 中文翻译》地址：github.com/Vonng/ddia现今，尤其是在互 @蚁工厂](https://weibo.com/2194035935/MtezF3Cxm)

Note: 《设计数据密集型应用 - 中文翻译》地址：github.com/Vonng/ddia现今，尤其是在互联网领域，大多数应用都属于数据密集型应用。本书从底层数据结构到顶层架构设计，将数据系统设计中的精髓娓娓道来。其中的宝贵经验无论是对架构师、DBA、还是后端工程师、甚至产品经理都会有帮助。作者： Martin Kleppmann原名：《Designing Data-Intensive Applications》译者：冯若航

Picture: [82c654dfly1gzf2g87h6qj20gt1h4wh3.jpg](https://weibo.cn//mblog/pic/LfHvh8tdn?rl=1)

Github: [github.com/Vonng/ddia](https://github.com/Vonng/ddia)

#### [南加州大学《高级自然语言处理》 的课堂笔记pdf下载：elanmarkowitz.github.io @蚁工厂](https://weibo.com/2194035935/MtfkG7yx0)

Note: 南加州大学《高级自然语言处理》 的课堂笔记pdf下载：elanmarkowitz.github.io/USC-CS662/assets/files/class_notes.pdf内容关于机器学习和自然语言处理中各种主题的综合说明：概念、技术和算法。 

Picture: [82c654dfly1hb52xjbehkj20xc0rl421.jpg](https://weibo.cn//mblog/pic/MtfkG7yx0?rl=1)

#### [电子书《高并发的哲学原理 Philosophical Principles of High Conc @蚁工厂](https://weibo.com/2194035935/MtoABzlvj)

Note: 电子书《高并发的哲学原理 Philosophical Principles of High Concurrency》作者 地址：github.com/johnlui/PPHC本书的目标是在作者有限的认知范围内，讨论一下高并发问题背后隐藏的一个哲学原理——找出单点，进行拆分。我们将从动静分离讲起，一步步深入 Apache、Nginx、epoll、虚拟机、k8s、异步非阻塞、协程、应用网关、L4/L7 负载均衡器、路由器(网关)、交换机、LVS、软件定义网络(SDN)、Keepalived、DPDK、ECMP、全冗余架构、用户态网卡、集中式存储、分布式存储、PCI-E 5.0、全村的希望 CXL、InnoDB 三级索引、内存缓存、KV 数据库、列存储、内存数据库、Shared-Nothing、计算存储分离、Paxos、微服务架构、削峰、基于地理位置拆分、高可用等等等等。并最终基于地球和人类社会的基本属性，设计出可以服务地球全体人类的高并发架构。作者的博客里还有很多好文。比如《性能之殇》系列博文，讨论了人们为了提高性能做出的种种努力 作者的博客里还有很多好文。比如《性能之殇》系列博文，讨论了人们为了提高性能做出的种种努力 

Picture: [82c654dfgy1hb67tbd90pj20xg0qt7m3.jpg](https://weibo.cn//mblog/pic/MtoABzlvj?rl=1)

Github: [github.com/johnlui/PPHC](https://github.com/johnlui/PPHC)

#### [【《自然语言处理进阶》课程笔记】《CS 662 Notes | Advanced Natural L @爱可可-爱生活](https://weibo.com/1402400261/MtoCgpihH)

Note: 【《自然语言处理进阶》课程笔记】《CS 662 Notes | Advanced Natural Language Processing - University of Southern California》by Jonathan May  great一天的任务就是点赞收藏

Picture: [5396ee05ly1hb67xqlol5j211s19aqig.jpg](https://weibo.cn//mblog/pic/MtoCgpihH?rl=1)

#### [【refstring - A c-string wrapper library designed f @网路冷眼](https://weibo.com/1715118170/MtpGHwAGw)

Note: 【refstring - A c-string wrapper library designed for efficient memory management】https:///github.com/Ratstail91/refstring refstring - 为高效内存管理而设计的 c 字符串包装器库。 

Github: [github.com/Ratstail91/refstring](https://github.com/Ratstail91/refstring)

#### [【MIT《机器学习矩阵积分及其应用》短期课程资料】’Matrix Calculus for Mach @爱可可-爱生活](https://weibo.com/1402400261/Mtq6tyWKv)

Note: 【MIT《机器学习矩阵积分及其应用》短期课程资料】’Matrix Calculus for Machine Learning and Beyond - MIT IAP short course: Matrix Calculus for Machine Learning and Beyond' MITMath GitHub: github.com/mitmath/matrixcalc  

Picture: [5396ee05ly1hb6ehnw106j21b40vg7qa.jpg](https://weibo.cn//mblog/pic/Mtq6tyWKv?rl=1)

Github: [github.com/mitmath/matrixcalc](https://github.com/mitmath/matrixcalc)

#### [【scikit-time：时间序列机器学习统一框架】'scikit-time - A unified @爱可可-爱生活](https://weibo.com/1402400261/Mtq7cbako)

Note: 【scikit-time：时间序列机器学习统一框架】'scikit-time - A unified framework for machine learning with time series' GitHub: github.com/scikit-time/scikit-time    

Github: [github.com/scikit-time/scikit-time](https://github.com/scikit-time/scikit-time)

#### [【如何快速搭建AI产品原型？这里是一份最新的AI黑客马拉松备用工具栈清单】’AI Hackathon @爱可可-爱生活](https://weibo.com/1402400261/Mts350Lxh)

Note: 【如何快速搭建AI产品原型？这里是一份最新的AI黑客马拉松备用工具栈清单】’AI Hackathon Stack' by sw-yx GitHub: github.com/sw-yx/ai-notes/blob/main/Resources/AI-hackathon-stack.md  

Picture: [5396ee05ly1hb6n38mvysj21aw158x0l.jpg](https://weibo.cn//mblog/pic/Mts350Lxh?rl=1)

Github: [github.com/sw-yx/ai-notes/blob/main/Resources/AI-hackathon-stack.md](https://github.com/sw-yx/ai-notes/blob/main/Resources/AI-hackathon-stack.md)

#### ['flaxlm - Train large Huggingface models with flex @爱可可-爱生活](https://weibo.com/1402400261/MtAKjzjUH)

Note: 'flaxlm - Train large Huggingface models with flexible data/model parallelism in Flax/JAX' Andy Ehrenberg GitHub: github.com/andyehrenberg/flaxlm  

Picture: [5396ee05ly1hb7pf52wpqj21bc120tvd.jpg](https://weibo.cn//mblog/pic/MtAKjzjUH?rl=1)

Github: [github.com/andyehrenberg/flaxlm](https://github.com/andyehrenberg/flaxlm)

#### [【OctoML PyTorch Profiler：一个Python库和云服务，旨在为使用最先进的机器 @爱可可-爱生活](https://weibo.com/1402400261/MtAGW7vDz)

Note: 【OctoML PyTorch Profiler：一个Python库和云服务，旨在为使用最先进的机器学习加速技术在云硬件上运行PyTorch模型提供最简单的体验】'OctoML PyTorch Profiler - a python library and cloud service designed to provide the simplest experience for running PyTorch models on cloud hardware with state-of-the-art ML acceleration technology' GitHub: github.com/octoml/octoml-profile 

Picture: [5396ee05ly1hb7p4fw0oqj224c0yi1kx.jpg](https://weibo.cn//mblog/pic/MtAGW7vDz?rl=1)

Github: [github.com/octoml/octoml-profile](https://github.com/octoml/octoml-profile)

#### [程序员在家做饭方法指南。 地址：anduin2017.github.io/HowToCook/用更清 @蚁工厂](https://weibo.com/2194035935/MtxUlpVRq)

Note: 程序员在家做饭方法指南。 地址：anduin2017.github.io/HowToCook/用更清晰精准的描述来整理常见菜的做法，以方便程序员在家做饭。 没有锅回复:新版本已经修复了这个bug。一人4g盐，尼玛，齁到死两回为什么没有使用脚本来自动化过程？

Picture: [82c654dfgy1hb7dj9m4ugj20zq1dhn6v.jpg](https://weibo.cn//mblog/pic/Lg0l8e89a?rl=1)

#### [电子书《Fundamentals of Data Visualization 数据可视化基础》（英文 @蚁工厂](https://weibo.com/2194035935/Mty189zaz)

Note: 电子书《Fundamentals of Data Visualization 数据可视化基础》（英文）本书会带你了解诸多经常遇到的可视化问题，还会对如何将庞大的数据集转化为清晰明了、让人信服的图表提供指南。O’Reilly出版了该书的实体书。中文版实体书链接： 

Picture: [82c654dfly1h2qroog8e0j20gw0m4acn.jpg](https://weibo.cn//mblog/pic/LvrEGxgjE?rl=1)

#### [斯坦福CS224N（Natural Language Processing）课程的一个新课件Lect @蚁工厂](https://weibo.com/2194035935/Mtzy683oc)

Note: 斯坦福CS224N（Natural Language Processing）课程的一个新课件Lecture 11: Prompting, Instruction Finetuning, and RLHFpdf下载：web.stanford.edu/class/cs224n/slides/cs224n-2023-lecture11-prompting-rlhf.pdf主要内容：GPT 1-3, in-context learning, (zero-shot) chain-of-thought, instruction finetuning, RLHF (w/ an  intro to RL for the uninitiated), constitutional AI

Picture: [82c654dfgy1hb7k6f3isxj21xn1324d4.jpg](https://weibo.cn//mblog/pic/Mtzy683oc?rl=1)

#### [[LG]《Masked Siamese ConvNets: Towards an Effective @爱可可-爱生活](https://weibo.com/1402400261/MtFRgqkIc)

Note: [LG]《Masked Siamese ConvNets: Towards an Effective Masking Strategy for General-purpose Siamese Networks》L Jing, J Zhu, Y LeCun [OpenAI & New York University] (2023)   

Picture: [5396ee05ly1hb8byyo1yyj21b60o8h1a.jpg](https://weibo.cn//mblog/pic/MtFRgqkIc?rl=1)

#### [电子书《Problem-solving with algorithms and data struc @蚁工厂](https://weibo.com/2194035935/MtHfKo41r)

Note: 电子书《Problem-solving with algorithms and data structures using Rust》地址：github.com/QMHTMY/RustBookpdf格式。全书分为九章，前两章介绍计算机科学的概念以及算法分析，是整本书的基础。第二到第六章是简单数据结构和算法的设计和实现。第七和八章是较复杂的树及图数据结构，树和图是许多大型软件的底层实现，这两章是基于前几章的更高级主题。最后一章是利用前面所学内容进行的实战项目，通过实战将所学数据结构和算法用于解

Picture: [82c654dfly1gzimvxepdpj20di1g0gnk.jpg](https://weibo.cn//mblog/pic/LgaBpz7cz?rl=1)

Github: [github.com/QMHTMY/RustBookpdf](https://github.com/QMHTMY/RustBookpdf)

#### [优化CPU和内存访问，提高程序性能的一些小技巧以分布式存储系统的性能调优来讲，随着硬件的不断升级，硬 @蚁工厂](https://weibo.com/2194035935/MtL9XwLKg)

Note: 优化CPU和内存访问，提高程序性能的一些小技巧以分布式存储系统的性能调优来讲，随着硬件的不断升级，硬盘和网络逐渐变得不再是绝对瓶颈。基于高速NVME SSD的全闪存储系统，CPU和内存访问优化逐渐成为了不可忽视的方向。曾经不太重视的优化方向，变得重要起来，曾经非常随意的代码编写习惯，也不能再那么随意。CPU和内存访问成为了程序性能的关键因素之一。一个好的内存布局和缓存优化可以有效提高程序性能。在本文中，我们将讨论一些优化CPU和内存访问的一些技巧，包括数据结构的热点字段放在同一个cache line、内存对齐以及缓存优化。首先，数据结构的热点字段放在同一个cache line可以有效提升程序性能。Cache line是CPU缓存中的一段连续内存区域，一次读取或写入Cache line中的数据会将整个Cache line加载到缓存中，而不是只加载部分数据。如果数据结构中的热点字段被放在不同的Cache line中，那么每次访问这些字段都需要从内存中加载Cache line，这将导致较高的访问延迟和CPU缓存竞争。因此，将热点字段放在同一个Cache line中可以减少内存访问开销，提高程序性能。具体来说，可以将结构体中的热点字段，放在结构体的开始处，或者临近的定义在一起。其次，内存对齐也是提升程序性能的一个因素。内存对齐指的是数据结构中的字段按照对齐方式排列，可以减少内存访问开销。例如，结构体中一个int类型的成员占用4个字节，如果该变量在内存中的地址不是4的倍数，那么访问该变量时需要进行额外的内存访问，这将增加访问延迟和CPU缓存竞争。因此，对于需要频繁访问的数据结构，内存对齐可以显著提高程序性能。当然GCC编译器会默认的添加一些padding或者hole，使得结构体中的字段对齐。最后，缓存优化也是提高程序性能的有效手段。缓存优化包括使用cache line对齐、避免False sharing等方法，可以减少缓存竞争，从而提高程序性能。例如，避免False sharing可以通过在数据结构中插入填充字段来实现。False sharing是指两个不相关的变量被分配到同一个Cache line中，这两个变量在不同的CPU核中访问。如果其中一个变量被修改，将导致整个Cache line无效，从而增加缓存竞争和访问延迟。通过在数据结构中插入填充字段，可以将不相关的变量分配到不同的Cache line中，从而避免False sharing，提高程序性能。总之，优化CPU和内存访问来提升程序性能，在需要高性能的应用中，变得越来越重要。通过将数据结构的热点字段放在同一个Cache line中、内存对齐以及缓存优化等技巧，可以减少内存访问开销，减少CPU Cache失效。掌握这些技巧并践行，有助于写出内存访问友好，性能更优的程序。-------------------------------云和恩墨 分布式存储团队 张洋//:转发微博

#### [【PaDiff：基于PaddlePaddle与PyTorch的模型精度对齐工具】'PaDiff -  @爱可可-爱生活](https://weibo.com/1402400261/Mv6bUBwI9)

Note: 【PaDiff：基于PaddlePaddle与PyTorch的模型精度对齐工具】'PaDiff - paddle debug toolkits' PaddlePaddle GitHub: github.com/PaddlePaddle/PaDiff   

Github: [github.com/PaddlePaddle/PaDiff](https://github.com/PaddlePaddle/PaDiff)

#### [【ChatLLaMA：集成 RLHF 的 LLaMA 开源实现，声称训练比 ChatGPT 快15倍 @爱可可-爱生活](https://weibo.com/1402400261/Mv8itlhcn)

Note: 【ChatLLaMA：集成 RLHF 的 LLaMA 开源实现，声称训练比 ChatGPT 快15倍】’ChatLLaMA - Open source implementation for LLaMA-based ChatGPT training process. Faster and cheaper training than ChatGPT (wip)' by Nebuly GitHub: github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllama 这么快。。。llama不是才几天了？

Picture: [5396ee05ly1hbjfatv3gxj21lc0xg7wh.jpg](https://weibo.cn//mblog/pic/Mv8itlhcn?rl=1)

Github: [github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllama](https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllama)

#### [【Python 高效网络分析工具 graph-tool 新版发布，值得一试】《graph-tool: @爱可可-爱生活](https://weibo.com/1402400261/MvdWfccz2)

Note: 【Python 高效网络分析工具 graph-tool 新版发布，值得一试】《graph-tool: Efficent network analysis with python》  Anaconda:conda create --name gt -c conda-forge graph-toolHomebrew:brew install graph-toolDebian/Ubuntu:apt-get install python3-graph-tool 回复:收到🫡[开学季]

Picture: [5396ee05ly1hbk43hd6v0j20xc0xadzb.jpg](https://weibo.cn//mblog/pic/MvdWfccz2?rl=1)

#### [Tilck，一个x86操作系统内核的教学项目，同时被设计为在二进制层面和linux兼容，这让它可以运 @蚁工厂](https://weibo.com/2194035935/MvdFj73Au)

Note: Tilck，一个x86操作系统内核的教学项目，同时被设计为在二进制层面和linux兼容，这让它可以运行如BusyBox这样的linux程序。地址：github.com/vvaltchev/tilck 牛

Picture: [82c654dfly1hbk2sa3vyyj20iw06emyo.jpg](https://weibo.cn//mblog/pic/MvdFj73Au?rl=1)

Github: [github.com/vvaltchev/tilck](https://github.com/vvaltchev/tilck)

#### [【EasyLM：易用的 JAX/Flax 大型语言模型高效并行训练/评估，支持 TPU】’EasyL @爱可可-爱生活](https://weibo.com/1402400261/MvfDhkU4p)

Note: 【EasyLM：易用的 JAX/Flax 大型语言模型高效并行训练/评估，支持 TPU】’EasyLM - Easy to use model parallel large language models in JAX/Flax with pjit support on cloud TPU pods.' Xinyang (Young) Geng GitHub: github.com/young-geng/EasyLM  

Picture: [5396ee05ly1hbkbontmi7j21b00niqf3.jpg](https://weibo.cn//mblog/pic/MvfDhkU4p?rl=1)

Github: [github.com/young-geng/EasyLM](https://github.com/young-geng/EasyLM)

#### [【ClearML：用于机器学习模型简易部署的命令行实用程序】’ClearML - Model-Ser @爱可可-爱生活](https://weibo.com/1402400261/MvfG6gOiC)

Note: 【ClearML：用于机器学习模型简易部署的命令行实用程序】’ClearML - Model-Serving Orchestration and Repository Solution' GitHub: github.com/allegroai/clearml-serving  

Picture: [5396ee05ly1hbkbvblfmpj21lc1tmty9.jpg](https://weibo.cn//mblog/pic/MvfG6gOiC?rl=1)

Github: [github.com/allegroai/clearml-serving](https://github.com/allegroai/clearml-serving)

#### [推荐五本书，算是我今年对计算机科学的理解；没有算法当然不是说算法不在计算机科学里，但算法是一个相当独 @蚁工厂](https://weibo.com/2194035935/MvnfkjkfJ)

Note: 推荐五本书，算是我今年对计算机科学的理解；没有算法当然不是说算法不在计算机科学里，但算法是一个相当独立的分支而且没什么选书的困惑，谁都知道该看哪本。离散数学也一样。计算理论也一样。所以这三个不用额外推荐；推荐之外的五本。++++第一本是特别好读的经典逻辑入门，它有edx的在线课程，课件全免费，教授fitch style书写natural deduction；就个人看法，这本书应该至少是和离散数学一起打基础。第二本还是逻辑学。逻辑学的教材特别多，Mendelson的是对经典逻辑，模型论，非常中规中距的介绍；其形式化和符号化的能力要求应该是数学专业的入门级和CS专业的中等程度。因为计算机语言理论现在跑的非常远，和经典逻辑有理解上的冲突，而且以证明论为主，那对模型论和经典逻辑的基础部分有个扎实的理解是很好的。毕竟formal language起源于对经典逻辑的研究，概念上和方法上都不该有含糊的地方，即使未来不做任何与模型论有关的方向。第三本是非常好读的证明论而且对计算机专业而言不用读全。因为逻辑系统劈叉了，起码了解基础的minimal logic, intuitionistci logic, classical logic的关系是很重要的；这本纯粹的证明论入门，proof tree和fitch style的介绍的都有，sequent calculus我还不清楚计算机语言理论里是否有应用。第四本是极其好的一层一层介绍类型论和形式化定理证明的；对lambda的介绍简明易懂；对计算机专业方向来说应该不用读到最后。这本对读者对逻辑，形式化，Language和induction的熟悉程度显著有要求，所以它不该是在逻辑和证明论之前读的，虽然它肯定是你最想看懂的，be patient。第五本是打酱油的，在所有PLT的书里它是最轻量的一个，但比SICP要深。因为最终你去看PLT的书的时候不可能不写代码的，那这本的Interpreter是不错的，而且这本书特别好的一点是习题量大。为什么在这里推荐了五本都没有包括Pierce的TAPL，Harper的PFPL，和大名鼎鼎的Software Foundations系列呢。因为这些可以看作是第四本在PLT领域的应用，就象数学有纯数学和应用数学一样。实际上我不喜欢TAPL和PFPL的原因就是他们试图把太多东西一起讲，应该把逻辑的还给逻辑，类型的还给类型，PL的留给PL，就象医学和生物学有关系，但是也有边界。清晰的知道边界在哪儿很重要。SF则走到了另一个极端，它全是证明论的东西但试图不教授学生证明论的逻辑部分而只是教授定理证明器怎么使用。这个现在是一种流行，但有点危险。因为计算机领域发明了这么多语言其实从学术角度而不是工程角度看，制造的混乱比解决的问题多；如果不去理解定理证明器背后的东西，证明论，类型论，定理证明器使用的类型系统如何编码逻辑和公理，优点和限制都在哪里，那未来会有越来越多的证明器，把学生们又埋在了另一个层面的语言中。如果把Logic, Type, Proof的基础内容去掉的话（例如有先导课程），PFPL的内容容量可能减少不只一半。++++Good Luck，年轻人。 

Picture: [62b0b493gy1hbkx34k092j20hv0lcta1.jpg](https://weibo.cn//mblog/pic/MvkDNcDnE?rl=1)

#### [一个开源的视频编辑器，lossless-cut。这款工具的目标是 FFmpeg 的GUI。貌似是用  @蚁工厂](https://weibo.com/2194035935/Mvp8UqxhX)

Note: 一个开源的视频编辑器，lossless-cut。这款工具的目标是 FFmpeg 的GUI。貌似是用 nodejs 写的。github.com/mifi/lossless-cut 只有一条轨道么

Picture: [008rupcegy1hblhn1o4ktj30op0o8tkv.jpg](https://weibo.cn//mblog/pic/Mvp88tTPJ?rl=1)

Github: [github.com/mifi/lossless-cut](https://github.com/mifi/lossless-cut)

#### [最近比较热的几项研究方向：1.controlnet;2. Meta开源的大模型系列LLaMA;3.多 @YaZhou-Li](https://weibo.com/1009508005/MvqkWeSG9)

Note: 最近比较热的几项研究方向：1.controlnet;2. Meta开源的大模型系列LLaMA;3.多模态大模型KOSMOS-1 

#### [【OpenICL：上下文学习开源框架】’OpenICL - An Open-Source Frame @爱可可-爱生活](https://weibo.com/1402400261/Mvrx7C3wM)

Note: 【OpenICL：上下文学习开源框架】’OpenICL - An Open-Source Framework for In-context Learning’ by Shark-NLP GitHub: github.com/Shark-NLP/OpenICL  

Picture: [5396ee05ly1hbls8rn14nj21ko0i4q9d.jpg](https://weibo.cn//mblog/pic/Mvrx7C3wM?rl=1)

Github: [github.com/Shark-NLP/OpenICL](https://github.com/Shark-NLP/OpenICL)

#### [作为海淀区信息检索 TOP5，跟你们推荐一个特别好的信息源：商务部出的《对外投资合作国别（地区）指南 @蚁工厂](https://weibo.com/2194035935/MvA0Do8wm)

Note: 作为海淀区信息检索 TOP5，跟你们推荐一个特别好的信息源：商务部出的《对外投资合作国别（地区）指南》。这套指南里提供的都是非常实用的信息，没有华丽无用的东西。不但特别全面，基本覆盖了整个世界，而且内容翔实，图文并茂。简直就是一套世界百科全书——应该说比百科全书更好。  mark转发微博教主威武，正常发挥

Picture: [53899d01ly1gskx0d5j9pj20v91gpe04.jpg](https://weibo.cn//mblog/pic/KphJHfikr?rl=1)

#### [同济大学赵炯编著的《Linux内核完全注释》中文版：www.oldlinux.org/downloa @蚁工厂](https://weibo.com/2194035935/MuC4lwSYi)

Note: 同济大学赵炯编著的《Linux内核完全注释》中文版：www.oldlinux.org/download/CLK-5.0-WithCover.pdf英文版：www.oldlinux.org/download/ECLK-5.0-WithCover.pdf可以下载中英文两个版本的pdf 👍看看保存

Picture: [82c654dfly1hbfh1esuumj211s0kx7ag.jpg](https://weibo.cn//mblog/pic/MuC4lwSYi?rl=1)

#### [【nanoChatGPT：支持 RLHF 的 nanoGPT】’nanoChatGPT - A cr @爱可可-爱生活](https://weibo.com/1402400261/MuEHwgtMy)

Note: 【nanoChatGPT：支持 RLHF 的 nanoGPT】’nanoChatGPT - A crude RLHF layer on top of nanoGPT with Gumbel-Softmax trick' sanjeevanahilan GitHub: github.com/sanjeevanahilan/nanoChatGPT  

Picture: [5396ee05ly1hbfsnpuz5hj21bk0agn3b.jpg](https://weibo.cn//mblog/pic/MuEHwgtMy?rl=1)

Github: [github.com/sanjeevanahilan/nanoChatGPT](https://github.com/sanjeevanahilan/nanoChatGPT)

#### [【理解大型语言模型】'Understanding large language models - U @爱可可-爱生活](https://weibo.com/1402400261/MuEKpnRiS)

Note: 【理解大型语言模型】'Understanding large language models - Understanding large language models' Anton Bacaj GitHub: github.com/abacaj/transformers  

Picture: [5396ee05ly1hbfsu8rongj22mb3mu4qq.jpg](https://weibo.cn//mblog/pic/MuEKpnRiS?rl=1)

Github: [github.com/abacaj/transformers](https://github.com/abacaj/transformers)

#### [《性能之巅 第2版》读书笔记（2）在第2章中，介绍了性能分析的基本术语、性能指标、分析方法以及统计、 @小川CD](https://weibo.com/1202332555/MvUBvinUL)

Note: 《性能之巅 第2版》读书笔记（2）在第2章中，介绍了性能分析的基本术语、性能指标、分析方法以及统计、监测和数据可视化方面的内容。这些内容非常丰富，下面从几个方面总结一些印象深刻的内容。一、关键性能指标：1.使用率 (1)基于时间的：指在观测周期内，系统或资源繁忙的时间占总时间的比例。使用率 = 繁忙时间 / 观测周期。例如，iostat工具用于观察磁盘利用率，忙碌百分比。需要注意的是，某些资源可以并行提供服务，即使使用率达到100%，性能下降的幅度也可能不会太大。例如，电梯在楼层间移动时，它虽然使用率达到100%，但仍可以容纳更多的乘客。然而，当使用率达到100%时，资源发生竞争时，性能会严重下降。 (2)基于容量的：系统或组件（如硬盘）都能够提供一定的吞吐量。不论性能处于何种级别，系统或组件都工作在其容量的某一比例上。这个比例就称为使用率。用容量定义的使用率意味着，100%使用的硬盘不能接受更多的工作。而用时间定义的使用率只是指时间上100%的忙碌。100%忙碌并不意味着100%的容量使用。参考电梯的例子。2.饱和度 (1)随着工作负载的增加，请求资源的数量超过了资源能够处理的数量。饱和度发生在使用率达到100%（基于容量）时，此时多个任务无法被处理，开始排队等待。需要注意的是，当谈到饱和度时，说明资源的使用率已经达到了100%，因此任务饱和度都是性能问题。二）性能分析方法：1.Ad Hoc 核对清单法(1)这种方法是为系统性能排查列出清单，包括硬件配置、系统配置、软件配置等，这些都不需要修改代码即可调整。例如，CPU 频率、是否开启超线程、内存大小以及通道数、NUMA 节点亲和性、CPU 核心绑定等等。2.USE 方法(1)USE 方法用于应用与性能研究，可以用来识别系统瓶颈。它基于以下三个指标：Utilization、Saturation、Errors。简言之，对于所有资源，查看它的使用率、饱和度和错误。首先检查错误，因为错误通常可以很快被解释（错误通常是客观的而不是主观的指标）。然后是饱和度检查，因为它比使用率解释得更快：任何级别的饱和度都可能是错误。最后是使用率，100% 使用率通常是瓶颈的表现，60% 以上使用可能会是问题。3.延时分析(1)延时分析是检查完成一项操作所需要的时间，然后把时间再分为小的时间段，接着对延时最大的时间段再次做划分，最后定位并量化问题的根本原因。4.性能箴言(1)不要做：消除不必要的工作。(2)做，但不要再做：缓存。(3)做少点：将刷新、轮询或更新的频率调低。(4)稍后再做：回写缓存。(5)在不注意的时候做：安排工作或在非工作时间进行。(6)同时做：从单线程切换到多线程。(7)做得更便宜：购买更贵的硬件。三）理论建模： 1）排队理论 (1)到达过程：描述的是请求到达排队系统的时间间隔。这个时间间隔可能是随机的、固定的或者是一个过程，例如泊松过程（指数分布的到达时间）。例如，在收费站的情况下，车辆到达收费站的时间就是一个时间上的分布。 (2)服务时间分布：描述的是服务中心的服务时间，可以是确定性分布、时间性分布或者其他类型分布。以收费站为例，工作人员为每个车辆提供服务的时间是固定的。 (3)服务中心数目：收费站可以有多个通道，每个通道都可以为车辆提供服务。 (4)队列长度L：L=kW，其中L是队列中的请求个数，k是平均达到率，W是该队列的平均等待时间。--------------------------------------云和恩墨 分布式存储团队 张洋

#### [【ChatLLaMA：基于 LLaMA 的开源 ChatGPT，训练 比 ChatGPT 快15倍】 @爱可可-爱生活](https://weibo.com/1402400261/Mw0p6c2az)

Note: 【ChatLLaMA：基于 LLaMA 的开源 ChatGPT，训练 比 ChatGPT 快15倍】’ChatLLaMA - Open source implementation for LLaMA-based ChatGPT runnable in a single GPU. 15x faster training process than ChatGPT' Juncong Moo GitHub: github.com/juncongmoo/chatllama  

Picture: [5396ee05ly1hbq26rdwzuj21b80veqms.jpg](https://weibo.cn//mblog/pic/Mw0p6c2az?rl=1)

Github: [github.com/juncongmoo/chatllama](https://github.com/juncongmoo/chatllama)

#### [Google发布了PaLM-E模型，这是一种具有实体感知的多模态语言模型，可以将连续的感官模态直接融 @宝玉xp](https://weibo.com/1727858283/Mwi0ahpns)

Note: Google发布了PaLM-E模型，这是一种具有实体感知的多模态语言模型，可以将连续的感官模态直接融入到语言嵌入空间中，建立单词和感知之间的联系。🔗 palm-e.github.io/看演示还挺酷的，可以执行“从抽屉里拿饼干”、“排列积木”这样的任务  神奇，LLM似乎突然打开了通向AGI的大门。毕竟“语言”除了可以是指令，也是人类思维和认知的体现

#### ['Minimal LLaMA - a random assortment of code for r @爱可可-爱生活](https://weibo.com/1402400261/MwEbYftdu)

Note: 'Minimal LLaMA - a random assortment of code for running and fine-tuning LLaMA.’ by Jason Phang GitHub: github.com/zphang/minimal-llama  

Picture: [5396ee05ly1hbuxtu6ao6j21b20k2wnu.jpg](https://weibo.cn//mblog/pic/MwEbYftdu?rl=1)

Github: [github.com/zphang/minimal-llama](https://github.com/zphang/minimal-llama)

#### [Krishnamohan Yerrabilli绘制的linux启动过程图解 。涉及涉及BIOS/UE @蚁工厂](https://weibo.com/2194035935/Mwj6S5bYy)

Note: Krishnamohan Yerrabilli绘制的linux启动过程图解 。涉及涉及BIOS/UEFI初始化、bootloader执行、内核初始化、systemd、系统初始化和用户登录。   转发微博用什么绘制的

Picture: [82c654dfly1hbscqbrw0yj231o1ooe81.jpg](https://weibo.cn//mblog/pic/Mwj6S5bYy?rl=1)

#### [【SuperImage：安卓图像超分辨率App】’SuperImage - Sharpen your @爱可可-爱生活](https://weibo.com/1402400261/MwsKJtBdW)

Note: 【SuperImage：安卓图像超分辨率App】’SuperImage - Sharpen your low-resolution pictures with the power of AI upscaling' Lucchetto GitHub: github.com/Lucchetto/SuperImage  回复:

Picture: [5396ee05ly1hbtjcb8i30j217z0yhkjl.jpg](https://weibo.cn//mblog/pic/MwsKJtBdW?rl=1)

Github: [github.com/Lucchetto/SuperImage](https://github.com/Lucchetto/SuperImage)

#### [在单台macbook上运行Facebook的大语言模型LLaMA地址：github.com/gger @蚁工厂](https://weibo.com/2194035935/MwOBEE6ps)

Note: 在单台macbook上运行Facebook的大语言模型LLaMA地址：github.com/ggerganov/llama.cpp非官方项目  只懂英语终端好漂亮给力 

Github: [github.com/ggerganov/llama.cpp](https://github.com/ggerganov/llama.cpp)

#### [CUDA编程入门（一）CUDA编程模型 （）CUDA编程入门（二）GPU硬件基础 （）CUDA编程入 @WinnieS的微博](https://weibo.com/2144454703/MwUsD4ddT)

Note: CUDA编程入门（一）CUDA编程模型 （）CUDA编程入门（二）GPU硬件基础 （）CUDA编程入门（三）从矩阵加法例程上手CUDA编程（）CUDA编程入门（四）并行归约（Reduction）算法 （）CUDA编程入门（五）更高效的并行归约算法 （）CUDA编程入门（六）展开循环继续优化 （）ZihaoZhao 深度学习算法|AI芯片|无人机 的知乎文章 回复:现查了查diffusion模型是干什么的win大是要搞GPT还是diffusion呀回复:为啥？[苦涩]A卡只能看看了…只能上班摸鱼用公司电脑搞cuda了

#### [AI开源项目推荐：myGPTReader🔗 github.com/madawei2699/myGPT @宝玉xp](https://weibo.com/1727858283/Mx2VFAWp1)

Note: AI开源项目推荐：myGPTReader🔗 github.com/madawei2699/myGPTReader基于 gpt_index 与 chatGPT 的 slack bot，功能如截图所示，可以作为Slack的机器人运行，对消息进行响应，对Url生成摘要。如果想体验的话可以加入这个 slack channel： 还有新的链接吗？这个链接失效了

Picture: [66fd066bgy1hbxyyaxcnfj22gk1j01kx.jpg](https://weibo.cn//mblog/pic/Mx2VFAWp1?rl=1)

Github: [github.com/madawei2699/myGPTReader](https://github.com/madawei2699/myGPTReader)

#### [《Linux 命令行与 Shell 脚本教程(WIP) 》地址：archlinuxstudio.gi @蚁工厂](https://weibo.com/2194035935/Mx23Ampw0)

Note: 《Linux 命令行与 Shell 脚本教程(WIP) 》地址：archlinuxstudio.github.io/ShellTutorial/本书以《Linux 命令行与 Shell 脚本编程大全(第 3 版)》，《鸟哥的 Linux 私房菜第四版》， Arch Wiki 以及维基百科为基准参考，精炼更新出一本实用教程，剔除过时内容与废话，并融入与时俱进的新内容。 

Picture: [82c654dfly1h07zuoyilzj20aq1hlwgo.jpg](https://weibo.cn//mblog/pic/LjvBKlt5B?rl=1)

#### [《性能之巅 第2版》读书笔记（3）在第4章中，主要介绍了性能调优中的一些观测工具，并对这些工具做了一 @小川CD](https://weibo.com/1202332555/MwXXa6jXw)

Note: 《性能之巅 第2版》读书笔记（3）在第4章中，主要介绍了性能调优中的一些观测工具，并对这些工具做了一些分类，以及介绍它们的数据来源。系统性能专家会熟练运用推理和数据分析技巧，从间接的数据和统计数据来分析数据的活动，因此首先需要获取数据。1） 性能观测工具可以按照系统级别和进程级别来分类，多数工具要么基于计数器要么基于事件。 2） 固定计数器：系统内核维护了各种提供系统统计数据的计数器，通常计数器被实现为无符号整型数，发生时间时递增。例如：系统级别的：vmstat、mpstat、iostat、nstat、sar，进程级别的：ps、top、pmap。3） 剖析（profiling）：通过对目标搜集采样或快照来归纳目标特征。与计数器不同，剖析通常只在需要时才启用，因为它们可能产生一些额外的CPU和存储开销。例如：系统级别的：perf、profile、vtune，进程级别的：grof、cachegrind。 4） 跟踪：跟踪每一次发生的记录事件，并可以存储事件的细节信息，供以后分析或生成摘要。与剖析区别在于，其目的是搜集或检查所有的事件，而不仅仅是某个样本。例如：系统级别的：tcpdump、biosnoop、execsnoop、perf、Ftrace、BCC、bpftrace，进程级别的：strace、gdb。 5） 监测：监测持续记录统计数据，以备日后需要。例如：sar可以记录几十种统计数据，包括CPU、内存、磁盘、网络、中断、电源等。6）监测数据来源：a) /proc：是由内核创建的一个在内存中运行的文件系统，其中包含很多目录，其中以进程ID命名的目录代表的就是那个进程。进程级别的统计数据包括：limits、maps、sched、schedstat、smaps、stat、statm、status、fd、cgroup和task。系统级别的统计数据包括：cpuinfo、diskstats、interrupts、loadavg、meminfo、net/dev、net/netstat、net/tcp、pressure、schedstat、self、slabinfo、stat和zoneinfo。b) /sys：原本是用于提供设备驱动统计数据的，但现在已经扩展到提供所有类型的统计数据，例如CPU信息和CPU缓存信息。c) 延时核算。其中包括：1）调度器延时：等待CPU执行；2）块IO：等待块IO完成；3）交换：等待页面交换（内存压力）；4）内存回收：等待内存回收例程执行。d) netlink：使用netlink工具包括：ip、ss、routel、ifconfig、netstat等。e) tracepoint：是一个基于静态检测的Linux内核事件源，是硬编码的检测点，放置在内核代码的逻辑位置。大约有2000多个检测点，其中大约有600个是用于检测系统调用的。f) kprobes：是一个基于动态检测的Linux内核事件源，可以跟踪任何内核函数和指令。g) uprobes：类似于kprobes，但是用于用户空间。可以动态检测应用程序和库中的函数。h) USDT：用户级静态定义跟踪，是用户空间版本的tracepoint。i) 硬件计数器：处理器和其他设备通常有硬件计数器用于观测活动。处理器上这类硬件计数器通常被称为性能监测计数器（PMC）。PMC是性能分析的一个重要资源，可以测量CPU缓存命中率、内核和设备总线使用率、互联使用率、失速周期等等。-------------------------------------云和恩墨 分布式存储团队 张洋回复:暂时没写大佬，有博客吗

#### [技术博客：Monitoring and Tuning the Linux Networking St @蚁工厂](https://weibo.com/2194035935/MxdQbgsol)

Note: 技术博客：Monitoring and Tuning the Linux Networking Stack监视和调整 Linux 网络堆栈，有两篇：接收数据：发送数据：Linux 网络栈很复杂。如果不深入了解到底发生了什么，就不可能监控或调整它（或任何其他复杂的软件）。通常，在 Internet 上，您可能会偶然发现一个示例 sysctl.conf ，其中包含一组应复制并粘贴到您的计算机上的 sysctl 值。这可能不是优化网络堆栈的最佳方式。监控网络堆栈需要仔细计算每一层的网络数据。从驱动程序开始并继续进行。这样您就可以确定丢包和错误发生的确切位置，然后调整设置以确定如何减少您看到的错误。

#### [【PaConvert：代码转换工具，能自动将其它深度学习框架训练或推理的代码，转换为PaddlePa @爱可可-爱生活](https://weibo.com/1402400261/MxdQBtQzW)

Note: 【PaConvert：代码转换工具，能自动将其它深度学习框架训练或推理的代码，转换为PaddlePaddle的代码，方便代码迁移】'PaConvert - Code Convert to PaddlePaddle Toolkit' PaddlePaddle GitHub: github.com/PaddlePaddle/PaConvert   

Picture: [5396ee05ly1hbzb9alvqgj21by0o2dsy.jpg](https://weibo.cn//mblog/pic/MxdQBtQzW?rl=1)

Github: [github.com/PaddlePaddle/PaConvert](https://github.com/PaddlePaddle/PaConvert)

#### [转个AI新闻：斯坦福微调了 7B LLaMA 模型，只用了 52K 的数据，达到了和达芬奇003类似 @宝玉xp](https://weibo.com/1727858283/MxcHnDMnr)

Note: 转个AI新闻：斯坦福微调了 7B LLaMA 模型，只用了 52K 的数据，达到了和达芬奇003类似的效果，并且可以跑在消费级设备上，比如树莓派。Web Demo：🔗 github.com/tatsu-lab/stanford_alpacaby orange.ai🐦 twitter.com/oran_ge/status/1635413279786012673🧵而且这个模型没有经过道德训练，也就是会乱说触犯各国人类禁忌的话。以后人手一个自己的本地语言模型，审查彻底的失灵。这个模型对硬件的低要求也说明中国半导体产业是完全可以靠自研来支撑国产AI的这个模型叫羊驼🦙文本大模型的 stable diffusion 一个大生态的开始训练成本奇低。数据生成过程产生 52K 条独特指令和相应的输出，使用 OpenAI API 的成本不到 500 美元。在 8 个 80GB A100 上微调一个 7B LLaMA 模型需要 3 个小时，这对大多数云计算提供商来说成本不到 100 美元。7B LLaMA不支持中文。欢迎安装体验国产6B版本Chat模型。项目已在github上开源。可以在消费级显卡上进行本地部署的ChatGLM-6B模型（INT4 量化级别下最低只需 6GB 显存）使用了和 ChatGPT 相似的技术，针对中文问答和对话进行了优化。仓库里是训练数据，和生成训练数据的代码，也挺够意思的了。仓库里是训练数据，和生成训练数据的代码，也挺够意思的了。我看量子位的文章说要等hugginface支持llama模型才会开源模型，现在github上这个不知道是啥esp32也能玩？？7B LLaMA不支持中文。欢迎安装体验国产6B版本Chat模型。项目已在github上开源。可以在消费级显卡上进行本地部署的ChatGLM-6B模型（INT4 量化级别下最低只需 6GB 显存）使用了和 ChatGPT 相似的技术，针对中文问答和对话进行了优化。Repost

Picture: [66fd066bgy1hbz66kiaigj21y6aggkjr.jpg](https://weibo.cn//mblog/pic/MxcHnDMnr?rl=1)

Github: [github.com/tatsu-lab/stanford_alpacaby](https://github.com/tatsu-lab/stanford_alpacaby)

#### [【RecStudio：基于 PyTorch 的高度模块化的高效推荐算法库】'RecStudio -  @爱可可-爱生活](https://weibo.com/1402400261/Mxnqgjge2)

Note: 【RecStudio：基于 PyTorch 的高度模块化的高效推荐算法库】'RecStudio - A highly-modularized and recommendation-efficient recommendation library based on PyTorch.' ustcml GitHub: github.com/ustcml/RecStudio  

Picture: [5396ee05ly1hc0hikg3gej20sm0lx11d.jpg](https://weibo.cn//mblog/pic/Mxnqgjge2?rl=1)

Github: [github.com/ustcml/RecStudio](https://github.com/ustcml/RecStudio)

#### [【SpeeQ：Python自动语音识别框架】’SpeeQ - A framework for aut @爱可可-爱生活](https://weibo.com/1402400261/MxnqQ4Efe)

Note: 【SpeeQ：Python自动语音识别框架】’SpeeQ - A framework for automatic speech recognition' Mahmoud Salhab GitHub: github.com/msalhab96/SpeeQ  

Picture: [5396ee05ly1hc0hkhjr2cj21bk0egjz5.jpg](https://weibo.cn//mblog/pic/MxnqQ4Efe?rl=1)

Github: [github.com/msalhab96/SpeeQ](https://github.com/msalhab96/SpeeQ)

#### [Midjourney V5  已经发布了，产出的图片效果真的惊艳，尤其是让人吐槽的AI不会画手的问题 @宝玉xp](https://weibo.com/1727858283/MxtSzfaLc)

Note: Midjourney V5  已经发布了，产出的图片效果真的惊艳，尤其是让人吐槽的AI不会画手的问题已经得到了极大改善！很多图已经很难分辨是AI画的还是人画的或者是照片。 AI绘画的一小步，人类的一大步。转发微博回复:我后悔了，V5超强哈哈哈哈哈，V4的风格太单一了，V5即使写不好提示词综合能力也强于V4，看我输入的“cat” 回复: 怪不得还是Alpha[老师好]亲测V5 alpha不太适合新手，需要写很长的精确控制才能出效果

Picture: [66fd066bgy1hc19yvfo04j235s0oeala.jpg](https://weibo.cn//mblog/pic/MxtSzfaLc?rl=1)

#### [推荐阅读：《Ultra fast ControlNet with 🧨 Diffusers》Stabl @宝玉xp](https://weibo.com/1727858283/MxrNnkWWV)

Note: 推荐阅读：《Ultra fast ControlNet with 🧨 Diffusers》Stable Diffusion生成图片一个最大问题就是你很难控制结果，ControlNet的诞生很大程度的解决了这个问题，可以让用户根据关键点、草图、分割图等来调节生成的结果。比如将卡通画转换成逼真的照片，或者用它作为室内设计师。此外，您还可以将涂鸦草图变成艺术绘画，甚至让一些著名的标志栩栩如生。另外文中提供了Colab链接，你可以直接通过Google Colab测试运行。图二，🐱的眼神太可爱了

Picture: [66fd066bgy1hc10o3pthij20vbcn1u12.jpg](https://weibo.cn//mblog/pic/MxrNnkWWV?rl=1)

#### [Operating System development tutorials in Rust on  @蚁工厂](https://weibo.com/2194035935/MxuZVz0yN)

Note: Operating System development tutorials in Rust on the Raspberry Pi树莓派上的Rust操作系统开发教程地址：github.com/rust-embedded/rust-raspberrypi-OS-tutorials本教程适用于刚接触 ARM 的 64 位 ARMv8-A 架构的业余操作系统开发人员。教程将逐步指导如何从头开始为 embedded system 编写单体操作系统 kernel 。它们涵盖常见操作系统任务的实现，例如写入串行控制台、设置虚拟内存和处理硬件异常。同时利用 Rust 的独特功能来提供安全性和速度。回复:吃灰派成了理财派好东西树莓派啥时候降价呐[苦涩] 

Picture: [82c654dfly1hc1eykwjjzj20xk18g1kx.jpg](https://weibo.cn//mblog/pic/MxuZVz0yN?rl=1)

Github: [github.com/rust-embedded/rust-raspberrypi-OS-tutorials](https://github.com/rust-embedded/rust-raspberrypi-OS-tutorials)

#### [电子书《数据结构与算法：Rust语言描述》作者电子科技大学梦寰地址：github.com/QMHTM @敖天羽](https://weibo.com/1888981347/MxP34vMFd)

Note: 电子书《数据结构与算法：Rust语言描述》作者电子科技大学梦寰地址：github.com/QMHTMY/RustBook一本 Rust 书籍，有简体和繁体版（英文版和日文版正在撰写中）。内容包括算法分析，基本数据结构和算法，外加一些实战。共有九章，其目录如下。    第一章：计算机科学        计算机科学        Rust 回顾及学习资源    第二章：算法分析        性能分析：大 O 分析法    第三章：基本数据结构        栈、队列、双端队列、链表、Vec    第四章：递归        递归三定律、尾递归、动态规划    第五章：查找        顺序查找、二分查找、哈希查找    第六章：排序        十大排序算法    第七章：树        二叉树、二叉堆、二叉查找树、平衡二叉树    第八章：图        图的表示、广度优先、深度优先、最短路径    第九章：实战        编辑距离、字典树、过滤器、缓存淘汰        一致性哈希、Base58编码、区块链

Picture: [82c654dfly1h0drb1f6y3j20iw0u576i.jpg](https://weibo.cn//mblog/pic/LkgOHdsN9?rl=1)

Github: [github.com/QMHTMY/RustBook](https://github.com/QMHTMY/RustBook)

#### [这周真是密集型的AI产品发布。-Stanford Alpaca 7B（LLaMA模型的微调）-GPT @蚁工厂](https://weibo.com/2194035935/MxEvdpkoT)

Note: 这周真是密集型的AI产品发布。-Stanford Alpaca 7B（LLaMA模型的微调）-GPT4-Claude（ChatGPT的一个竞品）-ChatGLM-6B（清华大学的开源双语对话语言模型）-Google的PaLM API-Pytorch 2.0-MidjourneyV5 （AI绘图）-文心一言-Microsoft 365 Copilot 文心遗言利好英伟达奇迹年代回复:微软和OpenAI还和AMD合作呢，AMD不考虑一下回复:没法改了回复:已经全仓英伟达利好英伟达满清入关 南明们纷纷说自己牛逼结果文心遗言爆发了这周真是密集型的AI产品发布。 -Stanford Alpaca 7B（LLaMA模型的微调） -GPT4 -Claude（ChatGPT的一个竞品） -ChatGLM-6B（清华大学的开源双语对话语言模型） -Google的PaLM API -Pytorch 2.0 -MidjourneyV5 （AI绘图） -文心一言 -Microsoft 365 Copilot   

#### ['nanoT5 (Encoder-Decoder / Pre-training + Fine-Tun @爱可可-爱生活](https://weibo.com/1402400261/MxG0PsAXq)

Note: 'nanoT5 (Encoder-Decoder / Pre-training + Fine-Tuning) - Fast & Simple repository for pre-training and fine-tuning T5-style models' Piotr Nawrot GitHub: github.com/PiotrNawrot/nanoT5  这个已经是牛夫人啦

Picture: [5396ee05ly1hc2rlgerz8j20w00m1477.jpg](https://weibo.cn//mblog/pic/MxG0PsAXq?rl=1)

Github: [github.com/PiotrNawrot/nanoT5](https://github.com/PiotrNawrot/nanoT5)

#### [【MiniLLM: 在消费级GPU上运行现代 LLM 的最小化系统，支持 LLAMA, BLOOM, @爱可可-爱生活](https://weibo.com/1402400261/MxG2JFpjU)

Note: 【MiniLLM: 在消费级GPU上运行现代 LLM 的最小化系统，支持 LLAMA, BLOOM, OPT 等】’🦜 MiniLLM: Large Language Models on Consumer GPUs - MiniLLM is a minimal system for running modern LLMs on consumer-grade GPUs' Volodymyr Kuleshov GitHub: github.com/kuleshov/minillm 实现指令还行，要推理就不行了  

Picture: [5396ee05ly1hc2rpghgp0j21bg0rs4bx.jpg](https://weibo.cn//mblog/pic/MxG2JFpjU?rl=1)

Github: [github.com/kuleshov/minillm](https://github.com/kuleshov/minillm)

#### [【PromptLib：为大型语言模型(尤其是 GPT-4和 ChatGPT 的早期模型)提供精确的新 @爱可可-爱生活](https://weibo.com/1402400261/MxG6t0BQi)

Note: 【PromptLib：为大型语言模型(尤其是 GPT-4和 ChatGPT 的早期模型)提供精确的新的和/或异常的提示的集合】'PromptLib - A collection of prompts for use with GPT-4 via ChatGPT, OpenAI API w/ Gradio frontend & notebook' Josh Pazmino GitHub: github.com/jmpaz/promptlib  

Picture: [5396ee05ly1hc2ry3b375j21nz16e7rd.jpg](https://weibo.cn//mblog/pic/MxG6t0BQi?rl=1)

Github: [github.com/jmpaz/promptlib](https://github.com/jmpaz/promptlib)

#### [【Knowledge：开源的个人书签搜索引擎，内建知识图谱】’Knowledge - Open-so @爱可可-爱生活](https://weibo.com/1402400261/MxJn4msW8)

Note: 【Knowledge：开源的个人书签搜索引擎，内建知识图谱】’Knowledge - Open-source personal bookmarks search engine' Raphael Sourty GitHub: github.com/raphaelsty/knowledge  [开学季]　  马

Github: [github.com/raphaelsty/knowledge](https://github.com/raphaelsty/knowledge)

#### [【BuildFlow：统一的批处理和流框架，可将任何 Python 函数转换为可伸缩的数据管道】'B @爱可可-爱生活](https://weibo.com/1402400261/MxQx1sChR)

Note: 【BuildFlow：统一的批处理和流框架，可将任何 Python 函数转换为可伸缩的数据管道】'BuildFlow - a unified batch and streaming framework that turns any python function into a scalable data pipeline.' launchflow GitHub: github.com/launchflow/buildflow  这个不错

Picture: [5396ee05ly1hc420uhg0dj21b00wkndf.jpg](https://weibo.cn//mblog/pic/MxQx1sChR?rl=1)

Github: [github.com/launchflow/buildflow](https://github.com/launchflow/buildflow)

#### [开源项目推荐：ChatGPT资料汇总学习🔗 github.com/dalinvip/Awesome- @宝玉xp](https://weibo.com/1727858283/MxWsWwm1E)

Note: 开源项目推荐：ChatGPT资料汇总学习🔗 github.com/dalinvip/Awesome-ChatGPT里面有不少不错的资料新闻时讯【时讯】Google发布Bard与ChatGPT竞争【时讯】重磅，微软发布 ChatGPT 版搜索引擎，用上了比 ChatGPT 更强大的技术【时讯】今天，微软重新发明搜索引擎：首款ChatGPT搜索来了【时讯】见证历史：ChatGPT版搜索引擎登场，12个新体验太震撼了【央视网】实测“山寨”ChatGPT：费用挺高，答案离谱【CCTV4】ChatGPT狂飙！科技巨头纷纷布局【机器之心】微软ChatGPT版必应被黑掉了，全部Prompt泄露【复旦大学】资讯｜复旦团队发布国内首个类ChatGPT模型MOSS，邀公众参与内测论文【OpenAI官方网站】ChatGPT Blog【ChatGPTPro】ChatGPTPro【GPT-1论文】Improving Language Understanding by Generative Pre-Training【GPT-2论文】Language Models are Unsupervised Multitask Learners【GPT-3论文】Language Models are Few-Shot Learners【InstructGPT论文】Training language models to follow instructions with human feedback【RHLF论文】Augmenting Reinforcement Learning with Human Feedback【RHLF相关论文12篇】RHLF论文集【PPO算法论文】Proximal Policy Optimization Algorithms【Sparrow】Improving alignment of dialogue agents via targeted human judgements【LaMda】LaMDA: Language Models for Dialog Applications三方代码实现【代码实现】 ColossalAI hpcaitech/ColossalAI/ChatGPT , 👍 如何使用可参考:博客介绍CLICK ME(点我查看全部)【代码实现】 ColossalAI hpcaitech/ColossalAI/ChatGPT , 👍 如何使用可参考:博客介绍资料【PDF资料】ChatGPT-真格基金分享.pdf【PDF资料】腾讯研究院AIGC发展趋势报告2023.pdf【PDF资料】从CHAT_GPT到生成式AI（Generative AI）：人工智能新范式，重新定义生产力.pdf【PDF资料】ChatGPT - 开启AI新纪元.pdf【PDF资料】ChatGPT研究框架【PDF资料】ChatGPT研究框架2023.pdf【PDF资料】AIGC行业深度报告-ChatGPT-重新定义搜索“入口”.pdf【PDF资料】三分钟看懂ChatGPT.pdf【PDF资料】从ChatGPT到通用智能新长征上的新变化.pdf【PDF资料】像ChatGPT这样的工具如何改变你的企业.pdf【PDF资料】揭秘ChatGPT身后的AIGC技术和它的中国同行们.pdf【PDF资料】ChatGPT_Prompts_使用场景.pdf【PDF资料】ChatGPT过去现在与未来.pdf技术解读【技术解读】huggingface解读 Illustrating Reinforcement Learning from Human Feedback (RLHF)【技术解读】ChatGPT发展历程、原理、技术架构详解和产业未来 （收录于先进AI技术深度解读）【技术解读】ChatGPT内核：InstructGPT，基于反馈指令的PPO强化学习【技术解读】HuggingFace-解读 ChatGPT 背后的技术重点：RLHF、IFT、CoT、红蓝对抗【技术解读】从零实现ChatGPT——RLHF技术笔记【技术解读】张俊林-通向AGI之路：大型语言模型（LLM）技术精要【技术解读】ChatGPT/InstructGPT详解【技术解读】 赛尔笔记 | 浅析ChatGPT的原理及应用【技术解读】抱抱脸：ChatGPT背后的算法——RLHF | 附12篇RLHF必刷论文(论文在上面资料中)【技术解读】ChatGPT背后人工智能算法全部由国外公司发明【技术解读】万字拆解！追溯ChatGPT各项能力的起源【技术解读】拆解追溯 GPT-3.5 各项能力的起源【技术解读】ChatGPT出来后，我们是否真的面临范式转变?【技术解读】腾讯技术工程|万字长文教你如何做出 ChatGPT视频讲解【李宏毅】ChatGPT (可能)是怎麼煉成的 - GPT 社會化的過程【陈縕侬】深度學習之應用 | ADL 17.3: OpenAI ChatGPT 驚驗眾人的對話互動式AI【李沐】InstructGPT 论文精读【论文精读·48】CLICK ME(点我查看全部)【李宏毅】ChatGPT (可能)是怎麼煉成的 - GPT 社會化的過程【陈縕侬】深度學習之應用 | ADL 17.3: OpenAI ChatGPT 驚驗眾人的對話互動式AI【李沐】InstructGPT 论文精读【论文精读·48】【油管】chatgpt基本工作原理简单清晰介绍中文ChatGPT【复旦大学】资讯｜复旦团队发布国内首个类ChatGPT模型MOSS，邀公众参与内测【复旦Moss】【复旦Moss Github】github.com/txsun1997/MOSSCLICK ME(点我查看全部)Github-ChatGPT【Github】在微信上迅速接入 ChatGPT，让它成为你最好的助手！【Github】Reverse Engineered ChatGPT API by OpenAI. Extensible for chatbots etc.【github】This is a collection of prompt examples to be used with the ChatGPT model.【Github】ChatGPT Desktop Application (Mac, Windows and Linux)【Github】ChatGPT 中文调教指南【Github】Node.js client for the unofficial ChatGPT API.【Github】几步即可获得一个基于 ChatGPT 的微信机器人【Github】ChatGPT for Google【Github】Curated list of resources for ChatGPT and GPT-3 from OpenAI【Github】OpenAI ChatGPT 的逆向工程SDK。直接使用网页最新ChatGPT。【Github】ChatGPT Android demonstrates OpenAI's ChatGPT on Android with Stream Chat SDK for Compose.【Github】ChatGPT Extension for VSCode【Github】ChatGPT Desktop App【Github】PyChatGPT【Github】OpenAI Teams Bot app 收藏

Github: [github.com/dalinvip/Awesome-ChatGPT](https://github.com/dalinvip/Awesome-ChatGPT)

Github: [github.com/txsun1997/MOSSCLICK](https://github.com/txsun1997/MOSSCLICK)

#### [Rust死灵书（《The Rustonomicon》：）的中文翻译版：，翻译者应该在字节从事Rust @蚁工厂](https://weibo.com/2194035935/MxY0Mm7J5)

Note: Rust死灵书（《The Rustonomicon》：）的中文翻译版：，翻译者应该在字节从事Rust基础架构工作。 

#### [【面向Vision/Speech/Robotic的大型语言模型相关资源列表】’Awesome-Col @爱可可-爱生活](https://weibo.com/1402400261/MxZXS9vM8)

Note: 【面向Vision/Speech/Robotic的大型语言模型相关资源列表】’Awesome-Colorful Large Language Model - Learn the colorful world (Vision/Speech/Robotic) from LLM' Yuxuan Wang GitHub: github.com/patrick-tssn/Awesome-Colorful-LLM  

Picture: [5396ee05ly1hc57oizqq9j21740u6aik.jpg](https://weibo.cn//mblog/pic/MxZXS9vM8?rl=1)

Github: [github.com/patrick-tssn/Awesome-Colorful-LLM](https://github.com/patrick-tssn/Awesome-Colorful-LLM)

#### [【one-glm：将 GLM 模型改成 OneFlow 后端运行， 获得大幅度的训练速度提升】’on @爱可可-爱生活](https://weibo.com/1402400261/My0h0AF9m)

Note: 【one-glm：将 GLM 模型改成 OneFlow 后端运行， 获得大幅度的训练速度提升】’one-glm - A more efficient GLM implementation!' OneFlow GitHub: github.com/Oneflow-Inc/one-glm  

Picture: [5396ee05ly1hc59139d1bj20oi0fmwgn.jpg](https://weibo.cn//mblog/pic/My0h0AF9m?rl=1)

Github: [github.com/Oneflow-Inc/one-glm](https://github.com/Oneflow-Inc/one-glm)

#### [【PCSeg: 开源 PyTorch 点云分割工具箱】'PCSeg: Open Source Poi @爱可可-爱生活](https://weibo.com/1402400261/My04gqSwL)

Note: 【PCSeg: 开源 PyTorch 点云分割工具箱】'PCSeg: Open Source Point Cloud Segmentation Toolbox and Benchmark' PJLab-ADG GitHub: github.com/PJLab-ADG/PCSeg  

Picture: [5396ee05ly1hc584co0u7j21660g6qek.jpg](https://weibo.cn//mblog/pic/My04gqSwL?rl=1)

Github: [github.com/PJLab-ADG/PCSeg](https://github.com/PJLab-ADG/PCSeg)

#### [【提示上下文学习相关资源列表】’Awesome resources for in-context l @爱可可-爱生活](https://weibo.com/1402400261/My0XfwlOX)

Note: 【提示上下文学习相关资源列表】’Awesome resources for in-context learning and prompt engineering: Mastery of the LLMs such as ChatGPT, GPT-3, and FlanT5, with up-to-date and cutting-edge updates.' EgoAlpha GitHub: github.com/EgoAlpha/prompt-in-context-learning  [2023]

Picture: [5396ee05ly1hc5c1xz0vdj21c216ukaf.jpg](https://weibo.cn//mblog/pic/My0XfwlOX?rl=1)

Github: [github.com/EgoAlpha/prompt-in-context-learning](https://github.com/EgoAlpha/prompt-in-context-learning)

#### ['llamacpp-python - Python bindings for llama.cpp'  @爱可可-爱生活](https://weibo.com/1402400261/My8mheUYQ)

Note: 'llamacpp-python - Python bindings for llama.cpp' Thomas Antony GitHub: github.com/thomasantony/llamacpp-python   

Github: [github.com/thomasantony/llamacpp-python](https://github.com/thomasantony/llamacpp-python)

#### [【3DTrans: 轻量简单的开源代码库，用于探索面向无人驾驶的迁移学习技术】'3DTrans: A @爱可可-爱生活](https://weibo.com/1402400261/My8ycBl9Q)

Note: 【3DTrans: 轻量简单的开源代码库，用于探索面向无人驾驶的迁移学习技术】'3DTrans: Autonomous Driving Transfer Learning Codebase - An open-source codebase for exploring the Autonomous Driving-oriented Transfer Learning Techniques' PJLab-ADG GitHub: github.com/PJLab-ADG/3DTrans 码住

Picture: [5396ee05ly1hc69kmhszgj21bm0k6gw1.jpg](https://weibo.cn//mblog/pic/My8ycBl9Q?rl=1)

Github: [github.com/PJLab-ADG/3DTrans](https://github.com/PJLab-ADG/3DTrans)

#### [《高性能并行编程与优化 - 课件》地址：github.com/parallel101/course教 @蚁工厂](https://weibo.com/2194035935/MyfqiclaW)

Note: 《高性能并行编程与优化 - 课件》地址：github.com/parallel101/course教学视频在b站“双笙子佯谬”频道。课程分为前半段和后半段，前半段主要介绍现代 C++，后半段主要介绍并行编程与优化。课程大纲如下：1.课程安排与开发环境搭建：cmake与git入门2.现代C++入门：常用STL容器，RAII内存管理3.现代C++进阶：模板元编程与函数式编程4.编译器如何自动优化：从汇编角度看C++5.C++11起的多线程编程：从mutex到无锁并行6.并行编程常用框架：OpenMP与Intel TBB7.被忽视的访存优化：内存带宽与cpu缓存机制8.GPU专题：wrap调度，共享内存，barrier9.并行算法实战：reduce，scan，矩阵乘法等10.存储大规模三维数据的关键：稀疏数据结构11.物理仿真实战：邻居搜索表实现pbf流体求解12.C++在ZENO中的工程实践：从primitive说起13.结业典礼：总结所学知识与优秀作业点评

Picture: [82c654dfly1h0h7nrc2p6j21m90u0wol.jpg](https://weibo.cn//mblog/pic/LkIEAubz3?rl=1)

Github: [github.com/parallel101/course](https://github.com/parallel101/course)

#### [《机器学习系统：设计和实现》本开源项目试图给读者讲解现代机器学习系统的设计原理和实现经验。在线阅读地 @蚁工厂](https://weibo.com/2194035935/MypLn4WZd)

Note: 《机器学习系统：设计和实现》本开源项目试图给读者讲解现代机器学习系统的设计原理和实现经验。在线阅读地址：openmlsys.github.io/现代机器学习框架具有复杂的内部架构和繁多的外部相关组件。在本书中，我们将对其细致拆分，深入解读 这么些日子走过来只有 让我佩服，综合实力非常强，边学边交易，平易近人的朋友谁不喜欢呢？，可以关注一起见证！

Picture: [82c654dfly1h0iconvq0xj20gh1i3wh2.jpg](https://weibo.cn//mblog/pic/LkRQChJvj?rl=1)

#### [刚不是分享了个PDF么  ，微博不支持上传PDF，但是能上传图片，不过最多18张。这个PDF有45页 @宝玉xp](https://weibo.com/1727858283/MyBE4cGeI)

Note: 刚不是分享了个PDF么  ，微博不支持上传PDF，但是能上传图片，不过最多18张。这个PDF有45页，明显不够发的，不过4页合并成一张刚好。但没有工具支持这样的需求，我就打开Cursor  ，给它一个prompt（大意）：Write a function to convert all the pages of a pdf to images, and merge every 4 images to 1 image with 2 rows and 2 colums.于是Cursor就帮我生成了一坨代码，一运行出错，错误信息扔给它，原来是没有装poppler，pdf2image需要poppler，按照提示安装了，在运行就好了。后来最后一张图只有1页，留白太多，Edit修改了一下最终成型，前后估计一二十分钟就搞定了。gist.github.com/JimLiu/a5e75557b639ca3eebb83f448ba26e49卧槽。。我惊呆了。。。牛的。。。 其实你这个流程可以做个简单的视频录屏。。。 真的。求录屏。。我那天让chatgpt给我写一个豆瓣爬虫.写的像模像样的.注释齐全..(可能)是豆瓣改版.页面都访问了.数据没爬到....再丢进cursor改一改.就可以用了..总共也就15分钟吧..现在demo或者临时用的脚本基本都不自己写了牛逼了请问代码输出到一半被截断的问题是怎么解决的呢？输入“继续”不管用呢。真的解放生产力cursor才0.13而已还支持Python？我咋记得只支持react用中文不行嘛现在demo或者临时用的脚本基本都不自己写了

Picture: [66fd066bgy1hc9tz9xmt8j2134150x00.jpg](https://weibo.cn//mblog/pic/MyBE4cGeI?rl=1)

Github: [github.com/JimLiu/a5e75557b639ca3eebb83f448ba26e49](https://github.com/JimLiu/a5e75557b639ca3eebb83f448ba26e49)

#### [训练 LLM 需要多少 GPU？假设您使用的是带有 FULL_SHARD 激活检查点的 FSDP，而 @宝玉xp](https://weibo.com/1727858283/Myx9P28EI)

Note: 训练 LLM 需要多少 GPU？假设您使用的是带有 FULL_SHARD 激活检查点的 FSDP，而不是 cpu_offload ，那么一个好的经验法则是：以 GB 为单位的集群总内存应该大于 16 * N（#billions of params）。要训练具有约 130 亿个参数的 GPT-13B 模型，GPU 的总内存至少为 16 * 13 = 208 GB。可以使用 8xA100-40GB 或 4xA100-80GB 等来完成此操作。🔗 github.com/mosaicml/examples/tree/main/examples/llm#how-many-gpus-do-i-need-to-train-a-llm

Picture: [66fd066bgy1hc99y25uwzj20xc0go79t.jpg](https://weibo.cn//mblog/pic/Myx9P28EI?rl=1)

Github: [github.com/mosaicml/examples/tree/main/examples/llm](https://github.com/mosaicml/examples/tree/main/examples/llm)

#### [【Imath：C++ 和 Python 库，用于计算机图形学中的 2D 和 3D 向量、矩阵和数学运 @爱可可-爱生活](https://weibo.com/1402400261/MyAEEbdHg)

Note: 【Imath：C++ 和 Python 库，用于计算机图形学中的 2D 和 3D 向量、矩阵和数学运算，包含了许多用于计算机图形学的数学函数，如向量、矩阵、四元数、平面、线、球、矩形、框、插值、随机数、颜色空间转换等】'Imath - Imath is a C++ and python library of 2D and 3D vector, matrix, and math operations for computer graphics' Academy Software Foundation GitHub: github.com/AcademySoftwareFoundation/Imath 转发微博

Picture: [5396ee05ly1hc9pmz88etj21bs0cwjxe.jpg](https://weibo.cn//mblog/pic/MyAEEbdHg?rl=1)

Github: [github.com/AcademySoftwareFoundation/Imath](https://github.com/AcademySoftwareFoundation/Imath)

#### [【SpTr: 快速且内存高效的PyTorch空间稀疏Transformer 库】'SpTr: PyT @爱可可-爱生活](https://weibo.com/1402400261/MyAQuu3SQ)

Note: 【SpTr: 快速且内存高效的PyTorch空间稀疏Transformer 库】'SpTr: PyTorch Spatially Sparse Transformer Library - A fast and memory-efficient libarary for sparse transformer with varying token numbers (e.g., 3D point cloud).' DV Lab GitHub: github.com/dvlab-research/SparseTransformer 

Picture: [5396ee05ly1hc9qftozw9j219s0em7cb.jpg](https://weibo.cn//mblog/pic/MyAQuu3SQ?rl=1)

Github: [github.com/dvlab-research/SparseTransformer](https://github.com/dvlab-research/SparseTransformer)

#### [【edge-tts：在Python程序里调用Edge的文本语音合成服务】’edge-tts - Us @爱可可-爱生活](https://weibo.com/1402400261/MyAYEDyAW)

Note: 【edge-tts：在Python程序里调用Edge的文本语音合成服务】’edge-tts - Use Microsoft Edge's online text-to-speech service from Python (without needing Microsoft Edge/Windows or an API key)' rany GitHub: github.com/rany2/edge-tts  mark这个库还不错，“实现听书自由”，自然人声，我写了个教程在b站

Picture: [5396ee05ly1hc9r30j6ckj21bk0ms453.jpg](https://weibo.cn//mblog/pic/MyAYEDyAW?rl=1)

Github: [github.com/rany2/edge-tts](https://github.com/rany2/edge-tts)

#### [勘误，之前说的发票OCR  不是用的ORC技术，而是donut，一种采用非OCR方式的文档识别Tra @宝玉xp](https://weibo.com/1727858283/MyTRC47NM)

Note: 勘误，之前说的发票OCR  不是用的ORC技术，而是donut，一种采用非OCR方式的文档识别Transformer技术，性能和效果远超OCR技术，连表格都能识别。🔗 github.com/clovaai/donutCSDN有篇文章有详细的介绍： 

Picture: [66fd066bgy1hcc1fzwc3dj233213y7wh.jpg](https://weibo.cn//mblog/pic/MyTEM311Z?rl=1)

Github: [github.com/clovaai/donutCSDN](https://github.com/clovaai/donutCSDN)

#### [【Computer Programming Course Skill Generator - Tur @敖天羽](https://weibo.com/1888981347/MyXomfXt2)

Note: 【Computer Programming Course Skill Generator - Turbocharge Your Skills with AI】 计算机编程课程技能生成器 - 用 AI 提升你的技能。不同的排列组合，可以生成的课程多达几百种。a. 5个经验级别：   Beginner   Novoice   Intermediate   Advanced   Expertb. 知识领域   Web开发   移动开发   数据科学   游戏开发   人工智能   网络安全   嵌入式系统   云计算   软件工程   编程语言   机器人技术   区块链   操作系统   联网技术   硬件   项目管理   设计   开发运维c. 每个知识领域的子领域。像极了游戏里的真技能树//:转发微博

Picture: [663aa05agy1hcchx5qtsgj20u015ldin.jpg](https://weibo.cn//mblog/pic/MyXmYCEAQ?rl=1)

#### [【Awesome GPT-4：关于 GPT-4语言模型的工具和资源大列表】'Awesome GPT- @爱可可-爱生活](https://weibo.com/1402400261/MyCV4g7tw)

Note: 【Awesome GPT-4：关于 GPT-4语言模型的工具和资源大列表】'Awesome GPT-4 - A curated list of tools and resources regarding the GPT-4 language model.' radi-cho GitHub: github.com/radi-cho/awesome-gpt4  Awesome

Picture: [5396ee05ly1hc9znnv006j211y0zgna1.jpg](https://weibo.cn//mblog/pic/MyCV4g7tw?rl=1)

Github: [github.com/radi-cho/awesome-gpt4](https://github.com/radi-cho/awesome-gpt4)

#### [微软发布的MM-REACT：一种将 ChatGPT 与视觉专家库集成以实现多模态推理和行动的系统范式 @蚁工厂](https://weibo.com/2194035935/MyCRhnjHK)

Note: 微软发布的MM-REACT：一种将 ChatGPT 与视觉专家库集成以实现多模态推理和行动的系统范式。项目地址：github.com/microsoft/MM-REACT论文：arxiv.org/abs/2303.11381 

Picture: [82c654dfly1hc9ze4m4ibj21o50wc7kp.jpg](https://weibo.cn//mblog/pic/MyCRhnjHK?rl=1)

Github: [github.com/microsoft/MM-REACT](https://github.com/microsoft/MM-REACT)

#### [嗯  之前 哥分享的 GPT embedding search 到ChatGPT 集成的标准化例子  @宝玉xp](https://weibo.com/1727858283/MzhsFn5k7)

Note: 嗯  之前 哥分享的 GPT embedding search 到ChatGPT 集成的标准化例子 我这边咨询也遇到了。 客户反馈 把搜到的文章放到 system context 然后让机器人就此回答 超纲的问题就回答不知道 结果机器人口无遮拦什么都对答如流。 我建议他把文章篇幅缩减到原来的1/3 就在共享屏幕里操作 马上机器人就不幻觉了。我推测因为篇幅过长 涉及到的领域也就不断增加 回答作用域就会在不知不觉中扩张因为客户在system context里面也没有很清晰的引用符号 文章内容中近似命令的话语也可能引发幻觉。建议包括1 减小 embedding 的分割，以一个语义自然段或者多个同问题的自然段为一个条目 避免大量数据堆到chat的系统上下文2 设置类似 ``` 或者json的表示引用的对应作用域符号 防止内容中的类似逻辑语句干扰3 在输出到用户之前加一层过滤 发现不正确的内容马上中止相应 并且代替用户和 agent说你不带说这个词儿，你再考虑一下回答 当然也可以用 completion 把上下文发一次 收尾一下就断开 比较省tokens4 使用额外的post prompt 偏方   

#### [【ChatGPT Memory：利用GPT和Redis数据存储，实现了无限上下文和自适应记忆功能，能 @爱可可-爱生活](https://weibo.com/1402400261/Mz4t4iwPu)

Note: 【ChatGPT Memory：利用GPT和Redis数据存储，实现了无限上下文和自适应记忆功能，能将ChatGPT API扩展到支持多个并发会话】'ChatGPT Memory - Allows to scale the ChatGPT API to multiple simultaneous sessions with infinite contextual and adaptive memory powered by GPT and Redis datastore.' Continuum LLMsGitHub: github.com/continuum-llms/chatgpt-memory 这个是真的牛有点费token我注册了一些账号，可以直接用，免去注册的麻烦。或者注册chat需要短信验证的也可以找我，帮你收验证码。现在推出了国内版，直接进，不用安全上网也能用。如果有什么不懂，都可以问。需要的可以看下第一条动态！回复:是吧mark !有点费token

Picture: [5396ee05ly1hcdd87zi6wj20gh0d3wgj.jpg](https://weibo.cn//mblog/pic/Mz4t4iwPu?rl=1)

Github: [github.com/continuum-llms/chatgpt-memory](https://github.com/continuum-llms/chatgpt-memory)

#### ['ChatGLM-6B-Slim：裁减掉20K图片Token的ChatGLM-6B，完全一样的性能， @爱可可-爱生活](https://weibo.com/1402400261/Mz4Tjhj5l)

Note: 'ChatGLM-6B-Slim：裁减掉20K图片Token的ChatGLM-6B，完全一样的性能，占用更小的显存' Silver GitHub: github.com/silverriver/ChatGLM-6B-Slim  回复:预留给多模态的太期待开源 gpt 的爆发了，感觉复制出一个数字自己指日可待图片token？

Picture: [5396ee05ly1hcdf578239j21ba0m8k7d.jpg](https://weibo.cn//mblog/pic/Mz4Tjhj5l?rl=1)

Github: [github.com/silverriver/ChatGLM-6B-Slim](https://github.com/silverriver/ChatGLM-6B-Slim)

#### [【Efficient Alpaca：基于LLaMA实现的开源项目，旨在通过微调 LLaMA-7B模型 @爱可可-爱生活](https://weibo.com/1402400261/Mz4R55uuJ)

Note: 【Efficient Alpaca：基于LLaMA实现的开源项目，旨在通过微调 LLaMA-7B模型在资源消耗更少、推理速度更快、更适合研究者使用方面提高Stanford Alpaca的性能】'Efficient Alpaca - The aim of this repository is to utilize LLaMA to reproduce and enhance the Stanford Alpaca' dropreg GitHub: github.com/dropreg/efficient_alpaca  [开学季]转发微博

Picture: [5396ee05ly1hcdexj02bkj21bk0wiarv.jpg](https://weibo.cn//mblog/pic/Mz4R55uuJ?rl=1)

Github: [github.com/dropreg/efficient_alpaca](https://github.com/dropreg/efficient_alpaca)

#### [《性能之巅 第2版》读书笔记（第6章上）1、正在等待和准备运行的软件线程数量是一个重要的指标，它可以 @小川CD](https://weibo.com/1202332555/Mz5CTnwon)

Note: 《性能之巅 第2版》读书笔记（第6章上）1、正在等待和准备运行的软件线程数量是一个重要的指标，它可以反映CPU的工作负载。当线程需要等待CPU运行时，这段时间也被称为运行队列延迟或者分发器队列延迟，而书中称之为调度器延迟。2、内核通常为每个CPU提供一个运行队列，并且尽可能让线程始终在同一个队列中运行，这种保持CPU亲和性的方法。在NUMA系统中，为每个CPU配备一个单独的运行队列可以提高内存本地性，使线程在同一个内存节点中运行，从而提高系统性能。3、每条指令周期数（CPI）是一个重要指标。一条指令通常包含几个步骤：指令预取、指令解码、执行、内存访问和寄存器回写。其中，内存访问是最慢的，通常需要数十个时钟周期读或写主存。在此期间，CPU将陷入停滞（这些周期被称为停滞周期）。这也是缓存对CPU性能至关重要的原因。4、指令流水线是一种CPU架构，它可以同时执行多个指令，通过同时执行不同指令的不同部分来实现。指令流水线可以将一条指令分解为多个简单的步骤，使其可以并发执行。这些步骤通常被称为处理器后端执行的微操作，具体实现取决于处理器。5、现代处理器支持乱序执行，但条件分支指令会导致预测错误，从而影响性能。处理器使用分支预测技术来优化这个问题，但是预测错误会导致指令流水线中的进度丢失。程序员可以通过插入提示信息来提高预测的准确性，例如在Linux内核代码中定义的likely和unlikely。6、CPU执行用户软件所花费的时间称为用户时间，而执行内核级软件所花费的时间称为内核时间。内核时间包括系统调用、内核线程和中断时间。计算密集型应用程序的用户时间和内核时间比例通常为99/1，而IO密集型应用程序的用户时间和内核时间比例可能达到70/30，因为它们执行了许多系统调用。7、当CPU被100%使用时，被称为饱和状态。在这种情况下，线程会遇到调度器延迟，因为它们需要等待一段时间才能在CPU上运行，这会降低总体性能。这种等待时间是指线程等待CPU运行队列或其他管理线程的数据结构所花费的时间。8、Intel处理器定义了处理器性能状态（P状态）和处理器电源状态（C状态）。P状态通过在正常执行中变换CPU频率以提供不同级别的性能。C状态通过提供不同的空闲状态，指执行停止期间节约耗能。C0表示正常执行，C1或更高级别表示空闲状态，数字越高，状态越深。简单来说，C1以上级别的CPU恢复执行需要一些时间。9、内核可能被缓存在不同处理器的多个CPU中。当一个CPU修改了数据时，所有缓存都需要知道它们的缓存拷贝已经失效，应该被丢弃。这会导致一个副作用，即LLC（最后一级缓存）访问延迟。LLC命中，缓存行未共享：约40个CPU周期；LLC命中，缓存行与另一个核共享：约65个CPU周期；LLC命中，缓存行被另一个核修改：约75个CPU周期。10、MMU负责虚拟地址到物理地址的转换。它在内存中维护一个页表，用于虚拟地址转换。TLB又称为转译存储缓冲区，相当于是页表的缓存。通常页面大小是4KB，通过使用大页（2MB），可以减少TLB和页表中维护的数据，从而减少TLB miss。11、多处理器架构中，处理器可以通过共享系统总线或专用互联进行连接，例如Intel的QPI、UPI、AMD的HT、ARM的CoreLink以及IBM的CAPI。UPI的带宽可以高达40GB/s，互联通常设计为高带宽，使其不成为瓶颈。但一旦成为瓶颈，涉及到互联的CPU指令可能会陷入停滞，如远程内存访问。IPC下降是此类情况的关键迹象。12、在NUMA系统中，使内核能感知NUMA架构可以极大提高性能，因为这样可以做出更好的调度和内存分配决策。系统可以自动监测并创建本地化的CPU和内存资源组，按照NUMA架构的拓扑结构组织起来。这种结构可以预估内存访问的开销。13、一些处理器和操作系统可以感知可纠正错误（ECC），并在无法纠正错误引起CPU故障之前将CPU下线作为预防措施。14、在实现了CPU限制或配额（资源控制、tasksets和cgroups）的环境中，CPU需要按照这些限制进行检查，而不仅仅是物理限制。可能会在物理CPU达到100%之前就用完了配额，比预期更早达到饱和。15、CPU负载的基本属性包括：CPU平均负载（使用率+饱和度）、用户时间与系统时间之比、系统调用频率、自愿上下文切换频率、中断频率。还需要检查其他指标，例如：遇到了什么类型的停滞周期？CPU互联的使用率是多少？中断的CPU用量是多少？等等。十分专业

#### [偶然间读到了 Firefox 团队写的这篇《Web 浏览器简史》。三言两语，横跨历史，从上帝视角俯视 @敖天羽](https://weibo.com/1888981347/MzJAKBPCq)

Note: 偶然间读到了 Firefox 团队写的这篇《Web 浏览器简史》。三言两语，横跨历史，从上帝视角俯视道出了 Web 浏览器的发展进程以及变革历史，看来团队内部有文案高手啊。 

Picture: [006fiYtfgy1hch52xnqbaj31344k0kjn.jpg](https://weibo.cn//mblog/pic/MzzgAp0Jf?rl=1)

#### [【Hugging Face的Transformers课程资料：为 Jax、PyTorch 和 Ten @爱可可-爱生活](https://weibo.com/1402400261/Mzcg681u5)

Note: 【Hugging Face的Transformers课程资料：为 Jax、PyTorch 和 TensorFlow 打造的先进的自然语言处理】'typical-sampling - Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.' Hugging Face GitHub: github.com/cimeister/typical-sampling  买入的时机是股票投资中最重要一环。没有只涨不跌的行情，也没有只跌不涨的行情。跟着中公603860一周吃到4个多板，稳中求胜，长期复利的特性深深吸引了我

Picture: [5396ee05ly1hcebmzmrqrj21mi10aaz9.jpg](https://weibo.cn//mblog/pic/Mzcg681u5?rl=1)

Github: [github.com/cimeister/typical-sampling](https://github.com/cimeister/typical-sampling)

#### ['LLaMA retrieval plugin - LLaMa retrieval plugin s @爱可可-爱生活](https://weibo.com/1402400261/Mzcq21W5d)

Note: 'LLaMA retrieval plugin - LLaMa retrieval plugin script using OpenAI's retrieval plugin' lastmile-ai GitHub: github.com/lastmile-ai/llama-retrieval-plugin  小白坐等应用到ChatGLM6B[送花花]不过本地向量数据库我也不会弄，还得等傻瓜包

Picture: [5396ee05ly1hcecd8evbpj21b20lw4ai.jpg](https://weibo.cn//mblog/pic/Mzcq21W5d?rl=1)

Github: [github.com/lastmile-ai/llama-retrieval-plugin](https://github.com/lastmile-ai/llama-retrieval-plugin)

#### [Serge - LLaMa made easy。Serge这个项目提供了一个基于 llama.cpp @蚁工厂](https://weibo.com/2194035935/MzfruyPFO)

Note: Serge - LLaMa made easy。Serge这个项目提供了一个基于 llama.cpp 的运行 Alpaca 模型的聊天界面并用docker封装，可以一键部署了。 运行至少需要4.5GB内存。 开源地址：github.com/nsarrazin/serge  llama对中文不好，中文目前开源的最好的是chatglm试了llama，hallucination还是太严重了

Github: [github.com/nsarrazin/serge](https://github.com/nsarrazin/serge)

#### [：GPT4AllGPT for All字面意思就是为所有人都能用的GPT，这是一个在Facebook @宝玉xp](https://weibo.com/1727858283/Mzush2csW)

Note: ：GPT4AllGPT for All字面意思就是为所有人都能用的GPT，这是一个在Facebook之前开源的LLaMa 基础上用 约80万 GPT-3.5-Turbo 生成的干净的助理数据集合上训练的聊天机器人，包括代码、故事和对话。我在本地测试了一下，运行速度还可以，中文支持不行，还遇到个死循环，英文的质量也一般。想在本地上跑GPT暂时可能还不行，但应该也不会太遥远！另外作者也分享了数据训练的过程，有兴趣的可以去测试一下🔗 github.com/nomic-ai/gpt4all用 约80万 GPT-3.5-Turbo 生成的干净的助理数据集——-。这个指的是什么方式获取的数据集啊？回复:谢谢大佬，我研究研究。//人人都能运行GPT，联想到去中心化的GPT联盟，配合区块链算力，合约等支撑，形成反对中心化AI，形成不同AI之间的算计模型大战，这个项目有王多鱼投么回复:那给你推荐清华这个：github.com/THUDM/ChatGLM-6B一直想找个开源的适合中文训练的模型

Github: [github.com/nomic-ai/gpt4all](https://github.com/nomic-ai/gpt4all)

Github: [github.com/THUDM/ChatGLM-6B](https://github.com/THUDM/ChatGLM-6B)

#### [推荐李沫老师的最新视频：《GPT-4论文精读【论文精读·53】》文字版可以参考以前我发过的 回复:回 @宝玉xp](https://weibo.com/1727858283/MzO6LkHdj)

Note: 推荐李沫老师的最新视频：《GPT-4论文精读【论文精读·53】》文字版可以参考以前我发过的 回复:回复:没建议，我还愁自己孩子选专业的事呢宝老师，就按照现在的科技发展趋势，如果对现在的初高中生，未来上大学选专业来说，你有什么建议，谢谢

#### [GitHub 上的开源项目：CodeCursor，你可以利用这个插件将 Cursor 快速集成到 V @GitHubDaily](https://weibo.com/5722964389/MzgfrmwMm)

Note: GitHub 上的开源项目：CodeCursor，你可以利用这个插件将 Cursor 快速集成到 VSCode 上。Cursor 代码编辑器介绍：GitHub：github.com/Helixform/CodeCursor  转发微博

Picture: [006fiYtfgy1hcel9xs52cj31210fh10u.jpg](https://weibo.cn//mblog/pic/MzgfrmwMm?rl=1)

Github: [github.com/Helixform/CodeCursor](https://github.com/Helixform/CodeCursor)

#### [OPENFLAMINGO：一个用于通过上下文学习训练视觉语言模型的开源框架，也是DeepMind 的 @蚁工厂](https://weibo.com/2194035935/MztmedhDZ)

Note: OPENFLAMINGO：一个用于通过上下文学习训练视觉语言模型的开源框架，也是DeepMind 的 Flamingo 模型的开源复制品。 OpenFlamingo 的核心是一个支持大型多模态模型 (LMM) 训练和评估的框架。地址：github.com/mlfoundations/open_flamingo在此存储库中，提供了用于训练和评估 OpenFlamingo 模型的 PyTorch 实现。还提供了在新的多模式 C4 数据集（即将推出）上训练的初始 OpenFlamingo 9B 模型。

Picture: [82c654dfly1hcgf4kfle8j220s18ue35.jpg](https://weibo.cn//mblog/pic/MztmedhDZ?rl=1)

Github: [github.com/mlfoundations/open_flamingo](https://github.com/mlfoundations/open_flamingo)

#### [Cerebras-GPT：一系列开放的、计算高效的大型语言模型Cerebras 开源了七个 GPT- @蚁工厂](https://weibo.com/2194035935/MztM0yl0g)

Note: Cerebras-GPT：一系列开放的、计算高效的大型语言模型Cerebras 开源了七个 GPT-3 模型，参数从 1.11 亿到 130 亿。这些模型使用 Chinchilla 公式进行训练，为准确性和计算效率设定了新的基准。 Cerebras-GPT 与迄今为止的任何公开可用模型相比，训练时间更快、训练成本更低，并且消耗的能量更少。这些系统在Andromeda AI 超级计算机上训练。😴硬件公司也下场干模型了么

Picture: [82c654dfly1hcggzgfrv7j22lg176keg.jpg](https://weibo.cn//mblog/pic/MztM0yl0g?rl=1)

#### [：openai-cookbook如果你想做OpenAI相关的开发，除了OpenAI的官方文档，还有它 @宝玉xp](https://weibo.com/1727858283/MzRXQ5LJY)

Note: ：openai-cookbook如果你想做OpenAI相关的开发，除了OpenAI的官方文档，还有它官方的Cookbook也值得好好看看，里面有各种指南和实例。API使用如何处理使用频率限制如何计算tokens用量如何使用streamChatGPT指南：如何与大语言模型一起工作指南：提高可高兴如何用多步prompt写单元测试文本写作实例文本解释实例文本编辑实例撰写代码实例代码编辑实例代码解释实例Embedding文本比较实例如何获取Embedding如何使用Embedding回答问题使用Embedding的语义搜索使用Embedding的技术建议聚类Embedding在2D或者3D中实现Embedding的可视化对长文本EmbeddingFine-tuning微调 GPT-3指南：对GPT-3进行微调对文本进行分类的最佳实践微调后的分类DALL-E如何用DALL-E生成和编辑图像Apps基于文件的问答网络抓取问题与解答微软Azure的替代API如何用Azure OpenAI使用ChatGPT如何从Azure OpenAI获得完成度如何从Azure OpenAI获得嵌入物如何用Azure OpenAI对GPT-3进行微调🔗 github.com/openai/openai-cookbook谢谢分享，准备找个时间阅读。24k star,恐怖如斯转发微博

Github: [github.com/openai/openai-cookbook](https://github.com/openai/openai-cookbook)

#### [强烈推荐一下这期播客：【大白话系列 #3】大白话聊 ChatGPT（Sarah & 王建硕）Sara @宝玉xp](https://weibo.com/1727858283/MzS42wNcb)

Note: 强烈推荐一下这期播客：【大白话系列 #3】大白话聊 ChatGPT（Sarah & 王建硕）Sarah提的问题非常好，王建硕特别善于用简单的比喻让你明白复杂的道理。比如说关于Fine-Tuning和Embedding，王建硕是这么比喻的：“预训练就有点像你家里面请了一个阿姨，这个阿姨从保洁公司送到你家里面的时候，她其实已经过预训练了。也就意味着保洁公司已经把如何打扫的这一些做家政的基础的工作，都已经帮你，她已经学会了。所以阿姨来了以后，我不用教她怎么拖地，怎么干什么。甚至于在她进到宝洁公司之前，她也经过她的小学老师预训练过汉语了。这样阿姨到我家里面来说，我需要对它进行 fine tune，就是微调，告诉它说我家里面什么地方，你怎么打扫什么东西，怎么摆放。其实可能有 2 个小时的微调，我就可以把阿姨调整到和我家里面的习惯一模一样了，所以这个成本就非常低。但是如果要是不是用预训练加微调这种模型，你给我一个空白的阿姨，不会讲话，不会讲中文，什么都不会，跟一个 2 岁的 1 岁的娃娃，或者像一个刚出生的宝宝给我。我要从教它这是苹果，那是橘子，教它汉语，直到教到它会有家政，基本上 15 年过去了，对吧。所以用这个例子，我觉得也是 ChatGPT，它帮你培训好了一个模型，这个通用模型包括基础的语言，它的所有的语言，我们现在所知道它都会那么几十种语言。它会一些基础基本的逻辑和一些基本的事实。比如它知道苹果甜的，铅球就是重的，苹果是水果的一部分等等这些的知识它都是有的，但是它没有特定知识。比如你要问它我们公司的年假制度是什么，ChatGPT 肯定不知道。所以我需要把这个模型拿过来以后把我的员工手册灌给它，把我的公司产品介绍灌给它，所有的规章制度灌给它，它一下就可以用它的流利的汉语或者西班牙语或者土耳其语，对我的内容把它解释出来。所以这就是预训练跟加上微调的好处。所以这种模式不仅仅在 ChatGPT 领域，在很多的比如绘画等等这些领域，它都是一个被预训练好的模型，有的甚至都可以直接用了，有的阿姨可能我什么都不用跟她说，她可能就直接用了，也可以再加一些的微调就可以了。”“embedding，就是 嵌入，就是 1536 维的向量的本地搜索等等。因为这个部分我们甚至都没有做微调，而仅仅是在本地建个数据库。相类比的话，就是阿姨来了，你就跟她讲了半天，其实她听进去了，你可以知道你改变了阿姨的脑结构里面的某一些的脑细胞的回路、神经元的连接，你稍微改了改，对吧？我把它叫做 Fine-Tuning。但是我甚至对阿姨有另外一种用法，来了以后，我也不让她改任何东西，甚至于她的神经元我一点都不改。只不过每个水壶旁边贴这个纸，上面写着水壶，应该怎么操作，而且它也不需要记住，因为记住就改变了。她不需要记住，她每次用水壶的时候就看了以后并且理解，操作完了以后就忘。其实我们现在用的是这种模式，把整个世界它所遇到的世界都贴满了这样的纸，而不需要去改变 1750 亿的参数中间的任何的参数。所以这两种方式都是可以做的。只不过我们现在暂时的选择的技术线路是用了到处贴纸的方式，而不是去改它的脑回路的这种方式。”还有它将的怎么让ChatGPT能报时的例子也很好玩：“所以这里面也在这里透露一个天大的秘密。很多人都想不明白，为什么我们的机器人，你问它几点了？它说现在是晚上 8:29。别人说这不科学呀，一个 2021 年训练的数据不再更新的模型怎么可能知道现在几点了？感觉跟变魔术一样。我把遮的这块布给它掀开了以后，其实很简单，我们你再问现在几点了，但实际上面我们给 ChatGPT 的 API 打过去的是这样的一句话，不是现在是几点了，而是现在是 20:29，请问现在是几点了？哈哈哈，OK，这就是一个我们的魔术的，如果你从背后来看……”还有关于为什么ChatGPT会胡说八道：“你知道 transformer 一个很重要的东西是，它的整个模型里面有两大部分，一个叫做 encoder，一个叫 decoder，就是编码器和解码器。你给它一个 apple 以后，它在内部会把它给 encode 成 1536 维的一个向量， 1536 个数字。这一堆数字就代表了在它训练模型里面苹果的含义。你还可以把任何一个数字可以把它再给重新给 decode 成文字。但是 decode 成文字的时候，你可以给它各种各样的指令了。比如我要把它用西班牙语 decode，它就会把同样的这 1536 维把它 decode 成 manzana。如果你说用英文，它就会 decode 成apple。这是一个 decode 过程，而 decode 过程它是还可以接着要求你要 decode 多长，多长了以后它会慢慢添油加醋，就越来越添油加醋。比如你要 decode 成十个字，它不但会 decode 成苹果，它会 decode 一个红扑扑的苹果。如果要是你让它 decode 成 1000 个字，它也可以添油加醋的把这 1000 个字都给你 decode 出来。所以你会看到我们的现在 GPT 的机器人很多的时候胡说八道的原因，因为它就是一个向量，就是 1536 维的一个向量。但是它会在解码的时候解码出很多的东西，但解码的过程中间，当向量的信息不足的时候，它会补全。所以整个的输入加上 encoder 变成向量，再通过 decoder 再输出的整个过程，我们把它叫做 transformer 变换器。这就是 ChatGPT 后面的三个字母的来源。....但是有一个好处是说，如果是 640* 640 的是一只猫， 8* 8 可能有点过分，但 64* 64 的你肯定还能看得出来它是只猫。但是它的尾巴上面的细节的每一个汗毛的，每一个毛发的那些细节肯定全丢失了，但是你可以看到它是只猫。这就是 encoder 干的事情，也就是 ChatGPT 怎么可以把 45T 的 data 全给压缩到了一个 175 个 billion（参数）的？这是其实巨大的压缩比。压缩完了以后，这个时候你让它生成的时候，它其实是把 64* 64 的小图片，再把它扩充到 640* 640 的时候，它只能往里面添油加醋了。对，它还是一只猫。但是它添油加醋的时候，好在它有太多的猫的这样的记忆，所以它就可以按照它的想象去画一只猫。这只猫和刚开始那只猫肯定是大差不差，但是不是同一只猫了。这也就是我们看到 ChatGPT 经常性地把很多，大家可以试一试，你给它一个 500 字的文章，让它帮你做个 summary 做总结，让它写出三条，它就给你写出三条的总结，你觉得总结的真的很好。然后你说你把这三条的总结再给它展成 500 字，它也还给你展成 500 字。对，你会发现这两个 500 字神似，因为它都是那三条。所谓的 64* 64 的核心是没变的，但是它的形不似。因为把 500 字给缩成，比如三句话，大概 30 个字，再展成 500 字，这个过程一定是丢失了大量的信息，又补充了大量的信息，它肯定不会是一样的。但整个过程我觉得特别形象的。所以我觉得这一篇它的那篇文章，可以是我看到的对于 ChatGPT 的原理描述最好的一篇文章，特别喜欢。”还是推荐大家听一下音频：文字稿：请问是怎么持续获得这么多高质量的关于AI的内容的呢，信息来源是哪呢，不如授人以渔所以老师有这方面的训练攻略吗？感谢博主，这段时间跟着学了好多东西收藏了有音频文件的话可以用开源的whisper转录回复: 1536 dimensions，向量维度。“The new embeddings have only 1536 dimensions, one-eighth the size of davinci-001 embeddings, making the new embeddings more cost effective in working with vector databases.” 1536是什么？回复:up主快成贾维斯了转发微博讲得很好！有点意思，不过感觉未来展望太乐观了，要我预测的话就是跟现代互联网发展一样，先开始都是比较正常比较友好，渐渐的牛鬼蛇神就都出来了。。。回复 的赞:感谢支持 回复 的赞:握手 

#### [：document.ai基于向量数据库与GPT3.5的通用本地知识库方案。如果你想搭建自己的AI智能 @宝玉xp](https://weibo.com/1727858283/MzUcXdQsM)

Note: ：document.ai基于向量数据库与GPT3.5的通用本地知识库方案。如果你想搭建自己的AI智能知识库系统  ，可以参考或者直接使用这套系统，整个流程很清晰，并且向量转换部分还可以不使用OpenAI的Embedding方案，自己训练Embedding模型（Text2Vec  ）。🔗 github.com/GanymedeNil/document.ai有点难以安装为什gpt可以用Text2Vec 生成的向量？这要研究下。终于来了，现在是又想用又怕后期他API 升级太快 😂回复:我是开玩笑的。这几天从你这边学了好多东西。感谢！回复: 当然不是AI发，但是借助AI很多事情可以变得高效你太高产了，我开始怀疑你的帖子都是AI发的来回复:都类似这和 gpt4-pdf 那个项目，功能是不是类似？

Picture: [66fd066bgy1hcjplu36yej20wu0k10u6.jpg](https://weibo.cn//mblog/pic/MzUcXdQsM?rl=1)

Github: [github.com/GanymedeNil/document.ai](https://github.com/GanymedeNil/document.ai)

#### [转：彭博发文介绍BloombergGPT，依托自身海量金融数据，构建了一个3630亿个标签的数据集， @宝玉xp](https://weibo.com/1727858283/MzUhhzpQo)

Note: 转：彭博发文介绍BloombergGPT，依托自身海量金融数据，构建了一个3630亿个标签的数据集，基于通用和金融业务的场景进行了混合模型训练。彭博称其在金融任务上超过了现有的模型（信息理解、情感分析、标注、实体命名等），而在通用场景上的表现则与之相当甚至优于现有模型。 彭博应该构建自己的内容数据embedding数据库，然后使用最先进的gpt调用处理。毕竟新闻数据每天都更新。记忆部门和逻辑部门各有专注。

Picture: [66fd066bgy1hcjpzfp87mj20t4112qsp.jpg](https://weibo.cn//mblog/pic/MzUhhzpQo?rl=1)

#### [Stable Diffusion 3要来了，但对机器性能要求更高，2.5倍消耗。“Stable Di @宝玉xp](https://weibo.com/1727858283/MzUziekCJ)

Note: Stable Diffusion 3要来了，但对机器性能要求更高，2.5倍消耗。“Stable Diffusion XL (#SDXL) 正在与我们的合作伙伴和dreamstudio.ai进行测试，以获得数据并进行精细化调整，然后进行开源发布。该模型是一个23亿个参数的变体（原始模型为9亿参数），具有一系列的改进，这些改进将被用于 Stable Diffusion 3。”应该不支持nsfw了我的本GG了对云端党也要求更高吗Source?2.1都还没试呢

Picture: [66fd066bgy1hcjrab3q2xj20t21qs1kx.jpg](https://weibo.cn//mblog/pic/MzUziekCJ?rl=1)

#### [打扰了，我又忍不住安利翻译插件了，没办法，真的一个比一个好用 —— Immersive Transl @蚁工厂](https://weibo.com/2194035935/Mzx65AG7r)

Note: 打扰了，我又忍不住安利翻译插件了，没办法，真的一个比一个好用 —— Immersive Translate （沉浸式翻译）可以把所有网站一键转为双语中英对照（包括discord），甚至一键制作双语电子书▶ 下载地址：（Chrome插件）▶ 开发者：Owen（个人主页 ）不仅可以切换各种主流翻译API（当然也包括OpenAI），而且非常戳我的是可以自定义翻译样式（设计师职业病）真的推荐大家试试这种不用切来切去的非破坏性阅读。回复:国内用腾讯翻译快我去试用了感觉不太行（不确定是不是我的使用方法问题[苦涩]）。原因有两个，一是只能是全文翻译，没发现截取文段翻译的功能；二是翻译速度挺慢的，可能是全文翻译数据太多，也可能是选用了谷歌翻译？

Picture: [68c4467dly1hcgu63srufj211e0ujth9.jpg](https://weibo.cn//mblog/pic/MzwQNnQFu?rl=1)

#### [【ChatGLM-MNN：将模型ChatGLM-6B转换到MNN并使用C++进行推理】'ChatGL @爱可可-爱生活](https://weibo.com/1402400261/Mzxrp4sVo)

Note: 【ChatGLM-MNN：将模型ChatGLM-6B转换到MNN并使用C++进行推理】'ChatGLM-MNN - Pure C++, Easy Deploy ChatGLM-6B.' wangzhaode GitHub: github.com/wangzhaode/ChatGLM-MNN  这个的多轮对话能力不如6B，而且真的操作起来太难了

Picture: [5396ee05ly1hcgx6awfyjj21b20m2akd.jpg](https://weibo.cn//mblog/pic/Mzxrp4sVo?rl=1)

Github: [github.com/wangzhaode/ChatGLM-MNN](https://github.com/wangzhaode/ChatGLM-MNN)

#### ['OFA-Chinese：中文多模态统一预训练模型 - transformers结构的中文OFA模型 @爱可可-爱生活](https://weibo.com/1402400261/MzxxjsTEZ)

Note: 'OFA-Chinese：中文多模态统一预训练模型 - transformers结构的中文OFA模型' Yang JianXin GitHub: github.com/yangjianxin1/OFA-Chinese  

Picture: [5396ee05ly1hcgxlocbp9j21b615s1kx.jpg](https://weibo.cn//mblog/pic/MzxxjsTEZ?rl=1)

Github: [github.com/yangjianxin1/OFA-Chinese](https://github.com/yangjianxin1/OFA-Chinese)

#### [【Gut：跨平台的好用git客户端】’Gut - An easy-to-use git client @爱可可-爱生活](https://weibo.com/1402400261/MzObk92p1)

Note: 【Gut：跨平台的好用git客户端】’Gut - An easy-to-use git client for Windows, macOS, and Linux' Julien C GitHub: github.com/julien040/gut  

Picture: [5396ee05ly1hciz2t2pukj219w1cawqp.jpg](https://weibo.cn//mblog/pic/MzObk92p1?rl=1)

Github: [github.com/julien040/gut](https://github.com/julien040/gut)

#### [【CachedEmbedding：基于ColossalAI的软件缓存方法来动态管理 CPU 和 GP @爱可可-爱生活](https://weibo.com/1402400261/MzET34PWq)

Note: 【CachedEmbedding：基于ColossalAI的软件缓存方法来动态管理 CPU 和 GPU 内存空间中极大嵌入表的 PyTorch EmbeddingBag 的扩展，可以在单个 GPU 上为 Criteo 1TB 数据集训练包括 91.10 GB 嵌入表的 DLRM 模型，只分配 3.75 GB 的CUDA 内存】’CachedEmbedding - A memory efficient DLRM training solution using ColossalAI' HPC-AI Tech GitHub: github.com/hpcaitech/CachedEmbedding 尤老师团队工程能力也太强了

Picture: [5396ee05ly1hchu0go77gj20zk0bwdl9.jpg](https://weibo.cn//mblog/pic/MzET34PWq?rl=1)

Github: [github.com/hpcaitech/CachedEmbedding](https://github.com/hpcaitech/CachedEmbedding)

#### [【Fixie - 一个使用大型语言模型构建应用程序的平台，提供Python SDK，允许将LLM与任 @爱可可-爱生活](https://weibo.com/1402400261/MA08sBc9c)

Note: 【Fixie - 一个使用大型语言模型构建应用程序的平台，提供Python SDK，允许将LLM与任意API、工具和数据集成，通过组合，可以使用非常少的代码创建复杂的工作流】'Fixie - The LLM Application Platform - Open source SDK to the Fixie platform.' Fixie.ai GitHub: github.com/fixie-ai/fixie-sdk 

Picture: [5396ee05ly1hckfuhial3j21bc0ua11z.jpg](https://weibo.cn//mblog/pic/MA08sBc9c?rl=1)

Github: [github.com/fixie-ai/fixie-sdk](https://github.com/fixie-ai/fixie-sdk)

#### [【OrbStack：以快速、轻量、简单的方式，在macOS上运行Docker容器和Linux虚拟机， @爱可可-爱生活](https://weibo.com/1402400261/MA0e48rIE)

Note: 【OrbStack：以快速、轻量、简单的方式，在macOS上运行Docker容器和Linux虚拟机，可以把它看作是一个超级WLS和Docker桌面的简单易用的替代品】'OrbStack - Fast, light, simple Docker containers & Linux machines for macOS' GitHub: github.com/orbstack/orbstack  已经在用了

Picture: [5396ee05ly1hckg8z77n5j21au108tl5.jpg](https://weibo.cn//mblog/pic/MA0e48rIE?rl=1)

Github: [github.com/orbstack/orbstack](https://github.com/orbstack/orbstack)

#### [' ChatGenTitle：使用百万arXiv论文信息在LLaMA模型上进行微调的论文题目生成模型 @爱可可-爱生活](https://weibo.com/1402400261/MA7uX8R7q)

Note: ' ChatGenTitle：使用百万arXiv论文信息在LLaMA模型上进行微调的论文题目生成模型' WangRongsheng GitHub: github.com/WangRongsheng/ChatGenTitle  这个科研品味…

Picture: [5396ee05ly1hclcd50s4wj21bc0v24ch.jpg](https://weibo.cn//mblog/pic/MA7uX8R7q?rl=1)

Github: [github.com/WangRongsheng/ChatGenTitle](https://github.com/WangRongsheng/ChatGenTitle)

#### [【Awesome Twitter Algo：Twitter开源推荐算法注释和解析项目】’Awesom @爱可可-爱生活](https://weibo.com/1402400261/MA7DK6xHF)

Note: 【Awesome Twitter Algo：Twitter开源推荐算法注释和解析项目】’Awesome Twitter Algo - The release of the Twitter algorithm, annotated for recsys' Vicki Boykis GitHub: github.com/veekaybee/awesome-twitter-algo  Awesome

Picture: [5396ee05ly1hclcwovt1mj21b40lwqad.jpg](https://weibo.cn//mblog/pic/MA7DK6xHF?rl=1)

Github: [github.com/veekaybee/awesome-twitter-algo](https://github.com/veekaybee/awesome-twitter-algo)

#### [麻省理工学院（MIT）深度学习入门6.S191：第4讲 深度生成建模，讲师：Ava Amini，20 @网路冷眼](https://weibo.com/1715118170/MzTtV8J7b)

Note: 麻省理工学院（MIT）深度学习入门6.S191：第4讲 深度生成建模，讲师：Ava Amini，2023版 概要：- 深度生成建模的基础是构建系统，不仅可以在数据中寻找模式，还可以在此基础上生成全新的数据实例。这是一个复杂而强大的概念，是深度学习的一个子集，近几年来得到了爆炸性的发展。- 潜在变量模型的两个子类型- 自动编码器信息潜在空间：自动编码器及其变体VAEs- 如何使编码分布平滑，以避免过度分歧？- 重参数化和发散的概念是如下所述的。- 自动发现面部检测数据集底层的特征，并使用其来理解其中存在的潜在偏见。- GAN如何生成数据- 通过街景和航拍图像之间的转换来考虑如何在谷歌地图的数据中转换领域 [惊喜]

#### [最近 ChatGPT 非常火爆的哦！其实底层技术就是深度学习。分享两本相关的书给大家，一本是图灵的鱼 @网路冷眼](https://weibo.com/1715118170/MzVclqDBK)

Note: 最近 ChatGPT 非常火爆的哦！其实底层技术就是深度学习。分享两本相关的书给大家，一本是图灵的鱼书（图1右），手把手教学，非常适合入门；另一本是Open AI 当年的CTO（现在已经是大佬一枚，位极总裁兼董事长了）入门 AI 的秘籍，封面上画着一个苹果（图1左），很惊喜吧！想要快速入门AI，不妨来看看这两本书。 人工智能##学习笔记##机器学习##深度学习#《深度学习入门》《深入浅出神经网络与深度学习》 

Picture: [663aa05agy1hcjbqmc39jj21hc0omaz3.jpg](https://weibo.cn//mblog/pic/MzR3qnu1R?rl=1)

#### [【Llama.cpp 30B runs with only 6GB of RAM now】https @网路冷眼](https://weibo.com/1715118170/MzY9QtOnV)

Note: 【Llama.cpp 30B runs with only 6GB of RAM now】https:///github.com/ggerganov/llama.cpp/pull/613 现在，Llama.cpp的30B版本只需要6GB的RAM就可以运行。这是一项重大的变化，将给我们带来三个好处：       您的推断命令加载速度应该快100倍       您可能能够安全地加载2倍大的模型       您可以运行许多并发推断进程这是通过更改文件格式实现的，因此我们可以将权重直接mmap()到内存中，而不必读取（read()）或复制它们，从而确保内核可以直接使文件缓存页面可供我们的推断进程访问。其次，由于它们不再与通过吉字节的标准i/o创建的内存页面竞争，因此文件缓存页面更不太可能被驱逐出去（这将强制加载命中磁盘），由此能够获得更好的性能。新的文件格式支持像LLaMA 7b这样的单文件模型，也支持像LLaMA 13B这样的多文件模型。我们的Python工具现在将foo.1、foo.2等文件合并成一个单一文件，这样映射它的C++代码就不需要每次重新调整数据了。这使得llama.cpp变得简单得多。其中的大部分加载代码现在已被删除。此外，此更改确保张量在32字节边界上正确对齐。这为使用需要内存对齐的操作，探索在一些微处理器上获得额外性能提升的可能性打开了大门。最后请注意，POSIX和Windows平台都得到了支持。  

Picture: [663aa05agy1hck74mupohj20na0isacm.jpg](https://weibo.cn//mblog/pic/MzY9QtOnV?rl=1)

Github: [github.com/ggerganov/llama.cpp/pull/613](https://github.com/ggerganov/llama.cpp/pull/613)

#### [ColossalChat：基于LLaMA和ColossalAI的类ChatGPT开源应用。只需不到  @蚁工厂](https://weibo.com/2194035935/MzCMTnCFy)

Note: ColossalChat：基于LLaMA和ColossalAI的类ChatGPT开源应用。只需不到 10B 个参数，通过 RLHF 微调即可达到中英文双语能力。地址：github.com/hpcaitech/ColossalAI/tree/main/applications/Chat在线体验：chat.colossalai.org/ 回复:图片评论 回复:llama，，，请问现在有没有比较好用的自动编写java单元测试的ai，急需转发微博官方训练的这个模型就是智障好在可以直接体验[苦涩]和chatgpt3.5差距有点大，是由ai-gpt-3训练的

Picture: [82c654dfly1hchkrzhtoyj213017wtn9.jpg](https://weibo.cn//mblog/pic/MzCMTnCFy?rl=1)

Github: [github.com/hpcaitech/ColossalAI/tree/main/applications/Chat](https://github.com/hpcaitech/ColossalAI/tree/main/applications/Chat)

#### [👉终端是开发者日常使用最为频繁的工具之一，而 Rust 编程语言因其性能和内存安全而闻名，为了让终端 @蚁工厂](https://weibo.com/2194035935/MzDJkrugF)

Note: 👉终端是开发者日常使用最为频繁的工具之一，而 Rust 编程语言因其性能和内存安全而闻名，为了让终端与 Rust 结合，我们找到了这些 Rust 编写的替代品，能够替代那些你正在使用，且不是由 Rust 编写的命令行工具。🤩本篇给大家介绍几款 Rust 终端工具：● zoxide —— 更智能的 cd 命令● Starship —— 适用于任何 shell 的轻量、快速的提示符● tealdeer —— tldr 的 rust 实现● Dust-Rust —— Rust 版本的 du 命令● fd —— 使用 Rust 编写的 find 命令替代品● BAT Rust —— cat 命令的一个替代品● ripgrep —— 正则表达式搜索工具● exa —— ls 的现代替代品● Bottom —— 跨平台图形化进程监控器✍🏻更多 Rust 终端工具可长按识别上方二维码查看，也欢迎大家评论区补充~只用fish一个warp.dev足矣

#### [电子书《神经网络与深度学习》复旦大学邱锡鹏教授的《神经网络与深度学习》一书较全面地介绍了神经网络、机 @蚁工厂](https://weibo.com/2194035935/MA5k01WGP)

Note: 电子书《神经网络与深度学习》复旦大学邱锡鹏教授的《神经网络与深度学习》一书较全面地介绍了神经网络、机器学习和深度学习的基本概念、模型和方法，同时也涉及深度学习中许多最新进展．书后还提供了相关数学分支的简要介绍，以供读者需要时参考．本书的写作目的是使得读者能够掌握神经网络与深度学习技术的基本原理，知其然还要知其所以然项目地址：github.com/nndl/nndl.github.io （包含ppt）直接下载地址：nndl.github.io/nndl-book.pdf

Picture: [82c654dfly1h0v26z8jcvj20u00wnn0p.jpg](https://weibo.cn//mblog/pic/LmxtzsC6m?rl=1)

Github: [github.com/nndl/nndl.github.io](https://github.com/nndl/nndl.github.io)

#### [会议结束，寒风凄雨中坐轮渡从亚洲回欧洲。在船上聊得太high，错过了下船，又被拉回了原点。只得从原点 @于仕琪老师](https://weibo.com/1917002727/MAcFFEj3E)

Note: 会议结束，寒风凄雨中坐轮渡从亚洲回欧洲。在船上聊得太high，错过了下船，又被拉回了原点。只得从原点再选一条船回。花了几元钱，足足坐了两个小时，真是赚翻了只能狂吃一顿烤肉来安慰。  

Picture: [724323e7ly1hclz6x5hs4j20tz1sxn5m.jpg](https://weibo.cn//mblog/pic/MAcFFEj3E?rl=1)

#### ['基于本地知识的 ChatGLM 应用实现 - 利用 ChatGLM-6B + langchain  @爱可可-爱生活](https://weibo.com/1402400261/MAgzLeXeq)

Note: '基于本地知识的 ChatGLM 应用实现 - 利用 ChatGLM-6B + langchain 实现的基于本地知识的 ChatGLM 应用 langchain-ChatGLM, local knowledge based ChatGLM with langchain' imClumsyPanda GitHub: github.com/imClumsyPanda/langchain-ChatGLM  谢谢老师推荐🙏mark

Picture: [5396ee05ly1hcmgdywf87j21c00jmqbf.jpg](https://weibo.cn//mblog/pic/MAgzLeXeq?rl=1)

Github: [github.com/imClumsyPanda/langchain-ChatGLM](https://github.com/imClumsyPanda/langchain-ChatGLM)

#### ['LLaMA.MMEngine - Training LLaMA language model wi @爱可可-爱生活](https://weibo.com/1402400261/MAgBoA1EL)

Note: 'LLaMA.MMEngine - Training LLaMA language model with MMEngine! It supports LoRA fine-tuning!' RangiLyu GitHub: github.com/RangiLyu/llama.mmengine  

Picture: [5396ee05ly1hcmgkb5k9fj21aw0ngqb4.jpg](https://weibo.cn//mblog/pic/MAgBoA1EL?rl=1)

Github: [github.com/RangiLyu/llama.mmengine](https://github.com/RangiLyu/llama.mmengine)

#### [昨天看到一个骚操作，如何判断大语言模型调优AI的水平。拿几万个问题，挨个问。然后把几家AI的回答，一 @蚁工厂](https://weibo.com/2194035935/MAf0Na6Bk)

Note: 昨天看到一个骚操作，如何判断大语言模型调优AI的水平。拿几万个问题，挨个问。然后把几家AI的回答，一起扔给ChatGPT，让他选出几个答案中，答案质量最好的那个。最后统计哪家AI的答案被ChatGPT选中的次数多。 正常流程是，在网上或其它地方找到几百tb的数据，找几千个人，一条条给你标注，一年半截后你就有数据集了bard直呼内行什么知识蒸馏

#### [文章分享《3090单卡5小时，每个人都能训练专属ChatGPT，港科大开源LMFlow》该项目由香港 @蚁工厂](https://weibo.com/2194035935/MAe2xdv5X)

Note: 文章分享《3090单卡5小时，每个人都能训练专属ChatGPT，港科大开源LMFlow》该项目由香港科技大学统计和机器学习实验室团队发起，致力于建立一个全开放的大模型研究平台，支持有限机器资源下的各类实验，并且在平台上提升现有的数据利用方式和优化算法效率，让平台发展成一个比之前方法更高效的大模型训练系统。llama-7B + LoRA + int8训练10G显存完全够用，大家冲啊

#### [【awesome-instruction-tuning(ChatGPT|LLaMA)-dataset @爱可可-爱生活](https://weibo.com/1402400261/MArBf77ma)

Note: 【awesome-instruction-tuning(ChatGPT|LLaMA)-dataset：用于训练聊天大语言模型(ChatGPT、LLaMA、Alpaca等)的开源指令微调数据集大列表】’awesome-instruction-tuning(ChatGPT|LLaMA)-dataset - A collection of open-source dataset to train instruction-following LLMs (ChatGPT,LLaMA,Alpaca)' dongdong GitHub: github.com/yaodongC/awesome-instruction-dataset Awesomemark

Picture: [5396ee05ly1hcnt3zbkuyj21bq14awsh.jpg](https://weibo.cn//mblog/pic/MArBf77ma?rl=1)

Github: [github.com/yaodongC/awesome-instruction-dataset](https://github.com/yaodongC/awesome-instruction-dataset)

#### [【 2000元训练比肩ChatGPT的开源大模型，GPT-4亲自盖章认证，模型权重均可下载】2000 @数据派THU](https://weibo.com/6004911042/MAsV7oGMF)

Note: 【 2000元训练比肩ChatGPT的开源大模型，GPT-4亲自盖章认证，模型权重均可下载】2000块（300美元），调教出一个达到ChatGPT九成功力的开源大模型。还是被GPT-4亲自盖章认证实力的那种。这事儿，一群主要来自加州大学伯克利分校的研究人员做到了。这个模型名叫Vicuna （小羊驼）。没错，熟悉的配方，熟悉的味道。Vicuna同样是基于Meta开源的LLaMA大模型（大羊驼）微调而来。与此前斯坦福大学基于LLaMA的Alpaca（还是羊驼）不同的是，尽管也薅了ChatGPT羊毛——用了ChatGPT生成的数据，但Vicuna所用的数据来自ShareGPT，而不是直接用OpenAI的API生成。更为特别的是，这一次，研究人员直接请来GPT-4本尊，给新模型“打分”。他们还提到：相比于Alpaca-13B等模型，GPT-4在绝大多数问题上偏向于Vicuna。

Picture: [006Fd7o3ly1hcnnryncizj30u00eb0v0.jpg](https://weibo.cn//mblog/pic/MAqoc0nLx?rl=1)

#### [Meta刚刚发布了Segment Anything，一个新的人工智能抠图模型，可以在任何图像/视频中 @宝玉xp](https://weibo.com/1727858283/MADYAiYzi)

Note: Meta刚刚发布了Segment Anything，一个新的人工智能抠图模型，可以在任何图像/视频中把某个物体图像单独抠出来，只需点几下就可以完成。刚自己测试了一下，效果非常赞！官方网站：测试演示地址：源代码：github.com/facebookresearch/segment-anything论文： 如果实时性能可以 前景很多抠好的图片点哪下载呢nice和苹果那个有什么区别？垃圾meta以后视频的制作更多彩多样了meta是想用这个引诱用户帮他做图像语义训练吧？收藏

Github: [github.com/facebookresearch/segment-anything](https://github.com/facebookresearch/segment-anything)

#### [只用不到6GB内存跑300亿参数大模型，在Linux上实现，GitHub星1.8whttps :// @敖天羽](https://weibo.com/1888981347/MAQqC95wG)

Note: 只用不到6GB内存跑300亿参数大模型，在Linux上实现，GitHub星1.8whttps ://github.com/ggerganov/llama.cpp/discussions/638 

Picture: [006Fd7o3ly1hcmlh6ma1sj31aa0ka49u.jpg](https://weibo.cn//mblog/pic/MAhIuzk8p?rl=1)

Github: [github.com/ggerganov/llama.cpp/discussions/638](https://github.com/ggerganov/llama.cpp/discussions/638)

#### ['BLOOM-LORA - ow-Rank adaptation for various Instr @爱可可-爱生活](https://weibo.com/1402400261/MACe53fCc)

Note: 'BLOOM-LORA - ow-Rank adaptation for various Instruct-Tuning using Alpaca-LoRA and Alpaca_data_cleaned.json' Linh T. Duong GitHub: github.com/linhduongtuan/BLOOM-LORA    

Picture: [5396ee05ly1hcp413fqbuj218u16847i.jpg](https://weibo.cn//mblog/pic/MACe53fCc?rl=1)

Github: [github.com/linhduongtuan/BLOOM-LORA](https://github.com/linhduongtuan/BLOOM-LORA)

#### [DaVinci: A Scalable Architecture for Neural Networ @WinnieS的微博](https://weibo.com/2144454703/MAGZffLWT)

Note: DaVinci: A Scalable Architecture for Neural Network Computing 2019年hotchips的材料图1：这张算力与存储的不同应用分布图，现在看，也很有指导意义。做产品线规划，明明白白图2：在PPA的三维坐标系中寻找自己的定位（方法论，上分~~大公司才能有的广撒网视角）图3：scalar vs vector vs tensor 面积和性能的对比，好清楚图4图5：内核架构，三个不同配置图6：2019年在调bert图7：访存模式也是千差万别图8：这个开发者层次，倒是非常清晰图9： 编译器是一个重点图10：三层结构图11：汽车soc图12： AI inference soc图13： 训练 soc图14： 3D-SRAM+HBM图15：参数看起来还是不错 （面积控制得也好，不过图就不截了）图16：这个系统 2PF/6kW 比DGX V100 2PF/10KW，有竞争力图17：2048个node， 512P，鹏程实验室就是这个配置吧后面还要floorplan，NOC，还有310的die shot， 3DSRAM的Floorplan非常有深度的分享可惜了……可惜了，如果这两年一直迭代，说不定也没h100啥事了 

Picture: [7fd1c82fgy1hcpnlvpfddj214m0lngvs.jpg](https://weibo.cn//mblog/pic/MAGZffLWT?rl=1)

#### [可以在笔记本电脑上运行的大语言模型（ LLM ）游乐场。在线Demo地址： 特点：    使用 Op @网路冷眼](https://weibo.com/1715118170/MAHMFddRG)

Note: 可以在笔记本电脑上运行的大语言模型（ LLM ）游乐场。在线Demo地址： 特点：    使用 OpenAI、Anthropic、Cohere、Forefront、HuggingFace、Aleph Alpha 和 llama.cpp 中的任何模型。    完整的 Playground UI，包括历史记录、参数调整、键盘快捷键和日志属性。    可以在同一个提示下比较不同的模型，单独调整模型参数，并使用不同的参数重试。    自动检测您 HuggingFace 缓存中的本地模型，并允许您安装新的模型。    可以在手机上使用。🔗 https:///github.com/nat/openplayground 

Github: [github.com/nat/openplayground](https://github.com/nat/openplayground)

#### [如果稍微有些 TCP/IP socket 编程知识，想学怎么写稳定的通信程序，iperf的代码可以借 @蚁工厂](https://weibo.com/2194035935/MAIKFF0pK)

Note: 如果稍微有些 TCP/IP socket 编程知识，想学怎么写稳定的通信程序，iperf的代码可以借鉴一下，总的代码量不多，涉及到socket的很多方面。https:// gitee.com/tjopenlab/iperf_como_zmq 

#### [最新的TPU-4的论文题目有两个关键处： reconfigurable （光学的）， hardwar @WinnieS的微博](https://weibo.com/2144454703/MAQQSBnW0)

Note: 最新的TPU-4的论文题目有两个关键处： reconfigurable （光学的）， hardware support for embedding摘要： 1， Optical circuit switches 可以reconfigure interconnect topoloy， 比 IB各种好， 小于5%的系统成本， 3%的系统功耗。 （代价小，IB太贵了）2，SparseCores, dataflow processors加速依赖于embeddings 的模型，代价是5%的面积和功耗3，挑参照物的时候，比了Graphcore 和 Nvidia A100图3：这是一个架构师狂喜的年代图4：Optical Circuit Switching： 3D Micro-Electro-Mechanical Systems (MEMS)镜子技术， 在一个光纤里可以双向发送光线，因此端口和光纤数都减半。 （不算太理解，高科技镜子，是吧）图5：两个TC，每个TC有4个128x128 MXU 和VPU图6： 数据并行，模型并行，pipeline并行 （但是我感觉都是一回事么）图7：倒是明白embedding了图8： sparse core图9： TPUv4的具体参数回复:在云上？v4玩了半年多了，速度比a100 dgx略快hbm只贴了32g

Picture: [7fd1c82fgy1hcqtocx600j20zs0bkdpw.jpg](https://weibo.cn//mblog/pic/MAQQSBnW0?rl=1)

#### [麻省理工学院（MIT） Daniel J. Sturteva 的博士论文【System design @网路冷眼](https://weibo.com/1715118170/MAQVH4sEv)

Note: 麻省理工学院（MIT） Daniel J. Sturteva 的博士论文【System design and the cost of architectural complexity 】系统设计和架构复杂性的成本。PDF格式。摘要：“许多现代系统非常庞大，以至于没有人真正理解它们的工作原理。在工程界，众所周知，设计中应使用架构模式（包括层次结构、模块和抽象层），因为它们在控制复杂性方面起着重要作用。这些模式使系统更易于演变，并使其各个部分保持在人类理解的范围内，以便分布式团队可以独立操作，同时共同构建一个连贯的整体。本研究旨在衡量架构复杂性（由于层次结构或模块化的缺乏或破坏而在系统内部产生的复杂性）与开发组织所承担的各种成本之间的关联。在一家成功的软件公司内进行了一项研究。使用MacCormack、Baldwin和Rusnak最近开发的技术，对其产品的八个版本的架构复杂度进行了衡量。同时还测量了重要的成本驱动因素，包括缺陷密度、开发人员生产率和员工流失率。使用各种统计技术探讨了成本和复杂性之间的关系。在这个研究环境中，我们发现架构复杂度的差异可以解释生产率下降50%、缺陷密度增加三倍以及员工流失率增加一个数量级。使用本论文开发的技术，公司应该能够通过为降低生产率、增加缺陷密度和增加员工流动性分配货币价值来估计其复杂性的财务成本。因此，公司应该能够更准确地估计旨在改进架构的重构工作的潜在价值。”🔗 dspace.mit.edu/handle/1721.1/79551有用的书。

Picture: [663aa05aly1hcqwwp1ntvj20i40ngwgg.jpg](https://weibo.cn//mblog/pic/MAQVH4sEv?rl=1)

#### [【GPTCache : 为语言模型开发的语义缓存，可以优化 API 调用和响应时间】'GPTCach @爱可可-爱生活](https://weibo.com/1402400261/MARTAwg6q)

Note: 【GPTCache : 为语言模型开发的语义缓存，可以优化 API 调用和响应时间】'GPTCache : A Library for Creating Semantic Cache for LLM Queries - GPTCache is a library for creating semantic cache to store responses from LLM queries.' Zilliz GitHub: github.com/zilliztech/gptcache 很直接的思路啊，计算相似度，实时更新上下文

Picture: [5396ee05ly1hcr17bejt4j21pg114dmk.jpg](https://weibo.cn//mblog/pic/MARTAwg6q?rl=1)

Github: [github.com/zilliztech/gptcache](https://github.com/zilliztech/gptcache)

#### ['Firefly(流萤): 中文对话式大语言模型，使用指令微调（Instruction Tuning @爱可可-爱生活](https://weibo.com/1402400261/MARPm4dFS)

Note: 'Firefly(流萤): 中文对话式大语言模型，使用指令微调（Instruction Tuning）在中文数据集上进行调优' Yang JianXin GitHub: github.com/yangjianxin1/Firefly  金庸小说占比不低啊

Picture: [5396ee05ly1hcr0wc68msj21be0ysk8d.jpg](https://weibo.cn//mblog/pic/MARPm4dFS?rl=1)

Github: [github.com/yangjianxin1/Firefly](https://github.com/yangjianxin1/Firefly)

#### ['awesome-decentralized-llm - Collection of LLM res @爱可可-爱生活](https://weibo.com/1402400261/MARUQfgfD)

Note: 'awesome-decentralized-llm - Collection of LLM resources that can be used to build products you can "own" or to perform reproducible research.' Ian Maurer GitHub: github.com/imaurer/awesome-decentralized-llm  AwesomeProof of prompt?

Picture: [5396ee05ly1hcr1a9megsj21bo1akniw.jpg](https://weibo.cn//mblog/pic/MARUQfgfD?rl=1)

Github: [github.com/imaurer/awesome-decentralized-llm](https://github.com/imaurer/awesome-decentralized-llm)

#### ['Creative Machine Learning course and notebook tut @爱可可-爱生活](https://weibo.com/1402400261/MARW5AVdn)

Note: 'Creative Machine Learning course and notebook tutorials in JAX, PyTorch and Numpy' ACIDS GitHub: github.com/acids-ircam/creative_ml  

Picture: [5396ee05ly1hcr1do0dhmj21ay0yanh0.jpg](https://weibo.cn//mblog/pic/MARW5AVdn?rl=1)

Github: [github.com/acids-ircam/creative_ml](https://github.com/acids-ircam/creative_ml)

#### [【AI Functions：使用OpenAI的GPT-4（或任意其他模型版本）实现的AI函数，可以执 @爱可可-爱生活](https://weibo.com/1402400261/MARZ0uKoL)

Note: 【AI Functions：使用OpenAI的GPT-4（或任意其他模型版本）实现的AI函数，可以执行各种任务】’AI Functions - AI-Powered Function Magic: Never code again with GPT models!' Toran Bruce Richards GitHub: github.com/Torantulino/AI-Functions  哈哈哈 我说这个例子怎么这么眼熟 上周chatgpt生成的sample和这个一毛一样

Picture: [5396ee05ly1hcr1k4c6dxj21bi0pu13n.jpg](https://weibo.cn//mblog/pic/MARZ0uKoL?rl=1)

Github: [github.com/Torantulino/AI-Functions](https://github.com/Torantulino/AI-Functions)

#### ['LeetChatGPT - AI-powered browser extension that e @爱可可-爱生活](https://weibo.com/1402400261/MASghicMK)

Note: 'LeetChatGPT - AI-powered browser extension that enhances your leetcode and hacker-rank experience.' Captone Habiyaremye GitHub: github.com/Liopun/leet-chatgpt-extension  

Picture: [5396ee05ly1hcr2tb2l23j21vp1bxe0q.jpg](https://weibo.cn//mblog/pic/MASghicMK?rl=1)

Github: [github.com/Liopun/leet-chatgpt-extension](https://github.com/Liopun/leet-chatgpt-extension)

#### [Lilian Weng的一篇分析提示工程的博文。Lilian Weng（翁丽莲）现为OpenAI应用 @蚁工厂](https://weibo.com/2194035935/MAUKCtSqu)

Note: Lilian Weng的一篇分析提示工程的博文。Lilian Weng（翁丽莲）现为OpenAI应用人工智能研究负责人地址：lilianweng.github.io/posts/2023-03-15-prompt-engineering/本文介绍了近几年大语言模型 (LLM) 所使用的 prompts分为了三类：zero shot prompt：直接给出指令few shot prompt: 给出示例及指令 -- 效果比前面这种好，代价是花的token更多。chain of thoughts (CoT): 给出一定的推理步骤，或者推理指令 -- 对复杂问题这种效果最好，但对简单问题可能相反。good job.   必读教材

#### [A Recipe for Training Large Models，这是一份训练大型机器学习模型的 @蚁工厂](https://weibo.com/2194035935/MB02g67zC)

Note: A Recipe for Training Large Models，这是一份训练大型机器学习模型的实用建议和技巧本指南的目的是：-- 帮助您训练大型模型（>1B 参数）--  避免不稳定性--  保存开始失败的实验而不从 0 重新开始 认识半年多了，个人觉得还是挺不错的，最近的0032和剑桥科技一路长虹  

Picture: [82c654dfly1hcs1520fmgj21400zqdmc.jpg](https://weibo.cn//mblog/pic/MB02g67zC?rl=1)

#### [StackLLaMa ，用 Stack Exchange（知名的程序员问答网站Stack Overf @蚁工厂](https://weibo.com/2194035935/MB0nHfEnA)

Note: StackLLaMa ，用 Stack Exchange（知名的程序员问答网站Stack Overflow是其一部分）的数据训练的模型，可以回答很多编程和技术问题。该模型包含 70 亿个参数。另外其博文对训练时整合人类反馈强化学习RLHF过程进行了详细讲解，可以作为学习参考。演示地址：huggingface.co/spaces/trl-lib/stack-llama技术介绍：huggingface.co/blog/stackllama回复:Python2回复:我感觉这个ai罹患精神分裂了……这写的什么python代码？？

Picture: [82c654dfly1hcs2nw3egwj2169140nb4.jpg](https://weibo.cn//mblog/pic/MB0nHfEnA?rl=1)

#### ['LLaMA Docker Playground - Quick Start LLaMA model @爱可可-爱生活](https://weibo.com/1402400261/MB1U4k7XC)

Note: 'LLaMA Docker Playground - Quick Start LLaMA models with multiple methods, and fine-tune 7B/65B with One-Click.' Su Yang GitHub: github.com/soulteary/llama-docker-playground  

Picture: [5396ee05ly1hcs9dyth17j21b2106h0j.jpg](https://weibo.cn//mblog/pic/MB1U4k7XC?rl=1)

Github: [github.com/soulteary/llama-docker-playground](https://github.com/soulteary/llama-docker-playground)

#### [大家都知道现在LLM的开发框架像LangChain/LlamaIndex都很火，LangChain刚 @宝玉xp](https://weibo.com/1727858283/MBaMRrRin)

Note: 大家都知道现在LLM的开发框架像LangChain/LlamaIndex都很火，LangChain刚刚更是融资了1000万美元。而这位有多款流行开源ChatGPT库的作者Travis却建议大家尽可能不要用开发框架，而是先尝试直接调用LLM的接口。他更是把这两个框架比喻做前端的jQuery和Angular，确实有用，但是现在还算不是前端的React。我和他的观点类似：用不用LangChain/LlamaIndex是其次，最重要是你得懂他们的工作原理是什么。现阶段它们帮你做的主要就是：文档拆分、向量化、向量存储检索、基于文档对话等这些事如果你搞懂了他们背后的原理，其实是不需要去用这些封装好的库的，或者说你能更好的去使用这些库。我也一直尝试去解释这背后的一些原理，相信我真的不复杂，像我这样没有学过人工智能专业的也可以搞明白。推荐一些历史微博：Embedding和向量化：如何借助embedding突破tokens的4K限制 Supabase文档检索原理：使用Embedding与仅仅在数据库上使用全文搜索有什么不同？Fine-Tuning：智能制造领域应用Fine-Tuning和Embedding 推荐阅读：《快速了解 OpenAI 的 fine-tune 和 Embedding 能力》 LangChain Agent：LangChain Agent原理 http://t.cn/A6NymDdG一个简单的开源类LangChain Agent项目介绍 gpt-4-search：http://t.cn/A6NymDdq文档对话开源项目：markprompt http://t.cn/A6NymDdUKindle GPT http://t.cn/A6NymDdb不会python也可以吗到头来还是什么都要学说的真的太对了，第一次我照着langchain 不到100行代码结合FAISS搞了个类似pdf QA ，啪的一下很快，但我都不知道是什么搞出来的，第二次从0开始写代码实现了一遍终于理解了mark转发微博回复:有了autogpt之类的工具，还有学python的必要吗？回复:买本图灵的python编程：从入门到实战，第三版快出了回复:学python不难，不懂就问ChatGPTmark有道理，但是历史惊人的相似不会python也可以吗到头来还是什么都要学确实，embed有官方接口，各向量仓库接口也简单，文档切割什么的字符串处理让gpt写说的真的太对了，第一次我照着langchain 不到100行代码结合FAISS搞了个类似pdf QA ，啪的一下很快，但我都不知道是什么搞出来的，第二次从0开始写代码实现了一遍终于理解了

Picture: [66fd066bgy1hctc2es8lfj20lo6k6kjm.jpg](https://weibo.cn//mblog/pic/MBaMRrRin?rl=1)

#### [【sdkit：易于使用的Python库，用于在AI艺术项目中使用Stable Diffusion算法 @爱可可-爱生活](https://weibo.com/1402400261/MB3nXkTCe)

Note: 【sdkit：易于使用的Python库，用于在AI艺术项目中使用Stable Diffusion算法，快速、功能丰富、内存高效】'sdkit - sdkit (stable diffusion kit) is an easy-to-use library for using Stable Diffusion in your AI Art projects. It is fast, feature-packed, and memory-efficient.' easydiffusion GitHub: github.com/easydiffusion/sdkit 

Picture: [5396ee05ly1hcsfxn74mbj21be0qub1t.jpg](https://weibo.cn//mblog/pic/MB3nXkTCe?rl=1)

Github: [github.com/easydiffusion/sdkit](https://github.com/easydiffusion/sdkit)

#### [【IEA: Image Editing Anything：Stable Diffusion + Se @爱可可-爱生活](https://weibo.com/1402400261/MBaCno2L4)

Note: 【IEA: Image Editing Anything：Stable Diffusion + Segmentation Anything 实现图像内容编辑】’IEA: Image Editing Anything - Using stable diffusion and segmentation anything models for image editing' feizc GitHub: github.com/feizc/IEA    

Picture: [5396ee05ly1hctbv1h0fqj219015qtzo.jpg](https://weibo.cn//mblog/pic/MBaCno2L4?rl=1)

Github: [github.com/feizc/IEA](https://github.com/feizc/IEA)

#### [《性能之巅 第2版》读书笔记（第7章）1、磁盘处理速度比内存低几个数量级，当主存满时，系统可能会在主 @小川CD](https://weibo.com/1202332555/MBceYhOzc)

Note: 《性能之巅 第2版》读书笔记（第7章）1、磁盘处理速度比内存低几个数量级，当主存满时，系统可能会在主存和磁盘之间交换数据，这会严重影响系统性能，因为这个过程非常缓慢，常常成为系统瓶颈。2、影响系统性能的因素还包括内存分配和释放、内存复制以及CPU管理内存地址映射的开销。对于多处理器系统，访问连接到本地CPU的内存比访问连接到远程CPU的内存延迟低，因此内存本地性也是一个影响因素。3、匿名页面换页会损害性能，当应用程序访问被调出的页时，会被读取页面的磁盘IO阻塞，这就是匿名页面换入，它会给应用程序带来同步延时。4、在MMU查找虚拟内存页面在主存中保存的位置时，如果没有找到相应的映射，将返回失败。这个失败被称为缺页，进而触发内核创建一个按需分配的映射。如果这个映射可以由内存中其他页面满足，这就被称为轻微缺页。需要访问存储设备的缺页称为严重缺页。5、虚拟内存页面可能处于以下几种状态：A)未分配，B)已分配但未映射，C)已分配并映射到主存，D)已分配并映射到物理交换空间（磁盘）。当页面被换出时，就处于状态D，从状态B到状态C就是缺页。如果需要磁盘IO，就是严重缺页，否则就是轻微缺页。已分配到主存中的页面大小称为常驻集合大小（RSS），而虚拟内存大小为B+C+D。6、主存使用率是指已被使用的内存占总内存的比例。文件系统缓存使用的内存可以被视为未使用，因为它可以被应用程序重用。当内存需求超过主存容量时，就会发生主存饱和。此时，操作系统会使用换页、进程交换（如果支持）或者使用OOM终止器来释放内存。7、内存分配器对系统性能有显著影响。通常，系统会提供多个可选的用户级分配器。这些分配器可以利用线程级对象缓存等技术来提高性能。然而，如果分配器碎片化或开销过高，也会对性能造成损害。8、工作集大小（WSS）是进程在运行时经常使用的主存大小。它是调整内存性能的有用指标。如果WSS可以放入CPU缓存而不是主存，那么性能将会大幅提升。9、主存的访问时间可以用CAS（列地址控制器）延时衡量，即从将需要读取的地址（列）发送到内存模块，到数据可读取之间的时间。这个时间取决于内存类型，比如DDR4，一般为10-20纳秒。10、内存总线的速度常常取决于处理器和主板所支持的内存接口标准。自1996年以来，一个通用标准是双倍数据速率同步动态随机访问内存（DDR SDRAM）。术语“双倍数据速率”指的是在时钟上升沿和下降沿都传输数据。而“同步”则指内存时钟与CPU时钟同步。11、系统架构可能会支持多个内存总线，以增加带宽。常见的倍数为双、三或四通道。12、由于TLB映射记录数量有限，使用更大的页可以增加从其缓存转换的内存范围，从而减少TLB未命中，提高系统性能。13、内核slab分配器管理特定大小的对象缓存，以便能够快速回收和重用内存，并避免分配页的开销。这对于经常处理固定大小结构的内核内存分配尤其有效。其基本方法是为每个CPU提供一个缓存，其中有M个对象元素，称为弹夹。每个CPU的弹夹可以在需要重新装填之前满足M次分配——就像用装满子弹的弹夹替换一个空弹夹一样。14、TCMalloc是一种用户级线程缓存的内存分配器，它利用每个线程的缓存来进行小规模内存分配，从而减少锁的竞争，提高性能。定期进行垃圾回收将内存转移到中央堆中以便于分配。15、jemalloc使用了多种技术来提高可扩展性并减少内存碎片，例如多个内存场、线程级别的缓存和小对象的slab等。16、当连续页扫描时间超过10秒时，这可能是内存压力的征兆。在Linux中，可以使用sar -B命令检查pgscan列；通过/proc/memory/pressure可以检查内存压力（饱和度）统计；另外还可以检查内存页的交换、空闲内存大小以及使用CPU剖析检查内存分配的代码路径。17、使用USE方法来评估内存使用情况：使用率（物理内存和虚拟内存的使用情况和空闲情况）、饱和度（页扫描、换页、交换和OOM的使用程度）和错误（软件和硬件错误，如内存的ECC错误）。18、在NUMA系统中，需要考虑内存是否被分配到合适的节点中；IPC和内存停滞周期频率是多少；内存总线的平衡性如何；相对于远程内存IO，执行了多少本地内存IO；进程是否存在内存泄漏等问题。19、静态性能调优需要考虑应用程序使用哪种内存分配器、主存速度、主存是否进行全面测试、操作系统是否支持NUMA、内存是否连接在同一个插槽上、有多少内存总线、BIOS中的设置是怎样的、是否配置和使用了巨型页以及使用了哪些内存可调参数。20、不同的应用程序负载会对内存访问速度产生不同的影响，有时甚至会比CPU时钟速度的影响更大。21、如果vmstat的si,so一直非0，那么系统正存在内存压力并执行交换到交换设备或文件的操作。22、sar可以用来统计换页、巨型页、内存使用率、交换空间统计信息、交换统计信息等。23、使用numastat可以查看在预定的NUMA节点上分配内存的情况，以及不在首选的NUMA节点上分配内存的情况，还可以查看在进程在其他地方运行时，分配在该节点上的内存情况。24、使用perf可以分析内存的性能，例如缺页、NUMA系统上的页迁移、vmscan事件、内存压缩事件等。另外，bpftrace也可以实现类似的功能。25、增加页面大小可以提高TLB缓存命中率，进而提升内存IO性能。现代处理器支持多种页面大小，例如默认的4KB和2MB的大页面。 

#### [电子书《rCore-Tutorial-Book》地址：rcore-os.github.io/rCor @蚁工厂](https://weibo.com/2194035935/MBkyHsjyA)

Note: 电子书《rCore-Tutorial-Book》地址：rcore-os.github.io/rCore-Tutorial-Book-v3/index.html这本教程旨在一步一步展示如何 从零开始 用 Rust 语言写一个基于 RISC-V 架构的 类 Unix 内核 。值得注意的是，本项目不仅支持模拟器环境（如 Qemu/terminus 等），还支持在真实硬件平台 Kendryte K210 上运行。

Picture: [82c654dfly1h13i4am2nqj20i5151q5q.jpg](https://weibo.cn//mblog/pic/LnLKBEhSo?rl=1)

#### [【huggingface-tokenizer-in-cxx：C++复现版Python Hugging @爱可可-爱生活](https://weibo.com/1402400261/MBkFoFwGZ)

Note: 【huggingface-tokenizer-in-cxx：C++复现版Python HuggingFace tokenizer】’huggingface-tokenizer-in-cxx' by Yi Wang GitHub: github.com/wangkuiyi/huggingface-tokenizer-in-cxx  

Picture: [5396ee05ly1hcuk7kksffj21c4162qm3.jpg](https://weibo.cn//mblog/pic/MBkFoFwGZ?rl=1)

Github: [github.com/wangkuiyi/huggingface-tokenizer-in-cxx](https://github.com/wangkuiyi/huggingface-tokenizer-in-cxx)

#### [朋友做的一个项目：ChatPaper，最近集成了一个新能力，可通过 AI 速读 5 万篇 AI 顶会 @GitHubDaily](https://weibo.com/5722964389/MBkWJ47D4)

Note: 朋友做的一个项目：ChatPaper，最近集成了一个新能力，可通过 AI 速读 5 万篇 AI 顶会论文。目前该功能已上线，大家可以体验下。地址：GitHub：github.com/kaixindelele/ChatPaper详细介绍： 我不懂，请问下这样读出来有什么收获？和chatpdf啥区别？回复:这边建议先去读个大学呢人生球球不一定是好球，但像老师强打者，随时都可挥棒。像这样的人还是要得多多关注滴！[/cp]回复:附议回复:有时候总结前人研究要阅读大量文献，但是不是所有文献都是相关的，ai就能够很大程度上提高初筛效率噻每天只能分析两篇呜呜回复:论文本来就是公开的回复:笑死我了😆回复:有没有可能大部分ai顶会论文是完全公开的..

Picture: [006fiYtfgy1hculhtyzg0j31hq1bo4cb.jpg](https://weibo.cn//mblog/pic/MBkWJ47D4?rl=1)

Github: [github.com/kaixindelele/ChatPaper](https://github.com/kaixindelele/ChatPaper)

#### [[CV]《SparseFormer: Sparse Visual Recognition via L @爱可可-爱生活](https://weibo.com/1402400261/MBqPrgW5R)

Note: [CV]《SparseFormer: Sparse Visual Recognition via Limited Latent Tokens》Z Gao, Z Tong, L Wang, M Z Shou [National University of Singapore & Tencent AI Lab & Nanjing University] (2023)   

Picture: [5396ee05ly1hcvb90dgqej20wo168tuu.jpg](https://weibo.cn//mblog/pic/MBqPoiwyp?rl=1)

#### [《算法设计与分析》课件地址：jasonyanglu.github.io/teaching/算法设计与 @蚁工厂](https://weibo.com/2194035935/MBwm7spsS)

Note: 《算法设计与分析》课件地址：jasonyanglu.github.io/teaching/算法设计与分析_2021这是厦门大学卢杨老师的课。本课程主要介绍算法的基础知识，包括抽象计算模型、算法基本概念、算法复杂性分析基础、算法设计的基本方法、以及算法复杂性理论基础。通过本课程的学习，要求学生达到以下目标：    了解可支持算法运行的抽象机器计算模型，算法的定义和复杂性概念，算法设计的基本技术方法，包括递归与分治法、贪心法、动态规划方法、回溯法、分支限界法以及高级图论算法等，理解并掌握算法复杂性的分析方法、NP完全性理论基础等计算复杂性的基本知识以及完全性证明概要。    通过教学和实践，培养学生运用数学工具和方法分析问题和从算法的角度运用数学工具解决问题的基本能力。    使学生能够正确地分析和评价一个算法，进一步设计出真正有效或更有效的算法。同时还有《深度学习》《离散数学》等课程的课件。

Picture: [82c654dfly1h15jd50dxsj21go0u0tfq.jpg](https://weibo.cn//mblog/pic/LnUUIkGNi?rl=1)

#### [Inference with Reference: Lossless Acceleration of @AMiner学术头条](https://weibo.com/1870858943/MBwokCadD)

Note: Inference with Reference: Lossless Acceleration of Large Language Models Nan Yang, Tao Ge, Liang Wang, Binxing Jiao, Daxin Jiang, Linjun Yang, Rangan Majumder, Furu WeiAI综述：本文介绍了一种针对大规模语言模型(Large Language Model，LLM)的加速器LLMA，通过对LLM输出与真实参考文本的相同部分进行复制，并通过高效的并行计算检查复制的结果是否合适，实现了对LLM推理过程的无损加速，特别适用于在搜索引擎和多轮对话等实际场景中存在大量重叠文本的情况下。

Picture: [6f830abfly1hcvzzk2xywj20z80ey48h.jpg](https://weibo.cn//mblog/pic/MBwokCadD?rl=1)

#### [【Becoming Rustacean- Write-ups on Rust (for and ag @网路冷眼](https://weibo.com/1715118170/MBxGBzpTt)

Note: 【Becoming Rustacean- Write-ups on Rust (for and against) Every Noob Should Consider Reading】🔗 www.nativebyx.dev/rust/becoming-rustacean/write-ups-on-rust-every-noob-should-consider-reading.html 成为 Rustacean 系列之二- 每个新手都应该考虑阅读的关于  的文章。 

Picture: [663aa05aly1hcw5p47dhlj21400fmtag.jpg](https://weibo.cn//mblog/pic/MBxGBzpTt?rl=1)

#### [【Becoming Rustacean - Rust Projects】🔗 www.nativeby @网路冷眼](https://weibo.com/1715118170/MBxKfgtY6)

Note: 【Becoming Rustacean - Rust Projects】🔗 www.nativebyx.dev/rust/becoming-rustacean/becoming-rustacean-rust-projects.html 成为 Rustacean 系列之三- 那些知名的以 开发的开源项目（包括现在如日中天的桌面客户端）。附图列出这些开源项目的Logo，都知道是哪些项目吗？ 

Picture: [663aa05aly1hcw5wj4omuj21400l5myx.jpg](https://weibo.cn//mblog/pic/MBxKfgtY6?rl=1)

#### [【Becoming Rustacean: Awesome Free Online Resources @网路冷眼](https://weibo.com/1715118170/MBxNykL9r)

Note: 【Becoming Rustacean: Awesome Free Online Resources to Learn Rust Programming Language】🔗 www.nativebyx.dev/rust/becoming-rustacean/awesome-free-online-resources-to-earn-rust-programming-language.html 成为Rustacean 系列之四：学习Rust编程语言的免费在线资源。 

Picture: [663aa05aly1hcw678buksj21900u077q.jpg](https://weibo.cn//mblog/pic/MBxNykL9r?rl=1)

#### [【Becoming Rustacean: Awesome Paid Online Resources @网路冷眼](https://weibo.com/1715118170/MBxRggyNF)

Note: 【Becoming Rustacean: Awesome Paid Online Resources to Learn Rust Programming Language】🔗 www.nativebyx.dev/rust/becoming-rustacean/awesome-paid-online-resources-to-earn-rust-programming-language.html 成为Rustacean 系列之五：学习  编程语言的优质付费在线资源。 rust不知道好不好学，但这螃蟹我是真馋了

Picture: [663aa05aly1hcw6goomwbj21400fm75v.jpg](https://weibo.cn//mblog/pic/MBxRggyNF?rl=1)

#### [【Becoming Rustacean: Rust Learning Path from Novic @网路冷眼](https://weibo.com/1715118170/MBxUB9vZE)

Note: 【Becoming Rustacean: Rust Learning Path from Novice to Mastery 】🔗 www.nativebyx.dev/rust/becoming-rustacean/rust-learning-path-from-novice-to-mastery.html 成为Rustacean 系列之六：从入门到精通的  学习路径。 感觉其实看螃蟹🦀️就够了。螃蟹那本也相当厚

Picture: [663aa05aly1hcw6p0ezb2j21400fmmzf.jpg](https://weibo.cn//mblog/pic/MBxUB9vZE?rl=1)

#### [【Becoming Rustacean: Memory Management in Rust 】🔗  @网路冷眼](https://weibo.com/1715118170/MBy0Ob3LH)

Note: 【Becoming Rustacean: Memory Management in Rust 】🔗 www.nativebyx.dev/rust/becoming-rustacean/memory-management-in-rust.html 成为Rustacean 系列之七： 中的内存管理。 

Picture: [663aa05aly1hcw74xi1sfj21400fmabd.jpg](https://weibo.cn//mblog/pic/MBy0Ob3LH?rl=1)

#### [博文：Bash One-Liners Explained （中文翻译）Bash One-Liners @蚁工厂](https://weibo.com/2194035935/MBD5l9P46)

Note: 博文：Bash One-Liners Explained （中文翻译）Bash One-Liners Explained 是一系列介绍 Bash 命令技巧的文章，由国外牛人 Peteris Krumins 撰写。凭借扎实的功底和丰富的经验，作者总结了许多快速解决问题的技巧，并且每一条都只要用简洁的一行 Bash 命令就可以完成，同时每一行命令文中都给出了非常详尽的解释。分5篇（一）: 文件处理；（二）: 操作字符串；（三）: 漫谈重定向；（四）: 历史命令；（五）: 命令行跳转；

Picture: [82c654dfly1h16n8otwe7j20qy0axgnn.jpg](https://weibo.cn//mblog/pic/Lo3WDoVjW?rl=1)

#### [【Are your memory-bound benchmarking timings normal @网路冷眼](https://weibo.com/1715118170/MBEJx5bKF)

Note: 【Are your memory-bound benchmarking timings normally distributed?】🔗 lemire.me/blog/2023/04/06/are-your-memory-bound-benchmarking-timings-normally-distributed/ 您的内存限制基准测试时间是否呈正态分布？ 

Picture: [663aa05aly8hcx0tj0795j20hs0dcjsm.jpg](https://weibo.cn//mblog/pic/MBEJx5bKF?rl=1)

#### [几篇分布式技术的技术博客：分布式存储技术（上）：HDFS 与 Ceph的架构原理、特性、优缺点解析  @蚁工厂](https://weibo.com/2194035935/MBFTNldNA)

Note: 几篇分布式技术的技术博客：分布式存储技术（上）：HDFS 与 Ceph的架构原理、特性、优缺点解析 分布式存储技术（下）：宽表存储与全文搜索引擎的架构原理、特性、优缺点解析分布式计算技术（上）：经典计算框架MapReduce、Spark 解析分布式计算技术（下）：Impala、Apache Flink、星环Slipstream

#### [微软下一代的Text to Speech，VALL-E，还没有发布，但是可以看（听）演示，它还支持不 @宝玉xp](https://weibo.com/1727858283/MBQFmBEyu)

Note: 微软下一代的Text to Speech，VALL-E，还没有发布，但是可以看（听）演示，它还支持不同情绪下的声音，比如愤怒、疲惫、厌恶等，它也能合成某个人的声音。🔗 valle-demo.github.io/ 已被夹，求link//:牛逼//:有一个很不错的开源实现 https:// github.com/lifeiteng/vall-e 复现 demo 地址 https:// lifeiteng.github.io/valle/index.html啊哈哈哈哈哈！知道当年我们听石蜡味TTS听得都特么想轻生了么！// :牛逼// :有一个很不错的开源实现 https:// github.com/lifeiteng/vall-e 复现 demo 地址 https:// lifeiteng.github.io/valle/index.html这个开源出的这么快呀

Picture: [66fd066bgy1hcy02k1ikej20t30fotbt.jpg](https://weibo.cn//mblog/pic/MBMJxx1a0?rl=1)

Github: [github.com/lifeiteng/vall-e](https://github.com/lifeiteng/vall-e)

#### [【Segment Anything Model (SAM) 相关扩展/项目/应用大列表】’Aweso @爱可可-爱生活](https://weibo.com/1402400261/MBGjvaZTM)

Note: 【Segment Anything Model (SAM) 相关扩展/项目/应用大列表】’Awesome-segment-anything-extensions - Segment-anything related awesome extensions/projects/repos.' Xiaohao XU GitHub: github.com/JerryX1110/awesome-segment-anything-extensions  还是老三样

Picture: [5396ee05ly1hcx7s4wphmj21v00eatl7.jpg](https://weibo.cn//mblog/pic/MBGjvaZTM?rl=1)

Github: [github.com/JerryX1110/awesome-segment-anything-extensions](https://github.com/JerryX1110/awesome-segment-anything-extensions)

#### [现在除了OpenAI的ChatGPT之外，最好用的GPT类应用当属Claude了，现在你可以通过Sl @宝玉xp](https://weibo.com/1727858283/MC5W2cZkC)

Note: 现在除了OpenAI的ChatGPT之外，最好用的GPT类应用当属Claude了，现在你可以通过Slack使用Claude，只要你有Slack账号，就可以把它加入你的channel和它对话，速度很快。地址：或者Slack的App市场  里面搜索Claude 通过 Poe 使用也不错Claude+更惊艳，可惜不能随意用40 买个 poe 会员想用找我回复:天使回复:有点奇怪，点进添加那里，确实提示地区会限制，还说近期会整理一份列表出来。我看网上有人说试试梯，试了几个不同地区的节点，去重新添加，目前可以用了……回复:不能了好像今天开始在Slack里面不能用Claude了，大概是限制了地区，请问各位朋友你们还能用吗？回复:今天发行被限制了，有搭建手册吗回复:第一次登录只需要填邮箱验证码，可以在slack设置里重置密码，这样就可以创建密码了

Picture: [66fd066bgy1hd0cwjt2dej218g0rswld.jpg](https://weibo.cn//mblog/pic/MC5W2cZkC?rl=1)

#### [大语言模型现在能跑到浏览器了介绍一下WebLLM，这是一个开源的聊天工具，将语言模型（LLMs）直接 @宝玉xp](https://weibo.com/1727858283/MC6bRyNjM)

Note: 大语言模型现在能跑到浏览器了介绍一下WebLLM，这是一个开源的聊天工具，将语言模型（LLMs）直接运行到浏览器上。现在可以通过WebGPU在你的浏览器页面上运行指令微调的LLaMA（Vicuna）模型，无需服务器支持。演示地址：mlc.ai/web-llm注：Mac上需要Chrome Canary 这两天我正在想这个问题，Web连接LLM是什么情况...不应该啊，模型多大？ 马克

Picture: [66fd066bgy1hd0dzkhb6zj22j41621kx.jpg](https://weibo.cn//mblog/pic/MC6bRyNjM?rl=1)

#### [Rust语言圣经(Rust Course)地址：course.rsRust语言圣经已写了 170 余 @蚁工厂](https://weibo.com/2194035935/MBY7Wdfqj)

Note: Rust语言圣经(Rust Course)地址：course.rsRust语言圣经已写了 170 余章，110 余万字。可作为Rust 日常开发工具书。分快速开始、Rust语言特性、常用工具链、开发实践、高级专题等部分。 

Picture: [82c654dfly1h18yjl3t5pj20h01k4q68.jpg](https://weibo.cn//mblog/pic/LondZa8lP?rl=1)

#### [谷歌研究院论文《教授大型语言模型进行自我调试》摘要：“大型语言模型（LLMs）在代码生成方面取得了令 @网路冷眼](https://weibo.com/1715118170/MBZncqt4a)

Note: 谷歌研究院论文《教授大型语言模型进行自我调试》摘要：“大型语言模型（LLMs）在代码生成方面取得了令人瞩目的性能，但对于复杂的编程任务，一次性生成正确的解决方案变得具有挑战性，因此一些先前的研究设计了程序修复方法来提高代码生成性能。在这项工作中，我们提出了自我调试（Self-Debugging）方法，教导大型语言模型通过少量示范来调试其预测的程序。特别地，我们展示了自我调试可以教导大型语言模型执行橡皮鸭调试（rubber duck debugging）；即，在没有任何代码正确性反馈或错误消息的情况下，模型能够通过自然语言解释生成的代码来识别其错误。自我调试在多个代码生成基准测试中实现了最先进的性能，包括文本到SQL生成的Spider数据集，C++到Python翻译的TransCoder和文本到Python生成的MBPP。在Spider基准测试中，由于没有单元测试来验证预测的正确性，通过代码解释，自我调试可以稳定地将基线提高2-3％，并将最难标签的问题的预测准确性提高9％。在TransCoder和MBPP中，由于有单元测试可用，自我调试可以将基线准确性提高高达12％。同时，通过利用反馈消息和重用失败的预测，自我调试显著提高了样本效率，并可以匹配或超越生成10倍以上候选程序的基线模型。”【Teaching Large Language Models to Self-Debug】🔗 arxiv.org/abs/2304.05128粗略看了下实验例子，感觉现在大厂那边用gpt辅助编程，都是列很多单元测试来对gpt生成代码进行校验，全部通过就当可用用的样子。跟论文里面的好像差不多。

Picture: [663aa05aly1hczjxbwqvgj20i40ngwhl.jpg](https://weibo.cn//mblog/pic/MBZncqt4a?rl=1)

#### [【Trident：为加速机器学习训练和推断而设计的性能库，包括高度优化的核、函数和模块，基于Open @爱可可-爱生活](https://weibo.com/1402400261/MC5Tflaf9)

Note: 【Trident：为加速机器学习训练和推断而设计的性能库，包括高度优化的核、函数和模块，基于OpenAI Triton实现。】'Trident - A performance library for machine learning applications.' kakaobrain GitHub: github.com/kakaobrain/trident   

Picture: [5396ee05ly8hd0chb9dl6j211i0u0ju8.jpg](https://weibo.cn//mblog/pic/MC5Tflaf9?rl=1)

Github: [github.com/kakaobrain/trident](https://github.com/kakaobrain/trident)

#### [Huggingface上的chatglm-6b已经有75万下载了 还有很多小朋友做了各种优化和新项目 @蚁工厂](https://weibo.com/2194035935/MC74oyT0K)

Note: Huggingface上的chatglm-6b已经有75万下载了 还有很多小朋友做了各种优化和新项目开发 甚至还做了教程，太赞了（我们自己的教程愧不如呀。。。。）。。。以下是部分基于本仓库开发的开源项目：SwissArmyTransformer: 一个Transformer统一编程框架，ChatGLM-6B已经在SAT中进行实现并可以进行P-tuning微调。ChatGLM-MNN: 一个基于 MNN 的 ChatGLM-6B C++ 推理实现，支持根据显存大小自动分配计算任务给 GPU 和 CPUChatGLM-Tuning: 基于 LoRA 对 ChatGLM-6B 进行微调。类似的项目还包括 Humanable ChatGLM/GPT Fine-tuning | ChatGLM 微调langchain-ChatGLM：基于本地知识的 ChatGLM 应用，基于LangChainbibliothecarius：快速构建服务以集成您的本地数据和AI模型，支持ChatGLM等本地化模型接入。闻达：大型语言模型调用平台，基于 ChatGLM-6B 实现了类 ChatPDF 功能JittorLLMs：最低3G显存或者没有显卡都可运行 ChatGLM-6B FP16， 支持Linux、windows、Mac部署ChatGLM-Finetuning：基于ChatGLM-6B模型，进行下游具体任务微调，涉及Freeze、Lora、P-tuning等，并进行实验效果对比。InstructGLM：基于ChatGLM-6B进行指令学习，汇总开源中英文指令数据，基于Lora进行指令数据微调，开放了Alpaca、Belle微调后的Lora权重，修复web_demo重复问题ChatGLM-web：基于FastAPI和Vue3搭建的ChatGLM演示网站(支持chatglm流式输出、前端调整模型参数、上下文选择、保存图片、知识库问答等功能)glm-bot：将ChatGLM接入Koishi可在各大聊天平台上调用ChatGLM以下是部分针对本项目的教程/文档：Windows部署文档ChatGLM-6B 的部署与微调教程 

Picture: [7ebeb44bly1hd0hcag8jvj221q0z64qp.jpg](https://weibo.cn//mblog/pic/MC6Y5hNlP?rl=1)

#### [VIM 用户手册 - by Bram Moolenaar地址：yianwillis.github.i @敖天羽](https://weibo.com/1888981347/MCf1FCkL4)

Note: VIM 用户手册 - by Bram Moolenaar地址：yianwillis.github.io/vimcdoc/包含用户手册和参考手册两个部分。用户手册面向任务的使用说明书，由简入繁，能像书一样从头读到尾。参考手册详细描述 Vim 的每一个命令的详细资料。 

Picture: [82c654dfly1h1bhartkonj20io1df0yy.jpg](https://weibo.cn//mblog/pic/LoK9R43Ku?rl=1)

#### [推荐阅读：《从AutoGPT谈起，看大语言模型使用工具的发展》《关于AutoGPT的疑惑, 它到底有 @宝玉xp](https://weibo.com/1727858283/MCfuYEv5r)

Note: 推荐阅读：《从AutoGPT谈起，看大语言模型使用工具的发展》《关于AutoGPT的疑惑, 它到底有没有CoT（Chain-of-Thought）?》作者Sverige_ Dong-seok（twitter.com/realrenmin）是NLP的博士，写过多篇ChatGPT相关的论文解析，相当专业，这次他尝试对AutoGPT的源码进行深度解析，分析了AutoGPT的实现原理，以及是否用了GPT-4与其他LLM与众不同的Chain-of-Thought (CoT) 和 Let's think step by step。当然他最后的结论是AutoGPT其实没有用到Chain-of-Thought (CoT) ：“可以确定的是，AutoGPT的prompting 方式没有显性的引入CoT，所以没有解锁reasoning。它只能严重依赖缓存做desicion making，一遍遍的重复action，有勇无谋，可以说它并没有真正在做reasoning。在以token计费的背景下，这种局限性被放大，徒有炫酷，让一般开发者望而却步。”具体建议直接看他的长文：《从AutoGPT谈起，看大语言模型使用工具的发展》《关于AutoGPT的疑惑, 它到底有没有CoT（Chain-of-Thought）?》《从Chain-of-Thought (CoT) 到 Let's think step by step》

Picture: [66fd066bgy1hd1gom2puyj20lmb2y7wk.jpg](https://weibo.cn//mblog/pic/MCeXV5sAO?rl=1)

#### [ 分享了他基于Embedding做的文档问答的经验，和传统的直接将问题做向量查询不一样，他让GPT先 @宝玉xp](https://weibo.com/1727858283/MCfIZoiA8)

Note:  分享了他基于Embedding做的文档问答的经验，和传统的直接将问题做向量查询不一样，他让GPT先对问题做一个关键字分析，然后根据分析的关键词结果再做向量搜索，这样匹配度更高，聪明的做法👍🏻文档地址就不发了，用的人太多，一晚上就烧了他十来刀😄，有心你总能找到———多轮问答跑了一天，目前效果很稳定，可以来解释一下是如何实现的了。问答通常的实现，embedding -> search -> llm，连续语义在第一步就丢失了。我的方案是在前面，先让 ChatGPT 解释问题，返回关键词，流程变为：explain -> embedding -> search -> llm。 具体 prompt 如下：`You are a fibjs development assistant, please give detail keywords for the my question, based on the previous discussion.There is no need to specifically include fibjs in the keywords.my question: ${ask_message}keywords: `———他的所有代码都是开源的：轻量向量数据库: github.com/fibjs/fibjs/blob/dev/fibjs/src/db/sql/Sqlite_vec.cpp开发文档索引: github.com/fibjs/fibjs/blob/dev/tools/gen_index.js问答测试: github.com/fibjs/fibjs/blob/dev/tools/ask.js文本提取模块: github.com/xicilion/fib-spliter自动嵌入文档的代理: github.com/xicilion/gptproxy我最近在攻克一个块吐血的问题学术论文再parse的时候，现有的所有工具模块都没办法去除页眉页脚。   直接导致一些关键性问题会参杂奇奇怪怪的回答。   现在目前差不多了，我再改改bug，提一个pr给chat paper不懂就问，embedding是啥呀？大佬，我看了下ask.js的代码，没看见有explain相关的代码，求解回复:多请求一次更慢了mark回复:确实没看到回复:也是2步  1  pymupdf先把图片存下来  2 paddleocr  提取图片关键信息。  回复:好的，谢谢大佬，我试一下。再弱弱的问一句，您去除页眉页脚是怎么实现的是用auto-gpt做的吗回复:好奇图片有解决方案吗响马账号呢

Picture: [66fd066bgy1hd1jzw5xpkj20iz0xcaj6.jpg](https://weibo.cn//mblog/pic/MCfIZoiA8?rl=1)

Github: [github.com/fibjs/fibjs/blob/dev/fibjs/src/db/sql/Sqlite_vec.cpp](https://github.com/fibjs/fibjs/blob/dev/fibjs/src/db/sql/Sqlite_vec.cpp)

Github: [github.com/fibjs/fibjs/blob/dev/tools/gen_index.js](https://github.com/fibjs/fibjs/blob/dev/tools/gen_index.js)

Github: [github.com/fibjs/fibjs/blob/dev/tools/ask.js](https://github.com/fibjs/fibjs/blob/dev/tools/ask.js)

Github: [github.com/xicilion/fib-spliter](https://github.com/xicilion/fib-spliter)

Github: [github.com/xicilion/gptproxy](https://github.com/xicilion/gptproxy)

#### [无需文字标签，完全自监督的Meta视觉大模型来了！小扎亲自官宣，发布即收获大量关注度——在语义分割、 @宝玉xp](https://weibo.com/1727858283/MCy3O00pi)

Note: 无需文字标签，完全自监督的Meta视觉大模型来了！小扎亲自官宣，发布即收获大量关注度——在语义分割、实例分割、深度估计和图像检索等任务中，这个名叫DINOv2的视觉大模型均取得了非常不错的效果。甚至有超过当前最好的开源视觉模型OpenCLIP之势。虽然此前Meta就发布过自监督学习视觉大模型DINO，不过这次AI识别图像特征的能力显然更进一步，准确分割出了视频中的主体。可别以为DINOv2通过自监督学会的只有图片分割。事实上，它已经能根据不同类别、不同场景下的照片，准确识别出同种物体（狗）的头部、身体和四肢长在哪。换而言之，DINOv2自己学会了找图像特征。目前Meta官方不仅已经放出了开源代码，而且还给了网页版Demo试玩。有网友内涵：什么叫开源，LLaMA，SAM，DINOv2这才叫开源！一起来看看，DINOv2的效果究竟如何：反正最后都是我腾讯、百度、字节跳动的，我们的优化遥遥领先话说meta才是真开源，一个llama生出多少小骆驼Facebook 已经在开源界一骑绝尘了

Picture: [006Fd7o3ly1hd3rvcolqlj30vq0euaf3.jpg](https://weibo.cn//mblog/pic/MCy37pFlG?rl=1)

#### [相信你对DevOps已经非常熟悉，但你是否听说过MLOps或者LLMOps呢？MLOps本质上仍然是 @宝玉xp](https://weibo.com/1727858283/MCGNYdW1j)

Note: 相信你对DevOps已经非常熟悉，但你是否听说过MLOps或者LLMOps呢？MLOps本质上仍然是DevOps，只是现在关注的是与AI和大型语言模型相关的产品。首先回顾一下DevOps的概念。DevOps是一种将开发（Development）和运维（Operations）紧密协作的工作方式，使得软件构建、测试和发布变得更加快速和可靠。DevOps的核心不仅在于Dev和Ops这两个概念，还在于其三个重要原则：1. 自动化：尽可能减少人工干预，降低交付成本，实现整个开发流程的自动化，包括线上部署、监控和报警。2. 信息透明和可衡量：确保整个开发过程中的数据以及产品运维的透明度，并使其可量化。例如，一个功能从需求到上线需要多长时间？故障回滚需要多长时间？当前API的性能如何，错误率如何，用户数量如何？3. 积极的跨职能协作文化：Dev和Ops之间没有部门壁垒，甚至分工的界限也不必过于明确。他们需要紧密协作，解决问题，总结教训，不推诿责任，鼓励创新。而在MLOps/LLMOps时代，与Ops协作的不仅有Dev，还有ML工程师！MLOps时代所需的知识也更为丰富：* LLM相关的专业知识，如Transformer、Embedding、Fine-tuning、LoRa等。* ML所需的工具，如PyTorch、Jupyter Notebook等。* 硬件方面，除了CPU和内存外，还需考虑显卡GPU，以及如何充分发挥多张显卡的并行运算能力。* 以及许多其他相关知识。在DevOps时代，项目追求快速发布和迭代。即使是Windows和Chrome这样的产品，也会每隔几周发布一次更新。然而，在MLOps时代，大型模型相关产品的发布速度尚无法达到如此快速。以OpenAI为例，从GPT-1到GPT-4，每个版本的开发都花费了一年以上的时间。除了模型训练费时费钱外，模型调优也需要大量时间投入，以避免安全和道德伦理问题。那么，MLOps时代的这些变化是否意味着DevOps的三个核心原则已过时呢？我认为这三个核心原则并未过时，只是具体实施方式发生了一些变化。1. 自动化：在MLOps领域，自动化同样至关重要。以模型训练为例，要保证模型训练质量，就需要大量的高质量数据。纯粹依靠人工是无法完成这项任务的，需要大量的自动化脚本甚至AI参与，帮助生成和标注高质量数据。业界普遍认为OpenAI的成功不仅在于技术上的突破，还在于工程上的成果。他们仅凭几百人的团队规模，便交付了GPT-4这样的产品，这背后离不开高度的自动化。2. 信息透明和可衡量：在MLOps时代，信息透明和可衡量仍然非常重要。例如，在模型训练和部署过程中，我们需要密切关注模型性能指标，如准确率、召回率和F1分数等。此外，我们还需要关注硬件资源使用情况，如CPU、GPU和内存使用率。实时监控这些指标可以帮助我们识别问题，提高模型性能，降低成本。因此，在MLOps时代，信息透明和可衡量仍然是关键。3. 积极的跨职能协作文化：MLOps时代要求更紧密的跨职能协作。与DevOps相比，MLOps涉及的角色更多样化，包括数据科学家、ML工程师、数据工程师等。这些角色需要共同努力，以确保模型在整个生命周期中的优秀表现。为此，团队成员需要保持开放的沟通，共同面对挑战，遵循最佳实践，并以创新和协作为核心价值观。在MLOps时代，DevOps的三个核心原则仍然具有指导意义。尽管具体实施细节有所不同，但自动化、信息透明可衡量以及积极的跨职能协作文化仍然是确保项目成功的关键要素。相关资源链接：madewithml.com🔗 github.com/GokuMohandas/mlops-course🐦 twitter.com/realrenmin/status/1648352446727462913?s=20Yatai —— 云原生上的 MLOps 平台

Picture: [66fd066bgy1hd4sgzbxb9j21ag1jk7qk.jpg](https://weibo.cn//mblog/pic/MCGNYdW1j?rl=1)

Github: [github.com/GokuMohandas/mlops-course](https://github.com/GokuMohandas/mlops-course)

#### [Google推出Bard（bard.google.com）后反响平平，不过他们刚刚推出了一个重大的更 @宝玉xp](https://weibo.com/1727858283/MD9EcjAto)

Note: Google推出Bard（bard.google.com）后反响平平，不过他们刚刚推出了一个重大的更新，在编程能力上有重大提升，支持20多种编程语言，包括 C++、Go、Java、Javascript、Python 和 Typescript等！现在，Bard 可以总结和解释代码片段，可以将 Python 代码直接导出到 Google Colab，不需要复制和粘贴。Bard 可以给 Google Spreadsheet编写函数。如果遇到代码错误，Bard 还可以帮你Debug代码。希望早日赶上ChatGPT，这样我们就可以有更多选择了！ 知识库这个赛道现在是不是竞争很激烈啊？想咨询一个问题，如果用户不是直接把prompt传递给openAI的服务器，而是把大模型神经网络的前几层进行本地处理，把处理完得到的向量传递给服务器，能避免用户隐私数据的泄露问题吗？

#### [「GitHub多星榜 ✨ 」🔥 TOP 15 🚀 612点击  「一个离职的工程师留下的奇葩脚本。可 @宝玉xp](https://weibo.com/1727858283/MD8HkqH1o)

Note: 「GitHub多星榜 ✨ 」🔥 TOP 15 🚀 612点击  「一个离职的工程师留下的奇葩脚本。可以拍老婆马屁、自动请假以及煮咖啡…  你写过什么好用的自动化脚本么？我最近写的一个是抽取 TimeTodo 数据生成周报，然后用 VScode 打开弹出窗口供编辑的… 」  Kumar是个印度很流行的姓，相当于中国的张，王

Picture: [40dfde6fly8hd88cadbcsj20p80mpq7d.jpg](https://weibo.cn//mblog/pic/MD88u1U31?rl=1)

#### [【txtinstruct：用于指令微调的数据集和模型】'txtinstruct - Datasets @爱可可-爱生活](https://weibo.com/1402400261/MCqSr3Hyb)

Note: 【txtinstruct：用于指令微调的数据集和模型】'txtinstruct - Datasets and models for instruction-tuning' NeuML GitHub: github.com/neuml/txtinstruct   

Picture: [5396ee05ly8hd2xccepsoj20xs0u0gqe.jpg](https://weibo.cn//mblog/pic/MCqSr3Hyb?rl=1)

Github: [github.com/neuml/txtinstruct](https://github.com/neuml/txtinstruct)

#### [[CL]《Shall We Pretrain Autoregressive Language Mod @爱可可-爱生活](https://weibo.com/1402400261/MCuI36Mf2)

Note: [CL]《Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study》B Wang, W Ping, P Xu, L McAfee, Z Liu, M Shoeybi, Y Dong, O Kuchaiev, B Li, C Xiao, A Anandkumar, B Catanzaro [NVIDIA & UIUC] (2023)   

Picture: [5396ee05ly1hd3e7t94egj20l61ai7ct.jpg](https://weibo.cn//mblog/pic/MCuHE21eJ?rl=1)

#### [[CL]《Learning to Compress Prompts with Gist Tokens @爱可可-爱生活](https://weibo.com/1402400261/MCEzgvuH9)

Note: [CL]《Learning to Compress Prompts with Gist Tokens》J Mu, X L Li, N Goodman [Stanford University] (2023)   

Picture: [5396ee05ly1hd4lo65j9uj20v217swvk.jpg](https://weibo.cn//mblog/pic/MCEzdAnEu?rl=1)

#### [[CL]《Low-code LLM: Visual Programming over LLMs》Y  @爱可可-爱生活](https://weibo.com/1402400261/MCEE8gM0w)

Note: [CL]《Low-code LLM: Visual Programming over LLMs》Y Cai, S Mao, W Wu, Z Wang, Y Liang, T Ge, C Wu, W You, T Song, Y Xia, J Tien, N Duan [Microsoft Research Asia] (2023)   

Picture: [5396ee05ly1hd4lv6vk7nj217g0sewx7.jpg](https://weibo.cn//mblog/pic/MCEE4lOUN?rl=1)

#### [【Transformer 视觉分割相关资源列表】’Transformer-Based Visual  @爱可可-爱生活](https://weibo.com/1402400261/MCQRDtlf0)

Note: 【Transformer 视觉分割相关资源列表】’Transformer-Based Visual Segmentation: A Survey' by Xiangtai Li GitHub: github.com/lxtGH/Awesome-Segmenation-With-Transformer   

Picture: [5396ee05ly8hd6431na8ij20yd0u0dlg.jpg](https://weibo.cn//mblog/pic/MCQRDtlf0?rl=1)

Github: [github.com/lxtGH/Awesome-Segmenation-With-Transformer](https://github.com/lxtGH/Awesome-Segmenation-With-Transformer)

#### [【StableLM: Stability AI最新开源的大语言模型，目前开放的是3B和7B的版本，后 @爱可可-爱生活](https://weibo.com/1402400261/MCQKMtQLC)

Note: 【StableLM: Stability AI最新开源的大语言模型，目前开放的是3B和7B的版本，后续会开放更大规模的模型，可商用】’StableLM: Stability AI Language Models - StableLM: Stability AI Language Models' Stability-AI GitHub: github.com/Stability-AI/StableLM     

Picture: [5396ee05ly8hd63k6v4ulj20w20u0n0a.jpg](https://weibo.cn//mblog/pic/MCQKMtQLC?rl=1)

Github: [github.com/Stability-AI/StableLM](https://github.com/Stability-AI/StableLM)

#### [【CompressGPT：提示压缩器，可以为大多数基于 LangChain 工具的提示减少约70%  @爱可可-爱生活](https://weibo.com/1402400261/MCTb84urV)

Note: 【CompressGPT：提示压缩器，可以为大多数基于 LangChain 工具的提示减少约70% 的Token，只需更改一行代码】’CompressGPT - Self-extracting GPT prompts for ~70% token savings' Yasyf Mohamedali GitHub: github.com/yasyf/compress-gpt   

Picture: [5396ee05ly8hd6do9imozj211y0u0440.jpg](https://weibo.cn//mblog/pic/MCTb84urV?rl=1)

Github: [github.com/yasyf/compress-gpt](https://github.com/yasyf/compress-gpt)

#### [CS-143 斯坦福编译原理(中文翻译) 合集斯坦福的编译原理课程，设计者开发了一个 Class-O @蚁工厂](https://weibo.com/2194035935/MCnh8EWms)

Note: CS-143 斯坦福编译原理(中文翻译) 合集斯坦福的编译原理课程，设计者开发了一个 Class-Object-Oriented-Language，简称 COOL 语言。这门课的核心就是通过理论知识的学习，为 COOL 语言实现一个编译器，将 COOL 高级语言编译为 MIPS 汇编并在 Spim 这个 MIPS 模拟器上成功执行。配套解读补充这个up很不容易

Picture: [82c654dfly1h1cymvw75uj20n00nsmz3.jpg](https://weibo.cn//mblog/pic/LoTti110l?rl=1)

#### [Google大数据三篇论文的中文翻译，这三篇论文开启了工业界大数据的时代。Hadoop和HBase可 @蚁工厂](https://weibo.com/2194035935/MCnWrtv1d)

Note: Google大数据三篇论文的中文翻译，这三篇论文开启了工业界大数据的时代。Hadoop和HBase可以说是这三篇的开源实现。《The Google File System》论文翻译地址：mrcroxx.github.io/posts/paper-reading/gfs-sosp2003/《MapReduce: Simplified Data Processing on Large Clusters》论文翻译地址：mrcroxx.github.io/posts/paper-reading/mapreduce-osdi04/《Bigtable: A Distributed Storage System for Structured Data》论文翻译地址：mrcroxx.github.io/posts/paper-reading/bigtable-osdi06/史称大数据狗三篇//:转发微博

Picture: [82c654dfly1h1crlrb8njj20cx11mwgl.jpg](https://weibo.cn//mblog/pic/LoRVl80kP?rl=1)

#### [🚨【放大招了】🚨想要训练GPT-4的小伙伴们看过来！本组朱芄蓉同学联合AI2、华大、哥大等单位推出了 @蚁工厂](https://weibo.com/2194035935/MCotkCDW8)

Note: 🚨【放大招了】🚨想要训练GPT-4的小伙伴们看过来！本组朱芄蓉同学联合AI2、华大、哥大等单位推出了由5.8亿图片、1亿文档、430亿token组成的超大文本图片交织数据集。这是训练开源大模型OpenFlamingo的训练数据集。论文与数据下载： 这得跑多久//://:当一下课代表，地址是: github.com /allenai /mmc4。其实建议把数据集放到HuggingFace上开源，这样下载会更方便些，也方便统计影响力模型遍地都是，数据集才是真正宝贵的资源

Picture: [62caff97gy1hd2mgrlfh0j21js160qc4.jpg](https://weibo.cn//mblog/pic/MCoqmdoF5?rl=1)

#### [由GPT4-交互对话生成的行业数据集地址：huggingface.co/camel-ai目前有生物、 @蚁工厂](https://weibo.com/2194035935/MCqodkGJZ)

Note: 由GPT4-交互对话生成的行业数据集地址：huggingface.co/camel-ai目前有生物、化学、数学、物理等行业。如生物数据集中有2万个问题-解答，分25个子项。新的数据集是由gpt-4跑出来的，老的有gpt-3.5的。    

Picture: [82c654dfly1hd2popf8e4j21qx0t2wo9.jpg](https://weibo.cn//mblog/pic/MCqodkGJZ?rl=1)

#### [斗胆做个预言，将来的大模型将会变成像芯片设计制造这样的foundry模式。个别有能力积攒算力的公司（ @蚁工厂](https://weibo.com/2194035935/MCxi43mqf)

Note: 斗胆做个预言，将来的大模型将会变成像芯片设计制造这样的foundry模式。个别有能力积攒算力的公司（foundry）会花数亿甚至百亿元级别的钱去训练通用大模型，然后客户公司会根据自己的需求在通用大模型基础上找foundry定制自己行业应用的大模型，调整好以后部署到客户公司的超算上，或者是由foundry及其合作伙伴维护的公共超算上。OpenAI等公司已经把路走通了，剩下的就是各大有潜力成为foundry的公司砸钱，而且这一块卷起来的速度会比IC制造快很多。摩尔定律只会要求晶体管数量多少个月内翻一番，所以IC业的foundry模式走了二三十年才到台积电一家独大；但是大模型foundry走到垄断可能只需要数年。不过这个速度也取决于市场扩张有多快。这样的结果是，先进制程的芯片、显卡、超算，需求量将会大增，每个省份稍微大一些的企业都会部署自己的计算中心。而且，算力作为国家战略资源的重要性将会极度上升，对先进制程的需求将会无比迫切。

#### [由北京人工智能学院和几所中美高校一起搞的中文语料库，收集并人工检查了约20万个中文指令调整样本。《C @蚁工厂](https://weibo.com/2194035935/MCyUO4tkr)

Note: 由北京人工智能学院和几所中美高校一起搞的中文语料库，收集并人工检查了约20万个中文指令调整样本。《Chinese Open Instruction Generalist: A Preliminary Release》1 北京人工智能学院，中国2 英国谢菲尔德大学计算机科学系。3 美国密歇根大学安阿伯分校4 美国达特茅斯大学5 中国浙江大学6 中国北京航空航天大学7 美国卡内基梅隆大学指令调整（Instruction tuning）被广泛认为是构建通用语言模型的关键技术，在 InstructGPT和 ChatGPT发布后，引起了研究人员和公众的关注。尽管面向英语的大规模语言模型（LLM）取得了令人印象深刻的进展，但目前尚未充分探究基于英语的基础 LLM 在多语言任务中是否能够在设计良好的指令调整下表现出与英语任务相近的性能，以及我们如何构建调整所需的语料库。为了弥补这一空白，我们提出了这个项目，试图通过适应4个子任务的固有特点的各种方法，创建一个中文指令数据集。我们收集了约20万个中文指令调整样本，这些样本经过人工检查，以确保高质量。我们还总结了现有的英文和中文指令语料库，并简要介绍了新建中文指令语料库的一些潜在应用。

Picture: [66fd066bgy1hd3uq40eclj212s0wwwpy.jpg](https://weibo.cn//mblog/pic/MCyrgk9KK?rl=1)

#### [转码路线图地址：wangzhe3224.github.io/zhuan-ma/注意；这不是一个计算机 @蚁工厂](https://weibo.com/2194035935/MCzQK5Eff)

Note: 转码路线图地址：wangzhe3224.github.io/zhuan-ma/注意；这不是一个计算机自学指南，这也不是一个 Leetcode 刷题指南。 这是一个帮助你转码的路线图，希望通过它帮助你快速实现职业转变，并且为未来的职业打好基础。本站的核心目的在于：根据不同的情况，列出最少的学习资料，高效建立正确的计算机知识框架。还转码呢，都卷成什么样了还转码呢，都卷成什么样了“泛泛，土木工程本硕博，智力一般，非211本科，985硕博，对计算机有兴趣浓厚。” 点开知乎主页一看，天大，伦敦大学院，牛津软工，这个简介写的真是。。。

Picture: [82c654dfly1hd3nqcqu1kj20e316njuq.jpg](https://weibo.cn//mblog/pic/MCzQK5Eff?rl=1)

#### [CreatorDB，一个MIT公开课 6.830 数据库系统的讲解和实现项目地址：github.co @蚁工厂](https://weibo.com/2194035935/MCAoQ1AOn)

Note: CreatorDB，一个MIT公开课 6.830 数据库系统的讲解和实现项目地址：github.com/CreatorsStack/CreatorDB该项目实现了一个简单的关系型数据库SimpleDb 。SimpleDb 是一个 DBMS 数据库管理系统, 包含存储, 算子, 优化, 事务, 索引 等, 全方位介绍了如何从0实现一个 DBMS, 可以说, 这门课是学习 TIDB 等其他分布式数据库的前提.

Picture: [82c654dfly1hd3pj3jyd4j20kz0hrwii.jpg](https://weibo.cn//mblog/pic/MCAoQ1AOn?rl=1)

Github: [github.com/CreatorsStack/CreatorDB](https://github.com/CreatorsStack/CreatorDB)

#### [电子书《Pen and Paper Exercises in Machine Learning》地址 @蚁工厂](https://weibo.com/2194035935/MCFpGjN0D)

Note: 电子书《Pen and Paper Exercises in Machine Learning》地址：arxiv.org/abs/2206.13446这本书包含了一系列关于机器学习的习题，并附有详细的解答。 希望详细程度足以让读者遵循解决方案并理解所使用的技术。 然而，这些练习并不能取代机器学习的教科书或课程。 作者假设读者已经看过相关的理论和概念，现在想通过解题练习加深理解。虽然编码和计算机模拟在机器学习中非常重要，但书中的练习（大部分）可以用笔和纸解决。 重点放在纸笔练习上，减少了篇幅，简化了演示文稿。 此外，它还可以让读者加强他们的数学技能。 但是，练习最好与计算机练习配对，以进一步加深理解。这里收集的练习主要是作者为赫尔辛基大学的“无监督机器学习”和爱丁堡大学的“概率建模和推理”课程开发的练习的联合。 这些练习并没有全面地涵盖所有的机器学习，但重点关注无监督方法，推理和学习。铁粉互动2好书呀

Picture: [82c654dfly1hd4pjc52mdj215c1j4jus.jpg](https://weibo.cn//mblog/pic/MCFpGjN0D?rl=1)

#### [电子书《从零开始的UEFI裸机编程》地址：kagurazakakotori.github.io/ub @蚁工厂](https://weibo.com/2194035935/MCJ1DsSDe)

Note: 电子书《从零开始的UEFI裸机编程》地址：kagurazakakotori.github.io/ubmp-cn/index.html大神 祐真 著, 神楽坂琴梨 译本书是一份入门向的UEFI编程教程，介绍如何在不使用外部库和开发工具链，只使用UEFI API的情况下编写UEFI应用程序，由两部分组成：    第一部分: 介绍UEFI的基本概念，如何阅读UEFI标准文档，并通过编写一个UEFI应用程序来介绍UEFI固件的常用功能。    第二部分: 介绍更多的UEFI API，以及如何引导Linux

Picture: [82c654dfly1h1eq8i50s6j20ii1kktd5.jpg](https://weibo.cn//mblog/pic/Lp7WTsjW6?rl=1)

#### [60秒完成Linux系统的性能分析(译)地址：   jeremyxu2010.github.io/2 @蚁工厂](https://weibo.com/2194035935/MCUtClDgM)

Note: 60秒完成Linux系统的性能分析(译)地址：   jeremyxu2010.github.io/2019/12/60秒完成linux系统的性能分析译/原文出自Netflix技术团队的博客。在本文中，Netflix性能工程团队将使用您应该使用的标准Linux工具在命令行中向您展示一个性能诊断过程的前60秒。在60秒内，您可以通过运行以下十个命令来了解有关系统资源使用和运行进程的信息。最应该关注的是一些很容易理解的错误、饱和度指标和资源利用率等指标。饱和度是衡量资源负载超出其处理能力的指标，它可以通过观察请求队列的长度或等待时间反映出来。回复:这才是标准姿势我都上来先top

Picture: [82c654dfly1h1g41odccaj20co0romyk.jpg](https://weibo.cn//mblog/pic/Lpj8OdNYy?rl=1)

#### [系列博文《Linux 网络栈原理、监控与调优》地址：arthurchiao.art/blog/lin @蚁工厂](https://weibo.com/2194035935/MCYbnqrNx)

Note: 系列博文《Linux 网络栈原理、监控与调优》地址：arthurchiao.art/blog/linux-net-stack-zh/本文尝试从技术研发与工程实践（而非纯理论学习）角度，在原理与实现、监控告警、 配置调优三方面介绍内核5.10 网络栈。由于内容非常多，因此分为了几篇系列文章。本文写的是 “Linux networking stack”，这里的 “stack” 指的不仅仅是内核协议栈， 而是包括内核协议栈在内的、从数据包到达物理网卡到最终被用户态程序收起的整个路径

Picture: [82c654dfly1hd70du6o5pj20vw0sg11c.jpg](https://weibo.cn//mblog/pic/MCYbnqrNx?rl=1)

#### [博文《缓存进阶使用指南》lvqiushi.github.io/2021/12/03/缓存进阶使用指南 @蚁工厂](https://weibo.com/2194035935/MCUulx47T)

Note: 博文《缓存进阶使用指南》lvqiushi.github.io/2021/12/03/缓存进阶使用指南/在目前大多数系统中，数据库还无法很好的支持横向扩展，所以在高流量下，都要依靠缓存来抗住高并发的访问请求，因此缓存就成为了一个至关重要的组件，对于开发人员来讲，如何正确使用缓存也变得至关重要。这篇文章总结了常见的缓存的选型方案，重点介绍了实际应用过程中缓存可能遇到的各种问题及应对。最后拔高了一下人生的意义。轮回

Picture: [82c654dfly1h1fw3fj6mtj20i30pjabd.jpg](https://weibo.cn//mblog/pic/LphkX0STs?rl=1)

#### [之前国内第一个引发轰动的复旦大学的大语言模型MOSS已经发布了。地址：github.com/Open @蚁工厂](https://weibo.com/2194035935/MD03HftRz)

Note: 之前国内第一个引发轰动的复旦大学的大语言模型MOSS已经发布了。地址：github.com/OpenLMLab/MOSSMOSS是一个支持中英双语和多种插件的开源对话语言模型，moss-moon系列模型具有160亿参数，在FP16精度下可在单张A100/A800或两张3090显卡运行，在INT4/8精度下可在单张3090显卡运行。MOSS基座语言模型在约七千亿中英文以及代码单词上预训练得到，后续经过对话指令微调、插件增强学习和人类偏好训练具备多轮对话能力及使用多种插件的能力。转发微博啊，流浪地球？苔总幼年版一个A800八万多转发微博啊，流浪地球？

Picture: [82c654dfly1hd78oj8wt9j20nc0c8tbh.jpg](https://weibo.cn//mblog/pic/MD03HftRz?rl=1)

Github: [github.com/OpenLMLab/MOSSMOSS](https://github.com/OpenLMLab/MOSSMOSS)

#### [电子书《动手学深度学习》第二版预览版面向中文读者的能运行、可讨论的深度学习教科书。作者是一众大佬。含 @蚁工厂](https://weibo.com/2194035935/MD40Qv3Ja)

Note: 电子书《动手学深度学习》第二版预览版面向中文读者的能运行、可讨论的深度学习教科书。作者是一众大佬。含 NumPy/MXNet、PyTorch 和 TensorFlow 实现。被全球 55 个国家 300 所大学用于教学。 

Picture: [82c654dfly1h1hdfvvnfhj21af0u0wiq.jpg](https://weibo.cn//mblog/pic/LptqBA5Jg?rl=1)

#### [手把手教你构建 C 语言编译器“手把手教你构建 C 语言编译器” 这一系列教程将带你从头编写一个 C @蚁工厂](https://weibo.com/2194035935/MD41x27mi)

Note: 手把手教你构建 C 语言编译器“手把手教你构建 C 语言编译器” 这一系列教程将带你从头编写一个 C 语言的编译器。希望通过这个系列，我们能对编译器的构建有一定的了解，同时，我们也将构建出一个能用的 C 语言编译器，尽管有许多语法并不支持。 //:好东西留给程序员//:转发微博好东西留给程序员//:转发微博

Picture: [82c654dfly1h1h0s5stclj20x90qlwl3.jpg](https://weibo.cn//mblog/pic/Lpqykmk54?rl=1)

#### [bark，一个开源的文本转语音的AI模型，生成那种很自然的，模拟正常说话口气的语音。支持多语言，包括 @蚁工厂](https://weibo.com/2194035935/MD8cHxoSt)

Note: bark，一个开源的文本转语音的AI模型，生成那种很自然的，模拟正常说话口气的语音。支持多语言，包括中文（但实测效果很像老外说中文那种腔调..），支持笑、叹息和哭泣等语气生成。还可以支持用A语言的腔调说B语言。地址：github.com/suno-ai/bark体验：huggingface.co/spaces/suno/bark 视频无画面有语音转文字的模型吗？colab玩了下，这个推理太慢了可以，很会起名字

Github: [github.com/suno-ai/bark](https://github.com/suno-ai/bark)

#### [NAT 穿透是如何工作的：技术原理及企业级实践本文翻译自 2020 年的一篇英文博客： How NA @蚁工厂](https://weibo.com/2194035935/MD90qsSF8)

Note: NAT 穿透是如何工作的：技术原理及企业级实践本文翻译自 2020 年的一篇英文博客： How NAT traversal works。设想这样一个问题：在北京和上海各有一台局域网的机器（例如一台是家里的台式机，一 台是连接到星巴克 WiFi 的笔记本），二者都是私网 IP 地址，但可以访问公网， 如何让这两台机器通信呢？既然二者都能访问公网，那最简单的方式当然是在公网上架设一个中继服务器： 两台机器分别连接到中继服务，后者完成双向转发。这种方式显然有很大的性能开销，而 且中继服务器很容易成为瓶颈。有没有办法不用中继，让两台机器直接通信呢？如果有一定的网络和协议基础，就会明白这事儿是可能的。Tailscale 的这篇史诗级长文由浅入深地展示了这种“可能”，如果完全实现本文所 介绍的技术，你将得到一个企业级的 NAT/防火墙穿透工具。 此外，如作者所说，去中心化软件领域中的许多有趣想法，简化之后其实都变成了 跨过公网（互联网）实现端到端直连 这一问题，因此本文的意义并不仅限于 NAT 穿透本身。SD-WAN技术SD-WAN技术

Picture: [82c654dfly1hd8a6dtuj2j20wg1mgtz5.jpg](https://weibo.cn//mblog/pic/MD90qsSF8?rl=1)

#### [Data Structures Reference，这个网站列出了常见数据结构介绍。包括每种数据结构 @蚁工厂](https://weibo.com/2194035935/MD8op1P9M)

Note: Data Structures Reference，这个网站列出了常见数据结构介绍。包括每种数据结构的介绍、图示、常见操作及其时间复杂度、python代码实现参考、常见应用场景等 

Picture: [82c654dfly1hd89h1aphbj20sq0qr0up.jpg](https://weibo.cn//mblog/pic/MD8op1P9M?rl=1)

#### [为了看懂数据库中的类型系统、表达式等知识，同事给我推荐了大名鼎鼎的TAPL（Types and Pr @蚁工厂](https://weibo.com/2194035935/MDagg7F73)

Note: 为了看懂数据库中的类型系统、表达式等知识，同事给我推荐了大名鼎鼎的TAPL（Types and Programming Languages）： ，600多页的大部头，不过目前看到第九章为止感觉还是大体能看得懂的。 

Picture: [61e884f9gy1hd8hm133buj20cc0dwq7k.jpg](https://weibo.cn//mblog/pic/MDaf7t1CT?rl=1)

#### [《从0到1构建计算机》系列博客地址：guosainpu.github.io/archive/?tag @蚁工厂](https://weibo.com/2194035935/MDcgICqd7)

Note: 《从0到1构建计算机》系列博客地址：guosainpu.github.io/archive/?tag=从0到1构建计算机这是作者学习From Nand To Tetris课程的笔记。“这门课程是一门基础性的课程，也是一门常读常新的课程，值得经常回顾和思考。这门课程也是一门很好的入门课程、框架课程（哈佛大学的学生把它戏称为计算机专业101课程），它让我们对计算机科学知识体系有了一个很直观的感受和实践。师傅领进门，如果后续我们对其中的某些方向比较感兴趣，可以再去深入地展开学习和研究。”

Picture: [82c654dfly1h1iesuqb10j20u014jq6v.jpg](https://weibo.cn//mblog/pic/LpDFT9JwQ?rl=1)

#### [【大型语言模型LLM相关资源(论文、开源模型等)列表】’AwesomeLLM - This proj @爱可可-爱生活](https://weibo.com/1402400261/MDaSmiuFs)

Note: 【大型语言模型LLM相关资源(论文、开源模型等)列表】’AwesomeLLM - This project collects awesome resources (e.g., papers, open-source models) for large language model (LLM)' MLNLP GitHub: github.com/MLNLP-World/Awesome-LLM   Awesome

Picture: [5396ee05ly8hd8kfiutn9j20w60u0afc.jpg](https://weibo.cn//mblog/pic/MDaSmiuFs?rl=1)

Github: [github.com/MLNLP-World/Awesome-LLM](https://github.com/MLNLP-World/Awesome-LLM)

#### [【WasmGPT：浏览器里运行的大语言模型聊天机器人，基于Cerebras-GPT-1.3B-Alp @爱可可-爱生活](https://weibo.com/1402400261/MDaP3tDhb)

Note: 【WasmGPT：浏览器里运行的大语言模型聊天机器人，基于Cerebras-GPT-1.3B-Alpaca-SP,，Cerebras-GPT-1.3B 的Alpaca数据集微调版模型】’WasmGPT - Tensor library for machine learning' Aleksey Smolenchuk GitHub: github.com/lxe/wasm-gpt   

Picture: [5396ee05ly8hd8jzoop0tj217k0oywip.jpg](https://weibo.cn//mblog/pic/MDaP3tDhb?rl=1)

Github: [github.com/lxe/wasm-gpt](https://github.com/lxe/wasm-gpt)

#### [，陆奇关于大模型的演讲，读上十遍不为过 很多行业的供需结构会被AI彻底改变，AI赋能超级个体，像教育 @宝玉xp](https://weibo.com/1727858283/MDnFyFMEG)

Note: ，陆奇关于大模型的演讲，读上十遍不为过 很多行业的供需结构会被AI彻底改变，AI赋能超级个体，像教育、医疗、法律和金融等服务业，AI会让很多高端服务逐渐平民化//:陆奇讲的有深度👍请问有没有视频版？//:回复:谢谢分享//:回复:ppt已经确认可以分享，5月北京还有一场现场分享 之后官方会出实录  //:陆奇讲的有深度👍请问有没有视频版？一个新时代的到来 //:回复:谢谢分享//:回复:ppt已经确认可以分享，5月北京还有一场现场分享 之后官方会出实录  //:陆奇讲的有深度👍请问有没有视频版？期待视频版//:回复:谢谢分享//:回复:ppt已经确认可以分享，5月北京还有一场现场分享 之后官方会出实录  //:陆奇讲的有深度👍请问有没有视频版？//:回复:谢谢分享//:回复:ppt已经确认可以分享，5月北京还有一场现场分享 之后官方会出实录  //:陆奇讲的有深度👍请问有没有视频版？mark这个讲的特别好//:回复:谢谢分享//:回复:ppt已经确认可以分享，5月北京还有一场现场分享 之后官方会出实录  //:陆奇讲的有深度👍请问有没有视频版？居然还有雷总

#### [一个教你怎么用ControlNet配合Stable Diffusion将原始视频转成卡通风格的方法。 @宝玉xp](https://weibo.com/1727858283/MDpCVb12O)

Note: 一个教你怎么用ControlNet配合Stable Diffusion将原始视频转成卡通风格的方法。建议有条件的还是油管看原始视频（链接见底部）。这种用视频生成视频的方法并不神秘，分三步：1. 先把原始视频逐帧拆成一系列JPG图片，根据你对质量的要求，可以每秒20张甚至更高。2. 然后把图片都存在一个目录，每一张图用SD + ControlNet逐张生成新的图片，这个过程就可以把原始图片换成新的风格（比如卡通风格）的图片。这个过程中ControlNet可以保证图片布局基本不变，配合模型和Lora可以产生新的图片风格。3. 把生成好的新的图片集合重新生成视频。具体参见视频🔗 www.youtube.com/watch?v=3FZuJdJGFfE 这种实现效率高吗？我用M1 max芯片顶配的笔记本电脑，Stable diffusion生成一张照片需要一分钟//:这种实现效率高吗？这个很有趣，可以给孩子们试试。回复:快快乐乐啦啦啦这个用mj可以替代sd吗看看回复:d-id看起来像是真人拍摄视频然后训练出来模型的，完全不是一个技术路线把世界统统变成二次元吧回复:1024*1024的图，用4080跑euler a30步大概10秒回复:想顺滑就提高帧率，工作量加大就好回复:SD更适合用部署在N卡上我用M1 max芯片顶配的笔记本电脑，Stable diffusion生成一张照片需要一分钟//:这种实现效率高吗？

#### [一种新的盗版搬运视频的套路，就是用AI把原始图片用ControlNet配合Stable Diffus @宝玉xp](https://weibo.com/1727858283/MDpEHp8eR)

Note: 一种新的盗版搬运视频的套路，就是用AI把原始图片用ControlNet配合Stable Diffusion重新生成一遍，既可以让图片更漂亮，又可以规避版权检测。视频中左边是原版  ，右边是AI的版本（twitter.com/sakakibara_sns/status/1649978400143216642），它把提示词权重开的非常低，这样就只是对原始图像做了微调。注意左边的水印洗没了。如何用ControlNet配合Stable Diffusion生成新的视频参考： 应该是逐帧转绘，图生图的时候把 denoising设置的很低，0.3以下。能看出背景还是 有一些晃动和变化的感觉没什么好大的差别啊，右边只是好看一点还是同一个人？AI去水印老本行了回复:前两天还有人在群里发这个，说是ai做的，明显是真人视频啊，原来只是ai盗视频回复:所有人统统回复:泰坦尼克号不是本来就全裸的吗您好，由于您这条视频收到多位大V互动，助您荣登视频号人气榜，知识领域第5名，榜单可在【发现页-视频-视频号人气榜】中展示，快来查看分享你的排名吧~榜单戳》一帧一帧的洗一遍？模特自己美颜也就是这样了这踏马不就是加个滤镜吗，换个角度其实滤镜也算ai的一种啊快抖日常教学。人要知福，惜福，再造福，才最有福

#### [推友Mengxin Liu（twitter.com/liumengxinfly）分享的Prompt技 @宝玉xp](https://weibo.com/1727858283/MDpIq8Gy6)

Note: 推友Mengxin Liu（twitter.com/liumengxinfly）分享的Prompt技巧：“把一个目标按照 SMART (Specific,Measurable,Achievable,Relevant,Time-bound)原则拆分成一个个任务”Prompt：I will give you a target, please split the target into tasks and the tasks must be specific, actionable, measurable, relevant and time bound . Below is my target:🔗 twitter.com/liumengxinfly/status/1650150104354136065回复:这些模板在哪里啊呀？请给个链接可以当个成功学咨询师//:问了问如何一年挣100万，感觉说的都是正确的废话。，大家可以点击试试 问了问如何一年挣100万，感觉说的都是正确的废话。，大家可以点击试试 所有咨询行业的模版都可以用了，让普通人也有机会体验咨询顾问的思维方式。SMART， SWOT，SCQA  STAR，Why-What-How，金字塔原理，享受带入公式的快感。哇学生第一次学到smart啥意思了 类似prompt的价值不止在于指挥AI按照你的想法输出，大家可以看到在这方面的进化很快，超级自动化是很多人能够看到的，但是实现超级自动化的路径在这儿是一个起点

Picture: [66fd066bgy1hdadxopxi8j20qw19gh4j.jpg](https://weibo.cn//mblog/pic/MDpIq8Gy6?rl=1)

#### [推荐阅读《人类替代计划：一份使用 AI 代替同事的指南》我觉得写的挺靠谱的，可以看看什么职业容易替代 @宝玉xp](https://weibo.com/1727858283/MDrB71Iqq)

Note: 推荐阅读《人类替代计划：一份使用 AI 代替同事的指南》我觉得写的挺靠谱的，可以看看什么职业容易替代什么不会，为未来做什么样的职业规划和调整。 回复:作者对各行业的了解非常有限，例如这个：如果不了解风格属于哪个设计师，就没法用这个设计师的名字来描述这一风格。简单的解决方案，就是把设计目标（越详细越好）告诉GPT，让GPT列了10种适合的风格，并简介风格特点，设计师背景。然后人工核实，再选一下。这跟是否了解设计风格，关系就不太大了。回复:写好了记得告诉我下：）嗯，我在写《如何用AI替代我的工作》…在IT领域，你只要跟人打交道，就不会被取代（非客服式问答）转给程序员女儿看看

#### [最新的一篇AI论文：《使用RMT方法让Transformer扩展到100万个token甚至更多》“循 @宝玉xp](https://weibo.com/1727858283/MDsKuv1lA)

Note: 最新的一篇AI论文：《使用RMT方法让Transformer扩展到100万个token甚至更多》“循环记忆Transformer能在多达200万个token之间保留信息。在推理过程中，该模型能有效地利用内存处理多达4096个片段，总长度达到2,048,000个token，这远远超过了之前报道的Transformer模型的最大输入尺寸（CoLT5（Ainslie等人，2023）的64K tokens，以及GPT-4（OpenAI，2023）的32K tokens）。在我们的实验中，这种增强保持了基本模型的内存大小在3.6GB。”太期待了，如果未来GPT能到这个大小，能做的事情就太多了。论文：项目：🔗github.com/booydar/t5-experiments/tree/scaling-report🔗回复 :这里说的是用来做语义相似度匹配的text embedding啥啊，transformer输入也要embeding啊回复 :哇哦，这个好，谢谢兄弟[彩虹屁]卧槽，太恐怖了embedding 即将被历史淘汰了回复:Bard最新上线的直接读取github repo功能你可以试试请问有没有方法可以上传一整个源码，让ChatGPT教我怎么写的回复:围绕AIGC简单聊一聊可以么回复: 非常感谢您的关注，我只是纯粹分享一点知识性的内容，目前对于其他的目前我没有什么想分享的。hello，我们是知名科技媒体公司至顶网，我们旗下有一个栏目叫《码客人生》，专注于记录程序员的百味人生。我们看到您在微博上分享了许多AIGC应用分享心得，对您很感兴趣，想要和您进一步聊一聊。您愿意和我们分享一下么

Picture: [66fd066bgy1hdarao35tpj20ze0vitho.jpg](https://weibo.cn//mblog/pic/MDsKuv1lA?rl=1)

Github: [github.com/booydar/t5-experiments/tree/scaling-report](https://github.com/booydar/t5-experiments/tree/scaling-report)

#### [推荐网站：“AI 论文速递”作者Rick Yu（twitter.com/cosmtrek）有感于 A @宝玉xp](https://weibo.com/1727858283/MDs8EAigq)

Note: 推荐网站：“AI 论文速递”作者Rick Yu（twitter.com/cosmtrek）有感于 AI 发展太快，写了个小项目 BriefGPT，抓取 Arxiv AI 领域论文，通过 GPT 生成中文标题和论文概要，高亮顶会论文，方便快速筛选。目前抓取了 2023 年论文，后面会补充前几年论文。 转发微博唉可惜我们领域好多文章都是不公开的。。。貌似抓去不了。。转发微博挺实用哈哈套娃了属于

Picture: [66fd066bgy1hdaolez18fj21xi1z2hdf.jpg](https://weibo.cn//mblog/pic/MDs8EAigq?rl=1)

#### [这几天看到GPT技术在往两个截然相反的方向发展得越来越离谱了，变化也是真的太快太快了。一个是Auto @宝玉xp](https://weibo.com/1727858283/MC9ZSzb8e)

Note: 这几天看到GPT技术在往两个截然相反的方向发展得越来越离谱了，变化也是真的太快太快了。一个是AutoGPT路线，主打一个AI联网自主行动的能力，面对复杂需求时甚至可以分裂成多个AI协同完成任务。另一个是GPT4ALL，作为开源的LLM模型可以被部署到个人电脑上，不需要网络、Token、API，只接受主人给它的资源，最后形成一个私有化的知识应答系统，任何一台普通配置的电脑都能运行。如果AutoGPT代表的是科幻电影里那种「天网」类型，让AI在无干预的情况下自己解决问题，那么GPT4ALL就是把AI又重新封装到了U盘里，专注于服务私人场景。很多数字骨灰盒都是用了GPT4ALL及相似技术，简单来说就是用个人数据作为语料去训练一个独立的AI工具，然后借助自然语言交互去完成信息的提取。其实我都觉得自己对此有很高的兴趣，我正在尝试跑通一个流程，就是以一份书单（大概几千本）为底，用AutoGPT的方式帮我收集电子版文件，然后全都喂给本地的GPT4ALL，最后写一个最简单的前端页面。那么是不是当我在了解货币政策的时候，随时可以用自然语言去问米塞斯、弗里德曼、伯南克这些大佬？让AI从那些浩瀚如烟的著作里精确的找到并整理出可以解答我的疑问的内容？当我需要论证某种英雄主义的时候，也可以让AI从茨威格、艾萨克森、欧文·斯通这些最负盛名的传记作家里问出对应的人物典故，四舍五入，也就相当于我可以随时调用人类历史里最精粹的创作成果？我觉得最重要的是，LLM可以解决长期困扰大家的一个难点，那就是知识的自由读取，第一我们也许读不了那么多的书，第二读了之后记忆也是抽象的，未必能够随时读取，第三用笔记或者存档这种方式以前也只能支持关键词的精确搜索，如果我的需求是笼统的——比如「米塞斯对德国的货币政策提了那些意见」——搜索就是不管用的，必须要回去翻阅、费力寻找。总之还是挺激动的，等我把这个方案跑通了再跟你们汇报吧。两个方向都很有吸引力。//:部署到本地电脑的这个分支，现在WebLLM已经可以运行GPT到浏览器了//:部署到本地电脑的这个分支，现在WebLLM已经可以运行GPT到浏览器了

#### [这是WebLLM初始化运行视频，你可以看到，打开网页后 ，当你输入第一条聊天消息，就会开始初始化LL @宝玉xp](https://weibo.com/1727858283/MCaN22cGz)

Note: 这是WebLLM初始化运行视频，你可以看到，打开网页后 ，当你输入第一条聊天消息，就会开始初始化LLM，大约需要下载4G的模型文件，然后就可以在浏览器中和WebLLM愉快的离线聊天了，就像浏览器中有一个不需要联网的ChatGPT。在我的Macbook Pro M1上速度很快，但是生成质量还远不及ChatGPT，不过未来可期。  

#### [中国红十字会出品的<日常急救手册> pdf文件本手册是一个指南，它介绍了一些关键的急救技能，比如怎样 @蚁工厂](https://weibo.com/2194035935/MCdvCFDkb)

Note: 中国红十字会出品的<日常急救手册> pdf文件本手册是一个指南，它介绍了一些关键的急救技能，比如怎样处置出血和烧伤。为方便阅读和使用，它提供了简明的文字指示和辅助图片，一步步地教你如何进行急救。 气道梗阻那页有问题

Picture: [82c654dfly1h1bfvc5mdej20u90u0n1n.jpg](https://weibo.cn//mblog/pic/LoH3EtTlx?rl=1)

#### [来了来了它来了，Web LLM让你在浏览器里本地运行大语言模型，有浏览器就能有ChatGPT  教授 @蚁工厂](https://weibo.com/2194035935/MCdOeztBt)

Note: 来了来了它来了，Web LLM让你在浏览器里本地运行大语言模型，有浏览器就能有ChatGPT  教授的团队真棒棒  需要本地显存，Mac的M系列CPU也有相应办法 本地显存.那可是有点贵

Picture: [698da9a7ly8hd142ff4dcj20v91voqg9.jpg](https://weibo.cn//mblog/pic/MCc6tEDcx?rl=1)

#### [分布式领域最重要的一篇论文，到底讲了什么？ 该论文指图灵奖得主Lamport在1978年发表的经典论 @蚁工厂](https://weibo.com/2194035935/MCe0ECBcb)

Note: 分布式领域最重要的一篇论文，到底讲了什么？ 该论文指图灵奖得主Lamport在1978年发表的经典论文，《Time, Clocks, and the Ordering of Events in a Distributed System》。Lamport这篇论文之所以重要，在于它深入到了分布式系统的基础层面，并延伸到宇宙的本质。除了提出「Happened Before」、逻辑时钟、事件偏序等等一系列概念之外，它还划定了系统的能力边界。它告诉我们，什么样的问题可以在系统内部，遵循一个纯异步的模型（asynchronous model）框架就能解决（比如非拜占庭模型下的共识问题）；而什么样的问题，必须求诸系统的“外部”（也就是物理世界）才能得到解决（比如拜占庭模型下的共识问题、线性一致性问题等）。所有这些，都深深地影响了人们对于分布式系统的思考方式。马马

#### [NVIDIA英伟达发布了一篇高分辨率文本生成视频的论文。视频潜在扩散模型LDM（Latent Dif @宝玉xp](https://weibo.com/1727858283/MCMvTq0Wg)

Note: NVIDIA英伟达发布了一篇高分辨率文本生成视频的论文。视频潜在扩散模型LDM（Latent Diffusion Models）利用压缩潜在空间中的扩散模型来生成高分辨率视频。以下是其工作原理的简要概述：1. 在图像数据集上预训练图像LDM。2. 通过添加时间层以模拟视频帧，将图像LDM转换为视频LDM。3. 在编码的视频序列上微调视频LDM，以创建视频生成器。4. 时间上对齐扩散模型的上采样器，以生成高分辨率视频。5. 在真实的512x1024分辨率驾驶视频上验证视频LDM，实现最先进的性能。6. 将该方法应用于创意内容创建中的文本到视频建模。论文：项目： 越来越强了，越来越奇妙了有连续性，但是还不够宝藏老师今日的AI小震撼。回复:这确实是近期看到的最强的一个背景好稳定啊！不会经常变得莫名其妙

#### [微软开源的AI课程：“人工智能系统（System for AI）”课程的中文名称设定为 人工智能系统 @宝玉xp](https://weibo.com/1727858283/MCPOHBPEY)

Note: 微软开源的AI课程：“人工智能系统（System for AI）”课程的中文名称设定为 人工智能系统，主要讲解支持人工智能的计算机系统设计，对应的英文课程名称为 System for AI。课程主要为本科生高年级和研究生设计，帮助学生：完整的了解支持深度学习的计算机系统架构，并通过实际的问题，来学习深度学习完整生命周期下的系统设计。介绍前沿的系统和人工智能相结合的研究工作，包括AI for Systems和Systems for AI，以帮助高年级的本科生和研究生更好的寻找和定义有意义的研究问题。从系统研究的角度出发设计实验课程。通过操作和应用主流和最新的框架、平台和工具来鼓励学生动手实现和优化系统模块，以提高解决实际问题的能力，而不仅仅是了解工具使用。🔗 microsoft.github.io/AI-System/🔗 github.com/microsoft/AI-System转发微博 支持转发微博看看去

Picture: [66fd066bgy1hd5zevvexcj22m21z2kjl.jpg](https://weibo.cn//mblog/pic/MCPOHBPEY?rl=1)

Github: [github.com/microsoft/AI-System](https://github.com/microsoft/AI-System)

#### [来自Alex Xu（畅销书System Design Interview作者）的《系统设计蓝图： 终 @宝玉xp](https://weibo.com/1727858283/MCVuog7cl)

Note: 来自Alex Xu（畅销书System Design Interview作者）的《系统设计蓝图： 终极指南》这是一张蓝图，将系统设计涉及的方方面面完整的表示出来了，但是并未涉及细节。涉及：- LB- Gateway- Communication- CDN- Database- Cache- MQ- ID Generation- Scalability- Availability- More 🔗  回复:Distributed?系统前面应该加个啥定语呢？关键这大佬产量高，日更

Picture: [66fd066bgy1hd6ofqi3lrj230035shdv.jpg](https://weibo.cn//mblog/pic/MCVuog7cl?rl=1)

#### [【Diagram GPT：用自然语言绘制流程图、时序图、类图、用户行程图、甘特图、 C4C 图】'D @爱可可-爱生活](https://weibo.com/1402400261/MCfPcFg6a)

Note: 【Diagram GPT：用自然语言绘制流程图、时序图、类图、用户行程图、甘特图、 C4C 图】'Diagram GPT - Draw flowchart, sequence diagram, class diagram, user journey, gantt, C4C diagram with nature language.' Fraser Xu GitHub: github.com/fraserxu/diagram-gpt   

Picture: [5396ee05ly8hd1kkbu665j21270u0dh9.jpg](https://weibo.cn//mblog/pic/MCfPcFg6a?rl=1)

Github: [github.com/fraserxu/diagram-gpt](https://github.com/fraserxu/diagram-gpt)

#### [【ez-text2vid：轻松运行文本到视频扩散，可定制视频长度、fps和尺寸，支持4GB 显卡/C @爱可可-爱生活](https://weibo.com/1402400261/MChuPBCyN)

Note: 【ez-text2vid：轻松运行文本到视频扩散，可定制视频长度、fps和尺寸，支持4GB 显卡/CPU】'ez-text2vid - Easily run text-to-video diffusion with customized video length, fps, and dimensions on 4GB video cards, as well as on CPU.' K.P. GitHub: github.com/kpthedev/ez-text2video  效果如何

Picture: [5396ee05ly8hd1rw6et1aj20rs0hhwgp.jpg](https://weibo.cn//mblog/pic/MChuPBCyN?rl=1)

Github: [github.com/kpthedev/ez-text2video](https://github.com/kpthedev/ez-text2video)

#### [《性能之巅 第2版》读书笔记（第8章）1、对于应用程序来说，文件系统性能比磁盘性能更为重要，因为应用 @小川CD](https://weibo.com/1202332555/MCies4St7)

Note: 《性能之巅 第2版》读书笔记（第8章）1、对于应用程序来说，文件系统性能比磁盘性能更为重要，因为应用程序交互和等待的是文件系统。为缓解磁盘的延时对应用程序的影响，文件系统通过缓存、缓冲以及异步IO等手段来提高性能。2、文件系统会在后台将一些要写入的数据刷新到磁盘中，可能会导致突然爆发的高延时磁盘IO，这在磁盘设备级的统计信息上会显示。然而，没有任何一个应用程序在等待这些操作完成。3、文件系统通过缓存（caching）提高读性能，通过缓冲（buffering）（在缓存中）提高写性能。4、文件系统一直以来都会顺序和连续地存放文件数据，以努力减少随机I/O的数量。当文件系统未能达成这个目标时，文件的存放变得杂乱无章，顺序的逻辑I/O被拆分成随机的物理I/O，这种情况称为碎片化。5、文件系统可以测量逻辑I/O的访问模式，从中识别出工作负载，然后通过预取或者预读来提高性能。6、如果预取的预测准确，应用程序的顺序读性能将会显著提升。但是如果预测不准，文件系统会发起应用程序不需要的I/O，这不仅会污染缓存，还会消耗磁盘和I/O传输的资源。readahead允许应用程序显式地预热文件系统缓存。7、回写缓存被广泛应用于文件系统，以提高写性能。当数据写入主存后，就认为写入已经成功并返回，之后再异步地把数据刷入磁盘。8、在某些情况下，使用非阻塞I/O是比较适合的，因为它可以避免创建线程带来的额外性能和资源开销。例如：aio、io_uring。9、通过文件系统到内存的方式可以提高文件系统I/O性能，这样可以避免read、write产生的系统调用和上下文切换开销。10、与应用程序I/O相比，磁盘I/O有时显得无关、间接、隐含、缩小或放大。它可能由其他应用程序、其他租户、其他内核任务或管理任务产生。它可能是间接的，例如通过文件系统预读或缓存进行。它可能是隐含的，例如通过内存映射加载/存储来完成。它可能会被缩小，例如通过文件系统缓存、写入抵消、压缩、合并和内存文件系统等方式。它也可能被放大，例如通过元数据、I/O对齐、文件系统日志、奇偶校验和RAID放大等方式。11、许多文件系统支持访问时间戳，可以记录每个文件和目录被访问的时间。这可能会导致读取文件时需要更新元数据，从而使读取变成消耗磁盘I/O资源的写入负载。12、当文件系统装满时，性能会因多种原因下降。在写入新数据时，需要花更多时间和磁盘I/O寻找磁盘上的空闲块。磁盘上的空闲块变得更小、更分散，而更新的I/O和随机的I/O则会影响文件系统的性能。13、Dcache可以提高路径名查找的性能。当遍历路径名时，查找其中的每个名称可以先检查Dcache，直接得到inode的映射，而不用一个一个地在目录中查找。14、基于块的文件系统将数据存储在固定大小的块中，这些块由存储在元数据块中的指针引用。对于大文件，这种方法需要大量块指针和元数据块，并且数据块的分布可能会变得零散，导致随机I/O。15、基于区段的文件系统预先为文件分配连续的空间，提高了元数据的性能，因为需要跟踪的对象更少。16、任何问题都可以进行跨时间段分析，找出最大值和最小值以及与时间相关的变化。平均时延是多少？是否存在高延迟的离群点？操作时延的整体分布是什么样的？17、操作频率是使用负载的最基本特征，而延迟则是其性能结果。延迟的好坏取决于负载、环境和延迟需求。18、让日志文件和数据库文件拥有单独的文件系统和磁盘，可以提高数据库性能。

#### [Monolith：TikTok 背后的推荐系统。在进行的系列博文的一部分，重点介绍对生产 ML 最佳 @网路冷眼](https://weibo.com/1715118170/MCj0P0JmC)

Note: Monolith：TikTok 背后的推荐系统。在进行的系列博文的一部分，重点介绍对生产 ML 最佳实践的开发做出贡献的论文中的见解。🔗 gantry.io/blog/papers-to-know-20230110/ 论文《Monolith: Real Time Recommendation System WithCollisionless Embedding Table》🔗 arxiv.org/pdf/2209.07663.pdf

Picture: [663aa05aly1hd1ylhn3u6j20m80acwf9.jpg](https://weibo.cn//mblog/pic/MCj0P0JmC?rl=1)

#### [CTF快速入门手册地址：github.com/ProbiusOfficial/CTF-QuickSt @蚁工厂](https://weibo.com/2194035935/MClYj8saI)

Note: CTF快速入门手册地址：github.com/ProbiusOfficial/CTF-QuickStart 针对0基础新手编写的CTF快速入门手册。CTF (Capture The Flag)中文一般译作夺旗赛，在网络安全领域中指的是网络安全技术人员之间进行技术竞技的一种比赛形式。 

Github: [github.com/ProbiusOfficial/CTF-QuickStart](https://github.com/ProbiusOfficial/CTF-QuickStart)

#### [【HyperDB：面向LLM应用的超快本地向量数据库，具有高度优化的C++后端向量存储，可通过MKL @爱可可-爱生活](https://weibo.com/1402400261/MCoydeX7v)

Note: 【HyperDB：面向LLM应用的超快本地向量数据库，具有高度优化的C++后端向量存储，可通过MKL BLAS进行硬件加速操作，支持id和元数据等高级功能】'HyperDB - A hyper-fast local vector database for use with LLM Agents. Now accepting SAFEs at $35M cap.' John Dagdelen GitHub: github.com/jdagdelen/hyperDB  目前看来来向量比fine turning 还是更有操作性

Picture: [5396ee05ly8hd2n33qdqej20r20mitam.jpg](https://weibo.cn//mblog/pic/MCoydeX7v?rl=1)

Github: [github.com/jdagdelen/hyperDB](https://github.com/jdagdelen/hyperDB)

#### ['Easydict - 一个简洁优雅的翻译词典 macOS App。开箱即用，支持离线 OCR 识别 @爱可可-爱生活](https://weibo.com/1402400261/MCovSEBll)

Note: 'Easydict - 一个简洁优雅的翻译词典 macOS App。开箱即用，支持离线 OCR 识别，支持有道词典，苹果系统翻译，DeepL，谷歌，百度和火山翻译。A concise and elegant Dictionary and Translator macOS App for looking up words and translating text.' Tisfeng GitHub: github.com/tisfeng/Easydict 

Picture: [5396ee05ly1hd2mw5x4c7j22ni1puhdw.jpg](https://weibo.cn//mblog/pic/MCovSEBll?rl=1)

Github: [github.com/tisfeng/Easydict](https://github.com/tisfeng/Easydict)

#### [加速计算： To speed-up compute-intensive parts of an ap @WinnieS的微博](https://weibo.com/2144454703/MDrL3DD1V)

Note: 加速计算： To speed-up compute-intensive parts of an applicationsoftware 2.0 ：用模型替代 编程语言 （大模型，也许改变趋势，代码行数未必减少了... ... 但是模型消耗的资源肯定是超过 普通的C语言了）看看这两种产品定位，那个更正确吧 

Picture: [7fd1c82fgy1hdamusgw24j21460k6nav.jpg](https://weibo.cn//mblog/pic/MDrL3DD1V?rl=1)

#### [🔥Scaling Transformer to 1M tokens and beyond with  @AMiner学术头条](https://weibo.com/1870858943/MDreOp6Bi)

Note: 🔥Scaling Transformer to 1M tokens and beyond with RMT 查看原文Aydar Bulatov, Yuri Kuratov, Mikhail S. BurtsevAI综述：这篇技术报告介绍了如何用一种叫做Recurrent Memory Transformer的架构来扩展BERT模型的上下文长度，达到了前所未有的两百万个标记，并且保持了高的内存检索精度。这种方法可以存储和处理局部和全局信息，并通过使用循环使输入序列的各个段之间的信息流动。实验证明了这种方法的有效性，具有显著的潜力，可以提高自然语言理解和生成任务中长期依赖处理的能力，同时为内存密集型应用程序实现大规模上下文处理提供可能。

Picture: [6f830abfly1hdaknsagioj20lu0jhwjd.jpg](https://weibo.cn//mblog/pic/MDreOp6Bi?rl=1)

#### [Deep Transfer Learning Applications in Intrusion D @AMiner学术头条](https://weibo.com/1870858943/MDtG0djjB)

Note: Deep Transfer Learning Applications in Intrusion Detection Systems: A Comprehensive Review Hamza Kheddar, Yassine Himeur, Ali Ismail AwadAI综述：本文主要介绍了深度转移学习（DTL）在入侵检测系统（IDS）中的应用，特别是在工业控制网络中的应用。文章介绍了最新的人工智能技术，特别是DTL技术的应用，以及相关的数据集、评估指标等信息。通过本文，读者可以了解在不同类型网络中使用DTL的最新研究现状，以及相关的算法和方法。

Picture: [6f830abfly1hdavfjkg86j20nx0n84bg.jpg](https://weibo.cn//mblog/pic/MDtG0djjB?rl=1)

#### [今天公众号有一篇文章《Midjourney：伟大的公司只需要十一人》蛮火的现在MidJourney的 @宝玉xp](https://weibo.com/1727858283/MDLe1irnG)

Note: 今天公众号有一篇文章《Midjourney：伟大的公司只需要十一人》蛮火的现在MidJourney的Discord服务器有一千四百多万人，而MJ的员工只有11个人！推友orange.ai写了一篇读后感：《Midjourney ，在旅途中你看到了什么风景？》两篇都推荐一下。去年8月份也有一份CEO的采访记录：创始人David没有找投资，但是因为他之前有过创业经历，信誉度很好，刚开始做MJ的时候，找云供应商申请GPU，一下子就给了1万个GPU。MJ训练的图像来源是从互联网抓取的，确实存在版权上的争议。大部分艺术家对此表示积极态度，说能让他们更高效。图像训练一次的成本大约要5W美元，但是需要十次二十次训练才能达到理想的效果。他们大量利用用户“喜欢”的生成结果来标注他们的模型结果，让生成效果更好。之所以用Discord，一个主要原因是他们发现用户不知道自己想要什么，但是放在一个Discord这样的聊天群中，用户之间能相互激发灵感相互学习。将生成的图片和用户的名字挂钩，使用的时候就会规范很多，能有效减少暴力血腥图片的产生。在生成名人照片时，会有一定的风格和外观，以避免深度伪装。那段时间的矿场倒闭潮应该也有影响吧国外云基建更为友好，分工更为精细，才能释放程序员最大的创新价值。但也要看到这11个人的履历至少在国内，大部分画师都表达的是消极态度，甚至用拼接成的尸块去形容。转发微博回复:不无可能回复:这种情况通常无需太多的人，而是要一个灵魂人物——他的关键思想或方法是成败决定性因素。那段时间的矿场倒闭潮应该也有影响吧小而美的公司是不是因为这种AI创业不需要太多软件开发的人，所以规模可以这么小？国内这就得从头开始做app 一年之后见了已关注您，互关吗

Picture: [66fd066bgy1hdczb9udbbj20u00fewfp.jpg](https://weibo.cn//mblog/pic/MDLe1irnG?rl=1)

#### [【Understanding IEEE 754 - Decimals Numbers in Comp @网路冷眼](https://weibo.com/1715118170/MCsCwws9c)

Note: 【Understanding IEEE 754 - Decimals Numbers in Computers】🔗 www.youtube.com/watch?v=j-tz_OohSR4&feature=youtu.be 了解 IEEE 754 - 计算机中的小数。 

Picture: [663aa05aly8hd3525ud1mj20x00ikwes.jpg](https://weibo.cn//mblog/pic/MCsCwws9c?rl=1)

#### [《Harnessing the Power of LLMs in Practice》 这篇论文来自A @宝玉xp](https://weibo.com/1727858283/MDUwY5WAF)

Note: 《Harnessing the Power of LLMs in Practice》 这篇论文来自Amazon 和 Texas A&M University ，他们整理了一个大语言模型的进化树，从Transformer分出来的三个分支：Encoder Only，Encode-Decoder，Decoder Only，最后以ChatGPT为代表的Decoder Only做成了，而以Google BERT为代表的Encoder Only全部被淘汰了。选对方向多么重要……完整的论文解析推荐看 indigo（twitter.com/indigo11）的推文🐦twitter.com/indigo11/status/1651427761813327872🐦🧵推荐我们组Jingfeng的总结，他可是真正训练过很多年LLM的人宝玉你好，请问你知道有没有LLM在做summarization的时候给出summary里每句话的source？在没有成功之前，大家都只是在参与一场「赌局」回复:谢谢！回复:回复:感谢。试了一下发现可以让gpt-4:1）给每句话打标； 2）做总结；3）给出总结里每句话的source。我还有个疑问是，chatgpt里的session功能是可以在api里实现的吗？还是每次api call都视作一个新session？不用那么麻烦，可以找我教你回复:你可以在prompt里面要求：总结三个要点，每个要点带上source，如果效果不好就给它一个示例宝玉你好，请问你知道有没有LLM在做summarization的时候给出summary里每句话的source？回复:看过 jingfeng 2 月份写的对 gpt reproduction 的思考，很有启发所以百度文心还能搞下去吗在没有成功之前，大家都只是在参与一场「赌局」//:回复: //:推荐我们组Jingfeng的总结，他可是真正训练过很多年LLM的人

#### [吴恩达和OpenAI携手推出了一门免费的Prompt Engineering（提示工程师）课程，旨在 @宝玉xp](https://weibo.com/1727858283/ME3Kv74Xj)

Note: 吴恩达和OpenAI携手推出了一门免费的Prompt Engineering（提示工程师）课程，旨在为AI开发者们提供一个全面而深入的学习平台。该课程内容涵盖了如何书写高质量的AI提示词，以及如何利用GPT-3的先进技术开发一个高效、智能的AI聊天机器人。无论你是初学者还是经验丰富的专业人士，该课程都将为你提供一种系统而有效的学习方法。课程地址： 网友歸藏（twitter.com/op7418）翻译了双语字幕：//:谢谢分享//:有大神已经把课程视频添加上中文字幕了。传送门:回复:看我推荐的另一个字幕翻译的，可以搜索我首页发现原链接提供了英文transcript，打开后，就可以用之前博主推荐的沉浸式翻译插件来翻译了。但由于transcript是字幕式分段的，翻译效果并不好，仅供辅助理解吧然而只有第一集。。继续啃生肉去回复:老哥真牛逼👍回复:你得学会搜索，比如在博主这里搜字幕两字，虽然不知道你要什么，但是不出来你想要的我吃了屏幕。我记得博主前几天推荐过一个基于chatGPT的视频字幕翻译工具，找不着了，博主还能推荐一下吗？谢谢！

#### [【Scoped Sensitive Programming : a new open source  @网路冷眼](https://weibo.com/1715118170/MCMgewifj)

Note: 【Scoped Sensitive Programming : a new open source C++ template library】🔗 github.com/erangithub/scoped Scoped Sensitive Programming：一个新的开源 C++ 模板库。 

Picture: [663aa05aly8hd5jrntxu9j20ou2m4wsq.jpg](https://weibo.cn//mblog/pic/MCMgewifj?rl=1)

Github: [github.com/erangithub/scoped](https://github.com/erangithub/scoped)

#### [【7 Python API Best Practices You Should Follow】🔗 t @网路冷眼](https://weibo.com/1715118170/MCOCmjziO)

Note: 【7 Python API Best Practices You Should Follow】🔗 technicbate.blogspot.com/2023/04/python-api-best-practices.html 您应该遵循的 7 个 Python API 最佳实践。 

#### [【MMC4: An open, billion-scale corpus of images int @网路冷眼](https://weibo.com/1715118170/MCU7k6mAc)

Note: 【MMC4: An open, billion-scale corpus of images interleaved with text】🔗 github.com/allenai/mmc4 MMC4：一个开放的、十亿规模的图像与文本交错的语料库。 

Picture: [663aa05aly8hd6ig9at4aj211x0autan.jpg](https://weibo.cn//mblog/pic/MCU7k6mAc?rl=1)

Github: [github.com/allenai/mmc4](https://github.com/allenai/mmc4)

#### [高速印刷电路板 (PCB) 设计指南。如其名称所示，高速印制电路板设计提供了高速信号传输。换句话说， @网路冷眼](https://weibo.com/1715118170/MCUo5CBFV)

Note: 高速印刷电路板 (PCB) 设计指南。如其名称所示，高速印制电路板设计提供了高速信号传输。换句话说，拥有高速设计PCB的设备可以以非常高的速率传输数据。这种能力为工程师和制造商开启了许多机会，帮助他们创建最先进的电子解决方案。然而，这也在开发阶段带来了一些困难，主要涉及信号在板上传播时的完整性。您可以通过选择正确的PCB材料来缓解完整性问题，但仍可能面临一些严重的挑战，包括：电磁干扰（EMI）；信号传播延迟；串扰；信号退化。通常被接受的PCB设计标准并不总是适用于高速设计。有一些特殊的高速PCB布局技术可以简化设计过程，并帮助您避免潜在的问题。我们稍后将讨论这些技术，但首先让我们指出一个高速PCB的主要特点。🔗 www.pcb-hero.com/blogs/lickys-column/high-speed-printed-circuit-board-pcb-design-guidelines

Picture: [663aa05aly1hd6jmtay2zj20k50fi0uc.jpg](https://weibo.cn//mblog/pic/MCUo5CBFV?rl=1)

#### [【Open-Source Graphic Rendering on Programmable RIS @网路冷眼](https://weibo.com/1715118170/MCVGO1D4r)

Note: 【Open-Source Graphic Rendering on Programmable RISC-V GPUs】🔗 dl.acm.org/doi/pdf/10.1145/3582016.3582024 可编程 RISC-V GPU 上的开源图形渲染。 

Picture: [663aa05aly8hd6pe5jqh2j20i40ng77u.jpg](https://weibo.cn//mblog/pic/MCVGO1D4r?rl=1)

#### [构建  增强型 Python REPL。“在此博客中，我分享了我在构建使用 ChatGPT 增强的  @网路冷眼](https://weibo.com/1715118170/MD0c786eD)

Note: 构建  增强型 Python REPL。“在此博客中，我分享了我在构建使用 ChatGPT 增强的 Python REPL 方面的经验。 我探索了应用程序的构建方式，并推测了在基于大型语言模型 (LLM) 构建的系统中可能出现的软件工程模式和范例。”🔗 isthisit.nz/posts/2023/building-a-chat-gpt-enhanced-python-repl/

Picture: [663aa05aly1hd79957y75j20v00sgn09.jpg](https://weibo.cn//mblog/pic/MD0c786eD?rl=1)

#### [【How to Master Programming: Top Free Courses to He @网路冷眼](https://weibo.com/1715118170/MDg7dAZrh)

Note: 【How to Master Programming: Top Free Courses to Help You Begin Your Journey】🔗 medium.com//how-to-master-programming-top-free-courses-to-help-you-begin-your-journey-bebac6eb56e7 如何掌握编程：顶级免费课程助您开启编程之旅。 

#### [使用 Fish shell 和 Tmux 的终极 shell 设置（第 1 部分）【My ultim @网路冷眼](https://weibo.com/1715118170/MDnuqbqTv)

Note: 使用 Fish shell 和 Tmux 的终极 shell 设置（第 1 部分）【My ultimate shell setup with Fish shell and Tmux (Part 1)】🔗 www.milanvit.net/post/my-ultimate-shell-setup-with-fish-shell-and-tmux/。 

Picture: [663aa05aly1hda44dl8dwj21400u0tnm.jpg](https://weibo.cn//mblog/pic/MDnuqbqTv?rl=1)

#### [【Python Monorepo: an Example. Part 1: Structure an @网路冷眼](https://weibo.com/1715118170/MDEtdcaHC)

Note: 【Python Monorepo: an Example. Part 1: Structure and Tooling】🔗 www.tweag.io/blog/2023-04-04-python-monorepo-1/ Python Monorepo：一个例子。 第 1 部分：结构和工具。 

#### [【Revisiting the Fast Inverse Square Root – Is It S @网路冷眼](https://weibo.com/1715118170/MDMjTj2hZ)

Note: 【Revisiting the Fast Inverse Square Root – Is It Still Useful?】🔗 hllmn.net/blog/2023-04-20_rsqrt/重新审视快速反平方根算法 - 它仍然有用吗？ 

Picture: [663aa05aly8hdd5qt7dx3j20go0dcaaf.jpg](https://weibo.cn//mblog/pic/MDMjTj2hZ?rl=1)

#### [【Modular: The world's fastest unified matrix multi @网路冷眼](https://weibo.com/1715118170/MDWxb9ryt)

Note: 【Modular: The world's fastest unified matrix multiplication】🔗 www.modular.com/blog/the-worlds-fastest-unified-matrix-multiplication 模块化：世界上最快的统一矩阵乘法。 

Picture: [663aa05aly8hdeeu6wm12j219v0u042h.jpg](https://weibo.cn//mblog/pic/MDWxb9ryt?rl=1)

#### [【Career advice no one gave me: Give a lot of notic @网路冷眼](https://weibo.com/1715118170/ME2P7pGmc)

Note: 【Career advice no one gave me: Give a lot of notice when you quit】🔗 davidlaprade.github.io/give-a-lot-of-notice 没有人给我的职业建议：辞职时要多加注意。 

#### [【Writing Portable ARM64 Assembly】🔗 ariadne.space/2 @网路冷眼](https://weibo.com/1715118170/MEbsE73zq)

Note: 【Writing Portable ARM64 Assembly】🔗 ariadne.space/2023/04/13/writing-portable-arm64-assembly/ 编写可移植的 ARM64 汇编。 

Picture: [663aa05aly8hdg8qj4aahj20rs1qudta.jpg](https://weibo.cn//mblog/pic/MEbsE73zq?rl=1)

#### [[LG]《Long-term Forecasting with TiDE: Time-series  @爱可可-爱生活](https://weibo.com/1402400261/MDpB3AmM8)

Note: [LG]《Long-term Forecasting with TiDE: Time-series Dense Encoder》A Das, W Kong, A Leach, R Sen, R Yu [Google Research & Google Cloud] (2023)   

Picture: [5396ee05ly1hdad9i4ws4j21do0g8n7e.jpg](https://weibo.cn//mblog/pic/MDpB0D3l9?rl=1)

#### [[CL]《Scaling Transformer to 1M tokens and beyond w @爱可可-爱生活](https://weibo.com/1402400261/MDyQfeeZr)

Note: [CL]《Scaling Transformer to 1M tokens and beyond with RMT》A Bulatov, Y Kuratov, M S. Burtsev [DeepPavlov] (2023)   

Picture: [5396ee05ly1hdbhvjrn2yj21ee0no7jx.jpg](https://weibo.cn//mblog/pic/MDyQcke81?rl=1)

#### ['Torchhd - Torchhd is a Python library for Hyperdi @爱可可-爱生活](https://weibo.com/1402400261/MDESthtyq)

Note: 'Torchhd - Torchhd is a Python library for Hyperdimensional Computing and Vector Symbolic Architectures' hyperdimensional-computing GitHub: github.com/hyperdimensional-computing/torchhd   

Picture: [5396ee05ly8hdc8vpfdnnj21600u078t.jpg](https://weibo.cn//mblog/pic/MDESthtyq?rl=1)

Github: [github.com/hyperdimensional-computing/torchhd](https://github.com/hyperdimensional-computing/torchhd)

#### [【HuggingChat：HuggingFace的开源大型语言模型(LLM)及在线聊天服务，目前不支 @爱可可-爱生活](https://weibo.com/1402400261/MDJy0FlwC)

Note: 【HuggingChat：HuggingFace的开源大型语言模型(LLM)及在线聊天服务，目前不支持中文回答】“HuggingChat - Making the best open source AI chat models available to everyone”   

Picture: [5396ee05ly8hdctgmbw4sj213c0u0q47.jpg](https://weibo.cn//mblog/pic/MDJy0FlwC?rl=1)

#### [【LaMini-LM: 从 ChatGPT 蒸馏的小型、高效的语言模型集合，在2.58 M 指令大规 @爱可可-爱生活](https://weibo.com/1402400261/MDLi52ZVE)

Note: 【LaMini-LM: 从 ChatGPT 蒸馏的小型、高效的语言模型集合，在2.58 M 指令大规模数据集上进行训练】'LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions - LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions' MBZUAI NLP department GitHub: github.com/mbzuai-nlp/LaMini-LM  

Picture: [5396ee05ly8hdd14h5ubsj215l0u0q7r.jpg](https://weibo.cn//mblog/pic/MDLi52ZVE?rl=1)

Github: [github.com/mbzuai-nlp/LaMini-LM](https://github.com/mbzuai-nlp/LaMini-LM)

#### [【killport：快速杀掉监听特定端口的进程】’killport - A command-line @爱可可-爱生活](https://weibo.com/1402400261/MDLnyecrr)

Note: 【killport：快速杀掉监听特定端口的进程】’killport - A command-line tool to easily kill processes running on a specified port.' Francisco Jiménez Cabrera GitHub: github.com/jkfran/killport   

Picture: [5396ee05ly8hdd1kzhvpoj216d0u00vu.jpg](https://weibo.cn//mblog/pic/MDLnyecrr?rl=1)

Github: [github.com/jkfran/killport](https://github.com/jkfran/killport)