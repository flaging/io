# 模型部署和加速

## 训练

### 训练框架

#### [Deepspeed](https://github.com/microsoft/DeepSpeed)

[DeepSpeed Chat: 一键式RLHF训练，让你的类ChatGPT千亿大模型提速省钱15倍](https://aijishu.com/a/1060000000397639)
* Deepspeed框架的[Chat模型训练实例](https://github.com/microsoft/DeepSpeedExamples/tree/master/applications/DeepSpeed-Chat).

[一文详解解 DeepSpeed](https://mp.weixin.qq.com/s/NYHTsxZZ7-DN7rfYPjTogQ?v_p=90&WBAPIAnalysisOriUICodes=10000001&wm=3333_2001&aid=01A2GUVvCiJ0bN45VH0AOVftc20OVPaYUZmVa1h1s_8-8xrdg.&from=10D5193010)

[一键式 RLHF 训练 DeepSpeed Chat（一）：理论篇](https://mp.weixin.qq.com/s/t5lT1NIZ6TysfgJks7kYKA?v_p=90&WBAPIAnalysisOriUICodes=10000001&wm=3333_2001&aid=01A2GUVvCiJ0bN45VH0AOVftc20OVPaYUZmVa1h1s_8-8xrdg.&from=10D5193010)

[DeepSpeed Inference: Enabling Efficient Inference of Transformer Models at Unprecedented Scale](https://arxiv.org/abs/2207.00032)

[DeepSpeed Compression: A composable library for extreme compression and zero-cost quantization](https://www.microsoft.com/en-us/research/blog/deepspeed-compression-a-composable-library-for-extreme-compression-and-zero-cost-quantization/)

[NLP大规模语言模型微调实践：DeepSpeed+Transformers实现简单快捷上手百亿参数模型微调](https://mp.weixin.qq.com/s/thlnokFT495NMOzC08FInw)

[人手一个 ChatGPT，微软 DeepSpeed Chat 震撼发布，一键 RLHF 训练千亿级大模型](https://www.ithome.com/0/686/048.htm)

[DeepSpeed-Chat：最强ChatGPT训练框架，一键完成RLHF训练！](https://mp.weixin.qq.com/s/CCFpr9rfpFmwHFLB29KGCg)

[使用DeepSpeed/P-Tuning v2对ChatGLM-6B进行微调](https://mp.weixin.qq.com/s/5Zx3I39cPzfWt-HN_e-jFw)

[ChatGLM_multi_gpu_zero_Tuning](https://github.com/CSHaitao/ChatGLM_mutli_gpu_tuning)

[【DeepSpeed 教程翻译】二，Megatron-LM GPT2，Zero 和 ZeRO-Offload](https://mp.weixin.qq.com/s/UO7bLghblw-uoErSnnQyEQ)

[【DeepSpeed 教程翻译】开始，安装细节和CIFAR-10 Tutorial](https://mp.weixin.qq.com/s/xpNQtl7hPs3fy9S7VRbIkg)

[DeepSpeed结合Megatron-LM训练GPT2模型笔记（上）](https://mp.weixin.qq.com/s?__biz=MzA4MjY4NTk0NQ==&mid=2247509973&idx=1&sn=556bdac8e4d35ae44e426e3032525fd8&chksm=9f831d43a8f49455d53b36220088baeccdba661b68d0ae9fa86b64e8025554d7bfb19537b599&scene=178&cur_album_id=2961704839032373253#rd)

[如何使用 Ray + DeepSpeed + HuggingFace 简单、快速、高效、高性价比地微调和部署大型语言模型](https://mp.weixin.qq.com/s/oJVTnStufXheobXvpVB8cQ)

### 数据并行

### 模型并行

### 流水并行

## ~~推理~~

### 推理框架

### 量化

### 剪枝

### 蒸馏

## 深度学习编译器

[如何开发编译器?](https://www.zhihu.com/question/28862935/answer/3049912195)
* 旷视编译器介绍
* 编译器最重要的两个概念是IR和PASS
* 前端优化方法
  * node level:去掉无用节点,替换搞笑节点
  * block level:代数简化,算子融合
  * dataflow level:静态内存优化
* 后端优化(见下图)
  * 通用优化:循环展开/循环融合/访存掩盖
  * 硬件优化:指令映射(gemm)/向量化(循环)/手工kernel
* MEGCC编译过程
  * Megengine导入模型并静态图优化
  * 转换为MLIR的MGB IR
  * 生成Abstract Kernel IR,最终转换成Kernel IR
  * 导出为runtime model和runtime kernel

![后端优化](../pics/back_end_optim.jpg)