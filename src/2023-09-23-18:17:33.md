

#### [电子书《A Commentary on the Sixth Edition Unix Operati @蚁工厂](https://weibo.com/2194035935/N2FpS0UU2)

Note: 电子书《A Commentary on the Sixth Edition Unix Operating System》Unix v6 操作系统评注地址：warsus.github.io/lions-/ 这本书以UNIX v6 的代码为例来讲解操作系统。屏幕分两列，一列是文档，一列是源代码，可以互相对照。 这个好

Picture: [82c654dfly1h2mznrma4nj20xl0edtap.jpg](https://weibo.cn//mblog/pic/LuWMNw4RR?rl=1)

#### [斯坦福NLP课程讲解这是ShowMeAI为斯坦福CS224n《自然语言处理与深度学习(Natural @蚁工厂](https://weibo.com/2194035935/N2vDQ4AbU)

Note: 斯坦福NLP课程讲解这是ShowMeAI为斯坦福CS224n《自然语言处理与深度学习(Natural Language Processing with Deep Learning)》课程的全部课件，做了中文翻译和注释。CS224n是顶级院校斯坦福出品的深度学习与自然语言处理方向专业课程。核心内容覆盖RNN、LSTM、CNN、transformer、bert、问答、摘要、文本生成、语言模型、阅读理解等前沿内容。

Picture: [82c654dfly1h2mpdwsxs0j20pm14tjy5.jpg](https://weibo.cn//mblog/pic/LuUsyoM4T?rl=1)

#### [吴恩达在推特上宣布了三门新的生成式AI课程，适合开发者进行学习，为迎接AI浪潮做准备：1、使用Ope @宝玉xp](https://weibo.com/1727858283/N3hLde3O9)

Note: 吴恩达在推特上宣布了三门新的生成式AI课程，适合开发者进行学习，为迎接AI浪潮做准备：1、使用OpenAI的ChatGPT API构建系统：超越单个提示，学习构建使用多个API调用LLM的复杂应用。同时，学习评估LLM的输出以确保安全性和准确性，并驱动迭代改进。2、LangChain用于LLM应用开发：学习这个强大的开源工具，用于构建使用LLM的应用，包括聊天机器人的记忆，文档上的问题回答，以及可以决定下一步采取什么行动的LLM代理。3、扩散模型如何工作：学习扩散模型的技术细节，这些模型支持Midjourney，DALL·E 2，和Stable Diffusion。你也会得到生成自己的视频游戏精灵的Jupyter工作代码！学习链接：也可以关注 随后会他上中文字幕版本！第三集：宝玉xp:第二集： //:第一集发布了： //:字幕制作中//：第二集： //：字幕制作中nb

Picture: [001MabKgly1heigqmos3fj60wm1fc1kx02.jpg](https://weibo.cn//mblog/pic/N3fHMqpH3?rl=1)

#### [[CL]《Aligning Large Language Models through Synthe @爱可可-爱生活](https://weibo.com/1402400261/N2jxNDpVz)

Note: [CL]《Aligning Large Language Models through Synthetic Feedback》S Kim, S Bae, J Shin, S Kang, D Kwak, K M Yoo, M Seo [NAVER Cloud] (2023)   

Picture: [5396ee05ly1hebbxc7pgyj20lw17capq.jpg](https://weibo.cn//mblog/pic/N2jxLhK50?rl=1)

#### [[CL]《Gorilla: Large Language Model Connected with  @爱可可-爱生活](https://weibo.com/1402400261/N2jA1jj9s)

Note: [CL]《Gorilla: Large Language Model Connected with Massive APIs》S G. Patil, T Zhang, X Wang, J E. Gonzalez [UC Berkeley & Microsoft Research] (2023)   

Picture: [5396ee05ly1hebc4bbx8zj21dy0wqkeo.jpg](https://weibo.cn//mblog/pic/N2jzVpMhG?rl=1)

#### [【你一直想知道的关于数学的一切：此书由布兰登·W·沙利文(Brendan W. Sullivan)撰 @爱可可-爱生活](https://weibo.com/1402400261/N2kLjnTfO)

Note: 【你一直想知道的关于数学的一切：此书由布兰登·W·沙利文(Brendan W. Sullivan)撰写，他是CMU数学科学系的博士生，这本书也是他博士论文的一部分。此书的目的是引导读者进入抽象数学和证明写作的世界，帮助他们培养数学思维和表达能力。主要内容分为两部分：学习数学思维和学习数学主题。每一部分包含几个章节，每个章节都有定义、定理、例子、练习和小测验，涵盖了集合、逻辑、归纳法、关系、函数、基数和组合数学等主题，这些主题是抽象数学的基础和工具。该书风格轻松幽默，既有严谨的证明，也有趣味性的问题，旨在激发读者的兴趣和好奇心】《Everything You Always Wanted To Know About Mathematics - A Guided Journey Into the World of Abstract Mathematics and the Writing of Proofs》by Brendan W. Sullivan  太好了，可以重新训练写严谨的证明已经开始读了 我想问为啥都艾特我的印象笔记？要是有中文版就更好了 

Picture: [5396ee05ly8hebhfgu7ttj20ss0uqtbi.jpg](https://weibo.cn//mblog/pic/N2kLjnTfO?rl=1)

#### [【最新的Chatbot匿名竞技场排行公布：新增了PaLM 2、Claude-instant-v1等参 @爱可可-爱生活](https://weibo.com/1402400261/N2l2GamUM)

Note: 【最新的Chatbot匿名竞技场排行公布：新增了PaLM 2、Claude-instant-v1等参与竞技，GPT-4、Claude-v1、Claude-instant-v1意料之中地牢牢占据前三位，PaLM 2刚一亮相就表现不俗，Vicuna-13B、Vicuna-7B、Koala-13B目前领跑开源赛区】《Chatbot Arena Leaderboard Updates (Week 4) | LMSYS Org》  

Picture: [5396ee05ly8hebijzaj1gj20u00u0wi0.jpg](https://weibo.cn//mblog/pic/N2l2GamUM?rl=1)

#### [【The-Compiler：Tree of Thoughts(ToT)范式下的新项目，目的是使自主编 @爱可可-爱生活](https://weibo.com/1402400261/N2mRnmAPR)

Note: 【The-Compiler：Tree of Thoughts(ToT)范式下的新项目，目的是使自主编程不仅成为现实，而且对你来说是一个轻松的任务】'The-Compiler - Seed, Code, Harvest: Grow Your Own App with Tree of Thoughts!' Eternal Reclaimer GitHub: github.com/kyegomez/the-compiler    代码还有bug

Picture: [5396ee05ly8hebqmie4blj20u01530xd.jpg](https://weibo.cn//mblog/pic/N2mRnmAPR?rl=1)

Github: [github.com/kyegomez/the-compiler](https://github.com/kyegomez/the-compiler)

#### [Sophia: A Scalable Stochastic Second-order Optimiz @AMiner学术头条](https://weibo.com/1870858943/N2nD0h4zR)

Note: Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training ChatPaper综述：这篇文章介绍了Sophia，一个可扩展的随机二阶优化器，用于语言模型预训练。文章指出语言模型预训练的成本巨大，优化算法的非微小改进会导致训练时间和成本的大幅减少。作者提出的Sophia优化器是一个简单可扩展的二阶优化器，使用对角Hessian的轻量级估计作为预处理器。该文论证了Sophia的效率，并提出了Sophia适应不同参数组件曲率的理论。作者在使用GPT-2模型进行语言建模的实验中表明，Sophia比Adam在步骤数量、总计算量和墙时钟时间方面都实现了2倍的加速。文章的主要问题是如何提高语言模型预训练的效率和降低成本。

Picture: [6f830abfly1hebu2jvli5j20y70v61bo.jpg](https://weibo.cn//mblog/pic/N2nD0h4zR?rl=1)

#### [吴恩达和OpenAI合作的新的“Building Systems with the ChatGPT  @宝玉xp](https://weibo.com/1727858283/N3pfz4TzW)

Note: 吴恩达和OpenAI合作的新的“Building Systems with the ChatGPT API | 使用ChatGPT API构建系统”的课程的第三课《Evaluate Inputs: Moderation | 输入评估： 审查》 课程地址： B站地址： B站合集：   个人觉得Azure在企业安全上应该更专业好的，感谢宝玉老师的解答，这里还有个担忧，之前 opanai 有出现过数据隐私泄露问题，所以我理解 prompt 是不是也有泄露可能，基于数据隐私考虑公司线上使用的话还是优先考虑 用微软的 azure 比较靠谱？回复:网络协议里面（http请求的内容里面）最好不要放prompt，不然一抓包就看到了“不要明文传输你的Prompt” 请问这个咋理解呢？先和gpt约定密钥吗？然后再aes加密？

#### [【CaMA: 一种支持中英语言的LLaMA模型，通过全量预训练和指令微调提高了中文理解能力、知识储备 @爱可可-爱生活](https://weibo.com/1402400261/N2HdamMod)

Note: 【CaMA: 一种支持中英语言的LLaMA模型，通过全量预训练和指令微调提高了中文理解能力、知识储备和指令理解能力】’CaMA: A Chinese-English Bilingual LLaMA Model - CaMA: A Chinese-English Bilingual LLaMA Model.' ZJUNLP GitHub: github.com/zjunlp/CaMA   

Picture: [5396ee05ly8hee8jdvwgnj20vt0u0wjx.jpg](https://weibo.cn//mblog/pic/N2HdamMod?rl=1)

Github: [github.com/zjunlp/CaMA](https://github.com/zjunlp/CaMA)

#### [【Axolotl：一个用于微调的代码库，支持使用不同的模型和注意力机制进行微调】'Axolotl - @爱可可-爱生活](https://weibo.com/1402400261/N2Hkan1Da)

Note: 【Axolotl：一个用于微调的代码库，支持使用不同的模型和注意力机制进行微调】'Axolotl - Go ahead and axolotl questions' OpenAccess-AI-Collective GitHub: github.com/OpenAccess-AI-Collective/axolotl     

Picture: [5396ee05ly8hee8sssm1kj212g0u077k.jpg](https://weibo.cn//mblog/pic/N2Hkan1Da?rl=1)

Github: [github.com/OpenAccess-AI-Collective/axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)

#### [【ToolBench：一个开放平台，用于训练、服务和评估大型语言模型，用于工具学习。支持单工具和多工 @爱可可-爱生活](https://weibo.com/1402400261/N2IuD1K8L)

Note: 【ToolBench：一个开放平台，用于训练、服务和评估大型语言模型，用于工具学习。支持单工具和多工具场景，并提供包括模型的思维过程、工具执行和执行结果在内的响应，提供了数据集、相应的训练和评估脚本，以及在 ToolBench 上进行微调的功能强大的模型 ToolLLaMA】’ToolBench - An open platform for training, serving, and evaluating large language model for tool learning.' OpenBMB GitHub: github.com/OpenBMB/ToolBench  

Picture: [5396ee05ly8heee55cn29j21k20sgn0n.jpg](https://weibo.cn//mblog/pic/N2IuD1K8L?rl=1)

Github: [github.com/OpenBMB/ToolBench](https://github.com/OpenBMB/ToolBench)

#### [【Streaming Audio Transformers for Online Audio Tag @爱可可-爱生活](https://weibo.com/1402400261/N2Iq7uvjU)

Note: 【Streaming Audio Transformers for Online Audio Tagging：用于在线音频标记的流式音频Transformer】'Streaming Audio Transformers for Online Audio Tagging - Streaming Audiotransformers for online Audio tagging' Heinrich Dinkel GitHub: github.com/RicherMans/SAT   

Picture: [5396ee05ly8heedus2tnkj21d80p445r.jpg](https://weibo.cn//mblog/pic/N2Iq7uvjU?rl=1)

Github: [github.com/RicherMans/SAT](https://github.com/RicherMans/SAT)

#### [【免费书：《LangChain和LlamaIndex项目实践手册：将大型语言模型应用于现实世界》，一 @爱可可-爱生活](https://weibo.com/1402400261/N2NaT6drz)

Note: 【免费书：《LangChain和LlamaIndex项目实践手册：将大型语言模型应用于现实世界》，一本介绍如何利用LangChain和LlamaIndex项目以及OpenAI GPT-3和ChatGPT API解决一系列有趣问题的书。LangChain是一个用于构建大型语言模型应用程序的框架，LlamaIndex是一个用于搜索本地文档的工具。该书涵盖了安装和使用LangChain和LlamaIndex的基本要求，以及使用Google Knowledge Graph API、使用Hugging Face开源模型、使用Zapier集成等方面的示例。它还提供了关于大型语言模型的概述和使用场景的讨论。该书的目标读者是希望构建自己的工具并提升程序设计能力的开发人员】《LangChain and LlamaIndex Projects Lab Book: Hooking Large Language Models Up to the Real World - Using GPT-3, ChatGPT, and Hugging Face Models in Applications》Mark Watson  回复:成功保存至Notion 

Picture: [5396ee05ly8heeyujv2hyj20hs0nf78u.jpg](https://weibo.cn//mblog/pic/N2NaT6drz?rl=1)

#### [电子书《Understanding Deep Learning 》Simon J.D. Prince @蚁工厂](https://weibo.com/2194035935/N2N5e4Go0)

Note: 电子书《Understanding Deep Learning 》Simon J.D. Prince教授今年撰写的新书《理解深度学习》，电子书和配套讲义下载地址： udlbook.github.io/udlbook/深度学习的历史在科学中是非常不寻常的。一小群科学家在看似没有前景的领域坚持工作了二十五年，革新了一个领域，对社会产生了巨大影响。这本书的标题是“理解深度学习”，以区别于涵盖编码和其他实践方面的卷。这本书主要是关于深度学习的基本思想。书的第一部分介绍了深度学习模型，并讨论了如何训练它们，衡量它们的性能，并提高这个性能。下一部分考虑了专门针对图像、文本和图形数据的架构。这些章节只需要入门级的线性代数、微积分和概率知识，应该对任何在定量学科的二年级本科生都是可接受的。书的后续部分处理生成模型和强化学习。这些章节需要更多的概率和微积分知识，并针对更高级的学生。第十二章变形金刚，这是人工智能翻译的回复:翻译的没有问题

Picture: [82c654dfly1heeygppy9wj21gz1edq77.jpg](https://weibo.cn//mblog/pic/N2N5e4Go0?rl=1)

#### [统计学电子书《Regression and Other Stories》地址：avehtari.gi @蚁工厂](https://weibo.com/2194035935/N2Nbu5KjV)

Note: 统计学电子书《Regression and Other Stories》地址：avehtari.github.io/ROS-Examples/这本书由剑桥大学出版社出版，名为《回归与其他故事》，作者是Andrew Gelman、Jennifer Hill和Aki Vehtari。许多关于回归的教科书都关注理论和最简单的例子。然而，真正的统计问题是复杂和微妙的。这不是一本关于回归理论的书。这是一本关于如何使用回归来解决比较、估计、预测和因果推断的实际问题的书。它关注实际问题，如样本大小和缺失数据，以及广泛的目标和技术。它直接跳入你可以立即使用的方法和计算机代码。

Picture: [82c654dfly1heeywpabpmj205006lq3s.jpg](https://weibo.cn//mblog/pic/N2Nbu5KjV?rl=1)

#### [State of GPT （上）训练分四个阶段： pretraining --99% 训练时间，也是 @WinnieS的微博](https://weibo.com/2144454703/N2Nhw7YmB)

Note: State of GPT （上）训练分四个阶段： pretraining --99% 训练时间，也是竞争所在supervised finetuningreward modelingreinforement learning 在pretraing之前，先要收集数据 （1.4T token/pretraining 需要1T token，还好，数据量也不是很大），然后要tokenization （一个token~0.75 word ）。给了两个例子，别人家的例子给的数字就准确很多，而且看起来用A100，比V100合算太多。 图6，训练数据的片段transformer的好处是multi-taskbase model只是完成文档， 不过如果合理提问，其实也可以完成Q&A 模型坍塌（model collapse）？20分钟之后，开始讲如何将GPT更好的用到应用上：

Picture: [7fd1c82fgy1heexbbwpclj21fo0r04ik.jpg](https://weibo.cn//mblog/pic/N2Nhw7YmB?rl=1)

#### ['xxim - 惺惺 —— 属于你的社交地盘！惺惺是一个100%开源社交平台，每个人都可以搭建自己的 @爱可可-爱生活](https://weibo.com/1402400261/N2OJWbmiZ)

Note: 'xxim - 惺惺 —— 属于你的社交地盘！惺惺是一个100%开源社交平台，每个人都可以搭建自己的服务器，掌握数据的所有权。此APP非盈利项目' GitHub: github.com/cherish-chat/xxim-server   感觉IM框架最稀有的功能的其实是类似discord机器人那种

Picture: [5396ee05ly8hef5rm5ac6j20v70u0gpi.jpg](https://weibo.cn//mblog/pic/N2OJWbmiZ?rl=1)

Github: [github.com/cherish-chat/xxim-server](https://github.com/cherish-chat/xxim-server)

#### [【SAMIST：使用SAM进行图像分割的Python GUI工具。使用SAMIST，可以选择模型类型 @爱可可-爱生活](https://weibo.com/1402400261/N2ON6Fg0m)

Note: 【SAMIST：使用SAM进行图像分割的Python GUI工具。使用SAMIST，可以选择模型类型、加载图像进行分割，并导出生成的蒙版】’SAMIST - Segment Anything Model (SAM) Image Segmentation Tool - SAMIST. Python GUI for image segmentation using SAM by Meta AI.' Alexander Dibrov GitHub: github.com/dibrale/samist  这好像是螳螂虾吧？ 

Picture: [5396ee05ly8hef5za4f4xj20c30hi0vc.jpg](https://weibo.cn//mblog/pic/N2ON6Fg0m?rl=1)

Github: [github.com/dibrale/samist](https://github.com/dibrale/samist)

#### [BigTrans: Augmenting Large Language Models with Mu @AMiner学术头条](https://weibo.com/1870858943/N308IgtiK)

Note: BigTrans: Augmenting Large Language Models with Multilingual Translation Capability over 100 Languages ChatPaper综述：该论文介绍了一个名为BigTrans的模型，它通过对LLaMA模型进行改进和优化，实现了对100多种语言的多语言翻译能力。该模型旨在探索LLMs在语言翻译方面的潜力，因为许多现有的LLMs只支持少量语言，而且通常是以英语为主导的。研究表明，BigTrans在许多语言对上表现出与ChatGPT和Google Translate相当的水平，甚至在8个语言对上表现更好。该论文的贡献在于扩展了现有的LLMs的应用范围，同时提高了对多语言翻译的支持。

Picture: [6f830abfly1hegk3tv5dhj20td0v0alk.jpg](https://weibo.cn//mblog/pic/N308IgtiK?rl=1)

#### [Improving CLIP Training with Language Rewrites Cha @AMiner学术头条](https://weibo.com/1870858943/N3jaqtPIv)

Note: Improving CLIP Training with Language Rewrites ChatPaper综述：本文介绍了一种名为Language augmented CLIP (LaCLIP)的方法，旨在通过语言重写增强CLIP训练。传统的CLIP模型在数据增强时仅针对图像进行操作，而语言输入则在整个训练过程中保持不变，导致模型无法充分接触多样化的文本描述。LaCLIP方法利用大型语言模型的上下文学习能力，对每张图像所对应的文本进行重写，以体现句子结构和词汇的多样性，同时保留原始的关键概念和意义。在训练时，LaCLIP随机选择原始文本或重写版本作为每张图像的文本增强。实验结果表明，使用LaCLIP方法进行CLIP预训练可以显著提高模型的传输性能，而且不会增加额外的计算或内存开销。具体而言，在CC12M数据集上，LaCLIP比CLIP的ImageNet零样本准确率提高了8.2%，在LAION-400M上则提高了2.4%。

Picture: [6f830abfly1heiw3wkpqsj213k0tftq9.jpg](https://weibo.cn//mblog/pic/N3jaqtPIv?rl=1)

#### [Tree-Ring Watermarks: Fingerprints for Diffusion I @AMiner学术头条](https://weibo.com/1870858943/N3jbj9VuM)

Note: Tree-Ring Watermarks: Fingerprints for Diffusion Images that are Invisible and Robust ChatPaper综述：本文介绍了一种名为Tree-Ring Watermarking的水印技术，能够在生成模型的输出上进行鲁棒性纹理标记，以追踪版权和防止AI生成内容的潜在危害。与现有方法不同，Tree-Ring Watermarking在采样过程中微妙地影响整个过程，从而产生对人类不可见的模型指纹。该水印将模式嵌入用于采样的初始噪声向量中，这些模式在傅里叶空间中构造，使它们对卷积、裁剪、膨胀、翻转和旋转无影响。在图像生成后，通过反演扩散过程来检测水印信号，以检索嵌入式信号的噪声向量。该技术可以轻松应用于任意扩散模型，包括文本条件的稳定扩散，作为插件，几乎没有失去FID指标。该水印被语义隐藏在图像空间中，比当前部署的水印替代方案更具鲁棒性。该研究可为应对AI生成内容带来的版权问题提供帮助。

Picture: [6f830abfly1heiw675ld4j213w0pundj.jpg](https://weibo.cn//mblog/pic/N3jbj9VuM?rl=1)

#### [电子书《机器学习系统：设计和实现》地址：openmlsys.github.io/index.html @Maeiee](https://weibo.com/1240212845/N37Ctm5I5)

Note: 电子书《机器学习系统：设计和实现》地址：openmlsys.github.io/index.html本书希望做成世界上第一本全面讲述机器学习系统知识的开源书籍。机器学习系统可以看作一门衔接机器学习和计算机系统的课程 

Picture: [82c654dfly1hehgyqj2q3j20g91ljn2k.jpg](https://weibo.cn//mblog/pic/N37B9w3DU?rl=1)

#### [【Chinese-Guanaco: 中文低资源量化训练/部署方案，中文Guanaco(原驼)大语言模 @Maeiee](https://weibo.com/1240212845/N3ldUBTdD)

Note: 【Chinese-Guanaco: 中文低资源量化训练/部署方案，中文Guanaco(原驼)大语言模型 QLora 量化训练 +本地CPU/GPU部署】’Chinese-Guanaco: Efficient Finetuning of Quantized LLMs for Chinese  —— 一个中文低资源的量化训练/部署方案 - 中文Guanaco(原驼)大语言模型 QLora 量化训练 +本地CPU/GPU部署 (Chinese Guanaco QLoRA: Efficient Finetuning of Quantized LLMs)' Robin GitHub: github.com/jianzhnie/Chinese-Guanaco  

Picture: [5396ee05ly8heiyxz116aj210t0u0djx.jpg](https://weibo.cn//mblog/pic/N3jOmpxtr?rl=1)

Github: [github.com/jianzhnie/Chinese-Guanaco](https://github.com/jianzhnie/Chinese-Guanaco)

#### [ LLM的兴起，又拉火了向量数据库，我们 AI 小组的工程师总结了向量数据库的基本原理和常见套装，包 @Maeiee](https://weibo.com/1240212845/N3uf7xOxY)

Note:  LLM的兴起，又拉火了向量数据库，我们 AI 小组的工程师总结了向量数据库的基本原理和常见套装，包括Faiss, Elasticsearch, Milvus, PGVector等，值得一读: 10分钟了解向量数据库  

#### [热门的视频， B站出的也蛮快COMPUTEX NVIDIA Keynote 2023 英伟达 演讲( @WinnieS的微博](https://weibo.com/2144454703/N2X2BcJVr)

Note: 热门的视频， B站出的也蛮快COMPUTEX NVIDIA Keynote 2023 英伟达 演讲( 上） 台北电脑展：1，老黄说，历史上一切创新，都是“更好更便宜”。 他家的机器，可真不便宜啊。 2，老黄一直把CPU构建的data center作为靶子 ，强调买越多的GPU server，越省钱。 好吧，好吧。 DPU说自己是数据中心的新center，GPU只说自己是加速，感觉GPU才是新center3， 图4，数据中心的这个公式，挺好4，老黄也提software 2.0了，Nvidia这个速度，压得人喘不过气来5，text 生成video，音乐的演示，还是很炫酷的6， 很多的创业公司

Picture: [7fd1c82fgy1heg47yyby8j20yx0g17be.jpg](https://weibo.cn//mblog/pic/N2X2BcJVr?rl=1)

#### [DALL-E 2DALL-E 2其实是三个子模块拼接而成的，具体来说：一个基于CLIP模型的编码模块 @WinnieS的微博](https://weibo.com/2144454703/N36n7y3Er)

Note: DALL-E 2DALL-E 2其实是三个子模块拼接而成的，具体来说：一个基于CLIP模型的编码模块，目标是训练好的文本和图像encoder，从而可以把文本和图像都被编码为相应的特征空间。一个先验（prior）模块，目标是实现文本编码到图像编码的转换。一个decoder模块，该模块通过解码图像编码生成目标图像。~~~~也摘自 

Picture: [7fd1c82fgy1hehbk5ig0rj20t30fs7dk.jpg](https://weibo.cn//mblog/pic/N36n7y3Er?rl=1)

#### [Stable Diffusion的整体上来说主要是三个部分，language model、diffu @WinnieS的微博](https://weibo.com/2144454703/N36m1y2Ha)

Note: Stable Diffusion的整体上来说主要是三个部分，language model、diffusion model和decoderLanguage model主要将输入的文本提示转化为可以输入到diffusion model使用的表示形式，通常使用embedding加上一些random noise输入到下一层diffusion model主要是一个时间条件U-Net，它将一些高斯噪声和文本表示作为模型输入，将对应的图像添加一点高斯噪声，从而得到一个稍微有噪点的图像，然后在时间线上重复这个过程，对于稍微有噪点的图像，继续添加高斯噪声，以获得更有噪点的图像，重复多次到几百次后就可以获得完全嘈杂的图像。这么做的过程中，知道每个步骤的图像版本。然后训练的NN就可以将噪声较大的示例作为输入，具有预测图像去噪版本的能力。在训练过程中，还有一个encoder，是decoder的对应部分，encoder的目标是将输入图像转化为具有高语义意义的缩减采样表示，但消除与手头图像不太相关的高频视觉噪声decoder的主要作用就是对应encoder的部分，获得扩散模型的输出并将其放大到完整图像。~~~~~摘自 图片评论 

Picture: [7fd1c82fgy1hehbg7x718j20u00bi7bj.jpg](https://weibo.cn//mblog/pic/N36m1y2Ha?rl=1)

#### [SHARPSHARP（Scalable Hierarchical Aggregation and R @WinnieS的微博](https://weibo.com/2144454703/N39DX55KA)

Note: SHARPSHARP（Scalable Hierarchical Aggregation and Reduction Protocol，可扩展分层次聚合和归约协议）是一种聚合通信（e.g. ML 梯度聚合、FL 模型聚合）网络卸载技术。SHARPv1：在 Switch-IB2 EDR InfiniBand 上实现，最大支持 256Byte 聚合通信卸载。SHARPv2：在 Quantum HDR InfiniBand 上实现，最大支持 2GByte 聚合通信卸载。在各种 HPC 和 AI 场景中，常常存在多种聚合类通信协议，这些聚合类通信由于涉及全局网络，常常会对 Application 的并行效率产生巨大的影响。

Picture: [7fd1c82fgy1hehpx9sca3j21400mojxl.jpg](https://weibo.cn//mblog/pic/N39DX55KA?rl=1)

#### [Pytorch & cambricon Pytorch ~~20分钟，感觉自己可会了  @WinnieS的微博](https://weibo.com/2144454703/N3h7GtJ6E)

Note: Pytorch & cambricon Pytorch ~~20分钟，感觉自己可会了 

Picture: [7fd1c82fgy1hein1agc30j21fe0tvtm9.jpg](https://weibo.cn//mblog/pic/N3h7GtJ6E?rl=1)

#### [沐曦光启智能研究院演讲 回复:视频截图win大，这些PPT你都去哪搞的呀，去当面找他们要都没有你这么 @WinnieS的微博](https://weibo.com/2144454703/N3jEGeJVU)

Note: 沐曦光启智能研究院演讲 回复:视频截图win大，这些PPT你都去哪搞的呀，去当面找他们要都没有你这么全

Picture: [7fd1c82fgy1heiy7t012kj20xo0jdah4.jpg](https://weibo.cn//mblog/pic/N3jEGeJVU?rl=1)

#### [天数智芯副总裁兼CTO吕坚平 我超，win大真的要allinai了呀 @WinnieS的微博](https://weibo.com/2144454703/N3jRz12XX)

Note: 天数智芯副总裁兼CTO吕坚平 我超，win大真的要allinai了呀

Picture: [7fd1c82fgy1heiz3m0b60j21cz0s5qti.jpg](https://weibo.cn//mblog/pic/N3jRz12XX?rl=1)

#### [昆仑芯科技研发总监王志鹏 ~~~昆仑芯的应用方面，应该是最强的，而且是跟上大模型这波最快的一家了吧  @WinnieS的微博](https://weibo.com/2144454703/N3k73hrUA)

Note: 昆仑芯科技研发总监王志鹏 ~~~昆仑芯的应用方面，应该是最强的，而且是跟上大模型这波最快的一家了吧 

Picture: [7fd1c82fgy1hej08dowqej20xw0jfak3.jpg](https://weibo.cn//mblog/pic/N3k73hrUA?rl=1)

#### [Spine switches interconnect all leaf switches in a @WinnieS的微博](https://weibo.com/2144454703/N3qSmodRm)

Note: Spine switches interconnect all leaf switches in a full-mesh topology.~~~~~这句话符合我的理解，但是好像跟Nvidia SuperPoD的网络不一样 

Picture: [7fd1c82fgy1heju4iiwppj20nn0ka7aw.jpg](https://weibo.cn//mblog/pic/N3qSmodRm?rl=1)

#### [炼丹不易，用丹有趣：State of GPT的番外解读  @刘群MT-to-Death](https://weibo.com/1917491813/N3bUeAKat)

Note: 炼丹不易，用丹有趣：State of GPT的番外解读 

#### [电子书《Building Secure and Reliable Systems》构建安全可靠的系统 @数据派THU](https://weibo.com/6004911042/N31Krlam5)

Note: 电子书《Building Secure and Reliable Systems》构建安全可靠的系统 - 一本由Google编写的书地址：google.github.io/building-secure-and-reliable-systems/Google编写这本书的目的是分享他们在大规模构建安全系统的经验。本书专注于将安全性和可靠性直接整合到软件和系统生命周期中，既突出保护系统并保持其可靠的技术和实践，也说明这些实践如何相互交互。这本书的目标是让你从专业安全性和可靠性的实践者那里提供关于系统设计、实施和维护的洞察。

Picture: [82c654dfly1hegd0rnnxrj238o495u12.jpg](https://weibo.cn//mblog/pic/N31lnr6PQ?rl=1)

#### [两篇文档，作者都是Daniel Stenberg，curl的开发者。一篇详细讲解HTTP/2的文档， @数据派THU](https://weibo.com/6004911042/N3bjqaNmO)

Note: 两篇文档，作者都是Daniel Stenberg，curl的开发者。一篇详细讲解HTTP/2的文档，主要内容包括该协议的背景、思想、协议本身的内容、对一些现有实现的探讨与对协议未来的展望。以及对应的HTTP3的，介绍HTTP/3以及其底层协议QUIC的文档，介绍它们的目的、原理、协议细节以及实现等。

Picture: [82c654dfly1h2rg99tzo2j20fz16b75k.jpg](https://weibo.cn//mblog/pic/LvAeVhUtA?rl=1)

#### [【！支持免费商用，比LLaMA65B小但更强，基于1万亿token】号称“史上最强的开源大语言模型” @数据派THU](https://weibo.com/6004911042/N3knYC9vq)

Note: 【！支持免费商用，比LLaMA65B小但更强，基于1万亿token】号称“史上最强的开源大语言模型”出现了。它叫Falcon（猎鹰），参数400亿，在1万亿高质量token上进行了训练。最终性能超越650亿的LLaMA，以及MPT、Redpajama等现有所有开源模型，一举登顶HuggingFace OpenLLM全球榜单。除了以上成绩，Falcon还可以只用到GPT-3 75%的训练预算，性能就显著超越GPT-3，且推理阶段的计算也只需GPT-3的1/5。据悉，这只半路杀出来的“猎鹰”来自阿联酋阿布扎比技术创新研究所(TII)。有意思的是，作为一个开源模型，TII在Falcon上推出了一个相当特别的授权许可证要求：可以商业使用，但如果用它产生的收益超过了100万美元，就要被收取10%的授权费。一时之间，争议满满。

Picture: [006Fd7o3gy1hef6soph8sj30vq0iqtdp.jpg](https://weibo.cn//mblog/pic/N2OYCnJlT?rl=1)

#### [ 用GPT-4实现可控文本图像生成，UC伯克利&微软提出新框架Control-GPT  @数据派THU](https://weibo.com/6004911042/N3upSf63y)

Note:  用GPT-4实现可控文本图像生成，UC伯克利&微软提出新框架Control-GPT 

Picture: [006ynZFUly1hek9rt9l7jj30u0087tb5.jpg](https://weibo.cn//mblog/pic/N3upSf63y?rl=1)

#### [电子书《Interpretable Machine Learning》可解释的机器学习 --一本使黑 @数据派THU](https://weibo.com/6004911042/N3uqmk8hc)

Note: 电子书《Interpretable Machine Learning》可解释的机器学习 --一本使黑箱模型可解释的指南。地址：christophm.github.io/interpretable-ml-book/机器学习对于改进产品、流程和研究具有巨大的潜力。但是，计算机通常不解释它们的预测，这是采用机器学习的一个障碍。这本书是关于如何使机器学习模型及其决策可解释的。在探索可解释性的概念之后，你将学习关于简单、可解释的模型，如决策树、决策规则和线性回归。本书的重点是解释黑箱模型的模型不可知方法，如特征重要性和累积局部效应，以及使用Shapley值和LIME解释个体预测。此外，本书还介绍了特定于深度神经网络的方法。所有的解释方法都被深入地解释和批判性地讨论。他们的内部工作原理是什么？他们的优点和缺点是什么？他们的输出如何被解释？这本书将使你能够选择并正确应用最适合你的机器学习项目的解释方法。推荐机器学习从业者、数据科学家、统计学家以及任何对使机器学习模型可解释感兴趣的人阅读这本书。

Picture: [82c654dfly1hejp7xf4inj212y1fy4jt.jpg](https://weibo.cn//mblog/pic/N3qrBfeES?rl=1)

#### [【新书草稿：《多智能体强化学习：基础与现代方法》内容包括多智能体强化学习的基础知识和现代方法，以及多 @爱可可-爱生活](https://weibo.com/1402400261/N2Wv0DhUs)

Note: 【新书草稿：《多智能体强化学习：基础与现代方法》内容包括多智能体强化学习的基础知识和现代方法，以及多智能体深度强化学习的算法和实践。还有附录和代码库的链接】《Multi-Agent Reinforcement Learning: Foundations and Modern Approaches》Stefano V. Albrecht,  Filippos Christianos,  Lukas Schäfer  GitHub: github.com/marl-book/fast-marl 

Picture: [5396ee05ly8heg3xs1uf4j214c0u0dkm.jpg](https://weibo.cn//mblog/pic/N2Wv0DhUs?rl=1)

Github: [github.com/marl-book/fast-marl](https://github.com/marl-book/fast-marl)

#### [今日推介(第1055期)：用随机位置编码提高Transformer的长度泛化能力、背包语言模型、统一 @爱可可-爱生活](https://weibo.com/1402400261/N2VFpkLCj)

Note: 今日推介(第1055期)：用随机位置编码提高Transformer的长度泛化能力、背包语言模型、统一通用的生物医学生成式预训练Transformer、大型语言模型作为工具制造者、在模拟人类社会中训练社会化对齐的语言模型、基于大型语言模型的重复博弈、基于共形化图神经网络的图不确定性量化 公·众·号：爱可可爱生活  

Picture: [5396ee05ly8heg0cjehbbj20u012i0xv.jpg](https://weibo.cn//mblog/pic/N2VFpkLCj?rl=1)

#### [【Goat: 擅长算术任务的LLaMA微调模型】'Goat: a Fine-tuned LLaMA  @爱可可-爱生活](https://weibo.com/1402400261/N2YtLydmE)

Note: 【Goat: 擅长算术任务的LLaMA微调模型】'Goat: a Fine-tuned LLaMA that is Good at Arithmetic Tasks - a Fine-tuned LLaMA that is Good at Arithmetic Tasks' SFeRn GitHub: github.com/liutiedong/goat   

Picture: [5396ee05ly8hegcr4m93rj213b0u0dko.jpg](https://weibo.cn//mblog/pic/N2YtLydmE?rl=1)

Github: [github.com/liutiedong/goat](https://github.com/liutiedong/goat)

#### [【免费书稿：理解深度学习】《Understanding Deep Learning》by Simon @爱可可-爱生活](https://weibo.com/1402400261/N2WN78rkw)

Note: 【免费书稿：理解深度学习】《Understanding Deep Learning》by Simon J.D. Prince udlbook.github.io/udlbook/ pdf: github.com/udlbook/udlbook/releases/download/v0.3.1/UnderstandingDeepLearning_15_12_22.pdf  

Picture: [5396ee05ly1h98v9rrdbij20xu1bcn9l.jpg](https://weibo.cn//mblog/pic/MkheztHke?rl=1)

Github: [github.com/udlbook/udlbook/releases/download/v0.3.1/UnderstandingDeepLearning_15_12_22.pdf](https://github.com/udlbook/udlbook/releases/download/v0.3.1/UnderstandingDeepLearning_15_12_22.pdf)

#### [公开课：Rust 101地址：github.com/tweedegolf/101-rsRust 10 @敖天羽](https://weibo.com/1888981347/N2xtnEimK)

Note: 公开课：Rust 101地址：github.com/tweedegolf/101-rsRust 101 是一门面向计算机科学专业学生的大学课程，介绍了 Rust 编程语言，适用于任何想要教授 Rust 的人。 

Picture: [82c654dfly1hecqn71bmij20xc0hggof.jpg](https://weibo.cn//mblog/pic/N2v140ygT?rl=1)

Github: [github.com/tweedegolf/101-rsRust](https://github.com/tweedegolf/101-rsRust)

#### [“当所有用来训练LLM（大型语言模型）的语料都训练完了怎么办？” 是不是你也想过这问题？Jay Ha @宝玉xp](https://weibo.com/1727858283/N2O23BEsa)

Note: “当所有用来训练LLM（大型语言模型）的语料都训练完了怎么办？” 是不是你也想过这问题？Jay Hack的这个推文针对这个问题有不错的论述。首先是结论：不用担心这个问题！想想如果未来LLM继续按照现在的模式发展，算力不再是瓶颈，模型和算法也一直在优化改进，但没有新的高质量的内容可供模型训练。所以很多人开始担心语料用尽后LLM怎么进一步提升和成长。不用担心，对文本进行训练只是一种LLM训练方法的一种，还有许多其他选项。一种方案是AI通过模仿专家进行学习，这是让AI能快速达到专家水平的一种方法，Google的Deepmind就是通过预测专家动作来学习Atari游戏的，相关研究成果可以参考：一种方案是Self criticism（注：字面意思是自我批评，但是感觉用在这里不恰当，更像是自我评价并纠正，自我训练）自我对弈，或者让模型与自己对弈，在很多非LLM的地方中都已经被证明是成功的。最典型的是在围棋中，AlphaZero通过数以亿计的自我对弈，自我学习并最终跟人类比取得巨大的优势。而在LLM中，Claude的公司Anthropic已经在"Constitutional AI" 中应用这种策略：- 生成一段内容- 让LLM对这个内容进行评价和编辑- 在编辑过的内容上进行微调整个过程不需要人类参与，而且被证明是有效的。具体可以参考这个链接：另外还有许多其他的LLMs也有通过自我评价、反馈就能自我提升的案例。例如：“Large Language Models can Self-Improve” 例如：“Improving Language Model Negotiation with Self-Play and In-Context Learning from AI Feedback” 除了以上两个方案外，还有一个更像人类行为的方案：通过与环境的互动来学习。这种方案通过让模型运行，对生成的结果进行观察和评估，进而微调，从而生成新的数据。这种方案中一个典型的案例是："LLMs可以教会自己编程"，让LLM自己编写一个难度较大的编程难题- 让LLM借助思维链（CoT chain-of-thought），让它根据任务生成代码 → 对生成的代码验证 → 对错误进行修正 → 迭代成功 → 更新参数。- 当它最终得到解决方案后，用结果对LLM进行微调，通过这样的迭代来优化大模型具体可以参考论文Language Models Can Teach Themselves to Program Better：这几天很火的玩Minecraft游戏的AI Agent Voyager，也是类似的策略，让GPT-4自主的决定下一步的任务， 根据任务需要调用技能库的代码，或者写新的任务操作的代码，并且在验证后更新技能库，这过程中都是AI自主学习完善，不需要人类干预。具体参考微博：http://t.cn/A6p26NjP从这些案例中我们不难发现，未来我们可以为LLM提供一定程度的自主权，让它和真实世界互动，在互动过程中基于环境的反馈来学习提升。一直以来这就是强化学习的工作方式，只是现在我们把它应用到了LLM上。可以设想一些应用场景：- 让类似于Voyager的AI游戏代理去玩堡垒之夜（Fortnite），帮你交友、赢比赛- 借助GPT-4的多模态和代码解释器（Code Interpreter）分析数据集并生成图标，以提升数据分析方面的能力- 欢迎分享你的想法另外，目前为止还有充足的视频资源供我们训练，多模态是LLM的未来。即使将来连视频资源都训练完了，LLMs还能通过自己训练自己、和环境互动等方式来提升自己。详细内容请参阅原始推文：🐦twitter.com/mathemagic1an/status/1662896309588881408🔗人类的那点知识不够他用了 他要自己发现知识[捂脸]自我训练会有问题 可能恶性循环 也可能正向以后真就（LLM/AI）神仙打架，凡人围观（遭殃）！AI 能力太强，凡人要么看不懂，要么速度跟不上，结局只能这样，除非人机结合或者飞升。高质量资料是人类历史积淀的，其他方式可能带来其他文明

Picture: [66fd066bgy1hef2mb4722j20xc0lmk4d.jpg](https://weibo.cn//mblog/pic/N2O23BEsa?rl=1)

#### [Sin3DM: Learning a Diffusion Model from a Single 3 @AMiner学术头条](https://weibo.com/1870858943/N2emWwwAi)

Note: Sin3DM: Learning a Diffusion Model from a Single 3D Textured Shape ChatPaper综述：本文介绍了一种名为Sin3DM的扩散模型，该模型可以从单个3D纹理形状中学习内部补丁分布，并生成具有精细几何和纹理细节的高质量变化。为了训练3D扩散模型，首先将输入压缩为较低维的潜在空间，然后在其上进行训练。通过大量的定性和定量评估，研究表明，该模型可以生成各种类型的3D形状，且质量优于先前的方法。

Picture: [6f830abfly1heap7kmcdzj20pa0t17n2.jpg](https://weibo.cn//mblog/pic/N2emWwwAi?rl=1)

#### [【ExpertLLaMA:一个使用ExpertPrompting构建的开源聊天机器人，其能力达到Ch @爱可可-爱生活](https://weibo.com/1402400261/N2f7Q8ZnW)

Note: 【ExpertLLaMA:一个使用ExpertPrompting构建的开源聊天机器人，其能力达到ChatGPT的96%。ExpertLLaMA通过在普通指令中添加专家身份描述，产生高质量、详细的专家级回答。本项目提供了方法简介、52,000个专家数据集样本、52,000个基线数据集样本、52,000个对应每个具体指令的专家身份描述、基于专家数据集训练的ExpertLLaMA检查点以及与Vicuna、LLaMA-GPT4等现有模型的评估结果】'ExpertLLaMA:Answering Instructions Like an Expert - An opensource ChatBot built with ExpertPrompting which achieves 96% of ChatGPT's capability.' OFA-Sys GitHub: github.com/OFA-Sys/ExpertLLaMA  [666]欢迎部署在星汉未来应用市场体验下  

Picture: [5396ee05ly8heasi58xgpj20v30u0tc1.jpg](https://weibo.cn//mblog/pic/N2f7Q8ZnW?rl=1)

Github: [github.com/OFA-Sys/ExpertLLaMA](https://github.com/OFA-Sys/ExpertLLaMA)

#### [推荐：《ChatGPT Prompt 分享活动》推友 向阳乔木 （twitter.com/vista @宝玉xp](https://weibo.com/1727858283/N2WfP7Iea)

Note: 推荐：《ChatGPT Prompt 分享活动》推友 向阳乔木 （twitter.com/vista8）组织的Prompt分享活动，已经收集了28条不错的Prompt，推荐参考飞书地址：原始推文：twitter.com/vista8/status/1663155102306426885🔗 回复:成功保存到你的Notion民间智慧转发微博

Picture: [66fd066bgy1heg2sn2mvpj20xa1minl5.jpg](https://weibo.cn//mblog/pic/N2WfP7Iea?rl=1)

#### [炼丹不易，用丹有趣：State of GPT的番外解读 RLHF在instructgpt中有//:好 @宝玉xp](https://weibo.com/1727858283/N37mIcQ7S)

Note: 炼丹不易，用丹有趣：State of GPT的番外解读 RLHF在instructgpt中有//:好专业的解读👍//:OpenAI的这个演讲确实精彩，建议按如下顺序食用: 看Slides() ->  看视频(http://t.cn/A6pU2Hgz)->看图文报道()。最后如果还意犹未尽，可以看看这个观后感：既梳理了整体的脉路，又加入了独到的点评。收藏好有意思//:好专业的解读👍//:OpenAI的这个演讲确实精彩，建议按如下顺序食用: 看Slides() ->  看视频(http://t.cn/A6pU2Hgz)->看图文报道()。最后如果还意犹未尽，可以看看这个观后感：既梳理了整体的脉路，又加入了独到的点评。How to train your (Chat)GPT Assistant！//:好专业的解读👍//:OpenAI的这个演讲确实精彩，建议按如下顺序食用: 看Slides() ->  看视频(http://t.cn/A6pU2Hgz)->看图文报道()。

#### [minikube 一条命令在本机启动 Kubernetes 集群的工具。一个可以在本地轻松运行 K8 @敖天羽](https://weibo.com/1888981347/N36ERj1Ih)

Note: minikube 一条命令在本机启动 Kubernetes 集群的工具。一个可以在本地轻松运行 K8s 集群的工具，它支持标准的 Kubernetes 功能，可作为本地开发 Kubernetes 应用程序的工具，适用于 macOS、Linux 和 Windows 操作系统。项目地址  

Picture: [006dfXnily1hehb6rs8twj30fz08ywgr.jpg](https://weibo.cn//mblog/pic/N36h2ajbl?rl=1)

#### [【Chainlit：一个Python应用开发框架，可以在几分钟内构建类似ChatGPT的用户界面。提 @爱可可-爱生活](https://weibo.com/1402400261/N2oMpz3Cp)

Note: 【Chainlit：一个Python应用开发框架，可以在几分钟内构建类似ChatGPT的用户界面。提供了中间步骤可视化、元素管理和显示(图像、文本、轮播等)以及云部署等关键功能】'Chainlit - Build Python LLM apps in minutes' Chainlit GitHub: github.com/Chainlit/chainlit   [欢乐熊出没]

Picture: [5396ee05ly8hebz507dadj21tl0u0gn5.jpg](https://weibo.cn//mblog/pic/N2oMpz3Cp?rl=1)

Github: [github.com/Chainlit/chainlit](https://github.com/Chainlit/chainlit)

#### [电子书《Bayesian Data Analysis》贝叶斯数据分析第三版下载地址：users.aa @蚁工厂](https://weibo.com/2194035935/N2WmTlBsa)

Note: 电子书《Bayesian Data Analysis》贝叶斯数据分析第三版下载地址：users.aalto.fi/~ave/BDA3.pdf这本书旨在扮演三个角色，服务于三个相关的受众：从基本原理开始的贝叶斯推断入门文本，关于统计学和相关领域中有效的当前贝叶斯建模和计算的研究生文本，以及应用统计学中的贝叶斯方法手册，供应用统计学的一般用户和研究者使用。尽管在早期部分是入门级的，但这本书绝对不是统计学的第一本入门教材。我们书中使用的数学是基本的概率和统计学，初级微积分和线性代数。第一章给出了概率符号的回顾，以及假设已经学过的更详细的主题列表。本书的实用导向意味着读者在概率、统计和线性代数的先前经验理想情况下应该包括强大的计算组件。只写一本入门文本会让许多读者只对概念元素有一种尝试，但没有指导他们进入真正的实际应用，除了那些贝叶斯方法基本上与标准的非贝叶斯分析一致的地方。另一方面，本书认为在没有先从数据分析视角介绍基本概念的情况下，介绍高级方法将是一个错误。此外，由于应用统计学的性质，关于当前贝叶斯方法的文本如果没有从真实应用中提取的各种实例，将是不完整的。回复:已保存至notion回复:成功收藏至Notion 

Picture: [82c654dfly1hef2rpf0wej21fl1go195.jpg](https://weibo.cn//mblog/pic/N2WmTlBsa?rl=1)

#### [计算机专业学习路线作者的话：对计算机科学有追求的同学（读研、想进大厂或工作之余想提升自己），非常推荐 @蚁工厂](https://weibo.com/2194035935/N2Wnnw9yy)

Note: 计算机专业学习路线作者的话：对计算机科学有追求的同学（读研、想进大厂或工作之余想提升自己），非常推荐你按照本学习路线花两三年的时间去深入学习，这对你今后的发展大有裨益。计算机专业应该学习哪些内容？6所CS名校对学生应该掌握哪些核心课程都有一个非常清晰的说明，本学习路线将这些学校对本科毕业生的要求以及课程的分类、顺序、重要程度等课程体系进行了一个说明。不过，由于计算机的课程十分庞杂，分的方向很多，比如斯坦福大学就针对不同方向（赛道）推出了不同的课程学习要求，这里没法一一都列出来，因此对这些课程进行了一定的筛选。转发微博我到现在还剩两门课没学完呢，根本没那么强的执行力。。。财会专业想业余提升自己，该走哪条路线呢码一下转发微博

Picture: [82c654dfly1heg3hom10ej20i41jlqdw.jpg](https://weibo.cn//mblog/pic/N2Wnnw9yy?rl=1)

#### [技术博客《Transformer Math 101》关于Transformer 语言模型的许多基本、 @蚁工厂](https://weibo.com/2194035935/N2Y3CeG5i)

Note: 技术博客《Transformer Math 101》关于Transformer 语言模型的许多基本、重要的信息可以相当简单地计算出来。不幸的是，这些方程在自然语言处理（NLP）社区中并不广为人知。本文的目的就是收集这些方程，以及与它们来源和重要性相关的知识。这篇文章主要关注的是训练成本，这些成本主要由显存（VRAM）因素主导。 [开学季]

Picture: [82c654dfly1hefdoqnq90j21g81hw4qp.jpg](https://weibo.cn//mblog/pic/N2Y3CeG5i?rl=1)

#### [电子书《Classifying 19th Century British Library books @蚁工厂](https://weibo.com/2194035935/N30Wded4q)

Note: 电子书《Classifying 19th Century British Library books using Crowdsourcing and Machine Learning》使用众包和机器学习对19世纪英国图书馆的书籍进行分类阅读：living-with-machines.github.io/genre-classification/intro.html相关资源：github.com/Living-with-machines/genre-classification用到的技术主要有--fastai--🤗 Transformers / Blurr  🤗 变形金刚/模糊--Snorkel

Picture: [82c654dfly1hegcxqlfm8j223c0ni4e8.jpg](https://weibo.cn//mblog/pic/N30Wded4q?rl=1)

Github: [github.com/Living-with-machines/genre-classification](https://github.com/Living-with-machines/genre-classification)

#### [Macaw-LLM，一个试验性的开源的多模态语言模型地址：github.com/lyuchenyan @蚁工厂](https://weibo.com/2194035935/N3fslDefA)

Note: Macaw-LLM，一个试验性的开源的多模态语言模型地址：github.com/lyuchenyang/Macaw-LLMMacaw-LLM是一项探索性的努力，它通过无缝地结合图像、视频、音频和文本数据，开创了多模态语言建模。它基于多个已有的开源项目，包括：CLIP：负责编码图像和视频帧。Whisper：负责编码音频数据。LLM（LLaMA/Vicuna/Bloom）：负责编码指令和生成响应的语言模型。[努力]感谢 转发我们在多模态大模型上的工作，文章、代码、模型会本周放出，欢迎关注！[送花花]回复:已保存至Notion[努力]感谢 转发我们在多模态大模型上的工作，文章、代码、模型会本周放出，欢迎关注！[送花花]回复:已收藏到Notion[赢牛奶]

Picture: [82c654dfly1heifmn642pj21ei0zuh3o.jpg](https://weibo.cn//mblog/pic/N3fslDefA?rl=1)

Github: [github.com/lyuchenyang/Macaw-LLMMacaw-LLM](https://github.com/lyuchenyang/Macaw-LLMMacaw-LLM)

#### [摩尔线程的夏季发布会1，原来OpenCL, Vulkan 是图显标准2，DirectX则是游戏的3， @蚁工厂](https://weibo.com/2194035935/N3gbljnxo)

Note: 摩尔线程的夏季发布会1，原来OpenCL, Vulkan 是图显标准2，DirectX则是游戏的3，游戏的生态，也是很要命的庞大4，第三部分 AI与云平台不错5， MUSA& MUSIFY6，MCCPlatform&MCCFlow7，元宇宙平台，棒棒哒8，摩笔马良，哈哈哈，这个名字棒棒哒，记住了不管产品实际怎么样，这个发布会，这个产品，工具，平台与方案的规划，都是顶级的。 大厂风格，有格调，有框架感，有覆盖度回复:这个叫国产吗，我不好说img的架构。。就是以前的powervr那个，现在被中资控制了才搞来的

Picture: [7fd1c82fgy1heihttxyg1j21fh0t7wpx.jpg](https://weibo.cn//mblog/pic/N3g5N5Hcd?rl=1)

#### [电子书《计算机网络：原理、协议和实践》（英文版）计算机网络：原理、协议和实践 是一本开源电子书，它解 @蚁工厂](https://weibo.com/2194035935/N3gwyxnZQ)

Note: 电子书《计算机网络：原理、协议和实践》（英文版）计算机网络：原理、协议和实践 是一本开源电子书，它解释了计算机网络的主要原理和 Internet 上使用的关键协议。第一部分描述了计算机网络的理论基础以及主要的算法和协议。 第二部分包含对主要 Internet 协议的详细说明，包括 HTTP , DNS ， TLS , 通信协议 ， UDP , IPv6 , BGP 等。 第三部分包含练习和实验，让学生测试他们的知识。

Picture: [82c654dfly1h2sjmdfxuej20v70u0tb4.jpg](https://weibo.cn//mblog/pic/LvG5J1oN9?rl=1)

#### [SelFee，一个迭代自修改的大语言模型。详细介绍：kaistai.github.io/SelFee @蚁工厂](https://weibo.com/2194035935/N3oP81sxe)

Note: SelFee，一个迭代自修改的大语言模型。详细介绍：kaistai.github.io/SelFee/该模型同样是在LLaMA基础上用chatgpt的数据做的微调。你问它一个问题，它回答后会自己问自己这个答案需要求改吗，如果自己觉得需要修改就再生成一个新答案，然后继续问自己这个回答是否需要修改，直到最终自己觉得不需要修改为止。该模型擅长创造性写作或长文本生成，但在数学，推理，事实和编码表现不佳（作者认为这是LLaMA的锅，要提高这些能力必须要提升基础模型了）。

Picture: [82c654dfly1hejl1ehtjfj21eo1224oj.jpg](https://weibo.cn//mblog/pic/N3oP81sxe?rl=1)

#### [【CodeTF：基于Python的代码大型语言模型(Code LLM)和代码智能的一站式Transf @爱可可-爱生活](https://weibo.com/1402400261/N3qx3fzTE)

Note: 【CodeTF：基于Python的代码大型语言模型(Code LLM)和代码智能的一站式Transformer库，提供了一个无缝的界面，用于训练和推断代码智能任务，如代码摘要、转换、代码生成等。旨在促进SOTA CodeLLMs在实际应用中的轻松集成。除了核心LLMs用于代码的特点外，CodeTF还提供了用于跨多种语言进行代码操作的实用程序，包括易于提取代码属性的功能】’CodeTF - A One-stop Transformer Library for State-of-the-art Code LLM - CodeTF: One-stop Transformer Library for State-of-the-art Code LLM' Salesforce GitHub: github.com/salesforce/CodeTF  

Picture: [5396ee05ly8hejsliu5tsj20up0u07b1.jpg](https://weibo.cn//mblog/pic/N3qx3fzTE?rl=1)

Github: [github.com/salesforce/CodeTF](https://github.com/salesforce/CodeTF)

#### [直白图解GPT2模型Self Attention注意力机制：实现过程及MTB语言模型核心代码阅读总结 @蚁工厂](https://weibo.com/2194035935/N3xM78XUs)

Note: 直白图解GPT2模型Self Attention注意力机制：实现过程及MTB语言模型核心代码阅读总结 

#### [吹爆清华出的“据意查句”这个神器：wantquotes.net，你只需要输入描述，就可以找到相应的名 @蚁工厂](https://weibo.com/2194035935/N3BvnkKsj)

Note: 吹爆清华出的“据意查句”这个神器：wantquotes.net，你只需要输入描述，就可以找到相应的名言名句！ 作文神器回复:已收藏到Notion[火箭浣熊]//://:清华NLP还出了个“反向词典“：wantwords.net，支持中英文，也是一大神器

Picture: [005FMk8Tly1h4kfym0xguj31bw0u0grk.jpg](https://weibo.cn//mblog/pic/LE58vxn0N?rl=1)

#### [跟上AI时代最好的办法就是阅读论文，这个repo集合了每周最佳的AI论文供大家阅读。地址：githu @Maeiee](https://weibo.com/1240212845/N3BJL6kkf)

Note: 跟上AI时代最好的办法就是阅读论文，这个repo集合了每周最佳的AI论文供大家阅读。地址：github.com/dair-ai/ML-Papers-of-the-Week [冲鸭]//://:转发

Picture: [71f81b09gy1heh93s45otj21eu15q7sl.jpg](https://weibo.cn//mblog/pic/N36sNqDxz?rl=1)

Github: [github.com/dair-ai/ML-Papers-of-the-Week](https://github.com/dair-ai/ML-Papers-of-the-Week)

#### [wtfpython，一些有趣且鲜为人知的 Python 特性.地址：github.com/satwi @蚁工厂](https://weibo.com/2194035935/N3CSX9Wpx)

Note: wtfpython，一些有趣且鲜为人知的 Python 特性.地址：github.com/satwikkansal/wtfpython这个有趣的项目意在收集 Python 中那些难以理解和反人类直觉的例子以及鲜为人知的功能特性, 并尝试讨论这些现象背后真正的原理!英文原版，有中文翻译。 回复:已收藏至你的Notion python

Picture: [82c654dfly1h2upeanjgzj20u01c8wp7.jpg](https://weibo.cn//mblog/pic/LvXHoDif4?rl=1)

Github: [github.com/satwikkansal/wtfpython](https://github.com/satwikkansal/wtfpython)

#### [《性能之殇》系列博文这是  大佬的博客。本系列博文的目标是讨论一下人们为了提高性能做出的种种努力，这 @蚁工厂](https://weibo.com/2194035935/N3J1zFxig)

Note: 《性能之殇》系列博文这是  大佬的博客。本系列博文的目标是讨论一下人们为了提高性能做出的种种努力，这里面包含硬件层面的 CPU、RAM、磁盘，操作系统层面的并发、并行、事件驱动，软件层面的多进程、多线程，网络层面的分布式，等等等等。事实上，上述名词并不局限于某一个层面，计算机从 CPU 内的门电路到显示器上浏览器中的某行字，是层层协作才得以实现的；计算机科学中的许多概念，都跨越了层级：事件驱动就是 CPU 和操作系统协作完成的。马

Picture: [82c654dfly1h2w3q59m2sj20pl0ct769.jpg](https://weibo.cn//mblog/pic/Lw965CCAP?rl=1)

#### [【femtoGPT：完全用 Rust 实现的极简预训练生成式Transformer(Generati @爱可可-爱生活](https://weibo.com/1402400261/N3Lj67MNh)

Note: 【femtoGPT：完全用 Rust 实现的极简预训练生成式Transformer(Generative Pretrained Transformer)。从张量处理逻辑到训练/推断的代码，一切都是从零开始实现的。这个架构与 Andrej Karpathy 的几乎完全相似。femtoGPT 是一个很好的起点，适合那些对大规模语言模型感兴趣并且想深入了解这些模型如何工作的人】'femtoGPT - Pure Rust implementation of a minimal Generative Pretrained Transformer' Keyvan Kambakhsh GitHub: github.com/keyvank/femtoGPT  

Picture: [5396ee05ly8hemcb0g8isj21by0tsqa7.jpg](https://weibo.cn//mblog/pic/N3Lj67MNh?rl=1)

Github: [github.com/keyvank/femtoGPT](https://github.com/keyvank/femtoGPT)

#### [《How Diffusion Models Work 扩散模型是如何工作的》第五集：“Trainin @宝玉xp](https://weibo.com/1727858283/N3SGNoFlh)

Note: 《How Diffusion Models Work 扩散模型是如何工作的》第五集：“Training 训练”  YouTube列表：youtube.com/watch?v=oSmlciqXOaU&list=PLiuLMb-dLdWKh6Oq46LZ3pLwlmYuMYl_g🔗  //：正文有油管合集，还没翻译完//：有没有翻译好的合集地址的？回复: 正文有油管合集，还没翻译完有没有翻译好的合集地址的？高效

#### [系列电子书《鸢尾花书：从加减乘除到机器学习》，包含“编程不难”“可视之美”“数学要素”“矩阵力量”“ @蚁工厂](https://weibo.com/2194035935/N3R82hK4e)

Note: 系列电子书《鸢尾花书：从加减乘除到机器学习》，包含“编程不难”“可视之美”“数学要素”“矩阵力量”“统计至简”“数据有道”“机器学习”七本电子书地址：github.com/Visualize-ML作者生姜DrGinger。本库是书籍的开源版。其中“数学要素”“矩阵力量”已经正式出版： 为生姜老师打call[彩虹屁]

Picture: [82c654dfly1hen1r1xj2sj21o50ul1hr.jpg](https://weibo.cn//mblog/pic/N3R82hK4e?rl=1)

Github: [github.com/Visualize-ML](https://github.com/Visualize-ML)

#### [【Google的生成式AI教程：从大型语言模型的基础知识到如何在Google Cloud上创建和部署 @爱可可-爱生活](https://weibo.com/1402400261/N3Rb07MCb)

Note: 【Google的生成式AI教程：从大型语言模型的基础知识到如何在Google Cloud上创建和部署生成式AI解决方案】《Google Cloud Skills Boost》   看完了，狗家夹杂了太多私货，还是Cohere的教程靠谱一些啊

Picture: [5396ee05ly8hen23h16egj20u025dai6.jpg](https://weibo.cn//mblog/pic/N3Rb07MCb?rl=1)

#### [【视觉AI芯片技术干货分享】深度解析为何高性能NPU更看重“性价比”？ ~~~ by爱芯元智AXER @WinnieS的微博](https://weibo.com/2144454703/N3RkUEwt3)

Note: 【视觉AI芯片技术干货分享】深度解析为何高性能NPU更看重“性价比”？ ~~~ by爱芯元智AXERA数据采集 ~~~好真实的展示混合精度NPU”的协同设计思路但是我的问题是， 如果用int4/int2 这种，得有按4bit或者2bit对齐（数据移动和计算）的能力吧？否则也是浪费 

Picture: [7fd1c82fgy1hen2tzm624j21d60gtjxz.jpg](https://weibo.cn//mblog/pic/N3RkUEwt3?rl=1)

#### [深入理解 Cache 工作原理 回复:感觉激发亮度确实砍了点，今天中午那么大太阳在阳光下只能激发到8 @程杰Rockie](https://weibo.com/1746378031/N3Teb1knf)

Note: 深入理解 Cache 工作原理 回复:感觉激发亮度确实砍了点，今天中午那么大太阳在阳光下只能激发到80%，还是看不太清，以前都可以激发满的回复:啥意思，发布时候吹的开始砍了吗？findx6p，131阴天激发不了亮度。玩游戏锁大核。最差的调度，还是最差的续航。笑死。

#### [哈喽大家好，5月热门论文必读论文总结来啦！5月，有35篇论文在社交平台和AMiner上得到热烈的讨论 @AMiner学术头条](https://weibo.com/1870858943/N3VqfAF8c)

Note: 哈喽大家好，5月热门论文必读论文总结来啦！5月，有35篇论文在社交平台和AMiner上得到热烈的讨论，分别来自OpenAI、谷歌、Meta、微软、清华大学、华为等机构。论文列表如下（点击链接可直接使用ChatPaper）：1. QLORA: Efficient Finetuning of Quantized LLMs2. Enhancing Chat Language Models by Scaling High-quality Instructional Conversations3. Let’s Verify Step by Step4. OlaGPT: Empowering LLMs With Human-like Problem-Solving Abilities5. Voyager: An Open-Ended Embodied Agent with Large Language Models6. Tree of Thoughts: Deliberate Problem Solving with Large Language Models7. Backpack Language Models8. Controllable Text-to-Image Generation with GPT-49. HuatuoGPT, towards Taming Language Model to Be a Doctor10. Large Language Models as Tool Makers11. Specifer: Accelerating Generative LLM Serving with Speculative Inference and Token Tree Verification12. Cheap and Quick: Efficient Vision-Language Instruction Tuning for Large Language Models13. ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation14. RecurrentGPT: Interactive Generation of (Arbitrarily) Long Text15. Ghost in the Minecraft: Generally Capable Agents for Open-World Enviroments via Large Language Models with Text-based Knowledge and Memory16. VanillaNet: the Power of Minimalism in Deep Learning17. Gorilla: Large Language Model Connected with Massive APIs18. Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training19. RWKV: Reinventing RNNs for the Transformer Era20. C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models21. M3KE: A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark for Chinese Large Language Models22. LIMA: Less Is More for Alignment23. Any-to-Any Generation via Composable Diffusion24. Evidence of Meaning in Language Models Trained on Programs25. A Comprehensive Survey on Segment Anything Model for Vision and Beyond26. Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold27. SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities28. Transfer Visual Prompt Generator across LLMs29. Unlimiformer: Long-Range Transformers with Unlimited Length Input30. AutoML-GPT: Automatic Machine Learning with GPT 31. GPT4Graph: Can Large Language Models Understand Graph Structured Data ? An Empirical Evaluation and Benchmarking32. Shap-E: Generating Conditional 3D Implicit Functions33. Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes34. PaLM 2 Technical Report35. ImageBind: One Embedding Space To Bind Them All如果你觉得有更好的论文，欢迎评论区留言[比耶]

Picture: [6f830abfly1henkyihp0qj21540w0x1n.jpg](https://weibo.cn//mblog/pic/N3VqfAF8c?rl=1)

#### [Deep Learning System地址：github.com/chenzomi12/DeepL @蚁工厂](https://weibo.com/2194035935/N40xvzCNW)

Note: Deep Learning System地址：github.com/chenzomi12/DeepLearningSystemDeep Learning系统核心原理介绍。第一部分基础篇介绍AI框架的AI框架核心技术，首先介绍任何一个AI框架都离不开的自动微分，通过自动微分功能后就会产生表示神经网络的图和算子，然后介绍AI框架前端的优化，还有最近很火的大模型分布式训练在AI框架中的关键技术。第二部分进进阶篇介绍AI框架AI编译器原理，将站在系统设计的角度，思考在设计现代机器学习系统中需要考虑的编译器问题，特别是中间表达乃至后端优化。第三部分是很实际的推理系统，讲了太多原理身体太虚容易消化不良，还是得回归到业务本质，让行业、企业能够真正应用起来，而推理系统涉及一些核心算法和注意的事情也分享下。第四部分硬核篇介绍AI芯片，这里就很硬核了，希望可以坚持到最后啦，从芯片的基础到AI芯片的范围都会涉及，芯片设计需要考虑上面AI框架的前端、后端编译，而不是停留在天天喊着吊打英伟达，被现实打趴。 马克回复:已保存至你的Notion回复:成功收藏至notion👍

Picture: [82c654dfly1heo7l699ycj21331ib1kx.jpg](https://weibo.cn//mblog/pic/N40xvzCNW?rl=1)

Github: [github.com/chenzomi12/DeepLearningSystemDeep](https://github.com/chenzomi12/DeepLearningSystemDeep)

#### [【嵌入(embeddings)入门资料集】’What are embeddings? - A dee @爱可可-爱生活](https://weibo.com/1402400261/N41WB6jfU)

Note: 【嵌入(embeddings)入门资料集】’What are embeddings? - A deep dive into embeddings starting from fundamentals' Vicki Boykis GitHub: github.com/veekaybee/what_are_embeddings   你好，你感兴趣的“开源”已开通了超话社区～ 超话社区是微博旗下兴趣互动社区，快来与志同道合的小伙伴们一起交流互动吧！ 戳我进入>> 

Picture: [5396ee05ly8heodrjywo0j20ct0cnq48.jpg](https://weibo.cn//mblog/pic/N41WB6jfU?rl=1)

Github: [github.com/veekaybee/what_are_embeddings](https://github.com/veekaybee/what_are_embeddings)

#### [oscourse.org这个网站是  老师的操作系统课程官方站。里面包括课程的文档、幻灯片和视频等内 @蚁工厂](https://weibo.com/2194035935/N451M9xm8)

Note: oscourse.org这个网站是  老师的操作系统课程官方站。里面包括课程的文档、幻灯片和视频等内容。这门课程关注操作系统的基础知识，包括操作系统结构、进程和线程、CPU调度、进程同步、内存管理、文件系统、I/O系统和安全性。它有一个相当大的实验部分，涉及到一个名为BLITZ的玩具操作系统的简化组件。这门课程的实验作业假设你已经具备基本的编程语言（如C）的工作知识，一些基本的调试技能，以及在Linux操作系统（一个UNIX变体）中使用命令行工具的能力。转发微博转发微博  回复:成功保存到notion加拿大工程院新晋院士

Picture: [82c654dfly1heo9ryua9nj213a1bgavj.jpg](https://weibo.cn//mblog/pic/N451M9xm8?rl=1)

#### [《性能之巅 第2版》读书笔记（第14章）1、Ftrace是Linux官方的跟踪器，它是一个多功能工具 @小川CD](https://weibo.com/1202332555/N45Eyj4u6)

Note: 《性能之巅 第2版》读书笔记（第14章）1、Ftrace是Linux官方的跟踪器，它是一个多功能工具，由不同的跟踪工具组成。Ftrace可以回答以下问题：1）某些内核函数被调用的频率如何？2）导致该函数被调用的代码路径是什么？3）某个内核函数调用了哪些子函数？4）禁用抢占的代码路径造成的最高延迟是多少？2、Ftrace包含剖析器和跟踪器，剖析器提供统计摘要，如计数和直方图，而跟踪器提供每个事件的详细信息。3、使用Ftrace功能的接口是tracefs文件系统，它应该挂载在/sys/kernel/tracing上。挂载命令：mount -t tracefs tracefs /sys/kernel/tracing4、要查看当前是否有使用Ftrace跟踪器，可以运行命令：cat /sys/kernel/debug/tracing/current_tracer；要启用跟踪器，需要将其名称写入该文件。例如，要启用blk跟踪器：echo blk > /sys/kernel/debug/tracing/current_tracer5、函数剖析器提供关于内核函数调用的统计数据，适用于研究正在使用的内核函数，并确定哪些函数最慢。函数剖析器的工作原理是在每个内核函数的开头使用编译后的剖析调用。6、函数跟踪器打印每个内核函数调用的详细信息，并使用前面提到的剖析工具。这可以显示各种函数的顺序，基于时间戳的模式，以及可能对应的CPU上的进程名称和PID。函数跟踪的开销比函数剖析高。7、trace_pipe文件是读取跟踪缓冲区的另一种接口。从该文件读取将返回一个无限的事件流。它使用事件，因此在读取一次后，事件就不再位于跟踪缓冲区中。8、跟踪点（tracepoint）是内核的静态监测工具，从技术上讲，跟踪点只是内核源代码中的跟踪函数。9、kprobes用于内核的动态监测，它创建供跟踪器使用的kprobe事件，与Ftrace共享tracefs输出和控制文件。10、uprobes是用户级的动态监测，它创建供跟踪器使用的uprobe事件，与Ftrace共享tracefs输出和控制文件。11、硬件延迟检测器（hwlat）是特殊用途跟踪器的一个例子。它可以监测到外部硬件事件对CPU性能的干扰。其工作原理是在禁用中断的情况下运行一个代码循环作为实验，测量每个循环迭代所消耗的时间。12、Trace-cmd是一个开源的Ftrace前端，它支持配置跟踪系统的子命令和选项、二进制输出格式和其他功能。对于事件源，它可以使用Ftrace函数、function_graph跟踪器、跟踪点和已配置的kprobes和uprobes。与perf相比，它对function和function_graph跟踪器的支持更好。13、KernelShark是一个用于trace-cmd输出文件的可视化用户界面。它可以帮助识别不同线程之间的交互引起的性能问题。14、perf-tools是本书作者开发的一个基于Ftrace和perf的高级性能分析工具集。

#### [面向开发者的 LLM 入门课程地址：github.com/datawhalechina/prompt @蚁工厂](https://weibo.com/2194035935/N49LA9fyC)

Note: 面向开发者的 LLM 入门课程地址：github.com/datawhalechina/prompt-engineering-for-developers这个库存放吴恩达大模型系列课程中文版，包括《Prompt Engineering》、《Building System》和《LangChain》 。《ChatGPT Prompt Engineering for Developers》、《Building Systems with the ChatGPT API》、《LangChain for LLM Application Development》等教程作为由吴恩达老师与 OpenAI 联合推出的官方教程，在可预见的未来会成为 LLM 的重要入门教程，但是目前还只支持英文版且国内访问受限，打造中文版且国内流畅访问的教程具有重要意义；同时，GPT 对中文、英文具有不同的理解能力，本教程在多次对比、实验之后确定了效果大致相当的中文 Prompt，支持学习者研究如何提升 ChatGPT 在中文语境下的理解与生成能力。回复:已收藏到notion

Picture: [82c654dfly1hepcb3ak4nj20uo0yl16u.jpg](https://weibo.cn//mblog/pic/N49LA9fyC?rl=1)

Github: [github.com/datawhalechina/prompt-engineering-for-developers](https://github.com/datawhalechina/prompt-engineering-for-developers)

#### [blink项目，地址：github.com/jart/blink这个项目包含两个程序：1.  bli @蚁工厂](https://weibo.com/2194035935/N4a0gbK8Q)

Note: blink项目，地址：github.com/jart/blink这个项目包含两个程序：1.  blink是一个虚拟机，它在不同的操作系统和硬件架构上运行x86-64-linux程序。它的设计目标与qemu-x86_64命令相同，但更小（仅为221kb），也更快2. blinkenlights是一个终端用户界面，可用于跨平台调试x86_64-linux或i8086程序。与GDB不同，Blinkenlights专注于可视化程序执行。它使用UNICODE IBM Code Page 437字符来显示二进制内存面板，这些面板会随着你逐步通过程序的汇编代码而改变。这些内存面板可以使用鼠标滚轮进行滚动和缩放。Blinkenlights还允许反向调试，其中在汇编显示上滚动滚轮允许回放执行历史。回复:未能收藏到你的Notion，无公共集成 token回复:成功保存到你的notion

Picture: [82c654dfly1hepcw7ue6uj21z4140u0z.jpg](https://weibo.cn//mblog/pic/N4a0gbK8Q?rl=1)

Github: [github.com/jart/blink](https://github.com/jart/blink)

#### [推荐一款让人爽心悦目的开源免费中文字体：LXGW WenKai / 霞鹜文楷，github.com/ @Maeiee](https://weibo.com/1240212845/N4adn7TtY)

Note: 推荐一款让人爽心悦目的开源免费中文字体：LXGW WenKai / 霞鹜文楷，github.com/lxgw/LxgwWenKai中文字体的体积一般比较大（2~5Mb），如果要用于网页正文渲染，可以考虑将字体文件分拆多份，每一份通过 unicode-range 这个 css 属性来指定生效字符范围，这种方式可以借助浏览器并行下载的能力，快速完成字体下载。我直接换到系统字体我也是obsidian 加这个字体

Picture: [6c0378f8gy1heohqn1jdej217g1cmat8.jpg](https://weibo.cn//mblog/pic/N42Q5gFB3?rl=1)

Github: [github.com/lxgw/LxgwWenKai](https://github.com/lxgw/LxgwWenKai)

#### [又来挖坑了，开始翻译《LangChain for LLM Application Developme @宝玉xp](https://weibo.com/1727858283/N4a313Tat)

Note: 又来挖坑了，开始翻译《LangChain for LLM Application Development 基于LangChain的大语言模型应用开发》第1集 Introduction 介绍  YouTube合集：youtube.com/watch?v=gUcYC0Iuw2g&list=PLiuLMb-dLdWIYYBF3k5JI_6Od593EIuEG🔗  辛苦，等着呢坐等  哈哈哈哈哈哈  b 站都是很生硬的翻译后面章节都是十几二十分钟，工作量够大。回复:第三集：太好了 最想看这个[666][666]回复:第二集发了：坐等  哈哈哈哈哈哈  b 站都是很生硬的翻译用能力当然自己写最好，但是这个出货快功在当下 利在国民 大大促进了民间中西方科学文化交流手动点赞 [666]用好结合大语言模型工具链的潜力是无穷的。后面章节都是十几二十分钟，工作量够大。

#### [llama.cpp, whisper.cpp的作者Georgi Gerganov开了新公司 ggml @Maeiee](https://weibo.com/1240212845/N4bpNcafd)

Note: llama.cpp, whisper.cpp的作者Georgi Gerganov开了新公司 ggml.ai。他的重大贡献是用C/C++重写了原本使用Python的底层神经网络推理代码，并且几乎不依赖于任何其它的库，效率非常之高。GGML的GG是他名字的缩写，也是这个项目所使用的神经网络的文件格式。这个项目可以称为古典的优雅和现代前沿的结合，告诉大家C/C++或是机器语言永远可以给你带来惊喜，因为它最简单最快速。

Picture: [71f81b09ly1hepd3wwmm4j20wg0za1kx.jpg](https://weibo.cn//mblog/pic/N4bbJewGj?rl=1)

#### [【FactAI: 智能事实核查服务，使用预训练模型来判断文章标题和正文之间的关系，以概率的形式输出这 @爱可可-爱生活](https://weibo.com/1402400261/N4bKudK13)

Note: 【FactAI: 智能事实核查服务，使用预训练模型来判断文章标题和正文之间的关系，以概率的形式输出这种关系的估计值，涵盖四个类别：无关、讨论、一致和不一致。】’FactAI: Intelligent Fact-Checking AI Service - Harnessing the Power of AI to Navigate the Information Age – Uncovering Truth, Promoting Transparency, and Championing Fact-Based Discourse!' Zhiwei Fang GitHub: github.com/pentilm/FactAI  标题党检验器

Picture: [5396ee05ly8hepl1lwtd1j21c00tqai0.jpg](https://weibo.cn//mblog/pic/N4bKudK13?rl=1)

Github: [github.com/pentilm/FactAI](https://github.com/pentilm/FactAI)

#### [基于LangChain的大语言模型应用开发3——记忆这一集强力推荐一下，讲了几个有价值的内容：1.  @宝玉xp](https://weibo.com/1727858283/N4gJf4njn)

Note: 基于LangChain的大语言模型应用开发3——记忆这一集强力推荐一下，讲了几个有价值的内容：1. LLM是没有记忆的，怎么保持会话的记忆？2. LLM是有上下文窗口限制的，怎么有效的保留历史会话消息？有哪些有效的方案？是否可以尽可能长的记录会话历史？课程地址：油管合集：www.youtube.com/watch?v=gUcYC0Iuw2g&list=PLiuLMb-dLdWIYYBF3k5JI_6Od593EIuEG🔗 

#### [又来挖坑了，开始翻译《LangChain for LLM Application Developme @宝玉xp](https://weibo.com/1727858283/N4hKpgYnJ)

Note: 又来挖坑了，开始翻译《LangChain for LLM Application Development 基于LangChain的大语言模型应用开发》第1集 Introduction 介绍  YouTube合集：youtube.com/watch?v=gUcYC0Iuw2g&list=PLiuLMb-dLdWIYYBF3k5JI_6Od593EIuEG🔗  

#### [推荐AI学习网站：通往AGI之路waytoagi.com网站内容很全，包含了学习AI知识相关的各种图 @宝玉xp](https://weibo.com/1727858283/N4jt8vO24)

Note: 推荐AI学习网站：通往AGI之路waytoagi.com网站内容很全，包含了学习AI知识相关的各种图文和视频资料，包括Prompt、AI绘画、插件等众多内容 留下你的QQ，我加你你好，QQ多少？感谢感谢！

Picture: [66fd066bgy1heq9atfbozj224c1hsb2a.jpg](https://weibo.cn//mblog/pic/N4hh9elsC?rl=1)

#### [微软在 GitHub 开源的 5 个面向初学者的技术教程，包括机器学习、Web 开发、物联网、数据科 @GitHubDaily](https://weibo.com/5722964389/N4bdelu6A)

Note: 微软在 GitHub 开源的 5 个面向初学者的技术教程，包括机器学习、Web 开发、物联网、数据科学、人工智能。详细介绍：这些教程有着以下特点：- 总课时均为期 12 周，共 24 节，让你可以合理安排学习计划；- 每个课程均附有项目实战开发讲解，强调实践出真知；- 每节课均附有测验说明、草图笔记、作业任务等内容，助你更系统、更全面的掌握课程内容。目前教程所有资源均已开源至 GitHub，大家可以好好学习一下。转发微博23 3067 关注Mark牛

Picture: [006fiYtfgy1hephya0k8gj30u00l5tjc.jpg](https://weibo.cn//mblog/pic/N4bdelu6A?rl=1)

#### [bootOS，一个只有512字节的操作系统，它是一个可以装入一个引导扇区的单体操作系统。它能够加载、 @蚁工厂](https://weibo.com/2194035935/N4jg642V2)

Note: bootOS，一个只有512字节的操作系统，它是一个可以装入一个引导扇区的单体操作系统。它能够加载、执行和保存程序。同时还维护一个文件系统。它可以处理任何起始大小为180K的软盘。地址：github.com/nanochess/bootOS可以在8088（比286还古老的CPU）上运行。 

Github: [github.com/nanochess/bootOS](https://github.com/nanochess/bootOS)

#### [GitHub 上一个强大的图像标记基础模型：Recognize Anything Model (RA @GitHubDaily](https://weibo.com/5722964389/N4n1FdB8q)

Note: GitHub 上一个强大的图像标记基础模型：Recognize Anything Model (RAM)。 RAM 采用一种新的图像标记范例，可高精度地识别任何常见类别，并利用大规模图像文本对进行训练，而不是手动注释。GitHub：github.com/xinyu1205/Recognize_Anything-Tag2TextRAM 的开发包括四个关键步骤：1. 通过自动文本语义解析大规模获取无注释图像标签；2. 使用统一标题和标记任务，训练初步模型进行自动注释，分别由原始文本和解析标签监督；3. 利用数据引擎生成额外注释并清除不正确的注释；4. 利用处理后的数据对模型进行再训练，并使用更小但质量更高的数据集进行微调。经过众多基准测试评估，RAM 的标记能力颇为优秀，效果明显优于 CLIP 和 BLIP。值得注意的是，RAM 甚至超越了完全监督的方式，甚至可媲美 Google API。回复:已保存至notion转发微博

Picture: [006fiYtfgy1heqyswl81rj31gs18ke81.jpg](https://weibo.cn//mblog/pic/N4n1FdB8q?rl=1)

Github: [github.com/xinyu1205/Recognize_Anything-Tag2TextRAM](https://github.com/xinyu1205/Recognize_Anything-Tag2TextRAM)

#### [今天学完了吴恩达的提示工程短课（ChatGPT Prompt Engineering for Dev @蚁工厂](https://weibo.com/2194035935/N4krAcalr)

Note: 今天学完了吴恩达的提示工程短课（ChatGPT Prompt Engineering for Developers），觉得还是很有收获的，分享一下我对每节课做的笔记：[玉兔捣药] Guidelines- 在复杂任务上，给AI多一点时间：把一个复杂问题分解成多个步骤的简单问题，让AI分步骤解决，而不是一次性提出。- 如果AI输出有错误，把错误返回给AI，让AI自己反思错误的内容，通常能得到正确的答案。[玉兔捣药] Iterative- 没有最好的prompt，只有根据自己的需求不断完善prompt：当你觉得你的prompt不work时，要分析可能的原因，尤其是有没有给出足够清楚的指示；修改后再次提交，并根据返回的结果再次迭代。- 可以对输出进行精确限定：例如长度可以限制到句子、单次和字符数。[玉兔捣药] Summarizing- 让GPT对文字内容进行分析时带有特定关注点，更关注数据还是更关注叙事。- 可以输出特定的list项，即只总结你指定的内容。- 还可以以html表格或者jason格式输出[玉兔捣药] Inferring- 大语言模型能够很好地代替一些传统NLP模型的功能，例如情绪分析，内容提取，主题判断等。- 而且使用起来更为灵活，不需外另外训练，可以用自然语言的形式描述任务。[玉兔捣药] Transforming- 可以指定GPT回复特定信息，然后将这个特定信息组合到预制好的text格式中，这样可以用更稳定的形式输出，而且节省token。- 可以方便地将文字在不同表现格式之间进行转换，例如从jason转换成html。- 可以比较修改前后的区别 by python redlines- 可以指定以某种学术写作格式输出，例如： - proofread and correct this review. Make it more compelling.  - Ensure it follows APA style guide and targets an advanced reader. [玉兔捣药]Expanding- 根据需要回答的情况给出尽可能详细的指导，要达到所需的详细程度通常需要用不断迭代修改的方式来完成。- Temperature参数与GPT回复的随机性和多样性成正比。 - 如果想要确定和稳定的输出用温度0 （同样的输入会总是会得到同样的输出） - 如果希望更有发散性、创造性的输出可以用温度0.7[玉兔捣药] Chatbot- 在API调用中可以分配不同的角色：系统，用户，助手（GPT）- 当你的描述足够详细时，就可以得到一个能够完成特定任务的机器人。（教程中的案例是一个自动接待点餐并生成小票记录的聊天机器人）▶课程链接：↑以上内容均精选自我每周更新的私人图书馆——知识星球：AI白日梦想家，加入方式请见我的微博置顶帖哈~！

Picture: [7420b8eegy1heqn7o0k48j20r40f5n0j.jpg](https://weibo.cn//mblog/pic/N4kqArIab?rl=1)

#### [【基于Stable Diffusion图像合成系统的完整C++ ONNX实现，包括原始的txt2im @爱可可-爱生活](https://weibo.com/1402400261/N4liQ7rSo)

Note: 【基于Stable Diffusion图像合成系统的完整C++ ONNX实现，包括原始的txt2img、img2img和修复图像的功能以及安全检查器。该方案不依赖Python，在单进程中运行整个图像生成过程，性能竞争力强，使部署变得更加简单和轻量化，只需要几个可执行文件、库文件和模型权重】’a C++ ONNX implementation of StableDiffusion.' Péter Major GitHub: github.com/axodox/axodox-machinelearning   

Picture: [5396ee05ly8heqr7i3afxj21c10u047r.jpg](https://weibo.cn//mblog/pic/N4liQ7rSo?rl=1)

Github: [github.com/axodox/axodox-machinelearning](https://github.com/axodox/axodox-machinelearning)

#### [【Youku-mPLUG：包含1000万条高质量视频和语言数据的中文预训练数据集。该数据集从中国知名 @爱可可-爱生活](https://weibo.com/1402400261/N4lonoAWY)

Note: 【Youku-mPLUG：包含1000万条高质量视频和语言数据的中文预训练数据集。该数据集从中国知名的视频分享网站Youku采集而来，具备安全性、多样性和质量的严格标准。该数据集提供了三个不同的多模态视频基准任务，用于评估预训练模型的能力，包括视频分类预测、视频文本检索和视频字幕生成】'Youku-mPLUG 10M Chinese Large-Scale Video Text Dataset - Youku-mPLUG: A 10 Million Large-scale Chinese Video-Language Pre-training Dataset and Benchmarks' X-PLUG GitHub: github.com/X-PLUG/Youku-mPLUG  转发微博

Picture: [5396ee05ly8heqrm9m7pmj212u0u07ea.jpg](https://weibo.cn//mblog/pic/N4lonoAWY?rl=1)

Github: [github.com/X-PLUG/Youku-mPLUG](https://github.com/X-PLUG/Youku-mPLUG)

#### [M3E Models ：Moka（北京希瑞亚斯科技）开源的系列文本嵌入模型。模型下载：hugging @蚁工厂](https://weibo.com/2194035935/N4mVOju1l)

Note: M3E Models ：Moka（北京希瑞亚斯科技）开源的系列文本嵌入模型。模型下载：huggingface.co/moka-ai/m3e-baseM3E Models 是使用千万级 (2200w+) 的中文句对数据集进行训练的 Embedding 模型，在文本分类和文本检索的任务上都超越了 openai-ada-002 模型。其数据集，模型，训练脚本，评测框架都开源。开发者之一是 回复:已收藏至notion感谢博主推荐，补充一下指标。在文本分类上，使用 MTEB 的方式评测了 6 种数据集，我们的模型 Average Acc 领先 openai-ada-002 2.01 个点,领先 text2vec 4.02 个点。 在文本检索上，使用 MTEB 的方式评测了 T2Ranking，我们的模型 ndcg 领先 openai-ada-002 2.18 个点，领先 text2vec 16.6 个点

Picture: [82c654dfly1heqxve188aj21790x4wxy.jpg](https://weibo.cn//mblog/pic/N4mVOju1l?rl=1)

#### [Nvidia's H100 80GB AI and HPC PCI 5.0 compute card @WinnieS的微博](https://weibo.com/2144454703/N4llk2lqe)

Note: Nvidia's H100 80GB AI and HPC PCI 5.0 compute card with passive cooling for servers. The board costs ￥4,745,950 ($36,405), which includes a ￥4,313,000 base price ($32,955), a ￥431,300 ($3308) consumption tax (sales tax), and a ¥1,650 ($13) delivery charge, according to the company (via Hermitage Akihabara). 这里￥是日元，不是人民币哈，要不然500万人民币一张卡，吓死人了

#### [“通往AGI之路：旨在提供一个全面系统、易于理解的Al学习路径，帮助您了解Al的从概念到应用等各方面 @爱可可-爱生活](https://weibo.com/1402400261/N4o19ojX0)

Note: “通往AGI之路：旨在提供一个全面系统、易于理解的Al学习路径，帮助您了解Al的从概念到应用等各方面知识，更重要的是希望引发您思考：「我可以用Al做什么，帮助自己更强大」”    感谢推荐Paper + 博客，看不完，根本看不完 

Picture: [5396ee05ly8her374pr5wj21bx0u0tfb.jpg](https://weibo.cn//mblog/pic/N4o19ojX0?rl=1)

#### [几个打破付费墙(Paywall)的网站/工具：“Unpaywall: An open databas @爱可可-爱生活](https://weibo.com/1402400261/N4nYtAQA8)

Note: 几个打破付费墙(Paywall)的网站/工具：“Unpaywall: An open database of 20 million free scholarly articles”  “PaperPanda: Access millions of research papers in one click” https://paperpanda.app/ “12ft Ladder: Show me a 10ft paywall, I’ll show you a 12ft ladder”  “Open Access Button: Avoid Paywalls, Request Research” 工具回复:成功收藏到你的notion赛博雷锋

Picture: [5396ee05ly8her2xsgr3uj217c0u0n81.jpg](https://weibo.cn//mblog/pic/N4nYtAQA8?rl=1)

#### [1,  Transformer Engine可以在FP8和FP16之间动态切换（混合精度）The c @WinnieS的微博](https://weibo.com/2144454703/N4oRN2EdZ)

Note: 1,  Transformer Engine可以在FP8和FP16之间动态切换（混合精度）The challenge for models is to intelligently manage the precision to maintain accuracy while gaining the performance of smaller, faster numerical formats. Transformer Engine enables this with custom, NVIDIA-tuned heuristics that dynamically choose between FP8 and FP16 calculations and automatically handle re-casting and scaling between these precisions in each layer.2，tensor core 可以3倍速浮点操作The NVIDIA Hopper architecture also advances fourth-generation Tensor Cores by tripling the floating-point operations per second compared with prior-generation TF32, FP64, FP16 and INT8 precisions.

Picture: [7fd1c82fgy1her6v7g0buj20r10lz41k.jpg](https://weibo.cn//mblog/pic/N4oRN2EdZ?rl=1)

#### [FlyCV —— 高性能计算机图像系统。类似OpenCV，比OpenCV更轻量、性能更高。地址：gi @蚁工厂](https://weibo.com/2194035935/N26yBc71a)

Note: FlyCV —— 高性能计算机图像系统。类似OpenCV，比OpenCV更轻量、性能更高。地址：github.com/PaddlePaddle/FlyCVFlyCV已在 ARM 架构下做了很多优化，相比其他图像处理库性能更为出色。除了速度更快之外，FlyCV提供了更加细粒度的编译选项控制，使得在库体积上非常轻量，可以按需编译 。 另外，在编译阶段，还提供了自定义命名空间的选项支持，可以方便快速地解决相同依赖库冲突的问题。FlyCV支持大多数主流的操作系统，包括android、armlinux、macos（x86 & arm）、windows，以及ios。厉害，正在找arm上的图像库  回复:成功保存至你的Notion  

Github: [github.com/PaddlePaddle/FlyCVFlyCV](https://github.com/PaddlePaddle/FlyCVFlyCV)

#### [最近翻译的系列课程：《Building Systems with the ChatGPT API》由 @宝玉xp](https://weibo.com/1727858283/N3AYf0P8A)

Note: 最近翻译的系列课程：《Building Systems with the ChatGPT API》由OpenAI官方和DeepLearningAI共同推出的关于如何用ChatGPT的API构建常见应用，以及如何用好Prompt完成复杂的任务，并且保证其安全性和生成质量。课程地址： 微博播放列表：B站播放列表：YouTube播放列表：www.youtube.com/watch?v=1SZOGp1D17E&list=PLiuLMb-dLdWKjX8ib9PhlCIx1jKMNxMpy🔗Google 的《Generative AI learning path》Google出品的生成式AI的原理，浅显易懂。课程地址：微博播放列表：B站播放列表：YouTube播放列表：www.youtube.com/watch?v=tbLOQ533Up8&list=PLiuLMb-dLdWJPpybrCYNhi6D9Vd4vz16i🔗《基于LangChain的LLM开发》有LangChain创始人主讲，详细介绍了LangChain的原理和设计系统，并且讲了如何用LangChain操作大语言模型完成常见任务。课程地址：http://t.cn/A6pqFTDo微博播放列表：http://t.cn/A6pfw839B站播放列表：http://t.cn/A6pmbefNYouTube播放列表：www.youtube.com/watch?v=gUcYC0Iuw2g&list=PLiuLMb-dLdWIYYBF3k5JI_6Od593EIuEG🔗《扩散模型是如何工作的》现在很火的AI生成图片的技术，你所熟知的MIdJourney、Stable Diffusion都是基于扩散模型，这个系列教程详细介绍了扩散模型的工作原理。课程地址：http://t.cn/A6pqFTDo微博播放列表：http://t.cn/A6ptoMEeB站播放列表：http://t.cn/A6pmbefpYouTube播放列表：www.youtube.com/watch?v=oSmlciqXOaU&list=PLiuLMb-dLdWKh6Oq46LZ3pLwlmYuMYl_g🔗《LangChain：构建与数据对话的聊天机器人》由LangChain创始人主讲的如何利用LangChain实现一个基于自己数据的问答机器人，同时详细介绍了嵌入、数据检索等基本原理。课程地址：http://t.cn/A60OBUEG微博播放列表：http://t.cn/A6pkgIHEYouTube播放列表：youtube.com/watch?v=JMScDV251ho&list=PLiuLMb-dLdWJX_EWk4RtQAjjrPLWaswTVB站播放列表：http://t.cn/A60OBUEb《大语言模型微调之道》这是由Sharon Zhou主讲的，教你如何在自己的数据上进一步微调自己的LLM，以完成特定的任务。课程地址：http://t.cn/A6OwZ6qc微博播放列表：http://t.cn/A6OwtXsEYouTube：www.youtube.com/watch?v=3apAPNXogAQ&list=PLiuLMb-dLdWKtPM1YahmDHOjKN_a2UievB站：http://t.cn/A6OwtaTp《大型语言模型与生成式AI》这是一门亚马逊的人工智能科学家开的课程，对于大语言模型和生成式AI介绍的非常清楚，很适合入门。课程地址：www.coursera.org/learn/generative-ai-with-llms/lecture/sAKto/rlhf-fine-tuning-with-reinforcement-learning微博播放列表：http://t.cn/A6puSD2x油管：www.youtube.com/watch?v=X7r4rL2T2lg&list=PLiuLMb-dLdWL4KBaU3FTM5f_oMcSvXcZwB站：http://t.cn/A602slTT请问是怎么翻译的？大佬，b站《Building Systems with the ChatGPT API》这个的“构建系统3”和“构建系统4”是不是视频传重复了啊？请教一下，已经本地部署好whisper，并且可以顺利的生成字幕文件，但是下一步使用API去翻译这个字幕的过程有点卡壳一直没成功。API Key确定没有问题，生成的英文字幕文件我以.txt和.srt都进行了尝试，但依旧没有找到好的参考的程序调用API，您这边是怎么处理这一步走的呢？（使用text-davinci-003） 存存回复:试试这个工具：新增加系列：《大型语言模型与生成式AI》 课程地址：www.coursera.org/learn/generative-ai-with-llms/lecture/sAKto/rlhf-fine-tuning-with-reinforcement-learning 微博： B站：新增加系列： 《大语言模型微调之道》 课程地址： 微博播放列表： YouTube：www.youtube.com/watch?v=3apAPNXogAQ&list=PLiuLMb-dLdWKtPM1YahmDHOjKN_a2Uiev B站回复: 开发的话用GitHub Copilot就能明显提升效率老师，能否整理一个如何利用ChatGPT提高开发效能的合集？回复: 只是善用ChatGPT罢了老师，你太高产了，我都怀疑你这个号背后是不是一个团队。

#### [之前Facebook搞的Segment Anything（分割一切）抠图技术引起了不小的轰动。不过其 @蚁工厂](https://weibo.com/2194035935/N4t7i0klf)

Note: 之前Facebook搞的Segment Anything（分割一切）抠图技术引起了不小的轰动。不过其在一些细节上还有有问题。sam-hq这个项目在其基础上做了升级，抠图质量更高地址：github.com/SysCV/sam-hq图片为两者效果对比 回复:已保存到notion

Github: [github.com/SysCV/sam-hq](https://github.com/SysCV/sam-hq)

#### [一位从安全小白成长为安全研究员的经验总结，，文中分享了大量学习资料、安全工具和创作者推荐。读这篇文章 @蚁工厂](https://weibo.com/2194035935/N4uuNnj7O)

Note: 一位从安全小白成长为安全研究员的经验总结，，文中分享了大量学习资料、安全工具和创作者推荐。读这篇文章，也感受到任何行业的成长都没有捷径，需要在浓密的知识里摸爬滚打，找到自己顺手的拳法，然后再进行专项式地逐个击破。 

#### [【大型语言模型(LLM)压缩相关论文和工具列表，用以加快语言模型的训练和推理速度】'Awesome- @爱可可-爱生活](https://weibo.com/1402400261/N4uH5a7Qo)

Note: 【大型语言模型(LLM)压缩相关论文和工具列表，用以加快语言模型的训练和推理速度】'Awesome-LLM-Compression - Awesome LLM compression research papers and tools.' Owen Huang GitHub: github.com/HuangOwen/Awesome-LLM-Compression   

Picture: [5396ee05ly8herwoq9xaoj20vr0u0q65.jpg](https://weibo.cn//mblog/pic/N4uH5a7Qo?rl=1)

Github: [github.com/HuangOwen/Awesome-LLM-Compression](https://github.com/HuangOwen/Awesome-LLM-Compression)

#### [13:35-14:05 - 基础大模型（语言）—— 工程化打造AI中的“CPU”林咏华 | 智源研究 @WinnieS的微博](https://weibo.com/2144454703/N4uWQ0FZQ)

Note: 13:35-14:05 - 基础大模型（语言）—— 工程化打造AI中的“CPU”林咏华 | 智源研究院副院长兼总工程师很精彩，听晚了。 有机会重听一下。 智源嘛

Picture: [7fd1c82fgy1herxt9yqx4j214z0kxk6k.jpg](https://weibo.cn//mblog/pic/N4uWQ0FZQ?rl=1)

#### [浅谈DGX服务器组网之server篇# 虽然刚刚看完H100的发布会，不认真看，果然看不出细节，就看 @WinnieS的微博](https://weibo.com/2144454703/N4wv8v04o)

Note: 浅谈DGX服务器组网之server篇# 虽然刚刚看完H100的发布会，不认真看，果然看不出细节，就看热闹了“每一块H100通过一块CX7芯片来连接到CPU”，这个为什么呢？ 以前是CPU 连PCIe switch， 连2个GPU， 连NVMe盘，可以认为是PCIe slot不够现在用CPU-CX7-GPU，这种1：1互联，有什么好处，就是让CX7，有机会做GPU direct么？ 不受CPU的PCIe 接口限制这个有点牵强， DGX是选定CPU，不会降级的。 如果其它OEM重新设计系统，都打算上这么贵的H100，谁还在CPU上省银子啊顶配cpu也带宽瓶颈严重，amdintel都垃圾不是lane不够，是因为cpu p2p带宽瓶颈，用cx7是做gpu direct ，而且这个卡支持roce也支持ib，八个gpu，八个网卡，很厉害

Picture: [7fd1c82fgy1hes4gqpheyj20u00ijn4o.jpg](https://weibo.cn//mblog/pic/N4wv8v04o?rl=1)

#### [0:00 - 引言0:28 - 柔术比赛17:51 - AI和开源运动30:22 - 下一代AI模型 @宝玉xp](https://weibo.com/1727858283/N4F2xoiDy)

Note: 0:00 - 引言0:28 - 柔术比赛17:51 - AI和开源运动30:22 - 下一代AI模型发布42:37 - Meta的AI未来1:03:15 - 机器人1:18:42 - 审查1:33:23 - Meta的新社交网络1:40:10 - 埃隆·马斯克1:44:15 - 裁员和解雇1:51:45 - 招聘1:57:37 - Meta Quest 32:04:34 - Apple Vision Pro2:10:50 - AI的存在主义风险2:17:13 - 权力2:20:44 - AGI时间线2:28:07 - Murph挑战2:33:22 - 具象化的AGI2:36:29 - 信仰 回复:回复:楼主有b站账号不？感觉b站看视频更方便回复:WhisperX + GPT-4 API，技术都分享过保持一下我的铁粉这个字幕段没看出来说的是什么宝藏up，以我对你的了解，您是不是用了自动的添加字幕的ai插件

#### [微软官方的Rust教程面向初学者和学生的教程。对学习一种日益广泛使用且越来越热门的新编程语言感兴趣吗 @蚁工厂](https://weibo.com/2194035935/N4LF4fCfE)

Note: 微软官方的Rust教程面向初学者和学生的教程。对学习一种日益广泛使用且越来越热门的新编程语言感兴趣吗？ 从此处开始！ 打下使用 Rust 构建快速、高效的程序所需的知识基础。 微软免费发的文档和教程真多学 rust第一步，换个不是 Windows的系统

Picture: [82c654dfly1h33yozqw5uj21fk0vo107.jpg](https://weibo.cn//mblog/pic/LxbbYDqqs?rl=1)

#### [北京智源人工智能研究院发布了Aquila语言大模型（悟道·天鹰）。Aquila是一个支持中英双语知识 @蚁工厂](https://weibo.com/2194035935/N4M6DodLa)

Note: 北京智源人工智能研究院发布了Aquila语言大模型（悟道·天鹰）。Aquila是一个支持中英双语知识、支持商用许可协议、符合国内数据合规需要的大规模开源语言模型。介绍：github.com/FlagAI-Open/FlagAI/blob/master/examples/Aquila/README.mdAquila模型所采用的tokenizer是由从头开始训练的，中文平均tokens量显著低于其他开源模型。加油！

Picture: [82c654dfly1heu1j86oo8j21500l6wmj.jpg](https://weibo.cn//mblog/pic/N4M6DodLa?rl=1)

Github: [github.com/FlagAI-Open/FlagAI/blob/master/examples/Aquila/README.mdAquila](https://github.com/FlagAI-Open/FlagAI/blob/master/examples/Aquila/README.mdAquila)

#### [Youtuber Lucy 给了你 5 个建议，帮你理解“说得很快”的英语www.youtube.c @宝玉xp](https://weibo.com/1727858283/N4MNE7LnE)

Note: Youtuber Lucy 给了你 5 个建议，帮你理解“说得很快”的英语www.youtube.com/watch?v=iHGiJSmFvBI🔗  感谢博主，这种翻译校对很花时间的[火箭浣熊]感谢分享感谢分享回复:这些字幕翻译是纯奉献啊，要是自己看也不用翻译，粉丝有福了[火箭浣熊]转发微博这个妹子好看感谢，宝玉老师真勤奋，是吾辈楷模回复:这个还好，看一遍就校对完了，最近翻译的LangChain那个系列都快翻译吐了，讲师水平太烂！感谢博主，这种翻译校对很花时间的

#### [今年的智源大会，还是很有看头， 有非常不错的看头。 建议大家看回放。 我截屏不少，只挑有感觉的，划个 @WinnieS的微博](https://weibo.com/2144454703/N4GxIiKoz)

Note: 今年的智源大会，还是很有看头， 有非常不错的看头。 建议大家看回放。 我截屏不少，只挑有感觉的，划个重点：（倒序）1， 比亚迪对车载平台的规划，非常清晰2，比亚迪，基于transformer的多传感器多任务融合感知3，比亚迪，多相机BEV目标感知模型（还有一个4D真值，不太懂就不放了）4，中国电信天翼云：面向大模型训练的高性能存储实践5，中国电信天翼云：大模型的存储，算力等要求6，璧仞：保障大模型训练的任务稳定性7，璧仞：数千张卡的训练集群8，璧仞：BR1049，璧仞：大模型训练的并行策略10，璧仞：生态（这张图好全）11，智源：九鼎平台：测试软件12，昆仑+paddlepaddle深度优化车的操控性能非常出色，真是一款驾驶乐趣十足的好车。这款车的空间利用非常合理，让人乘坐起来非常舒服。比亚迪的车身线条非常流畅，让人感觉非常时尚。壁砺™100P比104高差不多一倍的性能，居然不敢拿出来，看来是被制裁了转发微博

Picture: [7fd1c82fly1hetazabfc0j21160jr79d.jpg](https://weibo.cn//mblog/pic/N4GxIiKoz?rl=1)

#### [《性能之巅 第2版》读书笔记（第15章）1、BPF（Berkeley Packet Filter）是 @小川CD](https://weibo.com/1202332555/N4OT5Fma1)

Note: 《性能之巅 第2版》读书笔记（第15章）1、BPF（Berkeley Packet Filter）是一种虚拟机指令集，用于高效地进行事件过滤和处理。它最初用于网络数据包过滤，现已扩展到其他领域，如系统跟踪、性能分析等。BPF允许用户编写自定义的BPF程序，在内核和用户空间之间执行，实现灵活而高效的事件处理和数据收集。2、BCC和bpftrace是基于BPF的跟踪前端工具，提供了开发、跟踪和分析系统性能的工具集合。BCC适合定制复杂的工具，支持各种参数，或使用各种库；bpftrace适合单行命令或短工具（不接受参数或仅接受单一整数型参数）。3、BCC是BPF编译器集合的开源项目，包含大量高级性能分析工具以及构建这些工具的框架。4、一些BCC工具的例子包括：biolatency：将块IO（磁盘IO）延迟汇总为直方图。biotop：按进程汇总块IO。biosnoop：通过延迟和其他细节跟踪块IO。bitesize：将IO大小汇总为直方图。cpudist：将每个进程的on-CPU和off-CPU时间汇总为直方图。killsnoop：跟踪kill(2)系统调用所发出的信号。klockstat：汇总内核互斥锁的统计数据。llcstat：按进程汇总CPU缓存引用和缺失。offcputime：通过栈跟踪迹汇总off-CPU时间。offwaketime：通过off-CPU栈和waker栈汇总阻塞时间。oomkill：跟踪内存不足（OOM killer）。syscount：汇总系统调用的数量和延迟。......5、bpftrace是一个基于BPF和BCC的开源跟踪器，提供了一整套性能分析工具，同时也是开发新工具的高级语言。6、一些bpftrace命令的例子：按进程统计系统调用：bpftrace -e 'tracepoint:raw_syscalls:sys_enter {@[pid, comm] = count(); }'按用户级栈跟踪用户缺页进程统计：bpftrace -e 'tracepoint:exceptions:page_fault_user {@[ustack, comm] = count(); }'对块IO请求的用户栈跟踪进行统计：bpftrace -t 't:block:block_rq_issue { @[ustack] = count(); }'通过用户栈跟踪对malloc请求的字节数（高开销）进行加和：bpftrace -e 'u:/lib/x86_64-linux-gnu/libc-2.27.so:malloc { @[ustack[5]] = sum(arg0); }'统计上下文切换的栈跟踪：bpftrace -e 't:sched:sched_switch { @[kstack, ustack, comm] = count(); }'......7、bpftrace程序由一系列关联行为的探针组成。探针的格式为：probes { actions }可以选择性地在行为前添加过滤器表达式，只有当过滤器表达式为真时，行为才会发生。过滤器的格式为：probes /filter/ { actions }8、探针以探针类型名开头，后跟以冒号分隔的层次结构：type:identifier1[:identifier2]。层次结构由探针类型定义。使用逗号分隔的多个探针可以执行相同的操作。probe1,probe2,... { actions }。BEGIN和END是两个特殊的探针，分别表示bpftrace程序的开始和结束。某些探针接受通配符类型，例如：kprobe:vfs_*9、过滤器使用布尔表达式来确定是否执行行为。例如：/pid == 123/10、行为可以是单个语句或由分号分隔的多个语句：{ action one; action two; action three; }11、内置函数：exit(): 退出bpftrace；str(char*): 从指针返回字符串；system(format[, argument ...]): 在shell中运行命令。12、变量：内置变量：预先定义的变量，例如：进程ID：pid；进程名：comm；纳秒时间戳：nsecs；当前线程的task_struct：curtask。scratch变量：用于临时计算，以"$"为前缀，例如：$x = 1；$y = "hello"；$z = (struct task_struct*)curtask。map变量：使用BPF的map存储对象，以"@"为前缀，用于全局存储，可以在行为之间传递数据。例如：probe1 {  = 1; } probe2 { $x = ; }13、map函数：map可以被指定为特殊的函数，可以按自定义的方式存储和打印数据。赋值语句如： = count()，用于对事件进行计数，在打印时会显示计数值。

#### [《性能之巅 第2版》读书笔记（第15章）1、BPF（Berkeley Packet Filter）是 @蚁工厂](https://weibo.com/2194035935/N4Pqjhpmx)

Note: 《性能之巅 第2版》读书笔记（第15章）1、BPF（Berkeley Packet Filter）是一种虚拟机指令集，用于高效地进行事件过滤和处理。它最初用于网络数据包过滤，现已扩展到其他领域，如系统跟踪、性能分析等。BPF允许用户编写自定义的BPF程序，在内核和用户空间之间执行，实现灵活而高效的事件处理和数据收集。2、BCC和bpftrace是基于BPF的跟踪前端工具，提供了开发、跟踪和分析系统性能的工具集合。BCC适合定制复杂的工具，支持各种参数，或使用各种库；bpftrace适合单行命令或短工具（不接受参数或仅接受单一整数型参数）。3、BCC是BPF编译器集合的开源项目，包含大量高级性能分析工具以及构建这些工具的框架。4、一些BCC工具的例子包括：biolatency：将块IO（磁盘IO）延迟汇总为直方图。biotop：按进程汇总块IO。biosnoop：通过延迟和其他细节跟踪块IO。bitesize：将IO大小汇总为直方图。cpudist：将每个进程的on-CPU和off-CPU时间汇总为直方图。killsnoop：跟踪kill(2)系统调用所发出的信号。klockstat：汇总内核互斥锁的统计数据。llcstat：按进程汇总CPU缓存引用和缺失。offcputime：通过栈跟踪迹汇总off-CPU时间。offwaketime：通过off-CPU栈和waker栈汇总阻塞时间。oomkill：跟踪内存不足（OOM killer）。syscount：汇总系统调用的数量和延迟。......5、bpftrace是一个基于BPF和BCC的开源跟踪器，提供了一整套性能分析工具，同时也是开发新工具的高级语言。6、一些bpftrace命令的例子：按进程统计系统调用：bpftrace -e 'tracepoint:raw_syscalls:sys_enter {@[pid, comm] = count(); }'按用户级栈跟踪用户缺页进程统计：bpftrace -e 'tracepoint:exceptions:page_fault_user {@[ustack, comm] = count(); }'对块IO请求的用户栈跟踪进行统计：bpftrace -t 't:block:block_rq_issue { @[ustack] = count(); }'通过用户栈跟踪对malloc请求的字节数（高开销）进行加和：bpftrace -e 'u:/lib/x86_64-linux-gnu/libc-2.27.so:malloc { @[ustack[5]] = sum(arg0); }'统计上下文切换的栈跟踪：bpftrace -e 't:sched:sched_switch { @[kstack, ustack, comm] = count(); }'......7、bpftrace程序由一系列关联行为的探针组成。探针的格式为：probes { actions }可以选择性地在行为前添加过滤器表达式，只有当过滤器表达式为真时，行为才会发生。过滤器的格式为：probes /filter/ { actions }8、探针以探针类型名开头，后跟以冒号分隔的层次结构：type:identifier1[:identifier2]。层次结构由探针类型定义。使用逗号分隔的多个探针可以执行相同的操作。probe1,probe2,... { actions }。BEGIN和END是两个特殊的探针，分别表示bpftrace程序的开始和结束。某些探针接受通配符类型，例如：kprobe:vfs_*9、过滤器使用布尔表达式来确定是否执行行为。例如：/pid == 123/10、行为可以是单个语句或由分号分隔的多个语句：{ action one; action two; action three; }11、内置函数：exit(): 退出bpftrace；str(char*): 从指针返回字符串；system(format[, argument ...]): 在shell中运行命令。12、变量：内置变量：预先定义的变量，例如：进程ID：pid；进程名：comm；纳秒时间戳：nsecs；当前线程的task_struct：curtask。scratch变量：用于临时计算，以"$"为前缀，例如：$x = 1；$y = "hello"；$z = (struct task_struct*)curtask。map变量：使用BPF的map存储对象，以"@"为前缀，用于全局存储，可以在行为之间传递数据。例如：probe1 {  = 1; } probe2 { $x = ; }13、map函数：map可以被指定为特殊的函数，可以按自定义的方式存储和打印数据。赋值语句如： = count()，用于对事件进行计数，在打印时会显示计数值。//://:转发微博

#### [【LLaMA-LoRA Tuner：轻松评估和优化LLaMA模型的工具。支持LoRA低秩自适应。在G @爱可可-爱生活](https://weibo.com/1402400261/N4QJUF1yQ)

Note: 【LLaMA-LoRA Tuner：轻松评估和优化LLaMA模型的工具。支持LoRA低秩自适应。在Google Colab上一键运行，提供类似Gradio ChatGPT的聊天界面展示语言模型】'LLaMA-LoRA Tuner - UI tool for fine-tuning and testing your own LoRA models base on LLaMA, GPT-J and more. One-click run on Google Colab. + A Gradio ChatGPT-like Chat UI to demonstrate your language models.' Pokai Chang GitHub: github.com/zetavg/LLaMA-LoRA-Tuner  

Picture: [5396ee05ly8heum1gjpkxj212e0tw77f.jpg](https://weibo.cn//mblog/pic/N4QJUF1yQ?rl=1)

Github: [github.com/zetavg/LLaMA-LoRA-Tuner](https://github.com/zetavg/LLaMA-LoRA-Tuner)

#### [[LG]《CodeTF: One-stop Transformer Library for Stat @爱可可-爱生活](https://weibo.com/1402400261/N4UbFzHTe)

Note: [LG]《CodeTF: One-stop Transformer Library for State-of-the-art Code LLM》N D. Q. Bui, H Le, Y Wang, J Li, A D Gotmare, S C. H. Hoi [Salesforce AI Research] (2023)   

Picture: [5396ee05ly1hev13wlmp4j21m40rotx0.jpg](https://weibo.cn//mblog/pic/N4UbCiAsR?rl=1)

#### [OpenAI提供了适用于gpt-4的官方的GPT最佳实践地址：platform.openai.com @蚁工厂](https://weibo.com/2194035935/N4VncmsEW)

Note: OpenAI提供了适用于gpt-4的官方的GPT最佳实践地址：platform.openai.com/docs/guides/gpt-best-practices主要策略是六个1. Write clear instructions 写清楚说明2. Provide reference text 提供参考文本3. Split complex tasks into simpler subtasks 将复杂的任务拆分成更简单的子任务4. Give GPTs time to "think" 给予GPT时间“思考”5. Use external tools 使用外部工具6. Test changes systematically 系统地测试变化 (有时系统给你了一个很好的答案，但可能只是运气而不能复现)这跟我们平时开发项目时对团队各成员要求简直一模一样啊：需求人员要求能把需求写清楚、并能提供样例（原型）；系统设计的时候将复杂任务不断拆解、直至细分到可分配的WBS；对于开发人员尽量使用工具、提高开发效率，不重复造轮子；最后测试人员多测试，无论是功能还是性能，覆盖面都要足够广第一条太难了

#### [【Talk：基于whisper.cpp & llama.cpp和计算机直接语音对话】’Talk -  @爱可可-爱生活](https://weibo.com/1402400261/N4WCv2bR3)

Note: 【Talk：基于whisper.cpp & llama.cpp和计算机直接语音对话】’Talk - What if you could talk to your computer?' yacine GitHub: github.com/yacineMTB/talk   

Picture: [5396ee05ly8hevbzvujxgj20u00ybwh4.jpg](https://weibo.cn//mblog/pic/N4WCv2bR3?rl=1)

Github: [github.com/yacineMTB/talk](https://github.com/yacineMTB/talk)

#### [BOOT: Data-free Distillation of Denoising Diffusio @AMiner学术头条](https://weibo.com/1870858943/N4Xz3D1Dm)

Note: BOOT: Data-free Distillation of Denoising Diffusion Models with Bootstrapping ChatPaper综述：该论文介绍了一种新型技术，称为BOOT，可以通过有效的数据无关的蒸馏算法来解决扩散模型性能下降的问题。原因是由于迭代去噪导致生成速度缓慢。传统蒸馏方法需要实时数据或离线合成大量的训练数据，而BOOT则不需要这些过程。该方法可以针对大规模文本到图像扩散模型进行有效的改进，且结果表明，该方法既能实现高效的生成建模，还能处理高度复杂的分布。

Picture: [6f830abfly1hevg64h03ij20tl0vbk1u.jpg](https://weibo.cn//mblog/pic/N4Xz3D1Dm?rl=1)

#### [两篇翻译的技术博文：监视和调优Linux网络堆栈：接收数据 监视和调优Linux网络堆栈：发送数据  @蚁工厂](https://weibo.com/2194035935/N4ZjTwFP6)

Note: 两篇翻译的技术博文：监视和调优Linux网络堆栈：接收数据 监视和调优Linux网络堆栈：发送数据 这两篇文章解释了 Linux 内核的计算机如何发送/接收数据包，以及当数据包从网络流向用户程序时（或反向时），如何监视和调优网络栈的每个组件。Linux 网络栈是复杂的，没有一刀切的监控或调优解决方案。 如果您真的想调优网络栈，您别无选择，只能投入大量的时间、精力和金钱来了解网络系统的各个部分是如何交互的。回复:已保存至notion

Picture: [82c654dfly1hevnupbllyj20y11nnkab.jpg](https://weibo.cn//mblog/pic/N4ZjTwFP6?rl=1)

#### [HandBrake：一个开源的视频格式转换器，适用于大多数常见的视频文件和格式地址：github.c @蚁工厂](https://weibo.com/2194035935/N54nmBI0w)

Note: HandBrake：一个开源的视频格式转换器，适用于大多数常见的视频文件和格式地址：github.com/HandBrake/HandBrake支持.MP4、.MKV和WebM文件容器，AV1, H.265 and H.264, MPEG-4 、MPEG-2, VP8 、VP9等多种视频编码 👍回复:成功收藏到notion简单易用经典这个很好用

Picture: [82c654dfly1hewa6d20v0j21yp1bx4qq.jpg](https://weibo.cn//mblog/pic/N54nmBI0w?rl=1)

Github: [github.com/HandBrake/HandBrake](https://github.com/HandBrake/HandBrake)

#### [所有新硬件厂商都有一个倾向，就是assume AI框架能够导出一个完整的静态图（包括训练和推理），用 @WinnieS的微博](https://weibo.com/2144454703/N55uVoCCp)

Note: 所有新硬件厂商都有一个倾向，就是assume AI框架能够导出一个完整的静态图（包括训练和推理），用作自己软件栈的输入，来完成训练和推理能力的支持~~~~人间真实原理上，存在两条对接AI框架的路径。一条是直接对接到AI框架算子粒度，另一条是对接到AI框架算子粒度之下一个更细的原子IR粒度（比如HLO/Relay/ONNX/TorchScript，其中HLO只有200条左右指令)从硬件厂商角度来说，最希望的还是能够有一套具备“封闭且可完备描述模型行为的”原子IR粒度可供对接。TensorFlow算是一个对硬件厂商比较友好的框架，因为Google基于TPU做软硬全栈设计，所以XLA以及XLA所基于的HLO IR是比较适合硬件厂商进行对接的FB在推出PyTorch的时候，并没有考虑过软硬全栈设计eager mode，对DSA架构不够友好

Picture: [7fd1c82fly1hewet4jmrpj20xk0siaha.jpg](https://weibo.cn//mblog/pic/N55uVoCCp?rl=1)

#### [电子书《Inside The Python Virtual Machine》深入Python虚拟机这 @蚁工厂](https://weibo.com/2194035935/N564IsT5q)

Note: 电子书《Inside The Python Virtual Machine》深入Python虚拟机这份资料适合对CPython解释器的工作原理感兴趣的人。我们假设读者已经熟悉Python并理解该语言的基础知识。在这个阐述过程中，我们会浏览大量的C代码，所以对C有基础理解的读者会更容易理解。要理解这份资料，你只需要对学习CPython虚拟机有强烈的学习欲望。作者将Python程序的执行过程划分为两到三个主要阶段。相关的阶段取决于解释器的调用方式，本文将以不同的程度来介绍它们1. 初始化：此步骤涵盖了Python进程所需的各种数据结构的设置，只在通过命令提示符非交互式执行程序时才相关。2、 编译：这涉及到从源代码构建语法树、创建抽象语法树、构建符号表、生成代码对象等活动。3、 解释：这涉及到在某种上下文中执行生成的代码对象的字节码。本书在线阅读免费，下载收费。

Picture: [82c654dfly1hewhmrnsrkj20hs0n0wk3.jpg](https://weibo.cn//mblog/pic/N564IsT5q?rl=1)

#### [最近的很多开源模型都在基于GPT-4的数据做调优。微软表示你们这些模型学GPT都学的太浅了，徒有其表 @蚁工厂](https://weibo.com/2194035935/N5693EoXE)

Note: 最近的很多开源模型都在基于GPT-4的数据做调优。微软表示你们这些模型学GPT都学的太浅了，徒有其表。看我们搞个深层次的，不但要模仿GPT-4 的风格，还要学习其推理过程等等。微软刚发布了Orca的论文，这是一个130亿参数的模型，它学会模仿LFM的推理过程。Orca从GPT-4的丰富信号中学习，包括解释追踪；逐步的思考过程；以及其他复杂的指令。论文下载：aka.ms/orca-lm其能力在一些之前开源模型不擅长的评测（如考试或复杂推理）中效果已经接近了ChatGPT，较大幅度的超出其他的开源模型。Orca这个名字很恶趣味

Picture: [82c654dfly1hewch43b1jj20oc0h6q89.jpg](https://weibo.cn//mblog/pic/N5693EoXE?rl=1)

#### [电子书《High Performance Browser Networking》本书是谷歌公司高性能 @蚁工厂](https://weibo.com/2194035935/N59qmcfc7)

Note: 电子书《High Performance Browser Networking》本书是谷歌公司高性能团队核心成员的权威之作，堪称实战经验与规范解读完美结合的产物。本书目标是涵盖Web 开发者技术体系中应该掌握的所有网络及性能优化知识。全书以性能优化为主线，从TCP、UDP 和TLS 协议讲起，解释了如何针对这几种协议和基础设施来优化应用。然后深入探讨了无线和移动网络的工作机制。最后，揭示了HTTP 协议的底层细节，同时详细介绍了HTTP 2.0、 XHR、SSE、WebSocket、WebRTC 和DataChannel 等现代浏览器新增的具有革命性的新能力。中文翻译为：《 Web性能权威指南 》实体书地址： 

Picture: [82c654dfly1h36o2hkmpcj21a20a3gmf.jpg](https://weibo.cn//mblog/pic/Lxxfs5qbS?rl=1)

#### [最近看到了一份非常精简但很实用的《Web 界面开发指南》，其中仅有 4 页，却详细阐述了前端交互体验 @敖天羽](https://weibo.com/1888981347/N5ilx72Ls)

Note: 最近看到了一份非常精简但很实用的《Web 界面开发指南》，其中仅有 4 页，却详细阐述了前端交互体验的关键要点。持续更新中... 码住再看！原文链接： 

Picture: [795bf814ly1hexklzgal1j20p00an76r.jpg](https://weibo.cn//mblog/pic/N5eSGfFPa?rl=1)

#### [布伦丹·格雷格关于linux性能的资料整理，包括工具、文档、视频等布伦丹·格雷格是知名的计算性能专家 @蚁工厂](https://weibo.com/2194035935/N59Hbix7j)

Note: 布伦丹·格雷格关于linux性能的资料整理，包括工具、文档、视频等布伦丹·格雷格是知名的计算性能专家，在Intel和Netflix工作过，也是发明用火焰图分析性能的大佬。 

Picture: [82c654dfly1h36jwgf3tyj20dw0e4wgz.jpg](https://weibo.cn//mblog/pic/Lxwjr538F?rl=1)

#### [Foundations of Computer Science斯坦福的教科书，本书全面而详细地阐述了 @蚁工厂](https://weibo.com/2194035935/N5fcFhKOM)

Note: Foundations of Computer Science斯坦福的教科书，本书全面而详细地阐述了计算机科学的理论基础，从抽象概念的机械化到各种数据模型的建立，用算法、数据抽象等核心思想贯穿各个主题，很好地兼顾了学科广度和主题深度，帮助读者培养计算机领域的大局观，学习真正的计算机科学。在 的网站上还有免费的中文版： 马克//:转发微博

Picture: [82c654dfly1h37hp9qjn7j204h05gmxo.jpg](https://weibo.cn//mblog/pic/LxFcH6YSU?rl=1)

#### [Understanding DeepMind's Sorting Algorithm一篇分析/解释前 @蚁工厂](https://weibo.com/2194035935/N5hLxh0RL)

Note: Understanding DeepMind's Sorting Algorithm一篇分析/解释前几天DeepMind的用AlphaDev发现的排序算法的博文。作者Justine Tunney是个水平很高的妹子，也是Cosmopolitan Libc的作者。 Cosmopolitan Libc是一个可以使 C 语言像 Java 一样构建一次，即可到处运行的 C 语言库。 这个libc不仅仅是到处运行，而是编译完的二进制文件包含了PE和ELF头，可以直接在Windows和Linux等系统上执行，屌的一批，不过为了性能考虑运行第一次之后会删除其他平台的数据

#### [电子书《Mathematics for Machine Learning》机器学习的数学pdf格式， @蚁工厂](https://weibo.com/2194035935/N5fuGvRSs)

Note: 电子书《Mathematics for Machine Learning》机器学习的数学pdf格式，下载地址：mml-book.github.io/这是一本关于机器学习的数学书籍，旨在激励人们学习数学概念。这本书不打算涵盖高级机器学习技术，因为已经有很多书在做这方面的工作。本书的目标是提供必要的数学技能，以便读懂其他这些书籍。 没事的时候读一读

Picture: [82c654dfly1hexjjcknllj20w11ahqv6.jpg](https://weibo.cn//mblog/pic/N5fuGvRSs?rl=1)

#### [用C语言写一个简单的哈希表https://theleo.zone/posts/hashmap-in- @蚁工厂](https://weibo.com/2194035935/N5iYD2mbJ)

Note: 用C语言写一个简单的哈希表https://theleo.zone/posts/hashmap-in-c/作者觉得这是一个很好的练习，可以更多地了解哈希表及其背后的设计决策、哈希函数、C编程语言和内存管理。 将这篇文章翻译了一下，有需要的朋友可以参考：回复 :除了等宽以外，作者应该是一个视觉感很棒的人。当然，我也对那些把手机字体改为加奇怪的带拼音字体的一类人无敌意，我甚至会以为他们有特异功能。回复:或许是因为使用了等宽字体页面没有很特殊的背景、格式、字体，却看起来非常清爽，这是什么魔力

#### [系列博文《Writing a Linux Debugger》编写一个linux内核调试器地址：blo @蚁工厂](https://weibo.com/2194035935/N5oUnsMeR)

Note: 系列博文《Writing a Linux Debugger》编写一个linux内核调试器地址：blog.tartanllama.xyz/writing-a-linux-debugger-setup/调试器是开发人员工具包中最有价值的工具之一。然而，尽管这些工具被广泛使用，但关于它们的工作原理和如何编写调试器的资源并不多见，特别是与其他工具链技术（如编译器）相比。在本系列文章中，我们将了解调试器的工作原理，并编写一个用于调试Linux程序的调试器。我们的调试器将支持以下功能：    启动、暂停和继续执行    在内存地址、源代码行和函数入口设置断点    读取和写入寄存器和内存    单步执行    打印当前源代码位置    打印回溯信息    打印简单变量的值在最后一部分，我还将概述如何将以下功能添加到你的调试器中：    远程调试    共享库和动态加载支持    表达式求值    多线程调试支持项目主要使用C和C++，但它也可以很好地适用于编译成机器代码并输出标准DWARF调试信息的任何语言。

Picture: [82c654dfly1heymefvg3zj20m00s7n40.jpg](https://weibo.cn//mblog/pic/N5oUnsMeR?rl=1)

#### [【undb：注重隐私、统一的自托管无代码数据库，一个轻量的数据库，仅需要一个文件存储】'undb - @Maeiee](https://weibo.com/1240212845/N5r3mywtJ)

Note: 【undb：注重隐私、统一的自托管无代码数据库，一个轻量的数据库，仅需要一个文件存储】'undb - Private first, unified, self-hosted no code database.' undb-xyz GitHub: github.com/undb-xyz/undb   

Picture: [5396ee05ly8herwjz9898j22660u0n4d.jpg](https://weibo.cn//mblog/pic/N4uFlAnuo?rl=1)

Github: [github.com/undb-xyz/undb](https://github.com/undb-xyz/undb)

#### [技术博文《Myths Programmers Believe about CPU Caches》程序 @蚁工厂](https://weibo.com/2194035935/N5roCcQvM)

Note: 技术博文《Myths Programmers Believe about CPU Caches》程序员对CPU缓存的误解地址：作者Rajiv是 Intel 和 Sun 从事高速缓存工作的计算机工程师。作为一名软件开发人员，你可能会想知道为什么要关注CPU缓存设计。首先，缓存一致性的许多概念直接适用于分布式系统架构和数据库隔离级别。例如，了解硬件缓存中一致性是如何实现的，有助于更好地理解强一致性和最终一致性。它可以激发在分布式系统中如何更好地实施一致性的想法，使用相同的研究和原则应用于硬件。其次，对缓存的误解经常导致错误的断言，特别是涉及并发和竞态条件的情况。例如，常见的说法是并发编程之所以困难是因为“不同的核心可能在各自的缓存中具有不同/过期的值”。或者我们需要在Java等语言中使用volatile的原因是为了“防止共享数据被本地缓存”，并强制将其“读/写到主内存”。这些误解大多是无害的（甚至可能有帮助），但也可能导致糟糕的设计决策。

Picture: [82c654dfly1heymhsz0a7j20cv0f4tao.jpg](https://weibo.cn//mblog/pic/N5roCcQvM?rl=1)

#### [个人/小公司训练AI购买专业GPU的话价格还是太高。这篇文章： 比较了国外常见提供GPU云服务的厂商 @蚁工厂](https://weibo.com/2194035935/N5rXwkuqR)

Note: 个人/小公司训练AI购买专业GPU的话价格还是太高。这篇文章： 比较了国外常见提供GPU云服务的厂商，从可用性、价格、使用方便程度等多个角度做了比较。目前最便宜的H100供应商是CoreWeave - 每小时 2.23 美元最便宜的A100供应商是Lambda Labs - 每小时 1.10 美元 已收藏到你的Notion回复:成功保存至你的Notion

#### [4. Introduction to Image Generation 图像生成简介这是Google @宝玉xp](https://weibo.com/1727858283/N5vUvgLXZ)

Note: 4. Introduction to Image Generation 图像生成简介这是Google的一个AI入门课程，介绍扩散模型，这是一类在图像生成领域最近显示出潜力的机器学习模型。扩散模型的灵感来源于物理学，特别是热力学。在过去的几年中，扩散模型在研究和工业中都变得很受欢迎。扩散模型是Google Cloud上许多最先进的图像生成模型和工具的基础。本课程将向你介绍扩散模型背后的理论，以及如何在Vertex AI上训练和部署它们。课程地址： 印象中好像看宝玉老师之前发过这只是一个入门视频，想了解更多细节可以看DeepLearningAI的教学视频“扩散模型是如何工作的”，讲的更细，完整中英文字幕视频：

#### [3. Introduction to Responsible AI 负责任的人工智能入门这是Goog @宝玉xp](https://weibo.com/1727858283/N5vVtyzBa)

Note: 3. Introduction to Responsible AI 负责任的人工智能入门这是Google的一个AI入门课程，解释了什么是负责任的人工智能，为什么它很重要，以及谷歌如何在其产品中实施负责任的人工智能，谷歌的7项人工智能原则。  

#### [最近很火的书《为什么伟大不能计划》的主要作者Kenneth Stanley教授两年前在机器学习街头谈 @宝玉xp](https://weibo.com/1727858283/N5uen1dDp)

Note: 最近很火的书《为什么伟大不能计划》的主要作者Kenneth Stanley教授两年前在机器学习街头谈话（Machine Learning Street Talk）的一次访谈。www.youtube.com/watch?v=lhYGXYeMq_E 🔗Kenneth Stanley教授目前在旧金山的OpenAI担任研究科学经理。从机器学习街头谈话（Machine Learning Street Talk）开始，我们就一直梦想着能邀请到Kenneth来参加节目。有些观众可能还记得，我们的第一次节目是关于增强的POET论文，而Kenneth对此有深入的研究。他的论文已经被引用了超过16000次，最受欢迎的一篇论文是关于NEAT算法，被引用了超过3000次。他的研究兴趣包括神经进化、开放性、神经网络、人工生命和人工智能。他发明了一种没有明确定义目标的新奇性搜索概念。他的关键观点是，我们的生活、社会乃至我们的算法在各个方面都存在着目标的暴政。关键是，这些目标产生了趋同的行为和思维，并使我们无法发现通向伟大的踏脚石。他认为这种单调的目标迷恋，即我们每年都需要继续改进基准的想法是危险的。他在最近的书《为什么伟大不能计划》中详细写到了这个问题，这将是节目主要讨论的话题。我们也会讨论他关于机器学习开放性的想法。节目时间安排如下：00:00:00 介绍Kenneth 00:01:16 节目结构声明 00:04:16 热情的讨论 00:06:26 为什么伟大不能被计划以及目标的暴政00:14:40 中国手指陷阱  00:16:28 反向激励和反馈循环00:18:17 欺骗 00:23:29 迷宫例子 00:24:44 我们如何定义好奇心或有趣性 00:26:59 开放性 00:33:01 ICML 2019和Yannic, POET, 第一次MSLST 00:36:17 进化算法++ 00:43:18 POET, 第一次MLST  00:45:39 对GOFAI人员的一堂课 00:48:46 机器学习 -- 伟大的停滞 00:54:34 实际的科学成功通常是运气好，与几率相反 -- Biontech 00:56:21 Picbreeder和NEAT 01:10:47 Tim如何将这些观点应用到他的生活以及他为什么主持MLST 01:14:58 Keith关于UCF的短剧 01:15:13 主要节目开始 01:18:02 Kenneth为什么如此重视偶然的探索 01:24:10 Kenneth的想法在日常生活中的科学支持 01:27:12 我们应该放弃目标以实现它们。这是一个矛盾么？01:33:13 这不就是资源分配在探索和利用之间吗？ 01:39:06 目标只是程度问题么？ 01:42:38 我们如何在社会上为寻找宝藏分配资金 01:47:34 对有趣的敏锐嗅觉，投票可能是危险的 01:53:00 委员会是创新的反面 01:56:21 Kenneth是否将这些观点应用到他的真实生活中？01:59:48 差异性 vs 有趣性 vs 新奇性 vs 复杂性 02:08:13 Picbreeder 02:12:39 不是所有事物都在某种意义上是新的吗？ 02:16:35 想象一下如果没有选择压力会怎样？ 02:18:31 创新 == 环境的利用么？02:20:37 如果你已经知道创新是什么，是否可能找到捷径？ 02:21:11 Go Explore -- 这个算法编码了踏脚石吗？ 02:24:41 什么是有趣地不同？02:26:11 行为特征 / 多样性衡量你的广泛兴趣 02:30:54 塑造目标 02:32:49 为什么所有雄心勃勃的目标都有欺骗性？Picbreeder类比 02:35:59 探索 vs 利用, 科学 vs 工程 02:43:18 机器学习的思想流派，搜索能否引领到AGI 02:45:49 正式结束回复:可以的 感觉你要是搬yann lecun 那期讲神经网络extrapolation vs interpolation 的那期来满足math nerd的需求回复:后来看的人还是不少，微博播放量有4万多👍👍//://:一口气看完了。思如泉涌。需要再看。正反馈，负反馈；outer evolution loop，inner study loop；算法框架的部分总是这么吸引人，数学的部分嘛就…咳咳咳//：//：一口气看完了。思如泉涌。需要再看。正反馈，负反馈；Outer Evolution Loop，Inner Study Loop；算法框架的部分总是这么吸引人，数学的部分嘛就…咳咳咳回复:哈哈，别，我觉得视频还是挺好的，还是欢迎继续推荐多一些人说这句话我就少一些坑了宝玉老师的感觉

#### [红杉资本昨天发表的一篇文章《The New Language Model Stack》中一些数据很有 @宝玉xp](https://weibo.com/1727858283/N5wosafET)

Note: 红杉资本昨天发表的一篇文章《The New Language Model Stack》中一些数据很有价值：1. 65%的应用程序已经上线发布，比两个月前的50%有所增加，其余的仍在开发测试中。2. 94%的人正在使用大语言模型的API。在调查的样本中，OpenAI的GPT是明显的首选，占91%，然而对Anthropic的兴趣在过去的一个季度 

Picture: [66fd066bgy1hezpxfc9e9j21o015ojxv.jpg](https://weibo.cn//mblog/pic/N5wosafET?rl=1)

#### [4. Introduction to Image Generation 图像生成简介这是Google @宝玉xp](https://weibo.com/1727858283/N5wr2yZdf)

Note: 4. Introduction to Image Generation 图像生成简介这是Google的一个AI入门课程，介绍扩散模型，这是一类在图像生成领域最近显示出潜力的机器学习模型。扩散模型的灵感来源于物理学，特别是热力学。在过去的几年中，扩散模型在研究和工业中都变得很受欢迎。扩散模型是Google Cloud上许多最先进的图像生成模型和工具的基础。本课程将向你介绍扩散模型背后的理论，以及如何在Vertex AI上训练和部署它们。课程地址： 回复://:这只是一个入门视频，想了解更多细节可以看DeepLearningAI的教学视频“扩散模型是如何工作的”，讲的更细，完整中英文字幕视频：

#### [技术博文《Vector Search in 200 Lines of Rust》用200行Rust代 @蚁工厂](https://weibo.com/2194035935/N5wAkesH1)

Note: 技术博文《Vector Search in 200 Lines of Rust》用200行Rust代码写一个向量搜索数据库由于人工智能/机器学习的快速发展，向量数据库随处可见。虽然它们可以支持复杂的人工智能/机器学习应用，但向量搜索本身在概念上并不那么困难。在本文中，我们将介绍向量数据库的工作原理，并在不到200行Rust代码中构建一个简单的向量搜索库。所有的代码都可以在这个Github仓库中找到。我们在这里使用的方法基于一类名为"局部敏感哈希"的算法，这是流行库annoy中使用的算法。本文的目标不是介绍一个新的花哨算法/库，而是通过实际代码片段描述向量搜索的工作原理。

Picture: [82c654dfly1hezqruhh4wj218g0y51kx.jpg](https://weibo.cn//mblog/pic/N5wAkesH1?rl=1)

#### [Intel 8086 CPU在线模拟器地址：yjdoc2.github.io/8086-emulat @蚁工厂](https://weibo.com/2194035935/N5wMawc4C)

Note: Intel 8086 CPU在线模拟器地址：yjdoc2.github.io/8086-emulator-web/用它可以直接在浏览器中运行基于 8086 的汇编程序，运行时能够查看CPU寄存器，指针，状态位，内存等等。项目是开源的，还提供了一个命令行版本。底层是基于Rust写的Intel 8086 模拟器/虚拟机 github.com/YJDoc2/8086-Emulator 回复:已收藏至你的Notion

Picture: [82c654dfly1hezrl3jr3xj22uk1j5qtq.jpg](https://weibo.cn//mblog/pic/N5wMawc4C?rl=1)

Github: [github.com/YJDoc2/8086-Emulator](https://github.com/YJDoc2/8086-Emulator)

#### [宾夕法尼亚大学整理的网络上超过 300 万本免费图书索引地址：onlinebooks.library @蚁工厂](https://weibo.com/2194035935/N5ylh9bxG)

Note: 宾夕法尼亚大学整理的网络上超过 300 万本免费图书索引地址：onlinebooks.library.upenn.edu/注意不是提供下载，而是链接到提供浏览或下载的网站。各种老书居多。 转发微博

Picture: [82c654dfly1hezr3psyqhj21gj19gkcl.jpg](https://weibo.cn//mblog/pic/N5ylh9bxG?rl=1)

#### [今天看到我不间断更新的机器学习研究笔记在GitHub上获得了 6000+ GitHub star ！ @蚁工厂](https://weibo.com/2194035935/N5zGMcD8F)

Note: 今天看到我不间断更新的机器学习研究笔记在GitHub上获得了 6000+ GitHub star ！我至今仍然拒绝同事们好心的建议将我的机器学校研究课程放入 arixv 去得到更多的引用量。我不是特别起劲的原因是因为假若我只是将研究教程从一个大家可以看到的地方转移到另一个地方，那我个人对研究所做出的贡献不还是一样？

Picture: [006ibAEngy1h1lqrq9z6oj30v9145n42.jpg](https://weibo.cn//mblog/pic/Lq35xFUgQ?rl=1)

#### [《Open Data Structures》一本开放式的数据结构教科书地址：opendatastru @蚁工厂](https://weibo.com/2194035935/N5ynI6MTZ)

Note: 《Open Data Structures》一本开放式的数据结构教科书地址：opendatastructures.org/提供了伪代码版、Java 、C++版供阅读和下载。另外提供了LaTeX源码和对应的Python代码可以自己编译出Python版。 回复:成功收藏到你的notion回复:已收藏至你的notion回复:已收藏至你的Notion

Picture: [82c654dfly1hezs5ifonej21ca0umwmk.jpg](https://weibo.cn//mblog/pic/N5ynI6MTZ?rl=1)

#### [hexyl，一个终端上用的16进制查看器。地址：github.com/sharkdp/hexyl它使 @蚁工厂](https://weibo.com/2194035935/N5HEpbqv7)

Note: hexyl，一个终端上用的16进制查看器。地址：github.com/sharkdp/hexyl它使用彩色输出来区分不同类别的字节（空字节、可打印的 ASCII 字符、ASCII 空格字符、其他 ASCII 字符和非 ASCII）。 pc tools

Picture: [82c654dfly1hf13laguclj20iz0b8n5a.jpg](https://weibo.cn//mblog/pic/N5HEpbqv7?rl=1)

Github: [github.com/sharkdp/hexyl](https://github.com/sharkdp/hexyl)

#### [技术博客《从零开始编写Transformers（pytorch）》地址：u6684258.githu @Maeiee](https://weibo.com/1240212845/N5HSH3twQ)

Note: 技术博客《从零开始编写Transformers（pytorch）》地址：u6684258.github.io/_posts/2021-01-15-从零开始编写transformer-pytorch/本文先简单的介绍了Transformers的原理和self-attention，然后实现一个简单的transformer，并用它来做语义识别的project。 

Picture: [82c654dfly1hezb6hvnzhj20sv0csmzv.jpg](https://weibo.cn//mblog/pic/N5GakgYRw?rl=1)

#### [Fallacies of Distributed Systems地址：architecturenot @蚁工厂](https://weibo.com/2194035935/N5IGaeJGT)

Note: Fallacies of Distributed Systems地址：architecturenotes.co/fallacies-of-distributed-systems/这篇文章介绍了分布式系统常见的8个谬误（对初学者来说）:网络可靠、延迟为0、带宽是无限的、网络是安全的、网络拓扑不会改变、有一位管理员、传输成本为零、网络是同构的 

Picture: [82c654dfly1hf17yac5zzj21jk13a4qp.jpg](https://weibo.cn//mblog/pic/N5IGaeJGT?rl=1)

#### ['Anima - 第一个开源的基于QLoRA的33B中文大语言模型First QLoRA based @爱可可-爱生活](https://weibo.com/1402400261/N5ICzptCu)

Note: 'Anima - 第一个开源的基于QLoRA的33B中文大语言模型First QLoRA based open source 33B Chinese LLM' Gavin Li GitHub: github.com/lyogavin/Anima   

Picture: [5396ee05ly8hf17wgzbagj20x10u0gr0.jpg](https://weibo.cn//mblog/pic/N5ICzptCu?rl=1)

Github: [github.com/lyogavin/Anima](https://github.com/lyogavin/Anima)

#### [电子书《学习 wgpu》中文版地址：jinleili.github.io/learn-wgpu-zh @蚁工厂](https://weibo.com/2194035935/N5JqS5etl)

Note: 电子书《学习 wgpu》中文版地址：jinleili.github.io/learn-wgpu-zh/wgpu 是基于 WebGPU API 规范的、跨平台的、安全的、纯 Rust 图形 API。它是 Firefox、Servo 和 Deno 中 WebGPU 整合的核心。wgpu 不仅可以在 Web 环境运行，还可以在 macOS / iOS、Android、Window 和 Linux 等系统上原生运行。 webgpu. webnn

Picture: [82c654dfly1hf17nts23wj20fh1nhq8m.jpg](https://weibo.cn//mblog/pic/N5JqS5etl?rl=1)

#### [这个网站制作了很多空间站、航天飞机和火箭的折纸模型pdf文件。直接下载了打印就可以自己折一个立体模型 @蚁工厂](https://weibo.com/2194035935/N5PtOqEQZ)

Note: 这个网站制作了很多空间站、航天飞机和火箭的折纸模型pdf文件。直接下载了打印就可以自己折一个立体模型。也有中国空间站的，不过还没更新到最新的样式 

Picture: [82c654dfly1h3c7f3ne8lj20vg0t8gqg.jpg](https://weibo.cn//mblog/pic/Lygq5aIN8?rl=1)

#### [如果你的问题受内存带宽限制（例如模拟仿真用时间步进法求解偏微分方程，再例如稀疏矩阵运算），就算使用世 @蚁工厂](https://weibo.com/2194035935/N5TsOfXvU)

Note: 如果你的问题受内存带宽限制（例如模拟仿真用时间步进法求解偏微分方程，再例如稀疏矩阵运算），就算使用世界顶级的超级计算机，能实际利用的算力甚至不到硬件算力的 1%，99% 的时间都浪费在读写内存上。内存内计算技术何时才能到来？ 虚拟化cache！！！！！！！！真的是未来！！！！Intel 为科学计算用户准备的特别版 Sapphire Rapids Max 处理器也自带 64 GB HBM2e 内存 //:因为这个搞得1GB的cpu cache吗//:今年ISSCC苏妈的演讲也讲到了这个问题// :因为这个搞得1GB的cpu cache吗// :今年ISSCC苏妈的演讲也讲到了这个问题

Picture: [48ab9a77gy1hf2gccsev3j21hc0u0qv5.jpg](https://weibo.cn//mblog/pic/N5SGO6ttW?rl=1)

#### [《CPU性能分析与优化》读书笔记（1）1、即使CPU强大，如果执行的指令不是最优甚至是多余的，处理器 @小川CD](https://weibo.com/1202332555/N5UltgWGi)

Note: 《CPU性能分析与优化》读书笔记（1）1、即使CPU强大，如果执行的指令不是最优甚至是多余的，处理器也无法发挥作用。处理器不能将次优代码转化为性能更好的代码。2、编译器擅长消除冗余，但在需要做出复杂决策时（如内联函数和循环展开），编译器可能无法生成最佳代码。编译器通常不会改变程序使用的数据结构，而数据结构对性能至关重要。3、算法复杂度分析无法解释各种算法的分支预测和缓存的影响。它们通常被封装成一个隐含的常数C，这可能对性能产生巨大影响。4、多线程程序要求线程之间高效通信，避免不必要的资源消耗，并规避典型的多线程问题。5、现代处理器中有许多变化的组件，即使代码层面的微小改动也可能引起显著的性能变化。因此，优化程序不能仅依靠直觉，而应该基于测量结果。6、与大多数功能问题相比，性能问题通常更难跟踪和复现。基准测试每次运行的结果都不完全相同，而且性能分析通常需要使用统计方法处理测量偏差。7、现代系统中存在许多噪声因素，如CPU动态频率调节、文件系统缓存、UNIX环境变量大小、编译器链接顺序以及其他影响内存布局顺序的因素。8、软件性能退化指下一个版本错误地引入性能缺陷。微小的变化逐渐累积，可能导致更严重的性能问题。通常需要进行多次性能基准测试，而测试结果的方差越大，所需的测试次数就越多。9、系统高分辨率计数器（如clock_gettime）比硬件计时器（如TSC，汇编指令RDTSC）消耗更多CPU资源，达到10倍以上。10、CPU流水线定义了五个阶段：取指、译码、执行、访存和回写。流水线的时钟周期数通常由最慢的阶段决定。11、大多数现代CPU是超标量的，即它们可以在一个时钟周期内发射多条指令。类似于多条并发的流水线。12、编译器可以利用软件流水线、循环展开等技术来发现更多的指令级并行性（ILP）机会，因为编译器可以获得全局信息，而硬件受限于指令窗口的长度。13、硬件分支预测是一种避免控制冒险的技术，用于预测分支可能的方向并从预测路径执行指令。通过投机执行，CPU会对分支判断结果进行猜测，并从所选路径开始处理命令。如果预测错误，就会有分支预测错误惩罚，投机执行的结果必须被中止和丢弃。14、硬件多线程CPU的主要目的是在线程由于长时间延迟活动（如内存引用）而被阻塞时，以最小的延迟从一个上下文切换到另一个上下文，从而避免了保存和恢复线程上下文的成本。15、CPU缓存写操作有几种处理方式：写直达（write-through），同时写缓存和下一层级；回写（write-back），只写缓存；写入未命中时写分配（write-allocate），未命中缓存时需要加载数据到缓存；以及写入未命中时非写分配（no-write-allocate），直接写入下一层级。16、CPU缓存: 平均访问时延 = 命中的花费时间 + 未命中的比例 x 未命中的花费时间。17、减少缓存未命中的一种方法是预取指令和数据到不同层级的高速缓存。18、缺页代价很高，需要遍历整个页表层级结构。为了缓解这个问题，CPU支持一个称为翻译后备缓冲区（TLB）的硬件结构，用于缓存最近的翻译（从虚拟地址到物理地址的翻译）。是丹尼斯·巴赫瓦洛夫（Denis Bakhvalov）的《现代CPU性能分析与优化》吗高人

#### [LocalAI，OpenAI 的本地替代品。一个实现了在个人电脑上运行 LLM 模型，并集成了服务接 @Maeiee](https://weibo.com/1240212845/N5JcEi1IR)

Note: LocalAI，OpenAI 的本地替代品。一个实现了在个人电脑上运行 LLM 模型，并集成了服务接口和在线聊天界面的项目。虽然效果无法和 GPT-4 媲美，但它开箱即用且免费，支持 Vicuna、Alpaca、GPT4ALL 等模型。项目地址： 

Picture: [006dfXnily1hezt5nyf4xj313g0yl10d.jpg](https://weibo.cn//mblog/pic/N5x7X9Acr?rl=1)

#### [生成式AI学习5——编码器-解码器架构（上）概述5. Encoder-Decoder Archite @宝玉xp](https://weibo.com/1727858283/N61dDApdw)

Note: 生成式AI学习5——编码器-解码器架构（上）概述5. Encoder-Decoder Architecture: Overview 编码器-解码器架构（上）概述编码器-解码器架构  这门课程为你提供了编码器-解码器架构的概述，这是一种强大且普遍存在的机器学习架构，适用于如机器翻译、文本摘要和问题回答等序列到序列任务。你将学习到编码器-解码器架构的主要组件以及如何训练和使用这些模型。在相应的实验室演示中，你将使用TensorFlow从头开始编写编码器-解码器架构的简单实现，用于诗歌生成。  完成这门课程后，你可以获得上面显示的徽章！你可以通过访问个人资料页查看已经获得的所有徽章。通过向世界展示你已经开发的技能，提升你的云计算职业生涯！  编码器-解码器架构：概述  这个模块为你提供了编码器-解码器架构的概述，这是一种强大且普遍存在的机器学习架构，适用于如机器翻译、文本摘要和问题回答等序列到序列任务。你将学习到编码器-解码器架构的主要组件以及如何训练和使用这些模型。  课程地址：YouTube播放列表：www.youtube.com/watch?v=tbLOQ533Up8&list=PLiuLMb-dLdWJPpybrCYNhi6D9Vd4vz16i 

#### [【bootcamp：计算机科学基础知识自学指南】'bootcamp - a guide for pe @爱可可-爱生活](https://weibo.com/1402400261/N60FAyukQ)

Note: 【bootcamp：计算机科学基础知识自学指南】'bootcamp - a guide for people who want to self-study the basics of Computer Science, plus a some extras hot stuff.’ by Lesabotsy GitHub: github.com/Lesabotsy/bootcamp   

Picture: [5396ee05ly8hf3fl86sh7j21au0t6790.jpg](https://weibo.cn//mblog/pic/N60FAyukQ?rl=1)

Github: [github.com/Lesabotsy/bootcamp](https://github.com/Lesabotsy/bootcamp)

#### [huggingface的中文博客发布了，这个博客将以中文内容，向全球的中文开发者们提供来自英文博客的 @蚁工厂](https://weibo.com/2194035935/N60OcffS3)

Note: huggingface的中文博客发布了，这个博客将以中文内容，向全球的中文开发者们提供来自英文博客的翻译文章。🔗 huggingface.co/blog/zh 有rss吗

Picture: [006qCzTzgy1hf3fz2gjhgj30zo0k4jtp.jpg](https://weibo.cn//mblog/pic/N60KYsTxW?rl=1)

#### [Meta的大语言模型OpenLLaMA来了！目前有130亿、70亿和30亿参数三个版本，基于1T t @Maeiee](https://weibo.com/1240212845/N624emTmv)

Note: Meta的大语言模型OpenLLaMA来了！目前有130亿、70亿和30亿参数三个版本，基于1T token数据训练，项目地址： 

Picture: [006Fd7o3gy1hf3klq52lgj325s0roaoa.jpg](https://weibo.cn//mblog/pic/N61SeCGiv?rl=1)

#### [在同时具备5P双精度算力（64位）、25P单精度算力（32位）和100P半精度算力（16位）的情况下 @WinnieS的微博](https://weibo.com/2144454703/N62kG4hRZ)

Note: 在同时具备5P双精度算力（64位）、25P单精度算力（32位）和100P半精度算力（16位）的情况下，智能计算中心的基础设施价格约为1亿-1.5亿from  回复:这个批文是哪里批？现在这个领域真正值钱的是机架的zf批文

#### [Roop，可以一键实现 AI 换脸功能的开源项目，基于 Python 开发。仅需一张换脸图像，无需数 @宝玉xp](https://weibo.com/1727858283/N64oNdLjP)

Note: Roop，可以一键实现 AI 换脸功能的开源项目，基于 Python 开发。仅需一张换脸图像，无需数据集，无需训练，自带敏感图像检测功能。GitHub：github.com/s0md3v/roop 回复:宝玉老师，有没有面向个人的gpt应用，比方说做我个人的电子文档、书籍、图片等资料管理，有些文档不方便发布上传的，可以在本地做一些个性化的分析等等，可以理解为个性化的私人电子秘书这样的。

Github: [github.com/s0md3v/roop](https://github.com/s0md3v/roop)

#### [后端思维之数据库性能优化方案该篇文章主要从存储结构、存储系统中间两层的角度出发进行探讨，提出了8个优 @敖天羽](https://weibo.com/1888981347/N65da1F9o)

Note: 后端思维之数据库性能优化方案该篇文章主要从存储结构、存储系统中间两层的角度出发进行探讨，提出了8个优化方案。 

Picture: [82c654dfly1h3djsiwqvxj20hm1dljtw.jpg](https://weibo.cn//mblog/pic/Lyrxsob8q?rl=1)

#### [掌握了用stable diffusion在6G小显存下做高清大图的技术。安装Tiled Diffus @蚁工厂](https://weibo.com/2194035935/N69d0dkUG)

Note: 掌握了用stable diffusion在6G小显存下做高清大图的技术。安装Tiled Diffusion & VAE和4x-ultrasharp算法插件，它把把图切块处理然后再组合，可以打开noise inversion防止锐度不足。先生成512的小图，然后图生图放大到2048尺寸。这张图，咒语如下：In this lighthearted portrait, a young woman, approximately 18 years old, embraces the role of a fierce warrior. She confidently wields an array of paintbrushes and palette knives. Her war paint consists of bold, vibrant brushstrokes, while her armor is crafted from paint tubes and canvases splattered with colorful pigments. Standing atop a conquered hill of countless blank canvases, she is surrounded by a beautiful and vibrant landscape, symbolizing the power of art and creativity. With a joyous smile on her face, she resembles Hatsune Miku, exuding an aura reminiscent of the famous virtual singer. This close-up bust portrait is illuminated with bright and transparent scene lighting, accentuating every exquisite detail. <lora:FilmVelvia2:0.6>

Picture: [65acc9b7ly1hf4h97520pj20e80e87cr.jpg](https://weibo.cn//mblog/pic/N69cL3GbH?rl=1)

#### ['Vicuna-LoRA-RLHF-PyTorch - A full pipeline to fin @爱可可-爱生活](https://weibo.com/1402400261/N6jYxmpuu)

Note: 'Vicuna-LoRA-RLHF-PyTorch - A full pipeline to finetune Vicuna LLM with LoRA and RLHF on consumer hardware.' MK GitHub: github.com/jackaduma/Vicuna-LoRA-RLHF-PyTorch    1  

Picture: [5396ee05ly8hf5stkgxg1j213j0u0gon.jpg](https://weibo.cn//mblog/pic/N6jYxmpuu?rl=1)

Github: [github.com/jackaduma/Vicuna-LoRA-RLHF-PyTorch](https://github.com/jackaduma/Vicuna-LoRA-RLHF-PyTorch)

#### [【RL4CO：广泛的组合优化强化学习基准，使用PyTorch和Hydra构建】'RL4CO - an @爱可可-爱生活](https://weibo.com/1402400261/N6k0s9Lab)

Note: 【RL4CO：广泛的组合优化强化学习基准，使用PyTorch和Hydra构建】'RL4CO - an Extensive Reinforcement Learning for Combinatorial Optimization Benchmark' KAIST SILAB GitHub: github.com/kaist-silab/rl4co   

Picture: [5396ee05ly8hf5sybpb8vj217w0u044t.jpg](https://weibo.cn//mblog/pic/N6k0s9Lab?rl=1)

Github: [github.com/kaist-silab/rl4co](https://github.com/kaist-silab/rl4co)

#### [【DevPod：一个开源工具，可一键部署本地开发环境或者直接链接云端环境，使用你喜欢的任意编辑器进行 @爱可可-爱生活](https://weibo.com/1402400261/N6m5J5nYc)

Note: 【DevPod：一个开源工具，可一键部署本地开发环境或者直接链接云端环境，使用你喜欢的任意编辑器进行开发。完全本地开发，客户端，容器化，可扩展】“DevPod - Open Source Dev-Environments-As-Code”    

#### [【VectorDBBench: 向量数据库基准测试工具】'VectorDBBench: A Benc @爱可可-爱生活](https://weibo.com/1402400261/N6utswZed)

Note: 【VectorDBBench: 向量数据库基准测试工具】'VectorDBBench: A Benchmark Tool for VectorDB - A Benchmark Tool for VectorDB' Zilliz GitHub: github.com/zilliztech/VectorDBBench   

Picture: [5396ee05ly8hf73627u9ij20u00xm42b.jpg](https://weibo.cn//mblog/pic/N6utswZed?rl=1)

Github: [github.com/zilliztech/VectorDBBench](https://github.com/zilliztech/VectorDBBench)

#### [生成式AI学习6——编码器-解码器架构（下）Lab演练编码器-解码器架构这门课程为你提供了编码器-解 @宝玉xp](https://weibo.com/1727858283/N6pZExtW8)

Note: 生成式AI学习6——编码器-解码器架构（下）Lab演练编码器-解码器架构这门课程为你提供了编码器-解码器架构的概述，这是一种强大且普遍存在的机器学习架构，适用于如机器翻译、文本摘要和问题回答等序列到序列任务。你将学习到编码器-解码器架构的主要组件以及如何训练和使用这些模型。在相应的实验室演示中，你将使用TensorFlow从头开始编写编码器-解码器架构的简单实现，用于诗歌生成。完成这门课程后，你可以获得上面显示的徽章！你可以通过访问个人资料页查看已经获得的所有徽章。通过向世界展示你已经开发的技能，提升你的云计算职业生涯！编码器-解码器架构：Lab演练你将在TensorFlow中编码一个简单的编码器-解码器架构的实现，用于从头开始生成诗歌。课程地址：YouTube播放列表： 

#### [慕尼黑工业大学数据库查询优化课程（），搭配了600多页的讲义：。  @蚁工厂](https://weibo.com/2194035935/N6sbP1IM0)

Note: 慕尼黑工业大学数据库查询优化课程（），搭配了600多页的讲义：。 

#### [电子书《Elements of Programming》这本老书在出版十年后推出了免费pdf版。 中 @敖天羽](https://weibo.com/1888981347/N6Y990aEc)

Note: 电子书《Elements of Programming》这本老书在出版十年后推出了免费pdf版。 中文翻译版叫编程原本追溯数学原理，探求编程的本质，一窥STL的设计思想，体会程序设计的迭代式过程，发现处理问题的算法 

Picture: [82c654dfly1hfagmbfs87j205w08w0tj.jpg](https://weibo.cn//mblog/pic/N6Y15Fow8?rl=1)

#### [【LLaMA Server：将  LLaMA C++ 和 Chatbot UI 结合的 LLaMA  @爱可可-爱生活](https://weibo.com/1402400261/N6EYH58Ws)

Note: 【LLaMA Server：将  LLaMA C++ 和 Chatbot UI 结合的 LLaMA 服务】’LLaMA Server - LLaMA Server combines the power of LLaMA C++ with the beauty of Chatbot UI.' Yi Su GitHub: github.com/nuance1979/llama-server     

Picture: [5396ee05ly8hf8diynsh2j219e0rmmz7.jpg](https://weibo.cn//mblog/pic/N6EYH58Ws?rl=1)

Github: [github.com/nuance1979/llama-server](https://github.com/nuance1979/llama-server)

#### [[LG]《FFCV: Accelerating Training by Removing Data  @爱可可-爱生活](https://weibo.com/1402400261/N6ITE8Bne)

Note: [LG]《FFCV: Accelerating Training by Removing Data Bottlenecks》G Leclerc, A Ilyas, L Engstrom, S M Park, H Salman, A Madry [MIT] (2023)   

Picture: [5396ee05ly1hf8uu3zw14j21m20o6h4r.jpg](https://weibo.cn//mblog/pic/N6ITz3Ux3?rl=1)

#### [【LLM训练和推理提速技巧：ALiBi位置嵌入、稀疏注意力、FlashAttention、多查询注意 @爱可可-爱生活](https://weibo.com/1402400261/N6KpjF5zW)

Note: 【LLM训练和推理提速技巧：ALiBi位置嵌入、稀疏注意力、FlashAttention、多查询注意力、条件计算和80GB A100 GPU，优化训练和推理过程的速度可以使用更大的文本窗口】《The Secret Sauce behind 100K context window in LLMs: all tricks in one place | by Galina Alperovich | May, 2023 | GoPenAI》  

Picture: [5396ee05ly8hf91g8e4dej20eu0a0752.jpg](https://weibo.cn//mblog/pic/N6KpjF5zW?rl=1)

#### [lmsys发布了新一期的大预言模型排行目前参与评选的模型越来越多了第一的肯定还是GPT-4 开源但不 @蚁工厂](https://weibo.com/2194035935/N6MMSaFxD)

Note: lmsys发布了新一期的大预言模型排行目前参与评选的模型越来越多了第一的肯定还是GPT-4 开源但不可商用的最高的是的新发布的vicuna-33b：huggingface.co/lmsys/vicuna-33b-v1.3 

Picture: [82c654dfly1hf9bwf6gx9j20r91i3n82.jpg](https://weibo.cn//mblog/pic/N6MMSaFxD?rl=1)

#### [Byzer-LLM 帮你把微调成本打下来啦，史上最轻松！1. 硬件打下来了。只要一块24G 的消费级 @蚁工厂](https://weibo.com/2194035935/N6Uqj8o6q)

Note: Byzer-LLM 帮你把微调成本打下来啦，史上最轻松！1. 硬件打下来了。只要一块24G 的消费级显卡 就可以完成 7B ,13B 模型微调。2. 人工打下来了，只要会SQL 就可以做微调。 

#### [也看支持32K上下文的ChatGLM2-6B模型：优化点简读及现有开源模型主流训练优化点概述 本地知 @蚁工厂](https://weibo.com/2194035935/N72uBhoqd)

Note: 也看支持32K上下文的ChatGLM2-6B模型：优化点简读及现有开源模型主流训练优化点概述 本地知识库的技术路线估计得升级了// :32k上下文

#### [Every NVIDIA DGX benchmarked & power efficiency &  @WinnieS的微博](https://weibo.com/2144454703/N762w7x4v)

Note: Every NVIDIA DGX benchmarked & power efficiency & value compared, including the latest DGX H100列了历代的DGX系统的价格和性能www.youtube.com/watch?v=ktNZLLZnjbk 

#### [电子书《Principles of Programming Languages》编程语言原理pdf下 @蚁工厂](https://weibo.com/2194035935/N74tIEFdo)

Note: 电子书《Principles of Programming Languages》编程语言原理pdf下载：pl.cs.jhu.edu/pl/book/book.pdf“在这本书中，我们的目标是研究编程语言中的基本概念，而不是学习一系列特定的语言。语言易于学习，难的是理解它们背后的概念。我们依次研究的基本特性包括高阶函数、以记录和变量形式的数据结构、可变状态、异常、对象和类以及类型。我们还研究语言实现，包括语言解释器和语言编译器。在整本书中，我们为玩具语言编写小型解释器，而在第8章，我们编写了一个有原则的编译器。我们定义类型检查器来确定哪些程序是类型正确的，哪些不是。我们还通过操作语义和类型系统的概念，对解释器和类型检查器进行了更精确、数学化的理解。这两个概念历史上是从逻辑学家对编程的视角演变而来的。”转发微博转发微博

Picture: [82c654dfly1hfbbzz8nbej21al1fhq75.jpg](https://weibo.cn//mblog/pic/N74tIEFdo?rl=1)

#### [长文翻译：《What Is a Transformer Model？》来自 Nvidia Blog  @Maeiee](https://weibo.com/1240212845/N753VddDH)

Note: 长文翻译：《What Is a Transformer Model？》来自 Nvidia Blog 的 Transformer  介绍文章。文章的目录如图。 回复:已收藏到Notion

Picture: [49ec256dly1hfbkn4j34hj20bx0eldj9.jpg](https://weibo.cn//mblog/pic/N753VddDH?rl=1)

#### [电子书 《 Learn Enough Command Line to Be Dangerous 》命 @Maeiee](https://weibo.com/1240212845/N779mujNy)

Note: 电子书 《 Learn Enough Command Line to Be Dangerous 》命令行从入门到入狱这是是一本为完全初学者介绍命令行的书，它是一系列旨在向尽可能广泛的读者教授“计算机魔法”的基础知识的教程。它既针对与软件开发人员一起工作的人，也针对那些渴望成为开发人员的人。与大多数命令行的介绍不同，这本书并不假设读者具有相对较高的技术素养，它只假设读者具有一般的计算机知识（如如何启动应用程序，如何使用网络浏览器，如何打字等）。换句话说，这意味着它并不假设你知道如何使用文本编辑器，甚至不知道什么是文本编辑器。事实上，这本教程甚至不假设你知道什么是命令行，所以如果你对标题感到困惑，你仍然在正确的地方。最后，即使你已经知道如何使用命令行，遵循这个教程（并做练习）将有助于填补你知识的任何空白，甚至可能教你一些新的东西。

Picture: [82c654dfly1hfbc3v7ifhj207s0bojs6.jpg](https://weibo.cn//mblog/pic/N776TdfV3?rl=1)

#### [【Dynolog: 性能监控和追踪的遥测守护进程，从系统的不同组件(如Linux内核、CPU、磁盘、 @爱可可-爱生活](https://weibo.com/1402400261/N77iJrGKf)

Note: 【Dynolog: 性能监控和追踪的遥测守护进程，从系统的不同组件(如Linux内核、CPU、磁盘、Intel PT、GPU等)导出指标】'Dynolog: a performance monitoring daemon for heterogeneous CPU-GPU systems - Dynolog is a telemetry daemon for performance monitoring and tracing. It exports metrics from different components in the system like the linux kernel, CPU, disks, Intel PT, GPUs etc. Dynolog also integrates with pytorch and can trigger traces for distributed training applications.' Meta Incubator GitHub: github.com/facebookincubator/dynolog 

Picture: [5396ee05ly8hfbujvhmq6j214l0u0wll.jpg](https://weibo.cn//mblog/pic/N77iJrGKf?rl=1)

Github: [github.com/facebookincubator/dynolog](https://github.com/facebookincubator/dynolog)

#### [【 】🤔国内大模型正在紧锣密鼓研发中🥁……🔥现在一整个大状态堪称“百模大战”💯。🌊那名字给起的，上天 @数据派THU](https://weibo.com/6004911042/N78jFq4JC)

Note: 【 】🤔国内大模型正在紧锣密鼓研发中🥁……🔥现在一整个大状态堪称“百模大战”💯。🌊那名字给起的，上天入地，通古贯今，一个比一个🐮🍺。🔍有网友表示：感觉马上神话故事里的人名都不够用了！🔒以，各家大模型，你都听过哪些？🙋记不住木事儿，这不有网友在Github上给我们整整列出了74家的大模型🦀️🦀️。🔗并且还贴心附上了相关链接～～～😱这不看不知道，一看大模型早已在医疗、教育、金融等各行各业大展拳脚🦶，渗透速度如此之快。🪄这么多大模型，你一定可以找到属于你的便捷工具。列表上的大模型你都体验过哪些🤏？感兴趣的读者，点开🔗康康详细内容：

Picture: [006Fd7o3gy1hfbnnvi3snj31940qygsq.jpg](https://weibo.cn//mblog/pic/N75Jzh6Lq?rl=1)

#### [生成式AI学习7——注意力机制本课程将向你介绍注意力机制，这是一种强大的技术，使神经网络能够关注输入 @宝玉xp](https://weibo.com/1727858283/N73npnyjn)

Note: 生成式AI学习7——注意力机制本课程将向你介绍注意力机制，这是一种强大的技术，使神经网络能够关注输入序列的特定部分。你将学习注意力的工作原理，以及如何利用它来提高各种机器学习任务的性能，包括机器翻译、文本总结和问题回答。课程地址：播放列表： 回复:感谢！[666]转发就是学会了回复:之前传错了，现在是中文字幕了有中午字幕吗

#### [Transformer模型和BERT模型本课程向您介绍Transformer架构和来自Transfo @宝玉xp](https://weibo.com/1727858283/N75aD3c2w)

Note: Transformer模型和BERT模型本课程向您介绍Transformer架构和来自Transformer（BERT）的双向编码器表示法模型。您将学习Transformer架构的主要组件，如自我关注机制，以及如何使用它来构建BERT模型。你还会了解到BERT可用于的不同任务，如文本分类、问题回答和自然语言推理。在本课程中，您将了解到Transformer架构的主要组成部分，如自我关注机制，以及如何使用它来构建BERT模型。你还会了解到BERT可用于的不同任务，如文本分类、问题回答和自然语言推理。课程地址： 

#### [生成式AI学习9——Transformer模型和BERT模型（下）演示Transformer模型和B @宝玉xp](https://weibo.com/1727858283/N7aIU9CcK)

Note: 生成式AI学习9——Transformer模型和BERT模型（下）演示Transformer模型和BERT模型本课程向您介绍Transformer架构和来自Transformer（BERT）的双向编码器表示法模型。您将学习Transformer架构的主要组件，如自我关注机制，以及如何使用它来构建BERT模型。你还会了解到BERT可用于的不同任务，如文本分类、问题回答和自然语言推理。在本课程中，您将了解到Transformer架构的主要组成部分，如自我关注机制，以及如何使用它来构建BERT模型。你还会了解到BERT可用于的不同任务，如文本分类、问题回答和自然语言推理。课程地址： 回复:有没有b站的呢。微博看太不舒服了

#### [“建议大家看一下李宏毅老师讲解的Transformer，非常简单易懂（个人觉得史上最强transfo @WinnieS的微博](https://weibo.com/2144454703/N7h6yuhcR)

Note: “建议大家看一下李宏毅老师讲解的Transformer，非常简单易懂（个人觉得史上最强transformer讲解）：www.youtube.com/watch?v=ugWDIIOHtPA&list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&index=61”~~~~果然，零基础小白，看过也觉得直接会了，可以手撕transformer了   转发微博  回复:已保存到你的Notion回复:成功保存到notion 

#### [计算机网络图解系列（英文）包含开发人员的计算机网络基础知识、Linux iptables 图解、SS @incanation2038](https://weibo.com/6134470959/N7iBIs9Db)

Note: 计算机网络图解系列（英文）包含开发人员的计算机网络基础知识、Linux iptables 图解、SSH 隧道可视化指南等多篇博文。特点是有大量手工绘图。 

Picture: [82c654dfly1hfcwswj9n7j21jk0ne1cf.jpg](https://weibo.cn//mblog/pic/N7gqTiQUb?rl=1)

#### [Patterns of Distributed Systems，分布式系统的模式分布式系统的编程提供 @敖天羽](https://weibo.com/1888981347/N7m81afqv)

Note: Patterns of Distributed Systems，分布式系统的模式分布式系统的编程提供了特殊的挑战。它们通常需要我们有多份数据副本，这些副本需要保持同步。然而，我们不能依赖处理节点的可靠工作，网络延迟很容易导致不一致性。尽管如此，许多组织依赖于一系列核心的分布式软件来处理数据存储、消息传递、系统管理和计算能力。这些系统面临着共同的问题，他们用类似的解决方案来解决。本文识别并发展了这些解决方案作为模式，通过这些模式，我们可以建立对如何更好地理解、交流和教授分布式系统设计的理解。

Picture: [82c654dfly1hfdmzv5uq1j20ug0r2tjx.jpg](https://weibo.cn//mblog/pic/N7lThsdfO?rl=1)

#### [【xCodeEval：大规模多语言多任务代码理解、生成、翻译和检索基准】'xCodeEval - A @爱可可-爱生活](https://weibo.com/1402400261/N7dX2a1sR)

Note: 【xCodeEval：大规模多语言多任务代码理解、生成、翻译和检索基准】'xCodeEval - A Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and Retrieval' NLP Group, Nanyang Technological University GitHub: github.com/ntunlp/xCodeEval  

Picture: [5396ee05ly8hfcnxbg7h6j20y20kg784.jpg](https://weibo.cn//mblog/pic/N7dX2a1sR?rl=1)

Github: [github.com/ntunlp/xCodeEval](https://github.com/ntunlp/xCodeEval)

#### [【Falcon LLM – A 40B Model】https:///falconllm.tii.a @网路冷眼](https://weibo.com/1715118170/N7dNibXUt)

Note: 【Falcon LLM – A 40B Model】https:///falconllm.tii.ae/ 猎鹰 LLM – 40B 模型 

#### [重磅：前段时间引起轰动的DragGAN图像编辑神器，源代码已经公开。地址：github.com/Xi @宝玉xp](https://weibo.com/1727858283/N7m590wJX)

Note: 重磅：前段时间引起轰动的DragGAN图像编辑神器，源代码已经公开。地址：github.com/XingangPan/DragGANHuggingface演示地址：huggingface.co/spaces/radames/DragGan  我用CPU在本地跑，巨慢//：//：硬件要求太高了比美图秀秀牛逼啊

Github: [github.com/XingangPan/DragGANHuggingface](https://github.com/XingangPan/DragGANHuggingface)

#### [使用 Linux 命名空间、cgroup 和 chroot 构建您自己的 Docker：实践指南一篇 @敖天羽](https://weibo.com/1888981347/N7nwv94wg)

Note: 使用 Linux 命名空间、cgroup 和 chroot 构建您自己的 Docker：实践指南一篇短文（英文），目的是提供对构成Docker核心的基础技术的教育性探索。通过从零开始构建一个基本的容器环境，目标是深入理解这些底层技术如何协同工作以实现容器化。 

#### [【ZodGPT：通过函数获取OpenAI新版0613模型的结构化、全类型化的JSON输出】'ZodG @爱可可-爱生活](https://weibo.com/1402400261/N7ew0uenS)

Note: 【ZodGPT：通过函数获取OpenAI新版0613模型的结构化、全类型化的JSON输出】'ZodGPT - Get structured, fully typed JSON outputs from OpenAI's new 0613 models via functions' David Zhang GitHub: github.com/dzhng/zod-gpt   

Picture: [5396ee05ly8hfcqc4hwgsj210t0u00wf.jpg](https://weibo.cn//mblog/pic/N7ew0uenS?rl=1)

Github: [github.com/dzhng/zod-gpt](https://github.com/dzhng/zod-gpt)

#### [今天读到两篇好文章，讲 Hugging Face 的 transformers 库的，分享给大家：① @Maeiee](https://weibo.com/1240212845/N7gfQCiPc)

Note: 今天读到两篇好文章，讲 Hugging Face 的 transformers 库的，分享给大家：① 《聊聊transformers库——基础与入门》② 《聊聊transformers库——进阶-模型微调和保存》 马🐎

#### [🌳 DeepGPT上线啦。它是一个会深度思考、能完成复杂任务的GPT工具，说人话就是它会多层次分拆任 @蚁工厂](https://weibo.com/2194035935/N7guhDTtY)

Note: 🌳 DeepGPT上线啦。它是一个会深度思考、能完成复杂任务的GPT工具，说人话就是它会多层次分拆任务，然后通过联网和搜索插件完成，最后汇总为输出，所以可以搞定一些更为复杂的任务。比如按你的身高体重和空闲时间给你定制健身计划、按你的忌口和喜好为你编排一周食谱，还能写修仙小说和科技书籍。可Chat酱一样，纯网页，可以自己部署，支持api2d/openai。教学视频 官方仓库 https:///github.com/easychen/deepgpt-dist在线版本 https:///d.level06.com 独立部署版下载 https:///github.com/easychen/deepgpt-dist/blob/master/build.zip

Github: [github.com/easychen/deepgpt-dist](https://github.com/easychen/deepgpt-dist)

Github: [github.com/easychen/deepgpt-dist/blob/master/build.zip](https://github.com/easychen/deepgpt-dist/blob/master/build.zip)

#### [' 开源书《构筑大语言模型应用：应用开发与架构设计》- 一本关于 LLM 在真实世界应用的开源电子书 @Maeiee](https://weibo.com/1240212845/N7hceqanb)

Note: ' 开源书《构筑大语言模型应用：应用开发与架构设计》- 一本关于 LLM 在真实世界应用的开源电子书，介绍了大语言模型的基础知识和应用，以及如何构建自己的模型。其中包括Prompt的编写、开发和管理，探索最好的大语言模型能带来什么，以及LLM应用开发的模式和架构设计'  Fengda Huang GitHub: github.com/phodal/aigc  

Picture: [5396ee05ly8hfcqoqjwccj218r0u0wkm.jpg](https://weibo.cn//mblog/pic/N7ezQ79jL?rl=1)

Github: [github.com/phodal/aigc](https://github.com/phodal/aigc)

#### [使用 Linux 命名空间、cgroup 和 chroot 构建您自己的 Docker：实践指南一篇 @蚁工厂](https://weibo.com/2194035935/N7nh3uRw0)

Note: 使用 Linux 命名空间、cgroup 和 chroot 构建您自己的 Docker：实践指南一篇短文（英文），目的是提供对构成Docker核心的基础技术的教育性探索。通过从零开始构建一个基本的容器环境，目标是深入理解这些底层技术如何协同工作以实现容器化。 

#### [【Replit Code Instruct inference using CPU：CPU上运行的r @爱可可-爱生活](https://weibo.com/1402400261/N7o1n3fHg)

Note: 【Replit Code Instruct inference using CPU：CPU上运行的replit-3B编程指令模型推断】’Replit Code Instruct inference using CPU - Run inference on replit-3B code instruct model using CPU' Anton Bacaj GitHub: github.com/abacaj/replit-3B-inference   是什么好东西来的

Github: [github.com/abacaj/replit-3B-inference](https://github.com/abacaj/replit-3B-inference)

#### [Weights&Biases整的这个训练大语言模型的白皮书挺好的，其中的概念和技术都有提到，看完全局 @Maeiee](https://weibo.com/1240212845/N7qDwyAnW)

Note: Weights&Biases整的这个训练大语言模型的白皮书挺好的，其中的概念和技术都有提到，看完全局和细节都会有基本了解  

Picture: [6d1b7657gy1hfdrlwgm7qj20s30spq5m.jpg](https://weibo.cn//mblog/pic/N7mW2lvTP?rl=1)

#### [【ChatGPT Prompts for Academic Writing：学术写作提示工程实战指南 @爱可可-爱生活](https://weibo.com/1402400261/N7qVFuUjM)

Note: 【ChatGPT Prompts for Academic Writing：学术写作提示工程实战指南】’ChatGPT Prompts for Academic Writing - This list of writing prompts covers a range of topics and tasks, including brainstorming research ideas, improving language and style, conducting literature reviews, and developing research plans.' Ahmet Bahaddin Ersoz GitHub: github.com/ahmetbersoz/chatgpt-prompts-for-academic-writing  既然如此，那论文的注水效果讲贬低研究者的价值。。。。好东西呀

Picture: [5396ee05ly8hfe97nm536j21hc0u040d.jpg](https://weibo.cn//mblog/pic/N7qVFuUjM?rl=1)

Github: [github.com/ahmetbersoz/chatgpt-prompts-for-academic-writing](https://github.com/ahmetbersoz/chatgpt-prompts-for-academic-writing)

#### [《CPU性能分析与优化》读书笔记（2）1、通常情况下，CPU执行的指令数量通常比实际执行退休指令多。 @小川CD](https://weibo.com/1202332555/N7r59dWuu)

Note: 《CPU性能分析与优化》读书笔记（2）1、通常情况下，CPU执行的指令数量通常比实际执行退休指令多。可以使用"perf stat -e instruction"命令来收集退休指令的数量。2、当CPU被阻塞并等待内存访问时，CPU利用率可能会显示较高。在多线程上下文中，当线程等待处理资源时，可能会进行自旋。要排除自旋时间后的指标，以获取CPU的有效利用率。3、几乎所有现代x86 CPU的流水线都支持四发射。因此，在6个时钟周期内，可以指定24个微操作。如果只执行了12个微操作，那么执行这类代码的效率只有50%。4、"perf stat -e cycles,ref-cycles"指标中的ref-cycles表示统计的时钟周期数量，不受动态频率调整的影响。而cycles则统计真正的CPU时钟周期数，即会考虑频率调整的影响。5、CPU缓存未命中对性能有很大影响。指令缓存未命中被归类为前端停顿，数据缓存未命中则被归类为后端停顿。6、当发生分支预测错误时，CPU需要撤销最近投机执行的所有工作，这通常会导致10～20个时钟周期的性能损耗。7、代码插桩假设开发者可以掌控程序的代码，而跟踪通常用在黑盒场景，即用户不能修改应用程序代码，但是又想深入了解程序在幕后做了什么工作。8、采样是最常用的性能分析方法，通常与在程序中查找热点相关。而剖析是一个更广泛的术语，包括各种收集数据的技术，例如中断、代码插桩和PMC（性能计数器）。9、Linux perf 收集调用栈的三种方法：1）帧指针（fp）需要消耗一个寄存器，成本较高，但可实现开销较低的栈展开，适用于性能剖析。2）使用DWARF调试信息，需要在编译时添加-g参数。3）Intel的最后分支记录（LBR）调用图深度不如前两种方法。10、硬件有两个主要限制：1）计算速度（峰值计算性能，FLOPS）和数据搬移速度（峰值内存带宽，GB/s）。应用程序的最大性能受限于峰值计算性能和平台带宽与算术强度的乘积之间的较小值。11、静态代码分析工具。对于C/C++语言，有一些工具如Clang Static Analyzer、Klocwork和Cppcheck，旨在检查代码的正确性和语义。也有一些工具尝试解决代码性能问题。12、编译器在提升软件性能方面起着非常重要的作用。编译器优化报告应被视为工具箱中的关键工具之一。通过使用编译器优化报告，可以发现许多改进机会。

#### [推荐一个算法高频题的汇总网站：codetop.cc，针对国内互联网企业，可按照按岗位、部门进行热度分 @Maeiee](https://weibo.com/1240212845/N7rpN3Ur7)

Note: 推荐一个算法高频题的汇总网站：codetop.cc，针对国内互联网企业，可按照按岗位、部门进行热度分类。算法刷题，没必要全部做完，所有的 Medium 有思路且能写出来，同时部分热门 Hard 有思路就差不多了，总量应该在 200 题左右。 

Picture: [6c0378f8ly1hfebbk56h1j21k81gmtt4.jpg](https://weibo.cn//mblog/pic/N7roWpG23?rl=1)

#### [【commavq：包含10万个压缩驾驶视频的数据集，用于机器学习研究，可用于GPT视频预测模型的实验 @爱可可-爱生活](https://weibo.com/1402400261/N7xi5vUKH)

Note: 【commavq：包含10万个压缩驾驶视频的数据集，用于机器学习研究，可用于GPT视频预测模型的实验，还包含编码器/解码器和视频预测模型示例】'commaVQ - a dataset of compressed driving video' comma.ai GitHub: github.com/commaai/commavq   

Picture: [5396ee05ly8hff1acmauxj218o0u0wkv.jpg](https://weibo.cn//mblog/pic/N7xi5vUKH?rl=1)

Github: [github.com/commaai/commavq](https://github.com/commaai/commavq)

#### [电子书《The Linux Networking Architecture: Design and  @Maeiee](https://weibo.com/1240212845/N7zfhmKK8)

Note: 电子书《The Linux Networking Architecture: Design and Implementation of Network Protocols in the Linux Kernel 》pdf下载：本书旨在为给予和专业人士提供在Linux内核中实现网络功能所需的基础知识，同时也针对希望加深对操作系统中特定于网络的进程的理解的每个人。 本书介绍了Linux内核的关键组件和机制以及通信系统的设计。这本由专家编写的独特的Linux网络教程/参考为读者提供了一个实用的概述，并了解了Linux内核中网络协议的实现。 本书展示了如何在Linux操作系统中实现网络行为和协议。 这本书提供了Linux内核的介绍，主要集中在即将到来的内核版本2. 4，但也适用于版本2. 2内核。本书的结构遵循TCP/IP分层模型，从内核的网络设备驱动程序开始，继续到链路层协议（如PPP），最后给出TCP/IP协议族的所有核心协议的描述。 还包括其他补充协议，如RSVP、IP安全和移动的IP。英文版，以上内容机翻~

Picture: [82c654dfly1h3otcq4gbvj20ay0dvaal.jpg](https://weibo.cn//mblog/pic/LzVex8zGf?rl=1)

#### [您可以参加的最佳线性代数课程。100% 免费！麻省理工学院的吉尔伯特·斯特朗教授。看完这些视频，您将 @Maeiee](https://weibo.com/1240212845/N7B5dlowV)

Note: 您可以参加的最佳线性代数课程。100% 免费！麻省理工学院的吉尔伯特·斯特朗教授。看完这些视频，您将再也不会遇到线性代数问题！地址：ocw.mit.edu/courses/18-06-linear-algebra-spring-2010/ 

Picture: [71f81b09gy1hf5qnf6oijj225v1a14qp.jpg](https://weibo.cn//mblog/pic/N6kkwvXxD?rl=1)

#### [【发布16K上下文聊天模型LongChat-7B和LongChat-13B，其长程检索准确性比其他长 @爱可可-爱生活](https://weibo.com/1402400261/N7F9p1wPO)

Note: 【发布16K上下文聊天模型LongChat-7B和LongChat-13B，其长程检索准确性比其他长上下文开放模型(如MPT-7B-storywriter、MPT-30B-chat和ChatGLM2-6B)高出2倍；提供了 LongEval 工具包，用于验证长上下文能力，发现商业LLM表现良好，开源LLM往往无法实现所承诺的上下文长度】《How Long Can Open-Source LLMs Truly Promise on Context Length? | LMSYS Org》   

Picture: [5396ee05ly8hffzo3goz9j21nb0u077x.jpg](https://weibo.cn//mblog/pic/N7F9p1wPO?rl=1)

#### [电子书《 Linux Kernel Crash Book 》本书详细讨论了 Linux 系统崩溃相关 @蚁工厂](https://weibo.com/2194035935/N7IDoovPT)

Note: 电子书《 Linux Kernel Crash Book 》本书详细讨论了 Linux 系统崩溃相关的问题，包括原因、它们发生时的处理、如何收集有关它们的信息、如何分析这些信息以及如何解决问题等等。 

Picture: [82c654dfly1h3pzf0sfszj205k07u74g.jpg](https://weibo.cn//mblog/pic/LA4KL8emu?rl=1)

#### [这本书豆瓣9.1分，国内还未引进。但作者已经开源，有兴趣的可以看看。  @Maeiee](https://weibo.com/1240212845/N7JUF26ZY)

Note: 这本书豆瓣9.1分，国内还未引进。但作者已经开源，有兴趣的可以看看。 

Picture: [b95dea45ly1hfg9dgixkwj20kq0gx42v.jpg](https://weibo.cn//mblog/pic/N7HgQEo47?rl=1)

#### [【MosaicML无需修改代码即可迁移到AMD的GPU上(性能达到144 TFLOP/s)，AMD  @爱可可-爱生活](https://weibo.com/1402400261/N7NK1b3iP)

Note: 【MosaicML无需修改代码即可迁移到AMD的GPU上(性能达到144 TFLOP/s)，AMD MI250的LLM训练性能与NVIDIA A100-40GB相当，平均为80%，且随着AMD软件的改进，这一差距将进一步缩小】《Training LLMs with AMD MI250 GPUs and MosaicML》   

Picture: [5396ee05ly8hfh1t2yvk1j21l40u0n10.jpg](https://weibo.cn//mblog/pic/N7NK1b3iP?rl=1)

#### [教学项目，为 RISC-V 构建最小内核地址：github.com/peiyuanix/yuanix @蚁工厂](https://weibo.com/2194035935/N7OkLpzbq)

Note: 教学项目，为 RISC-V 构建最小内核地址：github.com/peiyuanix/yuanix-riscv-os项目目前还在进行中。已有的内容从qemu的使用，汇编和链接基础知识，用汇编和C实现RISC-V上的helloworld等 mark回复:已保存到你的notion

Picture: [82c654dfly1hfh4i0tjmaj20u310ztir.jpg](https://weibo.cn//mblog/pic/N7OkLpzbq?rl=1)

Github: [github.com/peiyuanix/yuanix-riscv-os](https://github.com/peiyuanix/yuanix-riscv-os)

#### [新发现：《Natural Language Processing with Transformers @Maeiee](https://weibo.com/1240212845/N7QEvbt98)

Note: 新发现：《Natural Language Processing with Transformers Building Language Applications with Hugging Face》这本书的三位作者，也是《在一张 24 GB 的消费级显卡上用 RLHF 微调 20B LLMs》这篇文章的作者。我的 Obsidian 知识库小小地涌现了一下  回复:已保存至notion回复:成功保存至Notion[666]回复:未能保存至你的Notion，Notion 创建页面失败回复:已收藏至你的Notion

Picture: [49ec256dly1hfhesdzzv8j20md0tnwsh.jpg](https://weibo.cn//mblog/pic/N7QEvbt98?rl=1)

#### [webvm，一个在浏览器里运行的linux虚拟机地址：github.com/leaningtech/ @蚁工厂](https://weibo.com/2194035935/N7R2RFfSK)

Note: webvm，一个在浏览器里运行的linux虚拟机地址：github.com/leaningtech/webvmwebvm由 CheerpX 虚拟化引擎提供支持，可在任何浏览器上安全、沙盒地执行 x86 二进制文件。 

Picture: [82c654dfly1hfhgiphvlmj20yl0af78c.jpg](https://weibo.cn//mblog/pic/N7R2RFfSK?rl=1)

Github: [github.com/leaningtech/webvmwebvm](https://github.com/leaningtech/webvmwebvm)

#### [在我们调用OpenAI的API的时候，除了Prompt和模型，还有几个参数可以选：Temperatu @宝玉xp](https://weibo.com/1727858283/N7WCegUjV)

Note: 在我们调用OpenAI的API的时候，除了Prompt和模型，还有几个参数可以选：Temperature、Top K和Top P。大部分都知道温度（Temperature）参数是可以控制输出的确定性的，温度越低，输出结果越确定；反之温度越高，输出结果越具有多样性。那么Top K和Top P是什么呢？看完这个视频你会找到答案！这个视频来自Google的Generative AI learning path课程系列的《Introduction to Generative AI Studio   生成式人工智能工作室介绍》完整视频：B站：Top K 可以让模型从可能性最高的前 K 个词中随机返回一个词，这种方法可以让模型不会总是选概率最高的那个，而是从概率最高的前K个词中随机选择一个词。但这种方法有一个缺陷，比如说你指定Top K是3，但如果概率最高的前3个词里面，第3个词其实概率很低相关度很弱，那么就会导致生成的结果不够好。Top P则是另一种选择方式，让模型可以从一组总和不超过 P 的词中选择。例如，Top P为0.75意味着你从一组累积概率大于0.75的词中取样。这样可以避免概率很低的词被选中。不过通常来说，你是用不上Top K和Top P的，但是知道一下它们是什么意思总是不错的。 

#### [大型语言模型与生成式AI——介绍LLM和生成式AI项目的生命周期3——生成式AI和大语言模型的输出  @宝玉xp](https://weibo.com/1727858283/N7YtOrGAy)

Note: 大型语言模型与生成式AI——介绍LLM和生成式AI项目的生命周期3——生成式AI和大语言模型的输出  这段视频主要介绍了大型语言模型（LLMs）的相关概念，使用场景，工作原理，以及如何生成创造性文本输出，并为生成性人工智能项目概述了一个项目生命周期。大型语言模型是传统机器学习的子集，能够通过在大量的数据中找到统计模式，学习如何模拟或近似人类的创造性内容。基础模型是经过数周甚至数月的训练，拥有数十亿参数的大型语言模型。这些模型不仅能处理语言，还能解决更复杂的任务，进行推理和解决问题。  在与这些模型的交互过程中，你将使用一种被称为“Prompt”的文本，模型会根据这个“Prompt”进行生成，其生成的结果被称为“完成”。一个具体的例子是，你可以询问模型关于太阳系中木卫三（Ganymede）的位置，模型会基于你的提示生成一个合理的回答。通过学习和使用这些模型，你可以快速地构建定制的解决方案，而不需要从头开始训练新的模型。 课程地址：www.coursera.org/learn/generative-ai-with-llms/lecture/IrsEw/generative-ai-llms播放列表：www.youtube.com/watch?v=bkDTEo1CCHk&list=PLiuLMb-dLdWL4KBaU3FTM5f_oMcSvXcZw 回复:难得有人关心下字体😄开源的霞鹜文楷 github.com/lxgw/LxgwWenKai奇特视角的问题：请问博主视频配的中文字体是哪个？怪好看的

#### [神器CLIP：连接文本和图像，打造可迁移的视觉模型Contrastive ：文本-图像对，一张图像和 @WinnieS的微博](https://weibo.com/2144454703/N7YvSbp00)

Note: 神器CLIP：连接文本和图像，打造可迁移的视觉模型Contrastive ：文本-图像对，一张图像和它对应的文本描述Text Encoder固定选择一个包含63M参数的text transformer模型Image Encoder采用了两种的不同的架构，一是常用的CNN架构ResNet，二是基于transformer的ViT 

#### ["Understanding the Fundamental Limitations of Vect @Maeiee](https://weibo.com/1240212845/N822CFVej)

Note: "Understanding the Fundamental Limitations of Vector-Based Retrieval for Building LLM-Powered Chatbots— (Part 1/3)"  

#### [“建议大家看一下李宏毅老师讲解的Transformer，非常简单易懂（个人觉得史上最强transfo @宝玉xp](https://weibo.com/1727858283/N84AkvUzb)

Note: “建议大家看一下李宏毅老师讲解的Transformer，非常简单易懂（个人觉得史上最强transformer讲解）：www.youtube.com/watch?v=ugWDIIOHtPA&list=PLJV_el3uVTsOK_ZK5L0Iv_EQoL1JefRL4&index=61”~~~~果然，零基础小白，看过也觉得直接会了，可以手撕transformer了 

#### [【eigenGPT：GPT2的最小化C++实现】’eigenGPT - Minimal C++ im @爱可可-爱生活](https://weibo.com/1402400261/N82bw4osy)

Note: 【eigenGPT：GPT2的最小化C++实现】’eigenGPT - Minimal C++ implementation of GPT2' David A Roberts GitHub: github.com/davidar/eigenGPT   

Github: [github.com/davidar/eigenGPT](https://github.com/davidar/eigenGPT)

#### [ 周末重装了一下macOS，所以有了这份儿 “Mac 开光指南（V3）”。主要对新入手macOS之后 @Maeiee](https://weibo.com/1240212845/N87IW2Ugr)

Note:  周末重装了一下macOS，所以有了这份儿 “Mac 开光指南（V3）”。主要对新入手macOS之后，安全研究/从业人员应该安装的基础软件，或者需要配置的开发环境，进行了记录和说明。具体的目录如图1所示。大家有相同需要的可以看一下，如果有其他想要咨询的也可以在评论区评论。PS：这份指南是基于 shockerli 的“Mac 开光指南（V2）”进行二创而来典型的被工具绑架

Picture: [0061ywhYly1hfixp4s8f4j30wq2vt1kx.jpg](https://weibo.cn//mblog/pic/N8361om8t?rl=1)

#### [用Python实现一个玩具编程语言“my”，作者用137行Python代码实现了一个基本的编程语言。 @蚁工厂](https://weibo.com/2194035935/N875Xe9X4)

Note: 用Python实现一个玩具编程语言“my”，作者用137行Python代码实现了一个基本的编程语言。 很像A=B那个游戏[开学季]

#### [王树森老师（深度强化学习一书的作者）的公开课《高级算法》地址：github.com/wangshus @蚁工厂](https://weibo.com/2194035935/N88uOuaQ6)

Note: 王树森老师（深度强化学习一书的作者）的公开课《高级算法》地址：github.com/wangshusen/AdvancedAlgorithms该库包括PPT和视频链接。另外在B站ShusenWang频道也有部分视频 诶 他讲过推荐系统也挺好的

Picture: [82c654dfly1hfjhhuc18mj218s14ktsu.jpg](https://weibo.cn//mblog/pic/N88uOuaQ6?rl=1)

Github: [github.com/wangshusen/AdvancedAlgorithms](https://github.com/wangshusen/AdvancedAlgorithms)

#### [DragGAN-Windows-GUI,DragGAN的windows封装。什么环境不用配置，解压直 @蚁工厂](https://weibo.com/2194035935/N8bBCji1o)

Note: DragGAN-Windows-GUI,DragGAN的windows封装。什么环境不用配置，解压直接用的dragGAN工具，内置17个模型。地址：github.com/zhaoyun0071/DragGAN-Windows-GUIDragGAN是前几天很火的那个通过拖动等方式对图中对象进行姿势、形状、表情和布局调整的AI工具。  硬件要求挺高吧

Github: [github.com/zhaoyun0071/DragGAN-Windows-GUIDragGAN](https://github.com/zhaoyun0071/DragGAN-Windows-GUIDragGAN)

#### [对大模型的微调，把预训练模型微调为可对话的模型地址：github.com/beyondguo/LLM @数据派THU](https://weibo.com/6004911042/N8uMkbHpR)

Note: 对大模型的微调，把预训练模型微调为可对话的模型地址：github.com/beyondguo/LLM-Tuning目前支持：--清华 ChatGLM2-6B 的 LoRA 微调--百川智能 baichuan-7B 的 LoRA 微调--清华 ChatGLM-6B 的 LoRA 微调 

Picture: [82c654dfly1hfm1vhwobfj21750u2k5i.jpg](https://weibo.cn//mblog/pic/N8u986mDB?rl=1)

Github: [github.com/beyondguo/LLM-Tuning](https://github.com/beyondguo/LLM-Tuning)

#### [如何写一个Web服务器 （C语言版）作者：”本文介绍了Zaver，一个结构简单，支持高并发的http @Maeiee](https://weibo.com/1240212845/N8vkdp85u)

Note: 如何写一个Web服务器 （C语言版）作者：”本文介绍了Zaver，一个结构简单，支持高并发的http服务器。基本架构是事件循环 + non-blocking I/O + 线程池。Zaver的代码风格参考了Nginx的风格，所以在可读性上非常高。另外，Zaver提供了配置文件和命令行参数解析，以及完善的Makefile和源代码结构，也可以帮助任何一个C初学者入门一个项目是怎么构建的。”

#### [昨天发的让浏览器自动点击ChatGPT的“Continue generating”按钮的脚本  ，有 @宝玉xp](https://weibo.com/1727858283/N8yfGymYQ)

Note: 昨天发的让浏览器自动点击ChatGPT的“Continue generating”按钮的脚本  ，有个台湾网友在它基础上提出了一个更简单的方式：将脚本添加到浏览器的收藏夹，需要的时候点一下就可以。只要添加一条新书签，标题可以是任意文字，URL填写以下脚本：javascript:(function(){const observer=new MutationObserver(()=>{[...document.querySelectorAll('button.btn')].forEach((btn)=>{if(btn.innerText.includes('Continue generating')){console.log('Found the button of "Continue generating"');setTimeout(()=>{console.log('Clicked it to continue generating after 1 second');btn.click();},1000);}});});observer.observe(document.forms[0],{attributes:false,childList:true,subtree:true,});})();用篡改猴上的脚本，一劳永逸

Picture: [66fd066bgy1hfmrkbz5sxj20e80emabb.jpg](https://weibo.cn//mblog/pic/N8yfGymYQ?rl=1)

#### [ 发现这个东西很好，为什么之前的容器宿主机都没有用上呢，为此还得自己根据 cgroup 实现一套 C @敖天羽](https://weibo.com/1888981347/N8d9y2ytZ)

Note:  发现这个东西很好，为什么之前的容器宿主机都没有用上呢，为此还得自己根据 cgroup 实现一套 CPU usage percent 计算  

#### [一本值得一生推的书：Being Logical: A Guide to Good ThinkingB @Maeiee](https://weibo.com/1240212845/N8cYMbxV7)

Note: 一本值得一生推的书：Being Logical: A Guide to Good ThinkingBeing Logical是美国逻辑学教授麦克伦尼（D.Q.McInerny）的逻辑学著作。与很多人对逻辑学著作的刻板印象不同，这本书并没有包含太多艰深晦涩的术语，相反，它的可读性非常高。作者将这本书定位于逻辑学入门书籍（Logic is a science and an art. This book is intended to introduce readers to the rudiments of the science as well as to the basic skills associated with the art.），并且在书中花费大量的篇幅来强调那些看似很浅显但我们却经常犯错的逻辑学概念，比如不要混淆“观点”和“事实”，不要想当然地认为你的听众会领悟你没有直接表达的意思，不要对人不对事等。为了更好地说明这些概念，书中还列举了不少例子作为佐证，每一个例子都能引起你对既有观念的思考。正如作者在书中所说，逻辑是有效思考的前提条件，也是日常生活的行动起点。逻辑思维的应用非常广，它不仅仅对学术有帮助，它还可以帮助我们在生活中做出更好的选择和决策。另外，这本书英文版只有140多页，用词难度也不高，一个下午就能读完，非常推荐将这本书作为第一本逻辑学书籍。

Picture: [8261caaagy1heyrt8etrfj20ku19441u.jpg](https://weibo.cn//mblog/pic/N5oFkk7eY?rl=1)

#### [新文章发布了《两万字教你自己动手开发互联网搜索引擎》，同时，示例项目也是一个可以运行的开源 Go 互 @蚁工厂](https://weibo.com/2194035935/N8heIfSDk)

Note: 新文章发布了《两万字教你自己动手开发互联网搜索引擎》，同时，示例项目也是一个可以运行的开源 Go 互联网搜索引擎：github.com/johnlui/DIY-Search-Engine 文章地址： 

Picture: [87beacably1hfkne60i8aj20mf0eygnl.jpg](https://weibo.cn//mblog/pic/N8h4GvKhz?rl=1)

Github: [github.com/johnlui/DIY-Search-Engine](https://github.com/johnlui/DIY-Search-Engine)

#### [StyleDrop，Google推出的一项新的文本生成图像技术。先给定一张特定风格的图片，然后用户输 @蚁工厂](https://weibo.com/2194035935/N8jZFheMU)

Note: StyleDrop，Google推出的一项新的文本生成图像技术。先给定一张特定风格的图片，然后用户输入的文本可以生产完全相同的风格的图片。详细介绍：styledrop.github.io/如图中左侧是输入的图，右侧是根据文本生成的图片。 

Picture: [82c654dfly1hekv9q9nfsj22801zlb2a.jpg](https://weibo.cn//mblog/pic/N3ziMtdZU?rl=1)

#### [博文《使用二八法则省力地学习 awk》在本文中，我们将学习到如何使用二八法则来省力轻松学习 linu @蚁工厂](https://weibo.com/2194035935/N8l3QtjT7)

Note: 博文《使用二八法则省力地学习 awk》在本文中，我们将学习到如何使用二八法则来省力轻松学习 linux 文本处理命令 awk。读完本文你就会学习到一种快速学习的方法， 以及使用 awk 来处理文本和 stdout。 

Picture: [82c654dfly1h3ulz3xdguj20dg0siwgm.jpg](https://weibo.cn//mblog/pic/LAGwK9scC?rl=1)

#### [【Noodle：开源学生学习效率平台，帮助学生管理与其教育相关的一切，包括任务、笔记、闪卡和时间表等 @数据派THU](https://weibo.com/6004911042/N8uMqmPrk)

Note: 【Noodle：开源学生学习效率平台，帮助学生管理与其教育相关的一切，包括任务、笔记、闪卡和时间表等，旨在通过提供一个单一平台来解决学生在管理教育方面所面临的问题】'Noodle - Open Source Education Platform' Ahmed Elsakaan GitHub: github.com/ixahmedxi/noodle   

Picture: [5396ee05ly8hflzhkvs28j21hb0u00yi.jpg](https://weibo.cn//mblog/pic/N8rXC6cRC?rl=1)

Github: [github.com/ixahmedxi/noodle](https://github.com/ixahmedxi/noodle)

#### ['Finetune-ChatGLM2-6B - ChatGLM2-6B 全参数微调，支持多轮对话的高 @蚁工厂](https://weibo.com/2194035935/N8E9E1B0Q)

Note: 'Finetune-ChatGLM2-6B - ChatGLM2-6B 全参数微调，支持多轮对话的高效微调。' SpongebBob GitHub: github.com/SpongebBob/Finetune-ChatGLM2-6B    //:转发微博

Picture: [5396ee05ly8hfndr6x08fj21ba0hcn0l.jpg](https://weibo.cn//mblog/pic/N8Dlmf5cK?rl=1)

Github: [github.com/SpongebBob/Finetune-ChatGLM2-6B](https://github.com/SpongebBob/Finetune-ChatGLM2-6B)

#### [【jiro-nn：用纯 Rust 构建和训练高效神经网络的框架，支持 CPU 和 GPU】'jiro @爱可可-爱生活](https://weibo.com/1402400261/N8DoHF154)

Note: 【jiro-nn：用纯 Rust 构建和训练高效神经网络的框架，支持 CPU 和 GPU】'jiro-nn - A framework for building and training efficient Neural Networks in pure Rust with support for both the CPU and the GPU.' Anicet Nougaret GitHub: github.com/AnicetNgrt/jiro-nn   

Picture: [5396ee05ly8hfndzb5yowj21ck0nitb9.jpg](https://weibo.cn//mblog/pic/N8DoHF154?rl=1)

Github: [github.com/AnicetNgrt/jiro-nn](https://github.com/AnicetNgrt/jiro-nn)

#### [技术博客《卡瓦邦噶！》这里是一个 SRE 的博客，讨论的内容有：Linux, Vim, Tmux,  @Maeiee](https://weibo.com/1240212845/N8MTcbLp6)

Note: 技术博客《卡瓦邦噶！》这里是一个 SRE 的博客，讨论的内容有：Linux, Vim, Tmux, NixOS, Python, Java, TCP/IP, Container, Docker, Ansible, Git, Graphviz, Redis, Prometheus, SSH, Shell, Bash, GNU, Github, C, C++, Unix, Nginx, Lua, Django, React 以及运维的方法论，编程的思考，工作的感悟。作者也是播客《捕蛇者说》的大佬之一。

Picture: [82c654dfly1hfo2fg76wzj20x61b01ir.jpg](https://weibo.cn//mblog/pic/N8KaM5VbB?rl=1)

#### [推荐阅读：《AI Agents大爆发：软件2.0雏形初现，OpenAI的下一步》这篇文章的原作者是L @蚁工厂](https://weibo.com/2194035935/N8KCx1ADv)

Note: 推荐阅读：《AI Agents大爆发：软件2.0雏形初现，OpenAI的下一步》这篇文章的原作者是Lilian Weng，她现在是 OpenAI 的 Head of Safety Systems，之前还领导过 OpenAI 的 Applied AI 团队。Lilian Weng 的这篇 Blog 可以说是目前 AI Agent 领域优质论文的系统综述，她将 Agents 定义为 LLM、记忆（Memory）、任务规划（Planning Skills）以及工具使用（Tool Use） 的集合，其中 LLM 是核心大脑，Memory、Planning Skills 以及 Tool Use 等则是 Agents 系统实现的三个关键组件，在文章中，她还对每个模块下实现路径进行了细致的梳理和说明。到今天，构建 AI Agent 的工具箱已经相对完善，但仍需要面对一些限制，例如上下文长度、长期规划和任务分解，以及 LLM 能力的稳定性等。英文原文：lilianweng.github.io/posts/2023-06-23-agent/🔗完整中文翻译 by 拾象 海外独角兽：

Picture: [66fd066bly8hflz5rd6amj21jj0m1mzn.jpg](https://weibo.cn//mblog/pic/N8rTC7OJZ?rl=1)

#### [电子书《Rust 程序设计语言》地址：kaisery.github.io/trpl-zh-cn/ti @蚁工厂](https://weibo.com/2194035935/N8IHryQJD)

Note: 电子书《Rust 程序设计语言》地址：kaisery.github.io/trpl-zh-cn/title-page.html欢迎阅读《Rust 程序设计语言》，这是一本 Rust 语言的入门书。Rust 程序设计语言能帮助你编写更快、更可靠的软件。在编程语言设计中，上层的编程效率和底层的细粒度控制往往不能兼得，而 Rust 则试图挑战这一矛盾。Rust 通过平衡技术能力和开发体验，允许你控制内存使用等底层细节，同时也不需要担心底层控制带来的各种麻烦。本书的英文原版作者为 Steve Klabnik 和 Carol Nichols，并由 Rust 社区补充完善。本简体中文译本由 Rust 中文社区翻译。👍回复:成功保存到你的Notion[赢牛奶]rust（未授权）[666]

Picture: [82c654dfly1hfo14c066jj20kk1nkgsn.jpg](https://weibo.cn//mblog/pic/N8IHryQJD?rl=1)

#### [Arm微架构第四期2023年Arm最新处理器架构分析——X4、A720和A520 嗯，就知道了直接不 @程杰Rockie](https://weibo.com/1746378031/N8Nr5kOnv)

Note: Arm微架构第四期2023年Arm最新处理器架构分析——X4、A720和A520 嗯，就知道了直接不用就好了这样下去arm不会学苹果，手机上取消小核吧，下代天玑和下下代骁龙，都有这个可能我想知道arm啥时候给小核心上乱序回复:虽然这么说，但是有些人会因为待机续航差一点点就嫌弃，不把实际耗电量说出来对比，整天一群人喊待机续航翻车，真的想顺着网线去一巴掌拍醒他们回复:现在手机待机才耗几个点啊，一晚上6到8小时也就3个点，有时候5g的话要到5到8个点。。一般晚上都会开启深度休眠，几乎没得啥子后台。  就算白天待机也就一两个点一个小时。。。  没得小核心，就是怕日用啥的功耗偏高，看小说，电视啥的功耗高。。？谢谢高质量的写作。我每次都看起来很好。谢谢。DSU120提供了一个有价值的功能，随着L3缓存越来越大，静态漏电也成为一个需要考虑的影响因素，会影响手机的待机耗电场景。DSU120提供了一个L3部分关闭的功能，在一些不需要使用那么大缓存的场景，关闭部分L3缓存，可以减少静态漏电。   担心9300待机续航不行的来看看

#### [【LMDeploy：涵盖了 LLM 任务的全套轻量化、部署和服务解决方案】'LMDeploy - L @爱可可-爱生活](https://weibo.com/1402400261/N8KIM50GJ)

Note: 【LMDeploy：涵盖了 LLM 任务的全套轻量化、部署和服务解决方案】'LMDeploy - LMDeploy is a toolkit for compressing, deploying, and serving LLM' InternLM GitHub: github.com/InternLM/lmdeploy  转发微博正好需要

Github: [github.com/InternLM/lmdeploy](https://github.com/InternLM/lmdeploy)

#### [【在不超过2GB VRAM GPU的普通消费硬件上生成和训练短音频样本】'A repository  @爱可可-爱生活](https://weibo.com/1402400261/N8KDlx6ou)

Note: 【在不超过2GB VRAM GPU的普通消费硬件上生成和训练短音频样本】'A repository for generating and training short audio samples with unconditional waveform diffusion on accessible consumer hardware (<2GB VRAM GPU)' Christopher Landschoot GitHub: github.com/crlandsc/tiny-audio-diffusion  

Picture: [5396ee05ly8hfo9wtaqf2j21c60s0gry.jpg](https://weibo.cn//mblog/pic/N8KDlx6ou?rl=1)

Github: [github.com/crlandsc/tiny-audio-diffusion](https://github.com/crlandsc/tiny-audio-diffusion)

#### [【大型语言模型评估相关论文资源列表】’A collection of papers and reso @爱可可-爱生活](https://weibo.com/1402400261/N8KqwlWa1)

Note: 【大型语言模型评估相关论文资源列表】’A collection of papers and resources related to Evaluation on Large Language Model' by MLGroupJLU GitHub: github.com/MLGroupJLU/LLM-eval-survey   mark

Picture: [5396ee05ly8hfo90c3oobj21dn0u0dpa.jpg](https://weibo.cn//mblog/pic/N8KqwlWa1?rl=1)

Github: [github.com/MLGroupJLU/LLM-eval-survey](https://github.com/MLGroupJLU/LLM-eval-survey)

#### [【：在自己的基础设施上优化和部署LLM，构建完全托管在自己基础设施上的LLM应用】’ - Deplo @爱可可-爱生活](https://weibo.com/1402400261/N8Kq4iKBu)

Note: 【：在自己的基础设施上优化和部署LLM，构建完全托管在自己基础设施上的LLM应用】’ - Deploy LLMs on your own cloud, Fine-Tune and Deploy LLMs On Your Own Infrastructure’ Haven GitHub: github.com/havenhq/haven   你好，你感兴趣的“开源”已开通了超话社区～ 超话社区是微博旗下兴趣互动社区，快来与志同道合的小伙伴们一起交流互动吧！ 戳我进入>> 

Picture: [5396ee05ly8hfo8yjpptuj20xr0j5dgt.jpg](https://weibo.cn//mblog/pic/N8Kq4iKBu?rl=1)

Github: [github.com/havenhq/haven](https://github.com/havenhq/haven)

#### [ 学术分享丨清华朱军团队新作：使用4位整数训练Transformer，比FP16快2.2倍，提速35 @数据派THU](https://weibo.com/6004911042/N9gVYASWC)

Note:  学术分享丨清华朱军团队新作：使用4位整数训练Transformer，比FP16快2.2倍，提速35.1%，加速AGI到来！ 

Picture: [006ynZFUly1hfs8jppedhj30u0095gni.jpg](https://weibo.cn//mblog/pic/N9gVYASWC?rl=1)

#### [【】线性代数的重点，已经有人帮忙画好了。一共只有12页纸，而且一半都是图解，小白也不用担心看不懂！现 @数据派THU](https://weibo.com/6004911042/N9gWD8g9u)

Note: 【】线性代数的重点，已经有人帮忙画好了。一共只有12页纸，而且一半都是图解，小白也不用担心看不懂！现在，这份笔记在GitHub已经获得了4k+次星标，还登上了热榜。 

Picture: [006Fd7o3ly1hfs4tl0kt0j30u00irn6n.jpg](https://weibo.cn//mblog/pic/N9g5Fl4Nu?rl=1)

#### [LLM+Embedding构建问答系统的局限性及优化方案    近期LangChain + LLM  @蚁工厂](https://weibo.com/2194035935/N9bfp3wEh)

Note: LLM+Embedding构建问答系统的局限性及优化方案    近期LangChain + LLM 方案高速发展，降低了知识问答等下游应用的开发门槛。但随着业务深入，一些局限性也日渐显露，比如：LLM意图识别准确性较低，交互链路长导致时间开销大；Embedding 不适合多词条聚合匹配等。本文结合实际案例，分析上述问题存在的根源，并提出基于传统 NLP 技术的解决思路。

#### [电子书《The-Art-of-Linear-Algebra》吉尔伯特·斯特朗 (Gilbert St @蚁工厂](https://weibo.com/2194035935/N9b0Nj5No)

Note: 电子书《The-Art-of-Linear-Algebra》吉尔伯特·斯特朗 (Gilbert Strang) 的《适合所有人的线性代数》的图解笔记地址：github.com/kenjihiranabe/The-Art-of-Linear-Algebra有中英文不同版本 这个看完有种听君一席话如听一席话的感觉 基本全是废话转发微博这个看完有种听君一席话如听一席话的感觉 基本全是废话这本和矩阵力量，各自特点？

Picture: [82c654dfly1hfriefnlvjj21hy1er4cj.jpg](https://weibo.cn//mblog/pic/N9b0Nj5No?rl=1)

Github: [github.com/kenjihiranabe/The-Art-of-Linear-Algebra](https://github.com/kenjihiranabe/The-Art-of-Linear-Algebra)

#### [学习英语利器是这个 OGDEN's BASIC ENGLISH 手册用 850 个单词极度简化英语学 @宝玉xp](https://weibo.com/1727858283/N90ru44zf)

Note: 学习英语利器是这个 OGDEN's BASIC ENGLISH 手册用 850 个单词极度简化英语学习和日常使用，覆盖 90% 的牛津字典概念，保持完整英语规则，用简单而完美的英语进行正常沟通🤖 ogden.basic-english.org 

Picture: [71f81b09gy1hfp73bz07wj20oo0lrk2m.jpg](https://weibo.cn//mblog/pic/N8UaAs3CN?rl=1)