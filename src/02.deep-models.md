# 深度学习模型与算法

模型, 应用和解决方案.

## CV

dinov2
* 图像子监督对比训练模型
* [github](https://github.com/facebookresearch/dinov2), [haai](https://hub.baai.ac.cn/view/25489), [aijishu](https://aijishu.com/a/1060000000398895)

dino
* [wechat](https://mp.weixin.qq.com/s?__biz=MzU1MzY0MDI2NA==&mid=2247499393&idx=1&sn=83e6eecb11e4dc03dde296d06d689e3c&chksm=fbed76a6cc9affb0095fa04452a111fd483720980208fc6edd09c0bd8f207e7f94d6c151a1cb&scene=21#wechat_redirect), [github](https://github.com/facebookresearch/dino), [arxiv](https://arxiv.org/abs/2104.14294)

## NLP

[From deep to long learning ?](https://hazyresearch.stanford.edu/blog/2023-03-27-long-learning)
* [hacker news](https://news.ycombinator.com/item?id=35502187)对此进行了详细的讨论

## AUDIO

[whisper](https://github.com/openai/whisper)
* [whisper.cpp](https://github.com/ggerganov/whisper.cpp): whisper模型的C++实现
* [Whisper JAX](https://github.com/sanchit-gandhi/whisper-jax): jax版本实现和加速
  * 加速内容: 音频分段批处理(7倍), 使用jax jit(2倍), 使用TPU替换GPU(5倍), 共70倍
* [Whisper](https://github.com/Const-me/Whisper): whisper模型的Windows客户端, 支持GPU, [小众软件](https://www.appinn.com/const-me-whisper/)推荐
* [openai-whisper-cpu](https://github.com/MiscellaneousStuff/openai-whisper-cpu): CPU量化提升吞吐
* [whisperX](https://github.com/m-bain/whisperX): 提升时间戳精准度
* [whisper_real_time](https://github.com/davabase/whisper_real_time): 实时调用音频转换成字符的demo
* [WAAS](https://github.com/schibsted/WAAS): whisper as a service
* [whisper openvino](https://github.com/zhuzilin/whisper-openvino): whisper openvino优化版本
* [faster-whisper](https://github.com/zhuzilin/whisper-openvino): 基于CTranslate2的whisper实现
* [huggingface finetune whisper](https://github.com/huggingface/blog/blob/main/fine-tune-whisper.md): huggingface官方的whisper finetune博客
* [AWS finetune whisper](https://aws.amazon.com/cn/blogs/china/fine-tuning-and-deploying-whisper-models-with-sagemaker/): AWS finetune博客, 示例在[github](https://github.com/aws-samples/amazon-sagemaker-fine-tune-and-deploy-wav2vec2-huggingface)
* [LanguageLeapAI](https://github.com/SociallyIneptWeeb/LanguageLeapAI): 基于whisper的翻译助理

[AudioGPT](https://www.aminer.cn/pub/6448967c71ac66d2cbd88151/audiogpt-understanding-and-generating-speech-music-sound-and-talking-head?f=wb): 论文[AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head](https://www.aminer.cn/pub/6448967c71ac66d2cbd88151/audiogpt-understanding-and-generating-speech-music-sound-and-talking-head?f=wb), 代码在[github](https://github.com/AIGC-Audio/AudioGPT)

## RECO

## BIGS

[LLaVA](https://llava-vl.github.io/)
* 多模态大模型,开源了数据集,模型和性能
* [github](https://github.com/haotian-liu/LLaVA), [arxiv](https://arxiv.org/abs/2304.08485), [haai](https://hub.baai.ac.cn/view/25839)

[minGPT-4](https://github.com/Vision-CAIR/MiniGPT-4)
* [github](https://github.com/Vision-CAIR/MiniGPT-4), [github.io](https://minigpt-4.github.io/), [githubdaily](https://githubdaily.gitee.io/posts/2023-04-17-minigpt-4/), [haai](https://hub.baai.ac.cn/view/25493), [jack cui](https://cuijiahua.com/blog/2023/04/ai-32.html), [paper with code](https://paperswithcode.com/paper/minigpt-4-enhancing-vision-language), [arxiv](https://arxiv.org/abs/2304.10592)
* [MiniGPT-4实现原理及其核心BLIP2模型实践：从代表性图文对数据集、BLIP2模型结构到调用实践](https://mp.weixin.qq.com/s/riPR6dAvhlJD0Gp4Rtbw1w)
* [weibo分析](https://weibo.com/1497035431/MCXq5BmDe)
  * CV 部分采用了 EVA、BEIT、timm 和 DeiT
  * NLP 部分采用了 LLaMA
  * 框架主体使用了 PyTorch
  * 分布式部分，用了Salesforce.com的一个基于 PyTorch 分布式的简单封装和加强库

[A Survey of Large Language Models](https://arxiv.org/abs/2303.18223)
* 大语言模型综述, [github](https://github.com/RUCAIBox/LLMSurvey/blob/main/assets/LLM_Survey_Chinese_0418.pdf)上有中文版

[Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision](https://github.com/IBM/Dromedary)
* IBM对模型产生内容进行无害化过滤

[Open-Llama](https://github.com/s-JoL/Open-Llama)
* 开源训练llama流程, [这里](http://home.ustc.edu.cn/~sl9292/)还部署了一个demo.

[GrilfriendGPT](https://github.com/EniasCailliau/GirlfriendGPT)
* 一个小应用,生成一个会发照片,语音,文字的虚拟女友

[multilingual-model-speech-recognition](https://ai.facebook.com/blog/multilingual-model-speech-recognition/)
* META开源的ASR模型,特点是支持1000多种语言,对小语种友好
* [github](https://github.com/facebookresearch/fairseq/tree/main/examples/mms), [paper](https://scontent-cgk1-1.xx.fbcdn.net/v/t39.8562-6/348836647_265923086001014_6878005808275791319_n.pdf?_nc_cat=104&ccb=1-7&_nc_sid=ae5e01&_nc_ohc=hjR-6nxcdOYAX-rEdBF&_nc_ht=scontent-cgk1-1.xx&oh=00_AfDmuOFfAUiIzeJ9TG0faxUXs_x6M81aj4GW3fhxjoOx3Q&oe=6475A14F)

## train

[Building Systems with the ChatGPT API](https://learn.deeplearning.ai/chatgpt-building-system/lesson/1/introduction)
* 吴恩达DLAI的prompt课程, [youtube](https://www.youtube.com/watch?v=1SZOGp1D17E&list=PLiuLMb-dLdWKjX8ib9PhlCIx1jKMNxMpy)有宝玉的翻译版本

[Transformer Math 101](https://blog.eleuther.ai/transformer-math/)
* transformer训练的一些数字知识, 可用于进行性能预估

[Transformer Inference Arithmetic](https://kipp.ly/blog/transformer-inference-arithmetic/)
* 推理部分详细计算

[Drag Your GAN](https://github.com/XingangPan/DragGAN)
* 使用GAN实现图像修改,只需要拖动图片

[SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities](https://github.com/0nutation/SpeechGPT)
* 使用GPT实现多模态对话, 能实现语音对话

[【LLM系列之底座模型对比】LLaMA、Palm、GLM、BLOOM、GPT模型结构对比](https://mp.weixin.qq.com/s/kqBROBbXIeu5Zu1luNpitw?v_p=90&WBAPIAnalysisOriUICodes=10000001&wm=3333_2001&aid=01A2GUVvCiJ0bN45VH0AOVftc20OVPaYUZmVa1h1s_8-8xrdg.&from=10D5193010)
* GPT: decoder只保留一个Masked-Multi-Head Attention
* LLaMA: RMSNorm,SwiGLU,Rotary Embedding, AdamW+Cosine learning rate schedule,因果多头注意力
* Palm:swiGLU,Parallel layers, Multi-Query Attention, RoPE, shared Input-Output Embedding
* GLM: layer norm的顺序和残差重新排列, 用于输出标记的单个线性层, Gelu, 二维位置编码
* BLOOM:ALiBi位置嵌入, Embedding LayerNorm再第一嵌入层后直接使用, 250K词汇表,字节BPE,两个全连接层

[chatglm_tuning: 基于 LoRA 和 P-Tuning v2 的 ChatGLM-6B 高效参数微调](https://mp.weixin.qq.com/s/fF1jci5l65opO1YPMOUuaw?v_p=90&WBAPIAnalysisOriUICodes=10000001&wm=3333_2001&aid=01A2GUVvCiJ0bN45VH0AOVftc20OVPaYUZmVa1h1s_8-8xrdg.&from=10D5193010)
* [Github 代码](https://github.com/zejunwang1/chatglm_tuning)
