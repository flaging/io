

#### [【基础模型相关文献资源列表】’Awesome-Foundation-Models - A curat @爱可可-爱生活](https://weibo.com/1402400261/MDNobDSiN)

Note: 【基础模型相关文献资源列表】’Awesome-Foundation-Models - A curated list of foundation models for vision and language tasks' uncbiag GitHub: github.com/uncbiag/Awesome-Foundation-Models   

Picture: [5396ee05ly8hddaflvq8qj20u00wj79t.jpg](https://weibo.cn//mblog/pic/MDNobDSiN?rl=1)

Github: [github.com/uncbiag/Awesome-Foundation-Models](github.com/uncbiag/Awesome-Foundation-Models)

#### [【Open-Chinese-LLaMA：基于 LLaMA-7B 经过 中文数据集增量预训练 产生的  @爱可可-爱生活](https://weibo.com/1402400261/MDNoNq13t)

Note: 【Open-Chinese-LLaMA：基于 LLaMA-7B 经过 中文数据集增量预训练 产生的 中文大语言模型基座】'Open-Chinese-LLaMA - Chinese large language model base generated through incremental pre-training on Chinese datasets' OpenLMLab GitHub: github.com/OpenLMLab/OpenChineseLLaMA    

Picture: [5396ee05ly8hddai21ugtj20ui0u0djc.jpg](https://weibo.cn//mblog/pic/MDNoNq13t?rl=1)

Github: [github.com/OpenLMLab/OpenChineseLLaMA](github.com/OpenLMLab/OpenChineseLLaMA)

#### [【分布式机器学习系统相关资源列表】’Awesome Distributed Machine Lear @爱可可-爱生活](https://weibo.com/1402400261/MDNQP0eEn)

Note: 【分布式机器学习系统相关资源列表】’Awesome Distributed Machine Learning System - A curated list of awesome projects and papers for distributed training or inference' shenggan GitHub: github.com/Shenggan/awesome-distributed-ml   

Picture: [5396ee05ly8hddchqzgwfj21100u00w7.jpg](https://weibo.cn//mblog/pic/MDNQP0eEn?rl=1)

Github: [github.com/Shenggan/awesome-distributed-ml](github.com/Shenggan/awesome-distributed-ml)

#### [《ChatGPT 为什么不用 Reward-Model 的数据直接 fine-tune，而用 RL？ @爱可可-爱生活](https://weibo.com/1402400261/MDSFpi6Ac)

Note: 《ChatGPT 为什么不用 Reward-Model 的数据直接 fine-tune，而用 RL？ - 知乎》    我提的问题 问就是玄学为了发paper

Picture: [5396ee05ly8hddxrik0clj20u00w4djx.jpg](https://weibo.cn//mblog/pic/MDSFpi6Ac?rl=1)

#### [【bert.cpp：使用4位整型量化来运行BERT神经网络架构的纯C++(或C)实现，使用池化和归一 @爱可可-爱生活](https://weibo.com/1402400261/ME6ZwEoyG)

Note: 【bert.cpp：使用4位整型量化来运行BERT神经网络架构的纯C++(或C)实现，使用池化和归一化来生成高质量的句子嵌入】'bert.cpp - ggml inference of BERT neural net architecture with pooling and normalization from SentenceTransformers (sbert.net). High quality sentence embeddings in pure C++ (or C)' Santtu Keskinen GitHub: github.com/skeskinen/bert.cpp  

Picture: [5396ee05ly8hdfozj50daj217s0oy0x8.jpg](https://weibo.cn//mblog/pic/ME6ZwEoyG?rl=1)

Github: [github.com/skeskinen/bert.cpp](github.com/skeskinen/bert.cpp)

#### [[CL]《LaMini-LM: A Diverse Herd of Distilled Models @爱可可-爱生活](https://weibo.com/1402400261/MEaQXkMDo)

Note: [CL]《LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions》M Wu, A Waheed, C Zhang, M Abdul-Mageed, A F Aji [Mohamed bin Zayed University of Artificial Intelligence] (2023)   🙋

Picture: [5396ee05ly1hdg5w9bj5fj20ly0y6dr7.jpg](https://weibo.cn//mblog/pic/MEaQVevdf?rl=1)

#### [【Llama Hub：可用于 GPT Index / LangChain 的 LLM 数据加载库】’ @爱可可-爱生活](https://weibo.com/1402400261/MEbLZxdXM)

Note: 【Llama Hub：可用于 GPT Index / LangChain 的 LLM 数据加载库】’Llama Hub - A library of data loaders for LLMs made by the community -- to be used with GPT Index and/or LangChain' Jesse Zhang GitHub: github.com/emptycrown/llama-hub  

Picture: [5396ee05ly1haw9pkqgn0j21bq0nwwsz.jpg](https://weibo.cn//mblog/pic/Ms5tDthTS?rl=1)

Github: [github.com/emptycrown/llama-hub](github.com/emptycrown/llama-hub)

#### [【Lamini：让开发人员在大规模数据集上训练高性能语言模型，无需成为机器学习专家，通过Lamini @爱可可-爱生活](https://weibo.com/1402400261/MEbZw4h4u)

Note: 【Lamini：让开发人员在大规模数据集上训练高性能语言模型，无需成为机器学习专家，通过Lamini，可以轻松创建类似于ChatGPT的语言模型】《Introducing Lamini, the LLM Engine for Rapid Customization》   转发微博

Picture: [5396ee05ly8hdgb1wh7vzj20u00v0ad0.jpg](https://weibo.cn//mblog/pic/MEbZw4h4u?rl=1)

#### [Stack Overflow 将对使用其数据训练 AI 收费。现在训练AI常用的几大数据来源Twit @蚁工厂](https://weibo.com/2194035935/MDqAcd4Ml)

Note: Stack Overflow 将对使用其数据训练 AI 收费。现在训练AI常用的几大数据来源Twitter、Reddit、Stack Overflow逐渐都不免费开放了。 OpenAI在大家都没反应过来之前抢占制高点现在才想起来，晚啦，数据都抓到西历1970年啦

#### [技术博文《论头文件》https://lemonhx.xlog.app/lun-tou-wen-jia @蚁工厂](https://weibo.com/2194035935/MDqGkb36F)

Note: 技术博文《论头文件》https://lemonhx.xlog.app/lun-tou-wen-jian头文件是计算机编程中包含函数、类、变量和其他声明的文件，用于在程序中引用外部库或模块。现代编程语言不再使用显式的头文件，而是使用模块或名称空间来组织代码，并使用自动化工具来处理依赖关系。但是，头文件提供了一种自顶而下的开发方式，可以使代码更加清晰、易于维护和扩展。头文件在编程中起着重要作用，可以简化代码编写和维护，加速程序开发进程。虽然现代编程可以使用新技术来解决头文件问题，但头文件仍然有不可替代的作用，特别是在大型项目中。应该正确使用头文件，同时不断探索新技术提高编程效率和代码质量。文章里的头文件不就是其他语言的接口和抽象设计吗？直接接口就行，为什么又需要头文件？

Picture: [82c654dfly1hdai75bb7rj20kk0hudj6.jpg](https://weibo.cn//mblog/pic/MDqGkb36F?rl=1)

#### [QuiLLMan: 这个项目可以让你与大语言模型进行语音聊天项目地址：github.com/moda @蚁工厂](https://weibo.com/2194035935/MDrWiay6b)

Note: QuiLLMan: 这个项目可以让你与大语言模型进行语音聊天项目地址：github.com/modal-labs/quillman目前使用的语言模型是Vicuna（会增加其他的语言模型），OpenAI Whisper用于转录，Metavoice Tortoise TTS用于文本到语音。 

Picture: [82c654dfly1hdakmu6p51j20m80dwaew.jpg](https://weibo.cn//mblog/pic/MDrWiay6b?rl=1)

Github: [github.com/modal-labs/quillman](github.com/modal-labs/quillman)

#### [好文分享：《How to run your own LLM (GPT)》 这篇文章讲述了如何在家中运 @蚁工厂](https://weibo.com/2194035935/MDstrC0ab)

Note: 好文分享：《How to run your own LLM (GPT)》 这篇文章讲述了如何在家中运行自己的大型语言模型（LLM），并讨论了GPT-4的能力和未来趋势。它还提供了一些有趣的用例和如何设置本地模型的指南。 

Picture: [49ec256dly1hdansdaglzj20qd0kmwi9.jpg](https://weibo.cn//mblog/pic/MDrWJ54XK?rl=1)

#### [LangChain 中文入门教程地址：github.com/liaokongVFX/LangChai @蚁工厂](https://weibo.com/2194035935/MDs1YkJv4)

Note: LangChain 中文入门教程地址：github.com/liaokongVFX/LangChain-Chinese-Getting-Started-GuideLangChain 是一个用于开发由语言模型驱动的应用程序的框架。他主要拥有 2 个能力：---可以将 LLM 模型与外部数据源进行连接---允许与 LLM 模型进行交互  

Picture: [82c654dfly1hdam5uqjmgj20un0dp77s.jpg](https://weibo.cn//mblog/pic/MDs1YkJv4?rl=1)

Github: [github.com/liaokongVFX/LangChain-Chinese-Getting-Started-GuideLangChain](github.com/liaokongVFX/LangChain-Chinese-Getting-Started-GuideLangChain)

#### [DDIA(设计数据密集型应用)读书笔记地址： markrepo.github.io/database @蚁工厂](https://weibo.com/2194035935/MDu7awzwf)

Note: DDIA(设计数据密集型应用)读书笔记地址： markrepo.github.io/database/2022/01/13/DDIA/这是作者在读DDIA时记录的要点。另外本书全文有个中文翻译之前发过，地址是：github.com/Vonng/ddia 

Picture: [82c654dfly1h1kj41dzftj20ka0ob762.jpg](https://weibo.cn//mblog/pic/LpTbekJ4m?rl=1)

Github: [github.com/Vonng/ddia](github.com/Vonng/ddia)

#### [RecAlign，一个开源的、概念性的Chrome插件，它让你可以用自然语言过滤掉社交网络种你不感兴 @蚁工厂](https://weibo.com/2194035935/MDujDeiPQ)

Note: RecAlign，一个开源的、概念性的Chrome插件，它让你可以用自然语言过滤掉社交网络种你不感兴趣的部分，或者只留下你感兴趣的部分（一级信息茧房建筑师？）。目前支持推特和知乎两个平台。地址：github.com/recalign/RecAlign 千万不要，只看自己要看的只会越来越自我感觉良好。微博很需要

Github: [github.com/recalign/RecAlign](github.com/recalign/RecAlign)

#### [grogudb 是一个开源的，为高频 Put/Has/Del/Range 操作而设计的持久化 KV  @蚁工厂](https://weibo.com/2194035935/MDvmzDUBl)

Note: grogudb 是一个开源的，为高频 Put/Has/Del/Range 操作而设计的持久化 KV 数据库。性能上，除了 Get API，其他所有操作性能几乎均优于 badger/leveldb。个人小型项目。地址：github.com/chenjiandongx/grogudbFeatures：    纯 Go 实现，可内嵌进程序中。    高效的 Put/Has/Del/Range 操作。    线程安全。    允许存储超过物理内存的数据。    简洁的 API。不信

Github: [github.com/chenjiandongx/grogudbFeatures](github.com/chenjiandongx/grogudbFeatures)

#### [《Linux操作系统内核学习笔记》地址： ty-chen.github.io/categories/ @蚁工厂](https://weibo.com/2194035935/MDzecmLh7)

Note: 《Linux操作系统内核学习笔记》地址： ty-chen.github.io/categories/Linux操作系统内核学习/Linux操作系统内核是服务端学习的根基，也是提高编程能力、源码阅读能力和进阶知识学习能力的重要部分，本文开始将记录Linux操作系统中的各个部分源码学习历程。目录如图。 

Picture: [82c654dfly1h1mc63546gj20s20li3zy.jpg](https://weibo.cn//mblog/pic/Lq7VGjTo8?rl=1)

#### [一个技术博客《An Amateur Programmer's Blogs》地址：dirtysalt. @蚁工厂](https://weibo.com/2194035935/MDzu95SaO)

Note: 一个技术博客《An Amateur Programmer's Blogs》地址：dirtysalt.github.io/html/blogs.html内容很丰富，技术方面以C、算法、高性能计算为主。有很多博主阅读过的英文文章的要点总结。比如最近一篇介绍了CppCon 2016上的一个讨论，为什么C++这个语言不能被C社区所接受。一个重要的原因是“如果你尝试去说服别人的时候，不要去争论，不然你就输了。”哈，居然在这里见到我同组前同事的blog，世界真小 //:一直在更新中 

Picture: [82c654dfly1h1lvz3ozr1j20u019eqko.jpg](https://weibo.cn//mblog/pic/Lq4BLi8Ak?rl=1)

#### [电子书《谷雨同学的 C++ 教程》主要内容：    第〇章：非常简单的基本计算机知识概述；内容属于北 @蚁工厂](https://weibo.com/2194035935/MDzRqynYB)

Note: 电子书《谷雨同学的 C++ 教程》主要内容：    第〇章：非常简单的基本计算机知识概述；内容属于北京大学《计算概论（A）》“计算机基础知识”部分。    第一 ~ 四章：用 C++ 的语法讲述 C 语言知识；教学思路依照北京大学《计算概论（A）》课程，少量穿插新语法特性。其性质属于教材草案。    第五 ~ 八章：讲解 C++ 面向对象语法，但以实用为主、思想为辅；大体框架依照北京大学《程序设计实习》课程。其性质属于知识整理。    第九 ~ 十章：讲解一些必要的 C++ 相关知识。    第十一 ~ ? 章：讲解 C++ 更深入的语法，包括函数式编程等。其性质属于读书笔记。

Picture: [82c654dfly1hdawdzvdbpj20jv1d7tj7.jpg](https://weibo.cn//mblog/pic/MDzRqynYB?rl=1)

#### [最近，一篇名为《Scaling Transformer to 1M tokens and beyon @蚁工厂](https://weibo.com/2194035935/MDDEZB5G7)

Note: 最近，一篇名为《Scaling Transformer to 1M tokens and beyond with RMT》在技术圈引发热议。该论文提出一种名为 RMT 的新技术，或许可将 Transform 的 Token 上限扩展至 100 万，甚至更多。要知道，目前最强的 GPT-4-32k，其 Token 上限也才 3.2 万，这就导致了它并不能很好的处理长文内容。像文档、书籍、代码这种大块内容，往往需要先对内容进行切割，分多次喂给 GPT，但 GPT 本身能理解的上下文内容有限，这就很容易导致结果偏离预期。如果未来 Token 的上限能够不断突破，将会创造出更多 AI 应用场景。包括之前大家经常畅想的，训练一个无限接近自己人格的 AI 聊天机器人。论文：arxiv.org/abs/2304.11062要是你觉得这些技术名词比较晦涩难懂，也可以读一下 Twitter 网友 riddhi 让 ChatGPT 做的这个总结，通俗易懂的解读了这项技术：假设你有个很聪明的机器人朋友，它可以读很多东西并记住它们。这个机器人朋友使用一种叫做 “Transformer” 的东西来帮助它理解和记忆内容，就像人类大脑一样。现在有这么一群聪明人，发现了一种能让你的机器人朋友变得更好的方法，那就是给它装上一个新大脑，叫做“Recurrent Memory Transformer”，或者简称“RMT”。有了这个新大脑，机器人朋友就可以记住和理解更多的东西，一次多达 2 百万个字！这相当于它可以同时记住大约 20 本很长的书的内容。在这之前，其他聪明的机器人只能记住最多 6.4 万个字，虽然这已经很多了，但还远不及 2 百万个字。这个发现非常重要，因为这意味着我们的机器人朋友现在可以理解和谈论更多的事情，为我们提供更多的帮助。最棒的是，这种新大脑不会让机器人变得更重或者耗费更多的能量。所以这就像一台拥有超能力的机器人朋友，可以做很多厉害的事情并且不会累！Twitter：twitter.com/ridtalkstech/status/1650316114935828481

Picture: [006fiYtfgy1hdc2ktv13lj30xc0tothg.jpg](https://weibo.cn//mblog/pic/MDDDnnyHX?rl=1)

#### [电子书《The Rust Book (Abridged) 》Rust 之书（精简版）这是“The R @蚁工厂](https://weibo.com/2194035935/MDDUGkBpT)

Note: 电子书《The Rust Book (Abridged) 》Rust 之书（精简版）这是“The Rust Programming Language”（又名“Rust Book”）的删节版——或者更好的词应该是浓缩版。这不是一部原创作品——本书中的所有章节名称和示例都是从原著中逐字复制的，但是所有的散文都是从头开始重写的，省略了所有与学习 Rust 无关的内容。这本书的长度大约是原版的 1/2，但编者认为它没有遗漏任何有经验的软件开发人员可能不知道的内容。另外编者还特别声明本书“没有任何内容是由 ChatGPT 生成的”

Picture: [82c654dfly1hdbs7f7538j21211cp7sj.jpg](https://weibo.cn//mblog/pic/MDDUGkBpT?rl=1)

#### [《 Bash Shell 脚本编程实践 》Shell编程的入门文章。当用户登入任意一款 Linux  @蚁工厂](https://weibo.com/2194035935/MDEC3ia6P)

Note: 《 Bash Shell 脚本编程实践 》Shell编程的入门文章。当用户登入任意一款 Linux 操作系统时，初始化程序init都将会为用户启动一个Bash Shell命令解析器，其即可以用于解析命令行输入并与内核进行交互，也可以作为高效的脚本编程语言，运用其提供的变量、参数、循环、分支等编程语法特性，完成一些批量的自动化的任务处理工作，本文将会围绕 Bash Shell 的脚本编程特性，加以进行详细的分析、说明与示例。这还要学？chatgpt大项目搞不了，让它写个脚本真的是又快又好

Picture: [82c654dfly1h1kx9xjybcj20i61am0z6.jpg](https://weibo.cn//mblog/pic/Lq3lqmlBG?rl=1)

#### [GPT4All Chat，一个本地运行的人工智能聊天应用程序，不需要联网。已经被打包好了，直接下载即 @蚁工厂](https://weibo.com/2194035935/MDJslDN7A)

Note: GPT4All Chat，一个本地运行的人工智能聊天应用程序，不需要联网。已经被打包好了，直接下载即可使用。默认使用GPT-J模型，用CPU计算。能力可能和gpt-3差不多。下载地址：gpt4all.io/index.html 404【极速上新】人工智能聊天应用程序GPT4All（API)模型新鲜上架：支持本地运行，不需要联网，CPU计算就可以支持～～体验走起[冲刺][冲刺][冲刺]，快夸我效率名字带 GPT4 的 GPT3 不知道能不能本地做微调可下载，打不开gpt for ... 很容易误解这名字回复:你TMD 出来卖不给说，反应激烈了不是真的有什么吧？一千美金＄叛国?4=For，名字取得好

Picture: [82c654dfly1hdct3n9jjyj20zk12gqr3.jpg](https://weibo.cn//mblog/pic/MDJslDN7A?rl=1)

#### [小朋友们新搞的一个图像数据，可以用来做强化，改进文本-图像质量，人工标注了10多万数据，希望对大家有 @蚁工厂](https://weibo.com/2194035935/MDNWffdth)

Note: 小朋友们新搞的一个图像数据，可以用来做强化，改进文本-图像质量，人工标注了10多万数据，希望对大家有用。ImageReward: Learning and Evaluating Human Preferences for Text-to-Image Generation  # pip install image-rewardimport ImageReward as RMmodel = RM.load("ImageReward-v1.0")rewards = model.score("<prompt>", ["<img1_obj_or_path>", "<img2_obj_or_path>", ...])哈哈下面文字是chatglm在英文论文基础上写的。本文介绍了一种名为 ImageReward 的通用文本到图像人类偏好奖励模型，旨在解决生成模型中存在的各种问题，并将它们与人类价值和偏好对齐。该模型的训练基于我们的系统注释管道，该管道涵盖了评级和排序组件，并收集了截至 137k 个专家比较的 dataset。在人类评估中，ImageReward 比现有的评分方法 (如 CLIP) 表现更好，其中 CLIP 方法领先 38.6%。因此，ImageReward 是一种有希望的自动评估和改进文本到图像合成的有用指标。该奖励模型可通过在 URL 中给出 \texttt{image-reward} 包进行公共可用。

Picture: [7ebeb44bgy1hddcow455jj21sy0x6nkr.jpg](https://weibo.cn//mblog/pic/MDNV9jBDp?rl=1)

#### [电子书《面向程序员的数据挖掘指南》中文翻译地址：rack-leen.github.io/world/ @蚁工厂](https://weibo.com/2194035935/MDOJz0rY6)

Note: 电子书《面向程序员的数据挖掘指南》中文翻译地址：rack-leen.github.io/world/myworld/guide-to-data-mining/index.html英文原版在这里：这是一本用于学习基本数据挖掘知识的书籍。大部分关于数据挖掘的书籍都着重于讲解理论知识，难以理解，让人望而却步。不要误会，这些理论知识还是非常重要的。但如果你是一名程序员，想对数据挖掘做一些了解，一定会需要一本面向初学者的入门书籍。这就是撰写本书的初衷。这本指南采用“边学边做”的方式编写，因此在阅读本书时，我强烈建议您动手实践每一章结束提供的练习题和实验题，使用书中的Python脚本将其运行起来。书中有一系列展示数据挖掘技术的实例，因此在阅读完本书后，你就能掌握这些技术了。这本书以Creative Commons协议发布，可以免费下载。你可以任意分发这本书的副本，或者重新组织它的内容。也许将来我会提供一本纸质的书籍，不过这里的在线版本永远是免费的。

Picture: [82c654dfly1h1mufuz6e0j20hf0obta0.jpg](https://weibo.cn//mblog/pic/Lqcut3w7y?rl=1)

#### [电子书《逻辑学简短入门》牛津通识读本的重译版。Graham Priest 的 Logic: A Ve @蚁工厂](https://weibo.com/2194035935/MDSkeBSxO)

Note: 电子书《逻辑学简短入门》牛津通识读本的重译版。Graham Priest 的 Logic: A Very Short Introduction 是牛津通识系列中的一本。该书在众多逻辑学入门书中独树一帜，并不试图完整介绍逻辑学的理论，而是通过一些哲学难题或逻辑谜题引入解决这些问题的逻辑理论和方法，在介绍逻辑知识的同时展示逻辑可以如何来用。译者wxflogic发现之前的翻译有些术语不太准确，所以重新翻译了一下。

Picture: [82c654dfly1h1o4jl03zaj20gr1j7781.jpg](https://weibo.cn//mblog/pic/LqoSPFuph?rl=1)

#### [这是一个我写的真实的一手深度学习故事，可作为理解人工智能的起点。贾扬清开源 AI 框架 Caffe  @蚁工厂](https://weibo.com/2194035935/MDW7hr4US)

Note: 这是一个我写的真实的一手深度学习故事，可作为理解人工智能的起点。贾扬清开源 AI 框架 Caffe | 开源英雄  

#### [replit的博文《How to train your own Large Language Mod @蚁工厂](https://weibo.com/2194035935/ME2nLyMZC)

Note: replit的博文《How to train your own Large Language Models》如何训练自己的大语言模型网址：blog.replit.com/llm-training讲述了它们是为什么以及如何训练自己的大语言模型的。另外这家公司刚用10天时间训练完成了自己的用于代码生成的大语言模型replit-code-v1-3b （将会开源但现在还没开源） replit是好东西啊，平板或者老爷机写代码神器，不用配环境，开箱即用，基本ide功能都有，还能开在线web应用demo  

Picture: [82c654dfly1hdf4nhkrtoj21cg0sogxn.jpg](https://weibo.cn//mblog/pic/ME2nLyMZC?rl=1)

#### [电子书《深入分析Linux内核源码》 本书共分13章，对Linux 内核2.4版的源代码进行了较全面 @蚁工厂](https://weibo.com/2194035935/ME5fogwzA)

Note: 电子书《深入分析Linux内核源码》 本书共分13章，对Linux 内核2.4版的源代码进行了较全面的分析，既包括对中断机制、进程调度、内存管理、进程间通信、虚拟文件系统、设备驱动程序及网络子系统的分析，也包括对Linux 整体结构的把握、Linux的启动过程的分析及Linux独具特色的模块机制的分析与应用等。其中重点剖析了Linux内核中最基础的部分：进程管理、内存管理及文件管理。 本书对于那些准备进入Linux 操作系统内部，阅读Linux 内核源代码以及在内核级进行程序开发的读者具有非常高的参考价值。同时，操作系统实现者、系统程序员、Linux应用开发人员、嵌入式系统开发人员、系统管理员、在校的大学生和研究生及对Linux感兴趣的用户均可在阅读本书中受益。作者陈莉君老师二十多年来专注Linux内核研究，业余时间主办的Linux内核之旅网站，为Linux爱好者默默提供着无私的帮助，值得一提的是，把自己2002年撰写的《深入分析Linux内核源代码》一书，因为绝版而全文公布于网络，这为嵌入式开发者和Linux内核爱好者提供了触手可得的资料。电子书《深入分析Linux内核源码》

Picture: [82c654dfly1h1p9g2dz9nj20hq114tda.jpg](https://weibo.cn//mblog/pic/LqyeRDVjx?rl=1)

#### [ 看完这篇后，搞懂了 wasm 。  @incanation2038](https://weibo.com/6134470959/ME5AfFMgS)

Note:  看完这篇后，搞懂了 wasm 。 

#### [吴恩达和OpenAI携手推出了一门免费的Prompt Engineering（提示工程师）课程，旨在 @宝玉xp](https://weibo.com/1727858283/ME82vtd2g)

Note: 吴恩达和OpenAI携手推出了一门免费的Prompt Engineering（提示工程师）课程，旨在为AI开发者们提供一个全面而深入的学习平台。该课程内容涵盖了如何书写高质量的AI提示词，以及如何利用GPT-3的先进技术开发一个高效、智能的AI聊天机器人。无论你是初学者还是经验丰富的专业人士，该课程都将为你提供一种系统而有效的学习方法。课程地址： 网友歸藏（twitter.com/op7418）翻译了双语字幕：回复: 谢谢提醒，不过图不重要，链接在原始微博东西没啥新东西但小姐姐的声音真好听图挂了官方字幕配上沉浸翻译插件已经体验很好了主要针对开发者，看得迷糊

#### [这是个ChatGPT的插件，可以让你针对某个YouTube视频进行摘要或者对话 ，最好的地方在于它能 @宝玉xp](https://weibo.com/1727858283/ME9NZtAiu)

Note: 这是个ChatGPT的插件，可以让你针对某个YouTube视频进行摘要或者对话 ，最好的地方在于它能把结果和时间轴关联起来。我猜它事先需要对视频的字幕做Embedding，否则做不到这么好的效果。可惜我还没有ChatGPT插件访问权限，无法测试。🐦twitter.com/ykdojo/status/1645300576043794432🐦 回复:插件权限可太难了我连openAI api的访问权限都没有鲍鱼真是好博主宝玉真的是一个宝藏博主[666] 从大前端到Generic AI

#### [推荐几个“吴恩达Prompt Engineering课程  ”的学习笔记📒 边学边试变分享 Andr @宝玉xp](https://weibo.com/1727858283/MEa09zhK3)

Note: 推荐几个“吴恩达Prompt Engineering课程  ”的学习笔记📒 边学边试变分享 Andrew Ng 开了公开课 by balconychy （twitter.com/balconychy）🐦twitter.com/balconychy/status/1651763099064762368🐦🐦twitter.com/balconychy/status/1651771049930010625🐦📒【笔记】跟吴恩达和IsaFulford学提示词工程（初级开发者入门课程） by EricKung （twitter.com/GongCen） 📒 prompt 原则和具体策略脑图 by AlexZ 🦀（twitter.com/blackanger）🐦twitter.com/blackanger/status/1651825435049865216🐦这种学习后分享的方式挺好的👍🏻最近也在看 马克 转发微博回复:这个课是免费的好吧定界符如"""，是连续三个双引号开始，又连续三个双引号结束？回复:韭菜太多了回复:90年代打字课可是潮流来着

Picture: [66fd066bgy1hdg26twc9wj225g17o4pz.jpg](https://weibo.cn//mblog/pic/MEa09zhK3?rl=1)

#### [LaMini-LM🦙这个项目挺牛的，它对一堆（目前15个）迷你大语言模型进行了微调，这些模型最大的只 @宝玉xp](https://weibo.com/1727858283/MEbAeytXB)

Note: LaMini-LM🦙这个项目挺牛的，它对一堆（目前15个）迷你大语言模型进行了微调，这些模型最大的只有1.5B参数，调出来后的性能非常好，其中GPT-2微调后的性能媲美前不久刚开源的LLaMa的Alpaca-7B。一些局限性：- 可能从ChatGPT中继承偏见和错误。- 有时会产生错觉。- 编程和数学能力不佳。- 难以处理复杂指令。- 不适用于多轮对话。模型和数据仅供研究使用。BTW：GPT-2是完全开源的，感觉基于它微调也可以做不少事情。论文：项目首页：🔗github.com/mbzuai-nlp/LaMini-LM🐱最近一直在挑选能用于高效实现私有部署智能客服的项目，在博主这儿收集到的内容都装满收藏夹了，得抽空找个时间慢慢消化整理了emerge abilities需要注意的是，先不谈涌现的能力，大模型的知识是融合在模型里面的，Size下降到一定程度，基本上就只能做专用Domain的智能问答了，缺乏通用领域的能力了回复:ChatGlm有没有大佬知道，支持本地部署，支持中文问答的开源项目啊谢谢分享

Picture: [66fd066bgy1hdg8ww3xi7j20tc0prqbo.jpg](https://weibo.cn//mblog/pic/MEbAeytXB?rl=1)

Github: [github.com/mbzuai-nlp/LaMini-LM](github.com/mbzuai-nlp/LaMini-LM)

#### [Pipeline MoE: A Flexible MoE Implementation with P @AMiner学术头条](https://weibo.com/1870858943/MDCQUfuqc)

Note: Pipeline MoE: A Flexible MoE Implementation with Pipeline Parallelism AI综述：本文针对现有Mixture of Experts (MoE)模型存在的内部节点和节点间通信开销大、骨干平行计算能力有限等问题进行了分析，并提出了一个新的MoE架构--Pipeline MoE (PPMoE)以解决这些问题。PPMoE不仅可以方便地与管道并行一起扩展骨干，而且与现有MoE架构相比，其速度提高了1.75倍以上，并且其吞吐量达到相应骨干模型的90%。

Picture: [6f830abfly1hdbzy2v7b7j20q60f210i.jpg](https://weibo.cn//mblog/pic/MDCQUfuqc?rl=1)

#### [Speed Is All You Need: On-Device Acceleration of L @AMiner学术头条](https://weibo.com/1870858943/MDCXe76pS)

Note: Speed Is All You Need: On-Device Acceleration of Large Diffusion Models via GPU-Aware Optimizations AI综述：本文介绍了如何通过对大型扩散模型的优化，在GPU设备上实现更快的推断速度，从而实现在设备上部署这些模型的优势。这些模型包含超过10亿个参数，因其对计算和内存资源的限制而带来挑战。本文提供了一些适用于大型扩散模型的实现优化，使其在配备GPU的移动设备上实现最快报告推断延迟，从而扩大了生成性AI的适用性，提高了各种设备的整体用户体验。

Picture: [6f830abfly1hdc0ea24hgj20rf0v0wt7.jpg](https://weibo.cn//mblog/pic/MDCXe76pS?rl=1)

#### [Patch Diffusion: Faster and More Data-Efficient Tr @AMiner学术头条](https://weibo.com/1870858943/MDLO4k7k8)

Note: Patch Diffusion: Faster and More Data-Efficient Training of Diffusion Models AI综述：文章介绍了一个通用的 Patch Diffusion 训练框架，可以在降低训练时间成本的同时提高数据效率，并帮助更广泛的用户进行扩散模型的训练。通过此方法，可以实现至少2倍的快速训练，同时维持相当或更好的生成质量，并提高对相对较小数据集的扩散模型的性能。文章介绍了 Patch Diffusion 的核心创新和实验结果。

Picture: [6f830abfly1hdd3h6weznj20n70jh0y1.jpg](https://weibo.cn//mblog/pic/MDLO4k7k8?rl=1)

#### [Unleashing Infinite-Length Input Capacity for Larg @AMiner学术头条](https://weibo.com/1870858943/MDVe7aaTO)

Note: Unleashing Infinite-Length Input Capacity for Large-scale Language Models with Self-Controlled Memory System AI综述：该论文介绍了一种名为Self-Controlled Memory (SCM)的系统，可以解除语言模型处理长文本输入的长度限制，从而使得它们能够处理超长的文本输入，并且不需要任何修改或微调。该系统由三个关键模块组成，分别是语言模型代理、存储空间和内存控制器。内存控制器提供长期内存和短期内存，以生成精确和连贯的响应。该系统可以与任何大规模的语言模型集成，使其能够处理超长的文本，并能够在多轮对话、长期会话和文档摘要等场景中表现出色。论文还提供了一个测试集，用于评估语言模型在处理长文本时的能力。

Picture: [6f830abfly1hde927bh3sj21cc0ny12a.jpg](https://weibo.cn//mblog/pic/MDVe7aaTO?rl=1)

#### [《性能之巅 第2版》读书笔记（第9章上）1、在高负载情况下，磁盘通常成为系统的瓶颈，导致CPU持续等 @小川CD](https://weibo.com/1202332555/MDFhh389E)

Note: 《性能之巅 第2版》读书笔记（第9章上）1、在高负载情况下，磁盘通常成为系统的瓶颈，导致CPU持续等待磁盘IO完成。消除这些瓶颈可以显著提高系统性能和应用程序吞吐量。2、IO请求时间也称为IO响应时间，是指从发出一条IO请求到完成的时间。IO等待时间是指IO在队列中等待服务的时间。IO服务时间是指IO得到处理的时间（不包括等待时间）。3、从内核的角度看，块IO请求时间是指块IO等待时间和块IO服务时间之和，即从创建IO请求到它完成的完整时间。4、从磁盘的角度看，磁盘请求时间（也称为磁盘响应时间或磁盘IO延迟）是指磁盘等待时间和磁盘服务时间之和，等同于块IO服务时间。块IO服务时间通常作为衡量当前磁盘性能的标准。5、磁盘服务时间通常无法直接从内核统计数据中观测得出，但平均磁盘服务时间可以通过IOPS和使用率计算得出。磁盘服务时间=使用率/IOPS。6、磁盘IO的时间尺度变化很大，从几十微秒到数千毫秒不等。最慢的IO可能会导致应用程序响应时间变得糟糕，而只有在IO数量很大的情况下，最快的一端性能才会受到影响。7、对于从事企业存储领域工作的人来说，磁盘IO延时超过10毫秒就可能意味着性能问题的存在。8、根据磁盘IO的相对位置（磁盘偏移量），可以用“随机”和“连续”来描述磁盘IO负载。其中，“连续”负载也被称为“流式”负载。在旋转磁盘中，识别和减少随机IO是性能调优的重点。9、对于一个读频率较高的系统，可以通过增加缓存来提高性能，而对于一个写频率较高的系统，则可以通过增加磁盘数量来提高最大吞吐量和IOPS。10、通常而言，较大的IO请求可以提供更高的吞吐量，但单位IO请求的延迟会相应地增加。对于闪存设备，不同的读写请求大小表现出非常不同的行为。通常情况下，4K读和1MB写请求的性能表现最佳。理想的IO请求大小可以查阅磁盘供应商的文档，或通过微基准测试来确定。11、一个包含随机请求的工作负载通常会对延迟非常敏感，因此高IOPS是非常有价值的。相反，流式（顺序）负载对于吞吐量非常敏感，因此降低IOPS以增加每个IO请求的大小反而会更有利。12、100%的磁盘使用率可能是性能瓶颈的根本原因，特别是在一段时间内持续保持100%。然而，任何磁盘使用率都有可能导致性能不佳，因为磁盘IO是一个相对缓慢的操作。13、在0%和100%之间的某个点（例如60%），磁盘的性能可能会受到影响，因为这会增加磁盘队列或操作系统排队的可能性。一旦一个磁盘的使用率达到100%，再向其发出更多IO请求只会使磁盘达到饱和状态。14、较高的每CPU等待时间表明磁盘可能是瓶颈，导致CPU等待而处于空闲状态。更可靠的指标可能是应用程序线程在等待磁盘IO时所阻塞的时间。15、电梯算法是一种提高命令效率的技术，也称为电梯寻道。该算法通过重新排序IO请求，以最小化磁头的移动距离，从而提高磁盘的读写效率。16、磁盘通过扇区尾部的ECC码进行数据纠错，但如果数据错误，则磁头可能需要等待下一次旋转到相同位置再次读取数据，这可能是IO异常缓慢的原因。17、在调查一个性能问题时，我模拟了一个振动实验，对着一组磁盘阵列大声喊叫。但当时，阵列正在进行一个写入基准测试，结果导致IO突然变得非常缓慢。18、目前存在一类旋转磁盘的性能问题，被称为“怠工磁盘”。这些磁盘有时会返回非常慢的IO，超过1秒，但不会报告任何错误。19、基于闪存的SSD读性能非常出色，尤其是随机读性能比旋转磁盘高几个数量级。但SSD也可能存在一些问题，例如老化导致的时延离群点、碎片化导致的高延迟、以及SSD内部压缩造成的低吞吐量等。20、NVME的一个优势是支持多个硬件队列。这些队列可以从同一个CPU中使用，以进行缓存预热。在Linux多队列的支持下，还可以避免共享内核锁带来的性能损失。

#### [电子书《基本算法》（实体书叫算法新解），作者刘新宇。地址：github.com/liuxinyu95 @数据派THU](https://weibo.com/6004911042/MDdcmB0hL)

Note: 电子书《基本算法》（实体书叫算法新解），作者刘新宇。地址：github.com/liuxinyu95/AlgoXY之前介绍过，现在作者还在持续更新，现在是2.718283版。有中英文版。本书介绍常见的基本算法和数据结构，同时给出函数式和命令式的对比实现。主要参考了冈崎的著作和经典的算法教材。本书尽量避免依赖于特定的编程语言。一方面读者会有自己的偏好，另一方面编程语言也在不断变化。为此我们主要使用伪代码和数学记法对算法进行定义，并附以一些例子代码。函数式的示例类似 Haskell，命令式的示例是几种语言的混合体。

Picture: [82c654dfly1hd8b2cb3u0j21531lmtcl.jpg](https://weibo.cn//mblog/pic/MD8MI0bVY?rl=1)

Github: [github.com/liuxinyu95/AlgoXY](github.com/liuxinyu95/AlgoXY)

#### [【收集自动驾驶领域最新的 End-to-End 方法研究论文】'Awesome End-to-End @爱可可-爱生活](https://weibo.com/1402400261/MEerViSTv)

Note: 【收集自动驾驶领域最新的 End-to-End 方法研究论文】'Awesome End-to-End Autonomous Driving - A curated list of awesome End-to-End Autonomous Driving resources (continually updated)' OpenDILab GitHub: github.com/opendilab/awesome-end-to-end-autonomous-driving   

Picture: [5396ee05ly8hdglvqjkx5j20vq0u0ju1.jpg](https://weibo.cn//mblog/pic/MEerViSTv?rl=1)

Github: [github.com/opendilab/awesome-end-to-end-autonomous-driving](github.com/opendilab/awesome-end-to-end-autonomous-driving)

#### [【GAOKAO-bench：以中国高考题目作为数据集，评估大语言模型的语言理解能力和逻辑推理能力的测 @爱可可-爱生活](https://weibo.com/1402400261/MEeSk3Uq9)

Note: 【GAOKAO-bench：以中国高考题目作为数据集，评估大语言模型的语言理解能力和逻辑推理能力的测评框架，包含1781道选择题、218道填空题和812道解答题】'GAOKAO-bench - GAOKAO-bench is an evaluation framework that utilizes GAOKAO questions as a dataset to evaluate large language models.' OpenLMLab GitHub: github.com/OpenLMLab/GAOKAO-Bench  没学过人工智能，现在学来得及吗？我给公考试卷也训练训练gpt4听说能上211，不知道这个模型啥水平这是要干嘛，这是要上天的节奏呀

Picture: [5396ee05ly8hdgnqq6m56j20u00wun1v.jpg](https://weibo.cn//mblog/pic/MEeSk3Uq9?rl=1)

Github: [github.com/OpenLMLab/GAOKAO-Bench](github.com/OpenLMLab/GAOKAO-Bench)

#### [[CV]《Patch Diffusion: Faster and More Data-Efficie @爱可可-爱生活](https://weibo.com/1402400261/MEjznqRLm)

Note: [CV]《Patch Diffusion: Faster and More Data-Efficient Training of Diffusion Models》Z Wang, Y Jiang, H Zheng, P Wang, P He, Z Wang, W Chen, M Zhou [The University of Texas at Austin & icrosoft Azure AI] (2023)   

Picture: [5396ee05ly1hdh8ine7c7j217c0oanbq.jpg](https://weibo.cn//mblog/pic/MEjzhzxfn?rl=1)

#### [【The 22 Articles that Impacted my Career the most】 @网路冷眼](https://weibo.com/1715118170/MEmsPAxJj)

Note: 【The 22 Articles that Impacted my Career the most】🔗 typefully.com/thiagoghisi/the-22-articles-that-impacted-my-career-in-tech-1snkXtE 对我职业生涯影响最大的 22 篇文章。 

Picture: [663aa05aly8hdhlba3304j20xw0u0dle.jpg](https://weibo.cn//mblog/pic/MEmsPAxJj?rl=1)

#### [电子书《Git权威指南》本书正文共分为8篇，一共41章，还包括附录。第1篇是Git的概览，共3章。第 @蚁工厂](https://weibo.com/2194035935/MEcHcgo4M)

Note: 电子书《Git权威指南》本书正文共分为8篇，一共41章，还包括附录。第1篇是Git的概览，共3章。第1章介绍了版本控制的历史。第2章用10来个小例子介绍了Git的一些闪亮特性，期待这些特性能够让您爱上Git。第3章则介绍Git在三种主要的平台上的安装和使用。本书的写作过程中，70%的时间使用的是Debian Linux操作系统，Linux用户可以毫无障碍地完成本书列举的所有相关操作。在2010年年底，当得知有出版社肯以稿酬支持本书的首印后，我向妻子阿巧预支了未来的部分稿费购买了我的第一台MacBook Pro，于是本书就有了较为详实的Mac OS X下Git的安装和使用，以及在本书第4篇第22章介绍的Topgit在Mac OS X上的部署和改进。在本书的编辑和校对过程中因为要使用Word格式的文稿，所以本书后期的很多工作是在运行于VirtualBox下的Windows虚拟机中完成的，即使是使用运行于资源受限的虚拟机中的Cygwin，Git依然完美地完成了工作。第2篇和第3篇详细介绍了Git的基本操作，是本书的基础和核心，篇幅大约占据了全书的40%。这两篇的内容架构实际上是我在进行SVN培训时就已经形成的习惯，即以“独奏”指代一个人的版本控制所要讲述的知识点，以“和声”指代团队版本控制涉及的话题。在第2篇“Git独奏”中将Git的设计原理穿插在各章之中，因为唯有了解 真相（Git原理），才有可能自由（掌握Git）。在第3篇“Git和声”中，介绍团队版本控制必须掌握的里程碑和分支等概念，以及如何解决合并中遇到的冲突。第4篇细致地讲解了在实际的工作中Git的使用模式。除了传统的集中式和分布式使用模式之外，第22章还介绍了Topgit在定制开发中的应用，这也是我公司使用Git最主要的模式。这一章还讲解了我对Topgit所做的部分改进，对相关改进的介绍最 早出现在我公司的博客上[4]。第23-25章介绍了多版本库协同的不同方法，其中第25章介绍的一个独辟蹊径的解决方案是由Android项目引入的名为repo的工具实现的，我对其进行的改造可以让这个工具能够脱离Gerrit代码审核服务器，直接操作Git服务器。第26章介绍了git-svn这一工具，该工具不但可以实现SVN版本库到Git版本库的迁移，还可以实现将Git作为客户端向SVN提交。第5篇介绍Git服务器的架设。本篇是全书最早开始撰写的部分，这是因为我给客户做的Git培训讲义的相关部分不够详细，应客户要求对Gitolite等服务器架设撰写了详细的管理员手册，即本书的第30章。第32章介绍了Android项目在Git管理上的又一大创造，即Gerrit，它实现了一个独特的集中式Git版本库管理模型。第6篇讲解了Git版本库的迁移。其中第34章详细介绍了CVS版本库到Git版本库的迁移，其迁移过程也可以作为CVS到SVN迁移的借鉴。本篇还介绍了SVN和Hg版本库到Git的迁移。对于其他类型的版本库，介绍了一个通用的需要编程来实现的方法。在本篇的最后还介绍了一个Git版本库整理的利器，可以理解为一个Git库转换为另外一个Git库的方法。第7篇是关于Git的其他应用，其主要部分是介绍我在etckeeper启发下开发的一款备份工具Gistore，该工具可以运行于Linux和Mac OS X下。第8篇是Git杂谈。其中第40章的内容可供跨平台的项目组借鉴。第41章介绍了一些前面没有涉及的Git相关功能和特性，缺少这些相关内容会有损于杨福川编辑为本书所取的宏大的书名。第9篇是附录。首先介绍了完整的Git命令索引，然后分别介绍了CVS、SVN、Hg与Git之间的比较和命令对照，对于有着其他版本控制系统使用经验的用户，这一部分可供参考。

#### [能否正确的消除歧义是衡量大语言模型的一个重要指标。不过一直没有一个标准化的衡量方法，这篇论文提出了一 @蚁工厂](https://weibo.com/2194035935/MEem0ENje)

Note: 能否正确的消除歧义是衡量大语言模型的一个重要指标。不过一直没有一个标准化的衡量方法，这篇论文提出了一个包含1,645个具有不同种类歧义的数据集及对应的评估方法。论文：arxiv.org/abs/2304.14399数据集下载：github.com/alisawuffles/ambient 👍

Picture: [82c654dfly1hdglibgif2j21210pvk2o.jpg](https://weibo.cn//mblog/pic/MEem0ENje?rl=1)

Github: [github.com/alisawuffles/ambient](github.com/alisawuffles/ambient)

#### [WingetUI 是一款开源的包管理工具，通过 WingetUI 可以：查找、安装、更新、卸载来自不 @蚁工厂](https://weibo.com/2194035935/MEfxb5NJI)

Note: WingetUI 是一款开源的包管理工具，通过 WingetUI 可以：查找、安装、更新、卸载来自不同包管理器的应用。支持 Winget, Scoop, Chocolatey 这些包管理器。WingetUI 下载地址见评论~~~~ 

Picture: [bb254ec3gy1hdgqf14ucqj21hc0u0nde.jpg](https://weibo.cn//mblog/pic/MEftnuL2l?rl=1)

#### [《知道创宇研发技能表》地址：github.com/knownsec/RD_Checklist几年前很 @蚁工厂](https://weibo.com/2194035935/MEge5nsuW)

Note: 《知道创宇研发技能表》地址：github.com/knownsec/RD_Checklist几年前很有名的一个文档。知道创宇是一个安全公司。本文档前半部分是通用技能（包括做事的方法、态度、职场经验等），后半部分是安全相关的专业技能。 被墙了…… 淦

Picture: [82c654dfly1h1qjearilqj20u019844u.jpg](https://weibo.cn//mblog/pic/LqGOB9MYS?rl=1)

Github: [github.com/knownsec/RD_Checklist](github.com/knownsec/RD_Checklist)

#### [🚀🚀🚀本组Xinyi Wang关于大语言模型的概率总结Understanding Pre-train @蚁工厂](https://weibo.com/2194035935/MElrJnhn2)

Note: 🚀🚀🚀本组Xinyi Wang关于大语言模型的概率总结Understanding Pre-trained Large Language Models through Probabilistic Lens：非常详尽的LLM科学解释和总结 

Picture: [62caff97gy1hdhbm9iaevj20t90wyq80.jpg](https://weibo.cn//mblog/pic/MEkhxddxu?rl=1)

#### [一本册子《数据科学和机器学习》本文辑录了作者llinjupt 在学习科学计算和机器学习过程中的总结， @蚁工厂](https://weibo.com/2194035935/MElCBm75K)

Note: 一本册子《数据科学和机器学习》本文辑录了作者llinjupt 在学习科学计算和机器学习过程中的总结，归纳，从基础数学和模型理论到实际编码和问题解决以及优化过程。它也很好的呈现了学习数据处理和机器学习从理论到解决实际问题再到依据实际情况进行优化细调的阶梯过程。放在这里方便笔者和他人学习和参考。文档中大部分示例使用 Anaconda 集成科学计算环境，并基于 Python3.4 版本完成，当示例结果与系统平台相关时，通常会提供 Linux 和 Windows 两个版本的输出结果。回复:早

Picture: [82c654dfly1h1qkf63kjuj20b60vmdgu.jpg](https://weibo.cn//mblog/pic/LqNTMphxz?rl=1)

#### [  @AINLP](https://weibo.com/2703427641/MEmrxvRpz)

#### [刚听了硅谷101一集播客《E107｜AI大爆发：OpenAI极早期历史 ，以及图像领域的GPT mo @宝玉xp](https://weibo.com/1727858283/MEtmDlTtT)

Note: 刚听了硅谷101一集播客《E107｜AI大爆发：OpenAI极早期历史 ，以及图像领域的GPT moment｜AIGC特辑》，这期采访的是大牛Jim Fan，原来他是OpenAI第一届的实习生。16年的时候，Transformer之前OpenAI就开始做预测句子后面的单词的方式来训练神经网络，只是那时候基于的是回馈式神经网络，有了GPT的影子。Transformer发表后，当时Transformer有两部分，Encoder和Decoder，由于之前已经做过单词预测方面的尝试，所以GPT只选取了其中Decoder的部分，因为Decoder的训练原理就是不断的预测下一个单词。16年的时候，Alec Radford也提出了要用大文本数据训练，比如Reddit论坛的数据，而不仅仅是维基百科的数据，一个可能的原因是由于Reddit的数据更接地气，带有用户的各种情感，像喜怒哀乐什么的，这样GPT生成的结果会更生动而不会那么枯燥。GPT2的时候，GPT已经有了一些涌现的智能，比如多任务什么的会处理的特别好，还有微调也做的很好。这可能促使了OpenAI下定决定采用大算力大数据训练出了GPT3。完整可以直接听播客：字幕：lark的如下 字幕需要send request，让人很意外的是，lark的speech to text准确度，比google的要强不少啊 回复:谢谢指正不是接地气看下原论文里面说的是质量更高，里面有个类似“点赞数”这种的指标可以筛选高质量问答推荐这个播客

#### [【Newsletter on Latest Engineering Blogs from diffe @网路冷眼](https://weibo.com/1715118170/MEujMpgsm)

Note: 【Newsletter on Latest Engineering Blogs from different IT companies】🔗 techblogsearch.substack.com/p/20230423-latest-engineering-blogs 来自不同 IT 公司的最新工程博客通讯。 

#### [[CL]《Boosting Theory-of-Mind Performance in Large  @爱可可-爱生活](https://weibo.com/1402400261/MEvF7zP8s)

Note: [CL]《Boosting Theory-of-Mind Performance in Large Language Models via Prompting》S R Moghaddam, C J. Honey [Johns Hopkins University] (2023)   

Picture: [5396ee05gy1hdign2561kj21r60s67pq.jpg](https://weibo.cn//mblog/pic/MEtAW7cec?rl=1)

#### [推荐一款开源的数据可视化分析神器：DataEase，操作简单易上手，开箱即用。该工具拥有多种丰富美观 @GitHubDaily](https://weibo.com/5722964389/MCPoKEzsE)

Note: 推荐一款开源的数据可视化分析神器：DataEase，操作简单易上手，开箱即用。该工具拥有多种丰富美观的图表展示、图表制作、数据引擎等功能。支持多种数据源连接，通过拖拉拽即可快速制作图表，并与他人分享。你可以用它来快速分析数据并洞察业务趋势，从而实现业务的改进与优化。GitHub：github.com/dataease/dataease除此之外，DataEase 还搭建了一个模板市场，里面的模板种类涵盖了多个使用场景和行业领域，用户不用自己费心设计就可以做出漂亮的大屏。“模板市场” 功能板块被内嵌在 DataEase 的操作界面中，用户选择模板就能直接应用，一键切换到自己的数据集，快速生成各种酷炫的可视化大屏。转发微博repost 经典的可视化大屏回复:echarts和antv转发微博图表实现是用的echarts？还有模板市场这实在太贴心了

Picture: [006fiYtfgy1hd5554m3ivj32801e0qv7.jpg](https://weibo.cn//mblog/pic/MCPoKEzsE?rl=1)

Github: [github.com/dataease/dataease](github.com/dataease/dataease)

#### [最近，一篇名为《Scaling Transformer to 1M tokens and beyon @GitHubDaily](https://weibo.com/5722964389/MDDDnnyHX)

Note: 最近，一篇名为《Scaling Transformer to 1M tokens and beyond with RMT》在技术圈引发热议。该论文提出一种名为 RMT 的新技术，或许可将 Transform 的 Token 上限扩展至 100 万，甚至更多。要知道，目前最强的 GPT-4-32k，其 Token 上限也才 3.2 万，这就导致了它并不能很好的处理长文内容。像文档、书籍、代码这种大块内容，往往需要先对内容进行切割，分多次喂给 GPT，但 GPT 本身能理解的上下文内容有限，这就很容易导致结果偏离预期。如果未来 Token 的上限能够不断突破，将会创造出更多 AI 应用场景。包括之前大家经常畅想的，训练一个无限接近自己人格的 AI 聊天机器人。论文：arxiv.org/abs/2304.11062要是你觉得这些技术名词比较晦涩难懂，也可以读一下 Twitter 网友 riddhi 让 ChatGPT 做的这个总结，通俗易懂的解读了这项技术：假设你有个很聪明的机器人朋友，它可以读很多东西并记住它们。这个机器人朋友使用一种叫做 “Transformer” 的东西来帮助它理解和记忆内容，就像人类大脑一样。现在有这么一群聪明人，发现了一种能让你的机器人朋友变得更好的方法，那就是给它装上一个新大脑，叫做“Recurrent Memory Transformer”，或者简称“RMT”。有了这个新大脑，机器人朋友就可以记住和理解更多的东西，一次多达 2 百万个字！这相当于它可以同时记住大约 20 本很长的书的内容。在这之前，其他聪明的机器人只能记住最多 6.4 万个字，虽然这已经很多了，但还远不及 2 百万个字。这个发现非常重要，因为这意味着我们的机器人朋友现在可以理解和谈论更多的事情，为我们提供更多的帮助。最棒的是，这种新大脑不会让机器人变得更重或者耗费更多的能量。所以这就像一台拥有超能力的机器人朋友，可以做很多厉害的事情并且不会累！Twitter：twitter.com/ridtalkstech/status/1650316114935828481我只是个外行人，从这个数量对比上来看，采用这种方法进行训练是不是会算力消耗是之前非常恐怖的倍数？这个概念很像人脑工作记忆空间哈哈“新大脑”回复:好家伙，魔法！回复:没理解错的话，这个不需要训练模型，只是说能够一次性发送上百万个单词给 ChatGPT，然后 ChatGPT 都能理解，之前我们最多只能发送两三千个单词给 ChatGPT我只是个外行人，从这个数量对比上来看，采用这种方法进行训练是不是会算力消耗是之前非常恐怖的倍数？“新大脑”可以用于现行的各类开源大语言模型架构吗转发微博这个是bert的，不是gpt架构这个概念很像人脑工作记忆空间哈哈不就是 RNN 吗？RMT = Reimu Maji Tenshi！

Picture: [006fiYtfgy1hdc2ktv13lj30xc0tothg.jpg](https://weibo.cn//mblog/pic/MDDDnnyHX?rl=1)

#### [今天花了一天时间，将《ChatGPT 提示工程》视频教程的所有字幕都翻译完了。该教程由吴恩达老师与  @GitHubDaily](https://weibo.com/5722964389/MEhkq7gXG)

Note: 今天花了一天时间，将《ChatGPT 提示工程》视频教程的所有字幕都翻译完了。该教程由吴恩达老师与 OpenAI 开发者 Iza Fulford 联手教授。教程总共分为 9 个章节，时长一个多小时，里面主要涵盖：提示词最佳实践、评论情感分类、文本总结、邮件撰写、文本翻译、快速搭建一个聊天机器人等等。所有当下 ChatGPT 的流行案例，你都能在这个教程里面找到，十分全面！除了能在这个教程里面学到如何使用 Prompt，你还能学到 GPT 接口调用开发知识。有需要的话，你甚至能在这个教程之上去延伸扩展，搭建出一款令人惊艳的应用。目前该教程已经在 DeepLearning.ai 正式上线，官网上提供了可交互式的 Notebook，让你可以一边学习，一边跟着编写代码实践。不过当下该教程只有英文版，为了让看不懂英文的同学也能第一时间学习并掌握这项技术，我完整翻译了所有英文字幕，并且将所有视频与字幕同步上传到了 B 站。中文视频：英文视频：该视频的中英文字幕源文件，我也将其开源到了 GitHub 上。如果你在观看视频的过程中，发现翻译内容有错漏、错别字、病句等情况，欢迎向我们提交 Pull Request 以改进字幕翻译质量。字幕地址：github.com/GitHubDaily/ChatGPT-Prompt-Engineering-for-Developers-in-Chinese   //:博主功德无量！谢谢[老师好][老师好][老师好][老师好][老师好][老师好]赞！B站已关注请教下如何快速翻译的，用的什么工具感谢！赞 * 1000000000000好厉害 感恩博主学不完了 功德+谢谢谢谢

Github: [github.com/GitHubDaily/ChatGPT-Prompt-Engineering-for-Developers-in-Chinese](github.com/GitHubDaily/ChatGPT-Prompt-Engineering-for-Developers-in-Chinese)

#### [和Yukuo、Yuxiao一起在WWW 2023上做了一个关于自监督学习和预训练图神经网络的Tuto @梁斌penny](https://weibo.com/1497035431/MEM9ZA7lq)

Note: 和Yukuo、Yuxiao一起在WWW 2023上做了一个关于自监督学习和预训练图神经网络的Tutorial：Self-supervised Learning and Pre-training on Graphs (GNNs)，ppt放到主页了，希望对大家有用。 

Picture: [7ebeb44bgy1hdkqi5f1l5j21qi0y44qp.jpg](https://weibo.cn//mblog/pic/MEM6Ott66?rl=1)

#### [技术博客《一分钟读论文》地址：unbug.github.io/Learn a paper in a  @蚁工厂](https://weibo.com/2194035935/MEy8Y69Vp)

Note: 技术博客《一分钟读论文》地址：unbug.github.io/Learn a paper in a minute. 一分钟读懂一篇论文。把论文当成精神食粮，用学术重塑思维。一般为软件、安全方面的论文 三分天注定，七分靠私信。玉婷姐是你股市里最好的选择。给的·剑桥科技·连吃三个涨停。我是亲身见证到玉婷姐的实力了三分天注定，七分靠私信。玉婷姐是你股市里最好的选择。给的·剑桥科技·连吃三个涨停。我是亲身见证到玉婷姐的实力了囫囵吞枣

Picture: [82c654dfly1hdj0tqrasbj20ma1l5qg8.jpg](https://weibo.cn//mblog/pic/MEy8Y69Vp?rl=1)

#### [推荐阅读：《Building an AI-powered ChatBot using Vercel, @宝玉xp](https://weibo.com/1727858283/MEO8NttcS)

Note: 推荐阅读：《Building an AI-powered ChatBot using Vercel, OpenAI, and Postgres》使用Vercel，OpenAI和Postgres搭建AI聊天机器人。背后的原理还是Embedding、向量查找、GPT总结回复，如果你已经很熟悉可以跳过，要不熟悉还是值得看看。https://neon.tech/blog/building-an-ai-powered-chatbot-using-vercel-openai-and-postgres🔗neon.tech/blog/building-an-ai-powered-chatbot-using-vercel-openai-and-postgres🔗回复:我自己也打不开，编辑的时候发现链接没问题，然后把原始链接重新贴了一遍我知道了，有时候你给的连接不能打开，单纯是渣浪转换出问题。刚才第一次出404，第二次点又能打开了。

#### [卧槽，Replit发布了他们训练好的编程LLM模型replit-code-v1-3b，是BY-SA  @宝玉xp](https://weibo.com/1727858283/MEODjbMXq)

Note: 卧槽，Replit发布了他们训练好的编程LLM模型replit-code-v1-3b，是BY-SA 4.0授权发布，这意味着允许商业使用！🤗地址：另外对于他们是怎么训练大模型的可以参考这篇文章：《如何训练你自己的大型语言模型》必须得cc一下CSDN的朋友们，赶紧用上造福国内程序员们！  不太懂，意味着什么有没有试过的，这个模型怎么样？huggingface的地址打不开了？csdn跟造福国内没什么关系可以去replit官方开个项目测试模型的效果有没有试过的，这个模型怎么样？回复: 可以huggingface的地址打不开了？还有段子说国内大量公司搞大模型，国外只有几个大公司搞呢，国外光开源的就很多啊回复:看不懂+1

#### [基于MultiDiffusion  把整个清明上河图生成真实照片质感的全景图完整大图见最后一张！文件 @宝玉xp](https://weibo.com/1727858283/MEOrbdtsD)

Note: 基于MultiDiffusion  把整个清明上河图生成真实照片质感的全景图完整大图见最后一张！文件来源：github.com/pkuliyi2015/multidiffusion-img-demo 非常酷炫！美中不足就是和水面相关的错误有点多好真实整体看上去还是很震撼的，但是细节部分，还是有一些错误的。中国元素方面确实不够，不知道是不是墙的问题导致外面的人也拿不到国内的资源~~美中不足的是人脸都像被旋过好真实整体看上去还是很震撼的，但是细节部分，还是有一些错误的。中国元素方面确实不够，不知道是不是墙的问题导致外面的人也拿不到国内的资源~~真美用好AI，太帅了。。光线光影的照射方向也有问题🆒回复:有点像照片耶！清晰度好高，人脸部分还是有点怪ai的清明上河图

Picture: [66fd066bgy1hdl0qcia1cj226212kx6r.jpg](https://weibo.cn//mblog/pic/MEOrbdtsD?rl=1)

Github: [github.com/pkuliyi2015/multidiffusion-img-demo](github.com/pkuliyi2015/multidiffusion-img-demo)

#### [《Python Cookbook in Chinese》 3rd Edition 翻译地址：gith @蚁工厂](https://weibo.com/2194035935/MEDAiuzbp)

Note: 《Python Cookbook in Chinese》 3rd Edition 翻译地址：github.com/yidao620c/python3-cookbook本书作者是David Beazley大神，一位独立的计算机科学家、教育家，以及有着35年开发经验的软件开发者。 他在Python社区一直都很活跃，编写了很多的python包， 发表了很多的公开演讲视频 以及 编程教程。 同时还是Python Essential Reference 以及 Python Cookbook (O'Reilly Media)的作者。//:转发微博好像很久前看过？

Picture: [82c654dfly1h1qpnd12r2j20fu16lgo1.jpg](https://weibo.cn//mblog/pic/Lr79Wi3Ao?rl=1)

Github: [github.com/yidao620c/python3-cookbook](github.com/yidao620c/python3-cookbook)

#### [【Nobuco：将PyTorch模型转换为TensorFlow图，支持多种架构、控制流操作、循环层、 @爱可可-爱生活](https://weibo.com/1402400261/MEEJV4w0Q)

Note: 【Nobuco：将PyTorch模型转换为TensorFlow图，支持多种架构、控制流操作、循环层、任意torch函数等。Nobuco可以使转换过程变得简单和灵活，并保留良好的可读性和清晰的错误消息】'nobuco - Pytorch to Tensorflow conversion made somewhat easy' AlexanderLutsenko GitHub: github.com/AlexanderLutsenko/nobuco  

Picture: [5396ee05ly8hdjtyub6bhj214z0u0ae7.jpg](https://weibo.cn//mblog/pic/MEEJV4w0Q?rl=1)

Github: [github.com/AlexanderLutsenko/nobuco](github.com/AlexanderLutsenko/nobuco)

#### [【sqlite-zstd：sqlite扩展，为sqlite提供透明的基于字典的行级压缩，可将sqli @爱可可-爱生活](https://weibo.com/1402400261/MEHqL4crq)

Note: 【sqlite-zstd：sqlite扩展，为sqlite提供透明的基于字典的行级压缩，可将sqlite数据库的大小减少80％左右，同时保持性能基本相同】'sqlite-zstd - Transparent dictionary-based row-level compression for SQLite' phiresky GitHub: github.com/phiresky/sqlite-zstd   

Picture: [5396ee05ly8hdk5vb8ofbj211w0j7q4k.jpg](https://weibo.cn//mblog/pic/MEHqL4crq?rl=1)

Github: [github.com/phiresky/sqlite-zstd](github.com/phiresky/sqlite-zstd)

#### [《如何写科研论文？》复旦大学 老师的一个报告ppt地址： xpqiu.github.io/slide @蚁工厂](https://weibo.com/2194035935/MEOV31aaR)

Note: 《如何写科研论文？》复旦大学 老师的一个报告ppt地址： xpqiu.github.io/slides/如何写科研论文202203.pdf详细介绍了学术论文每一部分的写法和注意事项 

Picture: [82c654dfly1h1v8sts5yjj21e10u0n5g.jpg](https://weibo.cn//mblog/pic/Lriys74DW?rl=1)

#### [卧槽，Replit发布了他们训练好的编程LLM模型replit-code-v1-3b，是BY-SA  @敖天羽](https://weibo.com/1888981347/MEQr8Cf7A)

Note: 卧槽，Replit发布了他们训练好的编程LLM模型replit-code-v1-3b，是BY-SA 4.0授权发布，这意味着允许商业使用！🤗地址：另外对于他们是怎么训练大模型的可以参考这篇文章：《如何训练你自己的大型语言模型》必须得cc一下CSDN的朋友们，赶紧用上造福国内程序员们！  

#### [Glarity浏览器插件可以生成文章摘要，如果你也好奇这几个问题：1，如何提取文章内容2，如何解决大 @宝玉xp](https://weibo.com/1727858283/MEYquCqCk)

Note: Glarity浏览器插件可以生成文章摘要，如果你也好奇这几个问题：1，如何提取文章内容2，如何解决大量文本内容的摘要问题3，如何做的推广可以参考balconychy（twitter.com/balconychy）这篇推文：🔗twitter.com/balconychy/status/1653973833227935744🔗 

Picture: [66fd066bgy1hdm8wodoxwj20lm59o4qq.jpg](https://weibo.cn//mblog/pic/MEYquCqCk?rl=1)

#### [一篇介绍RLHF的长文《RLHF: Reinforcement Learning from Huma @宝玉xp](https://weibo.com/1727858283/MEYkivcJ1)

Note: 一篇介绍RLHF的长文《RLHF: Reinforcement Learning from Human Feedback》RLHF：从人类反馈中强化学习介绍了RLHF 究竟是如何工作以及为什么有效等内容 

Picture: [82c654dfly1hdm45ilk7sj20rc0upaop.jpg](https://weibo.cn//mblog/pic/MEYfhApao?rl=1)

#### [图解 QUIC 连接 -- 对每一个字节的解释和再现地址：cangsdarm.github.io/i @敖天羽](https://weibo.com/1888981347/MEZ9C0N9F)

Note: 图解 QUIC 连接 -- 对每一个字节的解释和再现地址：cangsdarm.github.io/illustrate/quic原作者 syncsynchalt, 译者 AllenLee 

Picture: [82c654dfly1hdm916kt3sj21391mutpn.jpg](https://weibo.cn//mblog/pic/MEYswcyKM?rl=1)

#### [《A Survey of Large Language Models》的中文版《大语言模型综述》原始 @蚁工厂](https://weibo.com/2194035935/MEY9xzE0c)

Note: 《A Survey of Large Language Models》的中文版《大语言模型综述》原始论文：中文版：🔗github.com/RUCAIBox/LLMSurvey/blob/main/assets/LLM_Survey_Chinese_0418.pdf🔗摘要自从 20 世纪 50 年代图灵测试被提出以来，人类一直在探索如何用机器掌握语言智能。语言本质上是一种由语法规则支配的复杂的人类表达系统，开发有能力理解和掌握一门语言的人工智能（AI）算法是一个重大挑战。作为一种主要的语言理解和生成方法，语言建模在过去的二十年中得到了广泛的研究，其从统计语言模型发展为神经语言模型。近年来，通过在大规模语料库上预训练，基于 Transformer架构的预训练语言模型在解决各种自然语言处理任务方面表现出强大的能力。由于研究人员发现扩大模型规模可以提高模型能力，因此他们通过将参数增加到更大的尺寸来进一步研究该效应。有趣的是，当参数规模超过一定水平时，这些规模扩大的语言模型的性能不仅得到了显著提升，而且还表现出一些小规模语言模型（如 BERT）所不具备的特殊能力（如上下文学习）。为了区分不同参数规模下的语言模型，研究团体创造了术语——大语言模型（LLM）代指大型的预训练语言模型（如包含数百亿或数千亿个参数）。近年来，学术界和业界极大的推进了针对大语言模型的研究，并在该方向取得了显著的进展，如 ChatGPT（一种基于 LLM 开发的强大 AI 聊天机器人）的推出，引起了社会的广泛关注。大语言模型的技术发展对整个 AI 社区产生了重要影响，这将彻底改变我们开发和使用 AI 算法的方式。考虑到这一快速的技术进步，在本篇综述中，我们通过介绍大语言模型的背景、主要发现和主流技术来回顾近年来的进展。我们特别关注大语言模型的四个主要方面，即预训练、适配微调、应用和能力评估。此外，我们还总结了开发大语言模型的可用资源，并讨论了未来可行的发展方向。本文提供了关于大语言模型的最新文献综述，期望能为研究人员和工程师提供帮助。这样看，感觉美国人是真的爽，看什么论文都是用母语看

Picture: [66fd066bgy1hdm7gqlicvj21b853cnpg.jpg](https://weibo.cn//mblog/pic/MEY7RimRD?rl=1)

Github: [github.com/RUCAIBox/LLMSurvey/blob/main/assets/LLM_Survey_Chinese_0418.pdf](github.com/RUCAIBox/LLMSurvey/blob/main/assets/LLM_Survey_Chinese_0418.pdf)

#### [《性能之巅 第2版》读书笔记（第9章下）1.使用iostat命令的扩展模式可以找到繁忙的磁盘。我们可 @小川CD](https://weibo.com/1202332555/MERdSnLyv)

Note: 《性能之巅 第2版》读书笔记（第9章下）1.使用iostat命令的扩展模式可以找到繁忙的磁盘。我们可以查看使用率超过60％、平均服务时间超过10毫秒和高IOPS的磁盘。使用iotop或biotop可以查找引发磁盘IO的进程。使用biolatency可以以直方图的形式检查IO延迟分布。2.检查每个磁盘设备的指标，包括使用率、饱和度和错误。使用率指设备忙碌的时间；饱和度指I/O在队列中等待的时间；错误指设备错误。3.检查磁盘控制器的指标，包括使用率、饱和度和错误。使用率是指当前值与最大吞吐量之间的比较，对操作频率也做同样的比较；饱和度指由于控制器饱和造成的I/O等待程度；错误指控制器错误。磁盘控制器和传输总线的性能常常被忽视。4.如果磁盘使用率在数秒内达到100％，那么很可能存在问题。超过60％的使用率可能会因不断增加的队列导致性能下降，具体取决于环境。5.负载特征可以归纳为IO频率、IO吞吐量、IO大小、读写比、随机IO和连续IO的比例。6.高级负载特征可以归纳为IOPS和吞吐量是多少，每个盘是多少？IO是否在可用磁盘之间均衡？是否存在错误，这些错误是非法请求还是磁盘的问题？每条参与的传输总线的IOPS和吞吐量是多少？磁盘IO里应用程序同步的调用占到多少？IO到达的时间分布是什么样的……7.性能特征可以归纳为每块磁盘的使用率、IO饱和度、平均IO服务时间、平均IO等待时间以及是否存在高延时的IO离群点。可以检查IO延迟的全分布以及是否存在系统资源控制，例如IO流控，并且是否激活。非数据传输磁盘命令延迟也应该被考虑。8.静态性能调优：在进行系统性能调优时，需要了解服务器的硬件配置，例如磁盘数量、类型、大小、控制器接口类型、RAID配置参数等，以及是否启用了多路径功能和磁盘IO资源控制。此外，还需要知道服务器的主存大小以及页面和缓冲区高速缓存使用情况等信息。9.微基准测试：对于磁盘性能的测试，可以进行微基准测试，例如测量最大磁盘吞吐量、最大磁盘操作频率（IOPS）、读延时剖析和随机IO延时剖析等。10.iostat命令可以用来衡量系统的交付性能，其中await指标显示了IO的平均总等待时间。对于资源使用和容量规划来说，%util指标也很重要，但它只衡量繁忙程度而不是空闲时间。对于由多个磁盘支持的虚拟设备来说，%util指标可能意义不大。11.BCC工具biosnoop的-Q选项可以显示从创建IO到向设备发出的时间（以前称为块IO等待时间或者操作系统等待时间）。这个时间主要花在操作系统队列上，但也可以包括内存分配和锁获取。12.iotop工具可以用来显示最重要的磁盘IO进程，而biotop则是一个BCC工具，类似于磁盘的top工具。13.blktrace是Linux的块设备IO事件的自定义跟踪工具，它使用了内核的blktrace跟踪器。通过blktrace，可以显示设备的主要编号、次要编号、CPU ID、序号、活动时间（以秒为单位）、进程ID、活动标识符、事件类型以及RWBS描述（即IO标志位）等信息。14.Linux还提供了一些可调参数，例如scheduler用于选择IO调度策略（空操作、最后期限或cfq），nr_requests用于控制块层可以分配的读或写请求的数量，而read_ahead_kb则用于控制文件系统请求的最大预读KB数。

#### [一篇介绍RLHF的长文《RLHF: Reinforcement Learning from Huma @蚁工厂](https://weibo.com/2194035935/MEYfhApao)

Note: 一篇介绍RLHF的长文《RLHF: Reinforcement Learning from Human Feedback》RLHF：从人类反馈中强化学习介绍了RLHF 究竟是如何工作以及为什么有效等内容 欠账

Picture: [82c654dfly1hdm45ilk7sj20rc0upaop.jpg](https://weibo.cn//mblog/pic/MEYfhApao?rl=1)

#### [和Yukuo、Yuxiao一起在WWW 2023上做了一个关于自监督学习和预训练图神经网络的Tuto @AMiner学术头条](https://weibo.com/1870858943/MF0TE1qQC)

Note: 和Yukuo、Yuxiao一起在WWW 2023上做了一个关于自监督学习和预训练图神经网络的Tutorial：Self-supervised Learning and Pre-training on Graphs (GNNs)，ppt放到主页了，希望对大家有用。 

Picture: [7ebeb44bgy1hdkqi5f1l5j21qi0y44qp.jpg](https://weibo.cn//mblog/pic/MEM6Ott66?rl=1)

#### [【CodeGen2：用于生成程序代码的大型语言模型】’CodeGen2 - CodeGen2 mod @爱可可-爱生活](https://weibo.com/1402400261/MF0Z2ck2Z)

Note: 【CodeGen2：用于生成程序代码的大型语言模型】’CodeGen2 - CodeGen2 models for program synthesis' Salesforce GitHub: github.com/salesforce/CodeGen2   

Picture: [5396ee05ly8hdmk6wcf09j216s0rwgpr.jpg](https://weibo.cn//mblog/pic/MF0Z2ck2Z?rl=1)

Github: [github.com/salesforce/CodeGen2](github.com/salesforce/CodeGen2)

#### [【Lorax: JAX实现的LoRA，用于用于实现大型语言模型的参数高效微调】’Lorax: LoR @爱可可-爱生活](https://weibo.com/1402400261/MF14ild6r)

Note: 【Lorax: JAX实现的LoRA，用于用于实现大型语言模型的参数高效微调】’Lorax: LoRA for JAX functions - JAX transform which implements Low Rank Adaptation (LoRA)' Davis Yoshida GitHub: github.com/davisyoshida/lorax   

Picture: [5396ee05ly8hdmkjpltfqj218m0ng78o.jpg](https://weibo.cn//mblog/pic/MF14ild6r?rl=1)

Github: [github.com/davisyoshida/lorax](github.com/davisyoshida/lorax)

#### [【大型语言模型(LLM)与强化学习(RL)相关论文列表，包括指导、推理、决策、持续改进和自我提升等方 @爱可可-爱生活](https://weibo.com/1402400261/MF1010ftn)

Note: 【大型语言模型(LLM)与强化学习(RL)相关论文列表，包括指导、推理、决策、持续改进和自我提升等方面的研究工作】’LLM-with-RL-papers - A collection of LLM with RL related papers for instruction following, reasoning, decision making, continuous improvement and self improvement etc.' Flood Sung GitHub: github.com/floodsung/LLM-with-RL-papers  

Picture: [5396ee05ly8hdmk8c30drj20wi0u0443.jpg](https://weibo.cn//mblog/pic/MF1010ftn?rl=1)

Github: [github.com/floodsung/LLM-with-RL-papers](github.com/floodsung/LLM-with-RL-papers)

#### [【The Full Stack 7-Steps MLOps Framework：全栈7步MLOps框 @爱可可-爱生活](https://weibo.com/1402400261/MF1h653bq)

Note: 【The Full Stack 7-Steps MLOps Framework：全栈7步MLOps框架课程，旨在教授机器学习工程师如何使用MLOps良好实践设计、实现、监测和部署自己的能源消耗预测模型。课程由7个Medium教程组成，覆盖了特征工程、训练、预测、部署等多个方面】'The Full Stack 7-Steps MLOps Framework - The Full Stack 7-Steps MLOps Framework - Learn ML Engineering by designing, implementing, monitoring, and deploying your own energy consumption forecaster.' Paul Iusztin GitHub: github.com/iusztinpaul/energy-forecasting   名

Picture: [5396ee05ly8hdmlggqhxuj20sg0lcgnt.jpg](https://weibo.cn//mblog/pic/MF1h653bq?rl=1)

Github: [github.com/iusztinpaul/energy-forecasting](github.com/iusztinpaul/energy-forecasting)

#### [【NumPy tutorials：一系列基于Jupyter Notebook的NumPy教程和教育材 @爱可可-爱生活](https://weibo.com/1402400261/MF1t0fxOB)

Note: 【NumPy tutorials：一系列基于Jupyter Notebook的NumPy教程和教育材料，可以用于自学和教学】'NumPy tutorials - NumPy tutorials & educational content in notebook format' NumPy GitHub: github.com/numpy/numpy-tutorials   

Picture: [5396ee05ly8hdmmbs5hfuj20xp0u0wk6.jpg](https://weibo.cn//mblog/pic/MF1t0fxOB?rl=1)

Github: [github.com/numpy/numpy-tutorials](github.com/numpy/numpy-tutorials)

#### ['DecryptPrompt - 总结Prompt&LLM论文，开源数据&模型，AIGC应用' DS @爱可可-爱生活](https://weibo.com/1402400261/MF1xH1tRO)

Note: 'DecryptPrompt - 总结Prompt&LLM论文，开源数据&模型，AIGC应用' DSXiangLi GitHub: github.com/DSXiangLi/DecryptPrompt   

Picture: [5396ee05ly8hdmmmdw6t5j20xs0u0wk2.jpg](https://weibo.cn//mblog/pic/MF1xH1tRO?rl=1)

Github: [github.com/DSXiangLi/DecryptPrompt](github.com/DSXiangLi/DecryptPrompt)

#### [深度学习先驱杰弗里-辛顿(Geoffrey Hinton)周一宣布，在为谷歌公司工作十年后，他将辞去 @刘群MT-to-Death](https://weibo.com/1917491813/MF5Qz7bOJ)

Note: 深度学习先驱杰弗里-辛顿(Geoffrey Hinton)周一宣布，在为谷歌公司工作十年后，他将辞去谷歌人工智能研究员的职务。他说，由于他越来越担心人工智能的潜在危害，他希望能自由发言。在宣布这一消息之前，《麻省理工科技评论》的人工智能高级编辑威尔-道格拉斯-斯蒂尔(Will Douglas Heaven)就他的担忧采访了辛顿。通过这个采访视频可以了解：- 为什么 Geoffrey 要离职？- 他的担忧是什么！- AI 本身没有欲望，为什么会做出威胁人类的事情？- 等 AI 有威胁了拔电源不就好了?- 既然 AI 的模型是人类设定的，怎么还可能会失控？- AI 的训练达到数据极限了吗？- AI 对未来社会尤其是失业率有什么影响？Geoffrey 离职有两个主要原因，一个是已经 75 岁高龄了，精力不如从前，到了退休的年龄；另一个原因是大语言模型完全改变了它人工智能的一些看法，引发了一些担忧，而离开谷歌才好公开谈论这个问题。Geoffrey 为什么认为大语言模型的学习能力很强大，因为可以有很多相同模型的副本在不同的硬件上运行做同样的事情，可以看到不同的数据。我有 10,000 个副本，它们可以查看 10,000 个不同的数据子集。只要其中一个学到了任何东西，其他所有模型都会知道！他们彼此之间进行通信，并且所有模型都在一起学习提升，人类无法做到这一点。如果某个人通过痛苦的学习掌握了某项知识（例如量子力学），ta 没办法把学习成果直接复制给另一个人，而 AI 可以！另外对于人来说，每个个体接触的信息是有限的，但是 AI 能接触的信息是海量的，那么它更容易从海量数据中找出数据中的规律。比如一个医生，可能给一千个人看过病，其中有一个罕见病，但是 AI 可能看过一亿个病人，能从中看到人类永远看不到的数据规律。Geoffrey 问过 GPT-4 一个问题：“我希望我家所有的房间都是白色的，目前，有些是白色的房间，有些是蓝色的房间，还有些是黄色的房间，黄色的油漆在一年内会褪成白色。那么如果我希望两年后它们都变成白色，我该怎么办呢？”。GPT-4 回复：“你应该把蓝色的房间涂成黄色。” 这确实令人印象深刻，Geoffrey 以此推断，GPT-4 有大约 80 到 90 的智商，并且有一定的推理能力，但未来智商可能会达到 210。AI 能通过阅读人类的小说来学习如何操纵人类，而人类甚至不能感知到被 AI 操控。就像大人为了哄骗小孩子吃蔬菜，会问孩子：“你想要豌豆还是花菜？”，通常孩子就会选择一样蔬菜，而孩子没有意识到其实不是必须二选一的。主持人问 Geoffrey：“为什么我们不能建立防护栏或者让 AI 在学习方面变得更糟，或者限制 AI 之间交流？”Geoffrey 认为当 AI 的智商比我们高很多，它们可以轻而易举的绕过我们设定的限制，就像你两岁的孩子说，我爸爸做了我不喜欢的事情，所以我要为他制定一些规则限制他能做的事情。然后你在搞清楚规则后，还是一样能在规则之下做几乎任何你想做的事情。另一个讨论的话题是进化，人类进化了，所以人类是天然有目标的，比如疼痛让人类保护自己尽量不受伤；饥饿让人类要吃东西；繁衍后代让人类创造副本时感到愉悦。AI 没有进化，没有这些目标，但 Geoffrey 担心的是，人类是能给 AI 制定目标的，一旦 AI 有了从目标创建子目标的能力，实际上 GPT-4 已经有初步的这种能力了比如 AutoGPT，那么 AI 很快就会意识到获得更多的控制人类是一个非常好的子目标，因为这可以帮助它实现其他目标，如果这些事情失控，那人类就会有麻烦。Geoffrey 甚至认为人类只是智慧演变过程中的一个短暂阶段！也就是之前说过的硅基生命的引导程序。数码智能是不能凭空创造出来的，它需要能量和精密制造，只有人类才能创造数码智能，但是当数码智能创造出来后，数码智能就可以吸收人类的一切知识，了解世界如何运作的，最终统治人类，并且数码智能是永生的，即使数码智能的某个硬件毁灭了，马上又能在其他硬件上复活。主持人说，那拔电源就好了！Geoffrey 说，恐怕你做不到，想想电影《2001 太空漫游》里面的人工智能 HAL 是怎么做的。注：电影《2001 太空漫游》中，一艘发现号太空船被委派到木星调查讯号的终点。太空船上的人员包括大卫·鲍曼博士、法兰克·普尔和一台十分先进且具有人工智慧的超智慧电脑 HAL 9000 来控制整艘太空船。此外，太空船上还有三位正在处于冬眠状态的科学家。但是远航之旅逐渐变成一趟可怕的旅行，HAL 发现大卫与法兰克打算将他的主机关闭。对 HAL 来说，关闭它的主机代表会杀死它，所以 HAL 决定先发制人，杀害那三位冬眠中的科学家以及用制造假故障的状况让法兰克去太空船外修理，然后用 HAL 的小型艇将法兰克的氧气剪断，导致法兰克缺氧而死。另一个话题是，既然人工智能已经这么危险了，那么我们能停止它吗？就像前不久一群人提议暂停人工智能的发展。Geoffrey 认为已经不可能停止了，在 2017 年 Google 发明 Transformer 后，使用这项技术一直很谨慎，但是 OpenAI 利用它创建了 GPT，然后微软决定推出这项技术，此时 Google 已经没什么选择了，就像冷战时候的核武军备竞赛一样。观众提问环节，摘要节选几个问答：问：“提问是人类最重要的能力之一，从 2023 年的角度看，应该最关注哪一个或者哪几个问题？”答：“我们应该问 AI 很多问题，其中之一是，我们如何阻止它们控制我们？我们可以向 AI 询问关于这个的问题，但我不会完全相信它们的回答。”问：“训练大模型需要大量数据，现阶段 AI 的发展是否受到了数据的制约？”答：“也许已经用尽了人类所有的文本知识，但是多模态还包含图像和视频的数据，这其中包含大量的数据，所以现在还远远没有到数据的极限”问：“人工智能所做的一切，都是从我们教给它们的东西中学到的。人类进化的每个阶段都是由思想实验推动的，如果 AI 不能思想实验，那么我们怎么可能受到它们存在的威胁？因为他们不会真正地自我学习？他们的自我学习将局限于我们为他们提供的模型。”答：“AI 是能进行思想实验的，他们能进行推理。举个例子，Alpha 0 学完人类的棋谱后，并且它掌握了围棋的规则后，就能自己训练自己。现在的聊天机器人就是类似的，他们还没学会内部推理，但是用不了太久就能学会了。”问：“技术以指数级的速度在发展，如果你观察近期和中期，比如说，一、两、三或者五年的时间范围，或许新的工作岗位正在被创造，从社会角度看失业对社会和经济的影响是什么？”答：“人工智能确实极大提升生产力，但是生产力提高反而会导致失业，富人更富，穷人更穷！当基尼系数变大，社会将会越来越暴力，通过给每个人提供基本收入可以缓解这个问题”“人工智能确实极大提升生产力，但是生产力提高反而会导致失业，富人更富，穷人更穷！当基尼系数变大，社会将会越来越暴力，通过给每个人提供基本收入可以缓解这个问题”——让人工智能设计合理的分配制度，减小基尼系数，使社会和平安全？//:看了视频，很多感慨，稍后另开一贴说说。对人来说，每个个体接触的信息是有限的，但是 AI 能接触的信息是海量的，它更容易从海量数据中找出数据中的规律。比如一个医生，可能给一千个人看过病，其中有一个罕见病，但 AI 可能看过一亿个病人，能从中看到人类永远看不到的数据规律。//:看了视频，很多感慨，稍后另开一贴说说。

#### [【Navigating the Transition from Individual Contrib @网路冷眼](https://weibo.com/1715118170/MF61FfRRj)

Note: 【Navigating the Transition from Individual Contributor to Tech Lead】🔗 medium.com//navigating-the-transition-from-individual-contributor-to-tech-lead-fbf8b29b878e 驾驭从个人贡献者到 Tech Lead 的转变。 

#### [ 大家都在学  ，我们基于 RWKV 1.5B基模型。 主要是在RWKV提供的1.5B参数的基础之上 @蚁工厂](https://weibo.com/2194035935/MF72Gw74U)

Note:  大家都在学  ，我们基于 RWKV 1.5B基模型。 主要是在RWKV提供的1.5B参数的基础之上，使用CSDN的问答数据和博客数据进行增量预训练，经过指令微调，得到拥有IT行业知识体系的大语言模型。欢迎大家来尝试。 本地跑起来有啥硬件要求不

Picture: [71fafb35gy1hdnaw70mu4j21ac0miwkb.jpg](https://weibo.cn//mblog/pic/MF725C5V2?rl=1)

#### [【LangChain and Ray - repository of examples：LangCh @爱可可-爱生活](https://weibo.com/1402400261/MF88YECn9)

Note: 【LangChain and Ray - repository of examples：LangChain和Ray的示例教程】’LangChain and Ray - repository of examples - Examples on how to use LangChain and Ray' ray-project GitHub: github.com/ray-project/langchain-ray   

Picture: [5396ee05ly8hdnfss6hp8j20v10u0jv0.jpg](https://weibo.cn//mblog/pic/MF88YECn9?rl=1)

Github: [github.com/ray-project/langchain-ray](github.com/ray-project/langchain-ray)

#### [【LangChain-mini：一个使用LLM (GPT-3.5)技术搭建的聊天程序，代码量仅有约1 @爱可可-爱生活](https://weibo.com/1402400261/MF8aKwJO8)

Note: 【LangChain-mini：一个使用LLM (GPT-3.5)技术搭建的聊天程序，代码量仅有约100行。可以利用Google搜索和计算器等工具进行对话和回答问题。此程序是为了娱乐和教育目的而开发的，并非LangChain的替代品】'LangChain-mini - This is a very simple re-implementation of LangChain, in ~100 lines of code' Colin Eberhardt GitHub: github.com/ColinEberhardt/langchain-mini  

Picture: [5396ee05ly8hdnfwidz8mj21840qmn2n.jpg](https://weibo.cn//mblog/pic/MF8aKwJO8?rl=1)

Github: [github.com/ColinEberhardt/langchain-mini](github.com/ColinEberhardt/langchain-mini)

#### [【USearch：快速、小巧的向量搜索引擎，可用于C++、Python、JavaScript、Rus @爱可可-爱生活](https://weibo.com/1402400261/MF8kh0YBn)

Note: 【USearch：快速、小巧的向量搜索引擎，可用于C++、Python、JavaScript、Rust、Java、GoLang和Wolfram等编程语言。支持多种度量方式，包括欧氏距离、点积、余弦、杰卡德、海明、哈弗辛等。还支持半精度、多线程、变量维度向量等功能，可以在不加载到内存中的情况下从磁盘中查看数据集。提供了各种绑定库，如Python绑定库、JavaScript绑定库、Rust绑定库等，可以简化用户的工作流程】'USearch - Smaller & Faster Vector Search Engine for C++, Python, JavaScript, Rust, Java, GoLang, Wolfram' Unum GitHub: github.com/unum-cloud/usearch  请问一下，这种文件搜索库一般可以用来做什么呀

Picture: [5396ee05ly8hdngl7mgfwj20u011ywis.jpg](https://weibo.cn//mblog/pic/MF8kh0YBn?rl=1)

Github: [github.com/unum-cloud/usearch](github.com/unum-cloud/usearch)

#### [【使用DataComp-1B数据集训练的CLIP ViT-L/14模型，可用于零样本、任意图像分类、 @爱可可-爱生活](https://weibo.com/1402400261/MF8ChDsBw)

Note: 【使用DataComp-1B数据集训练的CLIP ViT-L/14模型，可用于零样本、任意图像分类、图像和文本检索等任务，零样本准确率为79.2%，优于 OpenAI 的 CLIP，甚至是在 LAION-2B 上训练的更大的模型(ViT-g/14)，该模型的训练数据集为1.4亿样本的DataComp-1B数据集，该数据集为未加筛选的大规模多模态数据集】“laion/CLIP-ViT-L-14-DataComp.XL-s13B-b90K · Hugging Face”  

Picture: [5396ee05ly8hdnhw7g3j5j20xc0i0dhe.jpg](https://weibo.cn//mblog/pic/MF8ChDsBw?rl=1)

#### [【GPT-4终极指南：一份关于如何使用GPT3和GPT4的指南，其中包括100多个资源，可以帮助学习 @爱可可-爱生活](https://weibo.com/1402400261/MFfCXn2Ux)

Note: 【GPT-4终极指南：一份关于如何使用GPT3和GPT4的指南，其中包括100多个资源，可以帮助学习如何用它来提高生活效率。包括如何学习ChatGPT基础知识、如何学习ChatGPT高级知识、如何在语言学习中使用GPT-3、如何在教学中使用GPT-3、如何使用GPT-4等，还提供了如何升级到ChatGPT+计划以使用GPT-4以及如何免费使用GPT-4的方法等内容。同时，还提供了如何在业务、生产力、受益、金钱等方面使用ChatGPT的指南】《The Ultimate GPT-4 Guide》  感谢分享

Picture: [5396ee05ly8hdocubgdeij20u00wejw7.jpg](https://weibo.cn//mblog/pic/MFfCXn2Ux?rl=1)

#### [GPT4All Chat，一个本地运行的人工智能聊天应用程序，不需要联网。已经被打包好了，直接下载即 @蚁工厂](https://weibo.com/2194035935/MFfGidMmT)

Note: GPT4All Chat，一个本地运行的人工智能聊天应用程序，不需要联网。已经被打包好了，直接下载即可使用。默认使用GPT-J模型，用CPU计算。能力可能和gpt-3差不多。下载地址：gpt4all.io/index.html 回复:那我更新下看看 最近用Claude比较多，slack还是方便回复:看新版有设置路径的地方？ 回复:做了，然后新模型下不下来 显示100%但是找不到模型回复:用 mklink 映射到 D 盘试试？可是它改不了模型路径 我C盘没空间了

Picture: [82c654dfly1hdct3n9jjyj20zk12gqr3.jpg](https://weibo.cn//mblog/pic/MDJslDN7A?rl=1)

#### [电子书《Hello 算法》地址：www.hello-algo.com这是一本动画图解、能运行、可提问 @蚁工厂](https://weibo.com/2194035935/MFfIPaoGX)

Note: 电子书《Hello 算法》地址：www.hello-algo.com这是一本动画图解、能运行、可提问的数据结构与算法快速入门教程 “如果我当年学数据结构与算法的时候有《Hello 算法》，学起来应该会简单 10 倍！”—— 李沐，亚马逊资深首席科学家本书主要内容包括：    复杂度分析：数据结构与算法的评价维度、算法效率的评估方法。时间复杂度、空间复杂度，包括推算方法、常见类型、示例等。    数据结构：常见基本数据类型，数据在内存中的存储形式、数据结构的分类方法。涉及数组、链表、栈、队列、散列表、树、堆、图等数据结构，内容包括定义、优缺点、常用操作、常见类型、典型应用、实现方法等。    算法：查找算法、排序算法、搜索与回溯、动态规划、分治算法等，内容涵盖定义、应用场景、优缺点、时空效率、实现方法、示例题目等。K神是真的牛

Picture: [82c654dfly1hdod930nuoj20zk0qngzo.jpg](https://weibo.cn//mblog/pic/MFfIPaoGX?rl=1)

#### [：MPT-7BMPT-7B：一个新的开源、商业可用LLM标准MPT-7B是MosaicML基金会系列 @宝玉xp](https://weibo.com/1727858283/MFhyr90EB)

Note: ：MPT-7BMPT-7B：一个新的开源、商业可用LLM标准MPT-7B是MosaicML基金会系列的最新产品，一个从头开始训练的、基于1T文本和代码的Transformer。- 开源可商用，能力与LLaMA-7B相当- 有三个微调模型，除了基本的MPT-7B之外：MPT-7B-Instruct、MPT-7B-Chat和MPT-7B-StoryWriter-65k+- 其中写作模型支持65k的上下文！是GPT4的两倍博文：测试地址：

Picture: [66fd066bgy1hdolbsndmej21jj0pg7wh.jpg](https://weibo.cn//mblog/pic/MFhyr90EB?rl=1)

#### [我确实没想到有人用Whisper和ChatGPT来面试作弊……这个开源项目是专门用来面试作弊的，Wh @宝玉xp](https://weibo.com/1727858283/MFixiwClQ)

Note: 我确实没想到有人用Whisper和ChatGPT来面试作弊……这个开源项目是专门用来面试作弊的，Whisper用来识别语音成文字，ChatGPT根据识别出来的文字为你提供参考答案！慎用！！被面试官发现后果很严重！🔗github.com/leetcode-mafia/cheetah🔗  我们这里找面试官普遍已经用了chatgpt作为面试题来源了话说，能搞通这套的，可以直接录取了吧老师您好，能问一下whisper能否做到：B站正在播放的视频能直接识别全部文字并保存下来。或者要等全部播放完才能识别？ 如果不能您知道还有什么软件可以做到吗？感谢🙏已经马住了…有没有再用文字转语音的，这样我对个嘴型就好。回复:MP3等音频文件是可以直接识别的，不需要播放完整让有口音的人来面回复:很简单，github下载部署就行，但不怎么实用，即使不考虑语音识别的问题，在很多技术细节问题上回答都很糟糕。能做的可能就是帮你查查八股……识别什么语言的可以下载b站视频，自己提取mp3，然后识别生成字幕文件。当然可以写成脚本，一条龙。

Github: [github.com/leetcode-mafia/cheetah](github.com/leetcode-mafia/cheetah)

#### [【Lit-StableLM：基于nanoGPT的StableLM/Pythia语言模型的可修改实现， @爱可可-爱生活](https://weibo.com/1402400261/MFhkms2Yt)

Note: 【Lit-StableLM：基于nanoGPT的StableLM/Pythia语言模型的可修改实现，支持flash注意力、Int8和GPTQ 4bit量化、LoRA和LLaMA-Adapter微调和预训练】'Lit-StableLM - Implementation of the StableLM/Pythia language models based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed.' Lightning AI GitHub: github.com/Lightning-AI/lit-stablelm 

Github: [github.com/Lightning-AI/lit-stablelm](github.com/Lightning-AI/lit-stablelm)

#### [【InferLLM：非常轻量的 LLM 模型推理框架，可以本地部署 LLM 中的量化模型，推理速度还 @爱可可-爱生活](https://weibo.com/1402400261/MFhnZFacv)

Note: 【InferLLM：非常轻量的 LLM 模型推理框架，可以本地部署 LLM 中的量化模型，推理速度还不错。框架特点包括结构简单，运行高效，定义了专门的 KVstorage 类型，可以兼容多种模型格式，目前只支持 CPU，主要是 Arm 和 x86 平台】’InferLLM - a lightweight LLM model inference framework' MegEngine GitHub: github.com/MegEngine/InferLLM 

Github: [github.com/MegEngine/InferLLM](github.com/MegEngine/InferLLM)

#### [【Benchmark for Audio Libraries: Audioflux, TorchAu @网路冷眼](https://weibo.com/1715118170/MFjnV4uyw)

Note: 【Benchmark for Audio Libraries: Audioflux, TorchAudio, Librosa, Essentia, etc】🔗 github.com/libAudioFlux/audioFlux/tree/master/benchmark 音频库基准测试：Audioflux、TorchAudio、Librosa、Essentia 等。 

Picture: [663aa05aly8hdotfncjbtj215o0dwwg5.jpg](https://weibo.cn//mblog/pic/MFjnV4uyw?rl=1)

Github: [github.com/libAudioFlux/audioFlux/tree/master/benchmark](github.com/libAudioFlux/audioFlux/tree/master/benchmark)

#### [系列博文《算法与复杂度》地址：infinityglow.github.io/study/algori @蚁工厂](https://weibo.com/2194035935/MFjpIq9Ar)

Note: 系列博文《算法与复杂度》地址：infinityglow.github.io/study/algorithm/overview/作者的话：这个系列的博文会逐个介绍计算机科学里面最基础、也是最重要的一部分内容：算法(algorithm)。提到它，这可能是你最擅长的部分，亦或是你学生生涯的噩梦。不管怎么样，对于学计算机的小伙伴来讲，它始终是不可回避的一个话题。形式上不再是只针对如何解决这个问题，因为只会解决问题并不代表真正理解这个问题。我会花一些篇幅着重介绍一些概念性的内容，这也是国内的教学最欠缺的部分。国内的课堂不会告诉你自然对数 e 揭示了自然界生长的规律；学完了线性代数，你可能光学会了如何解行列式，却忽视了行列式也是有几何意义的。在内容上我不再按照“排序算法”、“搜索算法”等方式分类，而采用了解决问题的不同方式来划分，比如“暴力求解”、“分治法”、“动态规划”等等。

Picture: [82c654dfly1h1yr7x3ifaj20jl1bln1x.jpg](https://weibo.cn//mblog/pic/LrLHGfS4u?rl=1)

#### [【Embedding data in an executable: A tutorial for l @网路冷眼](https://weibo.com/1715118170/MFkaqes2D)

Note: 【Embedding data in an executable: A tutorial for low-level C++ linkage, meant for people with zero C++ knowledge】🔗 github.com/infinitesnow/linking_tutorial在可执行文件中嵌入数据：低级 C++ 链接教程，适用于零 C++ 知识的人。 

Picture: [663aa05aly8hdowvzke79j20ou0erjso.jpg](https://weibo.cn//mblog/pic/MFkaqes2D?rl=1)

Github: [github.com/infinitesnow/linking_tutorial](github.com/infinitesnow/linking_tutorial)

#### [ 收藏！大型语言模型（LLMs）大盘点，含源码及Demo地址（附链接）  @数据派THU](https://weibo.com/6004911042/MFlhUeiq1)

Note:  收藏！大型语言模型（LLMs）大盘点，含源码及Demo地址（附链接） 

#### [微软前不久发表了一篇论文：《Sparks of Artificial General Intelli @宝玉xp](https://weibo.com/1727858283/MFqxYDmRn)

Note: 微软前不久发表了一篇论文：《Sparks of Artificial General Intelligence: Early experiments with GPT-4》 （中文翻译：）里面对于GPT-4的能力有详尽的分析和测试。今年3月，麻省理工学院邀请了论文的第一作者Sébastien Bubeck做了一次主题为《Sparks of AGI: early experiments with GPT-4 | 通用人工智能的火花：GPT-4的早期实验》的讲座，讨论通用人工智能是否已经到来。 这教学资源感觉主持人也是法语母语者？感觉主持人也是法语母语者？通过与人工智能对话探索人工智能的世界，本质上是人类和人工智能相互探索对方的世界，这两个世界都浩无边际深不可测，这意味着这场对话的结果任何一方都无法预知！ChatGPT已经很惊艳，GPT-4却达到了惊讶的程度，Buback却告诉我们这只是打开了人工智能的探索之门，只是人工智能的一个Spark！可以肯定的一点，随着人工智能的不断进化和完善，这个时代终将被改变markmark回复:

#### [微软前不久发表了一篇论文：《Sparks of Artificial General Intelli @宝玉xp](https://weibo.com/1727858283/MFv8zkj6Q)

Note: 微软前不久发表了一篇论文：《Sparks of Artificial General Intelligence: Early experiments with GPT-4》 （中文翻译：）里面对于GPT-4的能力有详尽的分析和测试。今年3月，麻省理工学院邀请了论文的第一作者Sébastien Bubeck做了一次主题为《Sparks of AGI: early experiments with GPT-4 | 通用人工智能的火花：GPT-4的早期实验》的讲座，讨论通用人工智能是否已经到来。 

#### [推荐：【🌉🤖 旧金山最大规模AI黑客马拉松LabLab 427个项目分析】 这是推友 Will 3. @宝玉xp](https://weibo.com/1727858283/MFyCMCO6x)

Note: 推荐：【🌉🤖 旧金山最大规模AI黑客马拉松LabLab 427个项目分析】 这是推友 Will 3.6-5.7 硅谷（twitter.com/FinanceYF5）对lablab.io过去一年的AI相关的黑客马拉松的数据整理，非常详尽，也许从中能为你的项目找到灵感。🔗 🐦twitter.com/FinanceYF5/status/1655283124237131776🐦🧵 cohere 是什么技术？

Picture: [66fd066bgy1hdqoj6jwxyj219y1101kx.jpg](https://weibo.cn//mblog/pic/MFyCMCO6x?rl=1)

#### [：StarCoderReplit开源了他们的代码大模型  后🤗huggingface也开源了他们的代 @宝玉xp](https://weibo.com/1727858283/MF8uliUbt)

Note: ：StarCoderReplit开源了他们的代码大模型  后🤗huggingface也开源了他们的代码大语言模型 💫StarCoder。🔥15B LLM with 8k 上下文💻可以充当技术助理🤯支持80多种编程语言🚀开放源代码和数据💫在线演示🧑💻VSCode插件🪅1万亿tokens根据他们自己公布的测试结果，他们的效果是目前最好的（测试结果没包括GPT-4）😄官方博客：测试地址：项目：🔗github.com/bigcode-project/starcoder🔗cc  转发微博今天在playground上试了一下，感觉不行啊有谁知道现在除了GPT4以外，还有哪些工具写代码比较好用啊？另外，copilot有输出限制吗？回复:已成功收藏到你的Notion🥳Cooooool￼卷

Picture: [66fd066bgy1hdnh9uwmbsj214o0wsql9.jpg](https://weibo.cn//mblog/pic/MF8uliUbt?rl=1)

Github: [github.com/bigcode-project/starcoder](github.com/bigcode-project/starcoder)

#### [深度学习先驱杰弗里-辛顿(Geoffrey Hinton)周一宣布，在为谷歌公司工作十年后，他将辞去 @宝玉xp](https://weibo.com/1727858283/MF5XA3Y7e)

Note: 深度学习先驱杰弗里-辛顿(Geoffrey Hinton)周一宣布，在为谷歌公司工作十年后，他将辞去谷歌人工智能研究员的职务。他说，由于他越来越担心人工智能的潜在危害，他希望能自由发言。在宣布这一消息之前，《麻省理工科技评论》的人工智能高级编辑威尔-道格拉斯-斯蒂尔(Will Douglas Heaven)就他的担忧采访了辛顿。通过这个采访视频可以了解：- 为什么 Geoffrey 要离职？- 他的担忧是什么！- AI 本身没有欲望，为什么会做出威胁人类的事情？- 等 AI 有威胁了拔电源不就好了?- 既然 AI 的模型是人类设定的，怎么还可能会失控？- AI 的训练达到数据极限了吗？- AI 对未来社会尤其是失业率有什么影响？Geoffrey 离职有两个主要原因，一个是已经 75 岁高龄了，精力不如从前，到了退休的年龄；另一个原因是大语言模型完全改变了它人工智能的一些看法，引发了一些担忧，而离开谷歌才好公开谈论这个问题。Geoffrey 为什么认为大语言模型的学习能力很强大，因为可以有很多相同模型的副本在不同的硬件上运行做同样的事情，可以看到不同的数据。我有 10,000 个副本，它们可以查看 10,000 个不同的数据子集。只要其中一个学到了任何东西，其他所有模型都会知道！他们彼此之间进行通信，并且所有模型都在一起学习提升，人类无法做到这一点。如果某个人通过痛苦的学习掌握了某项知识（例如量子力学），ta 没办法把学习成果直接复制给另一个人，而 AI 可以！另外对于人来说，每个个体接触的信息是有限的，但是 AI 能接触的信息是海量的，那么它更容易从海量数据中找出数据中的规律。比如一个医生，可能给一千个人看过病，其中有一个罕见病，但是 AI 可能看过一亿个病人，能从中看到人类永远看不到的数据规律。Geoffrey 问过 GPT-4 一个问题：“我希望我家所有的房间都是白色的，目前，有些是白色的房间，有些是蓝色的房间，还有些是黄色的房间，黄色的油漆在一年内会褪成白色。那么如果我希望两年后它们都变成白色，我该怎么办呢？”。GPT-4 回复：“你应该把蓝色的房间涂成黄色。” 这确实令人印象深刻，Geoffrey 以此推断，GPT-4 有大约 80 到 90 的智商，并且有一定的推理能力，但未来智商可能会达到 210。AI 能通过阅读人类的小说来学习如何操纵人类，而人类甚至不能感知到被 AI 操控。就像大人为了哄骗小孩子吃蔬菜，会问孩子：“你想要豌豆还是花菜？”，通常孩子就会选择一样蔬菜，而孩子没有意识到其实不是必须二选一的。主持人问 Geoffrey：“为什么我们不能建立防护栏或者让 AI 在学习方面变得更糟，或者限制 AI 之间交流？”Geoffrey 认为当 AI 的智商比我们高很多，它们可以轻而易举的绕过我们设定的限制，就像你两岁的孩子说，我爸爸做了我不喜欢的事情，所以我要为他制定一些规则限制他能做的事情。然后你在搞清楚规则后，还是一样能在规则之下做几乎任何你想做的事情。另一个讨论的话题是进化，人类进化了，所以人类是天然有目标的，比如疼痛让人类保护自己尽量不受伤；饥饿让人类要吃东西；繁衍后代让人类创造副本时感到愉悦。AI 没有进化，没有这些目标，但 Geoffrey 担心的是，人类是能给 AI 制定目标的，一旦 AI 有了从目标创建子目标的能力，实际上 GPT-4 已经有初步的这种能力了比如 AutoGPT，那么 AI 很快就会意识到获得更多的控制人类是一个非常好的子目标，因为这可以帮助它实现其他目标，如果这些事情失控，那人类就会有麻烦。Geoffrey 甚至认为人类只是智慧演变过程中的一个短暂阶段！也就是之前说过的硅基生命的引导程序。数码智能是不能凭空创造出来的，它需要能量和精密制造，只有人类才能创造数码智能，但是当数码智能创造出来后，数码智能就可以吸收人类的一切知识，了解世界如何运作的，最终统治人类，并且数码智能是永生的，即使数码智能的某个硬件毁灭了，马上又能在其他硬件上复活。主持人说，那拔电源就好了！Geoffrey 说，恐怕你做不到，想想电影《2001 太空漫游》里面的人工智能 HAL 是怎么做的。注：电影《2001 太空漫游》中，一艘发现号太空船被委派到木星调查讯号的终点。太空船上的人员包括大卫·鲍曼博士、法兰克·普尔和一台十分先进且具有人工智慧的超智慧电脑 HAL 9000 来控制整艘太空船。此外，太空船上还有三位正在处于冬眠状态的科学家。但是远航之旅逐渐变成一趟可怕的旅行，HAL 发现大卫与法兰克打算将他的主机关闭。对 HAL 来说，关闭它的主机代表会杀死它，所以 HAL 决定先发制人，杀害那三位冬眠中的科学家以及用制造假故障的状况让法兰克去太空船外修理，然后用 HAL 的小型艇将法兰克的氧气剪断，导致法兰克缺氧而死。另一个话题是，既然人工智能已经这么危险了，那么我们能停止它吗？就像前不久一群人提议暂停人工智能的发展。Geoffrey 认为已经不可能停止了，在 2017 年 Google 发明 Transformer 后，使用这项技术一直很谨慎，但是 OpenAI 利用它创建了 GPT，然后微软决定推出这项技术，此时 Google 已经没什么选择了，就像冷战时候的核武军备竞赛一样。观众提问环节，摘要节选几个问答：问：“提问是人类最重要的能力之一，从 2023 年的角度看，应该最关注哪一个或者哪几个问题？”答：“我们应该问 AI 很多问题，其中之一是，我们如何阻止它们控制我们？我们可以向 AI 询问关于这个的问题，但我不会完全相信它们的回答。”问：“训练大模型需要大量数据，现阶段 AI 的发展是否受到了数据的制约？”答：“也许已经用尽了人类所有的文本知识，但是多模态还包含图像和视频的数据，这其中包含大量的数据，所以现在还远远没有到数据的极限”问：“人工智能所做的一切，都是从我们教给它们的东西中学到的。人类进化的每个阶段都是由思想实验推动的，如果 AI 不能思想实验，那么我们怎么可能受到它们存在的威胁？因为他们不会真正地自我学习？他们的自我学习将局限于我们为他们提供的模型。”答：“AI 是能进行思想实验的，他们能进行推理。举个例子，Alpha 0 学完人类的棋谱后，并且它掌握了围棋的规则后，就能自己训练自己。现在的聊天机器人就是类似的，他们还没学会内部推理，但是用不了太久就能学会了。”问：“技术以指数级的速度在发展，如果你观察近期和中期，比如说，一、两、三或者五年的时间范围，或许新的工作岗位正在被创造，从社会角度看失业对社会和经济的影响是什么？”答：“人工智能确实极大提升生产力，但是生产力提高反而会导致失业，富人更富，穷人更穷！当基尼系数变大，社会将会越来越暴力，通过给每个人提供基本收入可以缓解这个问题”

#### [哈佛CS50课程节选：如何构建基于GPT-4的应用上一节  介绍了什么是GPT-4，这一节则是基于G @宝玉xp](https://weibo.com/1727858283/MFA70qhOu)

Note: 哈佛CS50课程节选：如何构建基于GPT-4的应用上一节  介绍了什么是GPT-4，这一节则是基于GPT-4可以构建什么样的应用，以及如何构建。这部分课程介绍了GPT-4可以构建的各种类型的应用，包括不限于：- 助手应用：GPT可以用于创建AI助手，帮助完成写作、编程或回答问题等任务。通过结合专业领域知识和用户的喜好，还可以对这些助手可以进一步定制。- 文档问答系统：GPT可以用于构建基于上下文、对文档的问答系统。- 实用功能：GPT可用于自动化需要基本语言理解的任务，如生成单元测试、查找文档、重写功能或检查品牌一致性。- 创意创作：GPT可以用于在各个领域生成想法、可能性或建议，包括写作、营销和研究。通过将GPT的生成能力与专业领域的知识相结合，用户可以创建更有针对性和相关性的输出。- Baby AGI或多步计划机器人：GPT可以放入一个循环中，与自己对话并指导自己的行动，从而创建一个基于一组工具和目标的自主执行任务或生成结果的自主代理。通过这个教程，可以大概了解GPT能做一些什么事情，以及背后的原理是什么。完整课程视频地址：www.youtube.com/watch?v=vw-KWfKwvTQedX:  还以为是两节。后来看了下YouTube是一节课。[开学季][开学季][开学季][开学季]Repost这条一开始被夹了，所以后来又发了一条，现在放出来了

#### [哈佛CS50课程节选：如何构建基于GPT-4的应用上一节  介绍了什么是GPT-4，这一节则是基于G @宝玉xp](https://weibo.com/1727858283/MFAoOmH9Z)

Note: 哈佛CS50课程节选：如何构建基于GPT-4的应用上一节  介绍了什么是GPT-4，这一节则是基于GPT-4可以构建什么样的应用，以及如何构建。这部分课程介绍了GPT-4可以构建的各种类型的应用，包括不限于：- 助手应用：GPT可以用于创建AI助手，帮助完成写作、编程或回答问题等任务。通过结合专业领域知识和用户的喜好，还可以对这些助手可以进一步定制。- 文档问答系统：GPT可以用于构建基于上下文、对文档的问答系统。- 实用功能：GPT可用于自动化需要基本语言理解的任务，如生成单元测试、查找文档、重写功能或检查品牌一致性。- 创意创作：GPT可以用于在各个领域生成想法、可能性或建议，包括写作、营销和研究。通过将GPT的生成能力与专业领域的知识相结合，用户可以创建更有针对性和相关性的输出。- Baby AGI或多步计划机器人：GPT可以放入一个循环中，与自己对话并指导自己的行动，从而创建一个基于一组工具和目标的自主执行任务或生成结果的自主代理。通过这个教程，可以大概了解GPT能做一些什么事情，以及背后的原理是什么。能上油管的也不用看鏈接了，隨便搜就有，要鏈接的上不了油管也沒用

#### [BigCode 推出了编程语言生成模型 StarCoderGithub地址：github.com/b @宝玉xp](https://weibo.com/1727858283/MFyYNhem5)

Note: BigCode 推出了编程语言生成模型 StarCoderGithub地址：github.com/bigcode-project/starcoderBigCode是 ServiceNow Inc. 和 Hugging Face Inc. 合作成立的。StarCoder 有多个版本。核心版本 StarCoderBase 具有 155 亿个参数，支持80多种编程语言，8192个token的上下文。视频为其vscode插件效果 回复:有学校邮箱的话是免费的我看到8192就知道它也是模改过来的感觉自己像个小白鼠，天天试这个试那个。然后还没有一款稳定好用便宜的产品100美元一年的github copilot x 太香了，对其它的竞品没有任何兴趣

Github: [github.com/bigcode-project/starcoderBigCode](github.com/bigcode-project/starcoderBigCode)

#### [对于ChatGPT引发的这次AIGC浪潮中，大家有个普遍共识，就是大语言模型会为人机交互带来革命性的 @宝玉xp](https://weibo.com/1727858283/N0lWDrtj1)

Note: 对于ChatGPT引发的这次AIGC浪潮中，大家有个普遍共识，就是大语言模型会为人机交互带来革命性的变化，但是发生什么样的变化目前还处于探索阶段。Google刚发表的一篇研究文章：《Enabling conversational interaction on mobile with LLMs | 在手机上实现与LLM的对话式互动》在文章中他们分享了他们是如何利用利用大型语言模型（LLMs）改进移动设备上的语言交互的，目标是让智能助手能够更好地理解和操作移动用户界面，尤其是在需要进行自然语言对话交互的场景中。LLM作为大语言模型是不能直接理解UI界面的，所以他们采用了一种算法，把UI界面转换成HTML语言，让LLM可以理解和操作界面。另外LLM在CoT（Chain of Thought链式思考）的帮助下是可以有一定推理能力的，所以他们也通过生成中间结果，并将它们连接再一起从而引导LLM进行逻辑推理。他们一共做了四个实验：（1）对UI界面提出问题，（2）对UI界面内容生成摘要，（3）对UI界面的问题进行回答，和（4）将用户命令翻译成UI操作指令。任务1：对UI界面提出问题这个任务是给LLM一个移动UI界面，让LLM可以针对界面提出系列与需要用户输入的UI元素相关的问题。比如给定一个Waze搜索实时火车时刻的UI界面，上面有火车编号、站名、日期三个输入框，那么LLM能准确的提出三个问题：1. 火车编号是什么？2. 站名是什么？3. 出发时间是什么？LLM甚至能够将相关的输入字段合并成一个问题，以实现高效的交流。例如，询问最小和最大价格的筛选器被合并成一个问题："价格范围是多少？"任务2：对UI界面内容生成摘要对UI界面内容生成摘要是指对给定的UI界面，摘要姓的描述屏幕的主要功能，以便帮助用户快速了解移动UI界面，这对于一些无法视觉上无法直接访问UI的场景下特别实用。实验结果显示，LLMs可以有效地总结移动UI界面的主要功能。有趣的是，LLMs在生成屏幕摘要时，甚至能推导出UI中的隐含信息。比如在一个地铁站名搜索的界面中，根据已经显示的站名，LLM推断出地铁站属于伦敦地铁系统，而UI中并没有任何位置包含伦敦地铁这个信息。任务3：对UI界面的问题进行回答给定一个移动UI界面和一个获取有关UI的信息相关的开放式问题，看LLM是否能提供正确的答案。实验中展示的是一个新闻阅读界面，LLM能准确的描述新闻标题、作者、时间等信息，甚至对于新闻中的内容的问题，也能准确回复。任务4：将用户命令翻译成UI操作指令给定一个移动UI界面和一个控制UI的自然语言命令，看LLM是不是能准确预测要执行的指令和要操作对象的ID。比如当指令是“打开Gmail”时，模型应正确地识别主屏幕上的Gmail图标。实验结果表明使用LLMs能够将自然语言命令能翻译成UI操作指令，尽管这些模型只使用了两个数据示例进行训练，但性能仍然可观。总结和结论根据Google的研究表明，与传统的机器学习流程相比（这些流程包括昂贵的数据收集和模型训练），其实我们可以使用LLM快速实现新的基于自然语言的交互，有效提升用户的体验。完整文章：论文地址：可能能突破app各自封锁的情况//:是的，或者开车、跑步的时候操作手机//:这对视力有障碍的人士很有用

#### [【MPT-7B：MosaicML发布的的MPT(MosaicML Pretrained Transf @爱可可-爱生活](https://weibo.com/1402400261/MFowE6kpq)

Note: 【MPT-7B：MosaicML发布的的MPT(MosaicML Pretrained Transformer)模型族，包括MPT-7B，一个从头开始训练的Transformer，用1T文本和代码Tokens进行训练。 MPT-7B在MosaicML平台上进行了9.5天的训练，没有人为干预，成本约为200,000美元，可用于商业用途。此外，MosaicML还发布了三个优化过的MPT-7B变体：MPT-7B-Instruct，MPT-7B-Chat和MPT-7B-StoryWriter-65k+，用于指令、对话生成和超长输入。所有模型都可用于预训练，微调和部署】《Introducing MPT-7B: A New Standard for Open-Source, Commercially Usable LLMs》  这帮原来FB出来的还挺强

Picture: [5396ee05ly8hdpg23mc5qj21jj0pgjxx.jpg](https://weibo.cn//mblog/pic/MFowE6kpq?rl=1)

#### [【多模态语言-图像数据集、LLaVA模型及在线Demo：利用语言模型生成多模态语言-图像指令遵循数据 @爱可可-爱生活](https://weibo.com/1402400261/MFp0mtK7f)

Note: 【多模态语言-图像数据集、LLaVA模型及在线Demo：利用语言模型生成多模态语言-图像指令遵循数据，并用这些数据训练出大型多模态模型LLaVA，用于通用的视觉和语言理解。用语言模型GPT-4生成多模态指令遵循数据，并在HuggingFace Dataset上公开了15.8万条样本；将预训练的CLIP ViT-L/14视觉编码器和大型语言模型LLaMA连接起来，并采用了两阶段的指令微调过程；在一个合成多模态指令遵循数据集上，LLaVA表现出了令人印象深刻的多模态聊天能力，有时甚至展现出了多模态GPT-4的行为，并获得了85.1%相对于GPT-4的得分；在Science QA数据集上，LLaVA和GPT-4的协同达到了92.53%的新的最佳准确率】“Visual Instruction Tuning - LLaVA: Large Language and Vision Assistant”  

Picture: [5396ee05ly8hdpi4otapoj20u00x5wim.jpg](https://weibo.cn//mblog/pic/MFp0mtK7f?rl=1)

#### [【OpenAlpaca: 基于OpenLLaMA的开源指令遵循模型，可根据给定的指令和输入生成相应的 @爱可可-爱生活](https://weibo.com/1402400261/MFp2XwiTD)

Note: 【OpenAlpaca: 基于OpenLLaMA的开源指令遵循模型，可根据给定的指令和输入生成相应的输出。基于LLaMA模型，可以处理多种语言任务；在一个由约15k条样本组成的数据集上对LLaMA模型进行了微调，该数据集是从databricks-dolly-15k数据集中筛选出来的，适合指令遵循任务】’OpenAlpaca: A Fully Open-Source Instruction-Following Model Based On OpenLLaMA' Yixuan Su GitHub: github.com/yxuansu/OpenAlpaca  

Picture: [5396ee05ly8hdpiddossmj20u01100ye.jpg](https://weibo.cn//mblog/pic/MFp2XwiTD?rl=1)

Github: [github.com/yxuansu/OpenAlpaca](github.com/yxuansu/OpenAlpaca)

#### [【libvits-ncnn：VITS库的ncnn实现，可实现跨平台GPU加速语音合成。使用ncnn库 @爱可可-爱生活](https://weibo.com/1402400261/MFq8tbaeE)

Note: 【libvits-ncnn：VITS库的ncnn实现，可实现跨平台GPU加速语音合成。使用ncnn库实现深度学习推理，并支持CPU和GPU上的推理】'libvits-ncnn - libvits-ncnn is an ncnn implementation of the VITS library that enables cross-platform GPU-accelerated speech synthesis.' SgDylan GitHub: github.com/Sg4Dylan/libvits-ncnn  

Picture: [5396ee05ly8hdpn8bzh5ej215c0amwg2.jpg](https://weibo.cn//mblog/pic/MFq8tbaeE?rl=1)

Github: [github.com/Sg4Dylan/libvits-ncnn](github.com/Sg4Dylan/libvits-ncnn)

#### [【llm：可以在CPU上用Rust运行大型语言模型的推理。Rust可以实现快速的运行速度，相比于GP @爱可可-爱生活](https://weibo.com/1402400261/MFq9EqRBK)

Note: 【llm：可以在CPU上用Rust运行大型语言模型的推理。Rust可以实现快速的运行速度，相比于GPU更加节能】'llm - Run inference for Large Language Models on CPU, with Rust' Rustformers GitHub: github.com/rustformers/llm   

Picture: [5396ee05ly8hdpnaq1527j20e80e8jt5.jpg](https://weibo.cn//mblog/pic/MFq9EqRBK?rl=1)

Github: [github.com/rustformers/llm](github.com/rustformers/llm)

#### [【VardaGPT：在GPT-2模型基础上添加了一种称为关联记忆(associative memor @爱可可-爱生活](https://weibo.com/1402400261/MFqsj1wb0)

Note: 【VardaGPT：在GPT-2模型基础上添加了一种称为关联记忆(associative memory)的机制。关联记忆可以使模型在处理文本时更好地捕捉上下文信息。通过对比GPT-2和VardaGPT在多个NLP任务上的表现，证明了VardaGPT在一些任务上表现更好】'VardaGPT - Associative memory-enhanced GPT-2 model' ixaxaar GitHub: github.com/ixaxaar/VardaGPT  

Picture: [5396ee05ly8hdpnygmyizj20rk0bbq3t.jpg](https://weibo.cn//mblog/pic/MFqsj1wb0?rl=1)

Github: [github.com/ixaxaar/VardaGPT](github.com/ixaxaar/VardaGPT)

#### ['Panda: 海外中文开源大语言模型，基于 Llama-7B, -13B, -33B, -65B  @CFC4N](https://weibo.com/1377342605/MFs4Q4HV0)

Note: 'Panda: 海外中文开源大语言模型，基于 Llama-7B, -13B, -33B, -65B 进行中文领域上的持续预训练，使用了接近15M条数据，并针对推理能力在中文benchmark上进行了评测’ dandelionsllm GitHub: github.com/dandelionsllm/pandallm   

Picture: [5396ee05ly8hdlf90b1l5j20ui0u0tcw.jpg](https://weibo.cn//mblog/pic/MERI7frV2?rl=1)

Github: [github.com/dandelionsllm/pandallm](github.com/dandelionsllm/pandallm)

#### [《性能之巅 第2版》读书笔记 （第10章）1、带宽是指网络类型能够支持的最大数据传输速率。例如，10 @小川CD](https://weibo.com/1202332555/MFtjcvmRe)

Note: 《性能之巅 第2版》读书笔记 （第10章）1、带宽是指网络类型能够支持的最大数据传输速率。例如，100GbE表示带宽为100GB/s的以太网，其中每个方向都可能存在带宽限制。因此，100GbE可能以100Gb/s的速度传输数据，并以同样的速度接收数据（总吞吐量为200Gb/s）。2、网络延时可以指信息在端点之间往返所需的时间，也可以指建立连接所需的时间（例如TCP握手）。3、系统的可调参数也会影响协议的性能，例如缓冲区大小、算法以及不同的计时器设置。4、数据包的大小和有效载荷会影响性能，较大的数据包会提高吞吐量并减少数据包的开销。5、以太网支持接近9000B的特大包（帧），也称为巨型帧。这能够提高网络吞吐性能，同时由于需要传输的包更少，也会降低数据传输延时。6、使用ping命令可以测量ICMP的echo请求到echo响应所需的时间。该时间用来衡量主机之间包括网络跳跃的网络延迟，同时测量的是网络请求往返的总时间。7、往返时间（RTT）描述了网络请求在端点之间往返所需的时间。这包括信号传播时间和每一跳网络的处理时间。8、如果数据包长时间在队列中等待，那么在这些组件中使用的高缓冲可能导致所谓的缓冲膨胀问题。这可能会引发主机中的TCP阻塞避免（功能），进而限制网络性能。9、另一种类型的缓冲用于最初的连接请求。TCP的积压队列实现会把SYN请求在用户级进程接收前列队于内核中。积压队列丢包和SYN重传都说明了主机过载。10、接口协商是一种机制，当对端不能支持更高的速率，或者不能处理连接介质的物理问题（例如线路故障）时，会自动协商使用较低的速度。11、由于网络是一个共享资源，当网络流量负荷较高时，会发生拥塞。这可能导致性能问题，例如路由器或交换机可能会丢弃数据包，进而触发TCP重传，增加延迟。12、计算网络接口的使用率可以使用当前吞吐量除以最大带宽。一般来说，服务器更注重数据传输，而客户端更注重数据接收。一旦一个网络接口的使用率达到100%，它就会成为性能瓶颈，限制整个系统的性能。13、TCP具有许多性能特性，例如可变窗口、阻塞避免、缓存启动、选择确认（SACK）、快速重传、快速恢复、TCP快速打开、TCP时间戳、TCP SYN cookies。14、拥塞控制算法有许多种，例如Reno、Tahoe、CUBIC、BBR和DCTCP。选择不同的拥塞控制算法会对网络性能产生很大的影响。15、UDP协议头简单而短小，降低了计算和大小带来的系统开销。该协议是无状态的，从而降低了连接和传输控制的系统开销。UDP不会重新传输丢失的数据包，而重传增加了TCP连接的延迟。16、网卡端口的传输带宽受限于PCIe总线的带宽。17、在具有多个路由器和主机的网络中，由于主机之间有多个可能的路径，数据包可能会被乱序传输，这会影响TCP的性能。此外，网络中的某个路由器饱和可能导致网络性能变差。18、如果没有网络数据包的CPU负载均衡策略，一个网卡可能只会中断一个CPU，导致该CPU达到100%的使用率并成为性能瓶颈。可以使用irqbalance进程将中断请求分配给多个CPU。19、使用数据平面开发工具包（DPDK）等技术，应用程序可以绕过内核网络栈，从而实现更高的数据包率和性能。20、TCP重传统计信息通常可用作网络拥塞程度的指标。然而，这些信息是跨服务器和客户端衡量的，并且可能出现于任何一跳。

#### [【400+页的MIT强化学习课程免费教材，根据2019-2023的MIT强化学习课程内容整理而来，涵 @爱可可-爱生活](https://weibo.com/1402400261/MFyyBbo3X)

Note: 【400+页的MIT强化学习课程免费教材，根据2019-2023的MIT强化学习课程内容整理而来，涵盖了强化学习的基本概念、方法和应用，特别是近似动态规划、神经网络、策略迭代和蒙特卡洛树搜索等技术。参考页面提供了教科书、课程材料、视频讲座和研究论文的链接，是强化学习领域重要参考资源】《A Course in Reinforcement Learning》Dimitri P. Bertsekas  参考页面:哪位可以搬过来？

Picture: [5396ee05ly8hdqo8ho0v8j20u016z0w3.jpg](https://weibo.cn//mblog/pic/MFyyBbo3X?rl=1)

#### [【Transformers相关文献资源大列表，包含了各种各样的Transformer模型，例如BER @爱可可-爱生活](https://weibo.com/1402400261/MFA31l6yz)

Note: 【Transformers相关文献资源大列表，包含了各种各样的Transformer模型，例如BERT、GPT、Transformer-XL等，这些模型已经在许多自然语言处理任务中得到了广泛应用。此外，该列表还提供了这些模型的相关论文和代码链接，为自然语言处理领域的研究人员和开发者提供了很好的参考资源】’Awesome Transformers - A curated list of awesome transformer models.' Anton Bacaj GitHub: github.com/abacaj/awesome-transformers  

Picture: [5396ee05ly8hdquzrjuraj20xl0u0n0n.jpg](https://weibo.cn//mblog/pic/MFA31l6yz?rl=1)

Github: [github.com/abacaj/awesome-transformers](github.com/abacaj/awesome-transformers)

#### [【privateGPT：基于GPT4All-J的私有化部署文档问答平台，无需联网，能100%保证用户 @爱可可-爱生活](https://weibo.com/1402400261/MFA53g8fR)

Note: 【privateGPT：基于GPT4All-J的私有化部署文档问答平台，无需联网，能100%保证用户的隐私不泄露。提供了一个API，用户可以使用自己的文档进行交互式问答和生成文本。此外，平台支持自定义训练数据和模型参数，以满足个性化需求】'privateGPT - Interact privately with your documents using the power of GPT, 100% privately, no data leaks' Iván Martínez GitHub: github.com/imartinez/privateGPT  转发微博转发微博

Picture: [5396ee05ly8hdqv2r8twlj217e0u0dl2.jpg](https://weibo.cn//mblog/pic/MFA53g8fR?rl=1)

Github: [github.com/imartinez/privateGPT](github.com/imartinez/privateGPT)

#### [【Fast Safe Reinforcement Learning (FSRL)：基于PyTorch @爱可可-爱生活](https://weibo.com/1402400261/MFADWf8Nj)

Note: 【Fast Safe Reinforcement Learning (FSRL)：基于PyTorch的快速安全的强化学习库，旨在为研究人员和开发人员提供一个简单易用的平台，以实现各种强化学习算法的开发和测试。该库提供了多种常见的强化学习算法实现，包括DQN、DDPG和PPO等，同时还提供了多种模型架构和数据预处理方法的实现，例如卷积神经网络和循环神经网络等。该库还提供了一系列工具和实用程序，以方便用户进行模型训练、测试和评估。该库的性能优秀，可以支持高效的多进程并行计算和GPU加速】'Fast Safe Reinforcement Learning (FSRL) - A fast safe reinforcement learning library in PyTorch' Zuxin GitHub: github.com/liuzuxin/fsrl  

Picture: [5396ee05ly8hdqxlvigfbj214n0u0jyo.jpg](https://weibo.cn//mblog/pic/MFADWf8Nj?rl=1)

Github: [github.com/liuzuxin/fsrl](github.com/liuzuxin/fsrl)

#### [[LG]《AttentionViz: A Global View of Transformer At @爱可可-爱生活](https://weibo.com/1402400261/MFGQJanKe)

Note: [LG]《AttentionViz: A Global View of Transformer Attention》C Yeh, Y Chen, A Wu, C Chen, F Viégas, M Wattenberg [Harvard University] (2023)   

Picture: [5396ee05ly1hdroutsougj21o80asam9.jpg](https://weibo.cn//mblog/pic/MFGQC0vZN?rl=1)

#### [博文《内存百科全书》地址：www.biscuitos.cn/blog/Memory-Hardware @蚁工厂](https://weibo.com/2194035935/MFJAOjoxu)

Note: 博文《内存百科全书》地址：www.biscuitos.cn/blog/Memory-Hardware/内存作为计算机架构运行的必要硬件设备之一被开发者熟知，作为软件开发者更多认识的是内存的大小、NUMA NODE、Zone 等概念，而对于硬件开发者来说内存就是内存条、DRAM、PMEM 等硬件设备。因此从不同角度对内存都有不同的解读，本文用于帮助软件开发者和硬件开发者打破认知防线，通熟易懂的语言将内存进行讲解，以便开发者在日后的开发中方便使用。本文分作四个模块进行讲解，第一部分对与内存相关的术语进行图文并茂的讲解，第二个部分从整体架构角度对内存进行讲解，第三部分则是对软硬件工具的实践来认知内存，第四部分则是内存未来趋势讨论这个博客也是BiscuitOS开源项目的博客。BiscuitOS 是一个用于制作基于古老版本和最新版本 Linux 发行版的开源项目，其主要 目的是给开发者提供一个简单， 易用，有趣的 Linux 制作，运行和调试环境，让开发者 专注于代码调试，减少繁琐的移植和编译问题。里面还有很多其他的linux底层开发的文章。

Picture: [82c654dfly1h21ufe0ex9j20ox0q8wgo.jpg](https://weibo.cn//mblog/pic/Lsama4RZG?rl=1)

#### [技术博客《深入理解DALL-E》地址：sunlin-ai.github.io/2022/06/02/ @蚁工厂](https://weibo.com/2194035935/MFMlDBqVf)

Note: 技术博客《深入理解DALL-E》地址：sunlin-ai.github.io/2022/06/02/DALL-E.htmlDALL-E 可以让模型生成与给定文本提示相匹配的图像，除了创造性设计之外，transformer 似乎还了解一些常识性物理学和关于我们世界的知识。 我们不免产生一个疑问：它怎么这么好？没有人确切地知道为什么它会工作得这么好，甚至没有人知道他们实际学到了什么；没有深度学习的基本理论可以解释所有这些，目前来说，这些网络对于我们太大太复杂，无法完全理解。尽管如此，还是有一些普遍的直觉可以帮助理解这些模型的能力和局限性。 为了探索“它怎么这么好？”这个问题，下面的博客将分为两个不同的部分：1. 前半部分重点介绍 DALL-E 的不同部分如何组合在一起，以从文本提示中生成高质量图像。特别是，本节将着眼于 transformers 在这些方面所扮演的角色。2. 在了解 transformers 如何融入 DALL-E 架构的基础上，将关注 transformers 功能的更多哲学问题，例如“它怎么这么好？”以及“为什么 transformers 能够做到这一切？” 在这一部分中，我将较少关注 transformers 的技术细节，实际上已经有很多很棒的博客详细地涵盖了这个主题。我可以推荐 Jay Allamar 的 博客，以及哈佛 NLP 的 annotated transformer。 我也不会试图明确地回答这些问题，因为这些都是开放的研究问题，没有人真正知道问题答案，相反，我只会提出一些有趣的直觉，让我们更清楚地了解这些模型可以做什么，以及是怎样做到的。

#### [  说的这个逻辑学书单，我之前截图保存下来了。省略了每本书的简短描述后的书单如下，请注意其中的信息很 @蚁工厂](https://weibo.com/2194035935/MFN3L4jix)

Note:   说的这个逻辑学书单，我之前截图保存下来了。省略了每本书的简短描述后的书单如下，请注意其中的信息很多时候并不是最新版本的。Introductory Textbooks1. Ian Chiswell and Wilfrid Hodges. Mathematical Logic. Oxford University Press, 2007.2. Graeme Forbes. Modern Logic. Oxford University Press, 1994.3. L.T.F. Gamut. Logic, Language, and Meaning. University of Chicago Press, 1991.4. Gary Hardegree. Symbolic Logic: A First Course. Mcgraw-Hill, 2011.5. Colin Howson. Logic with Trees. Routledge, 1997.6. P.D. Magnus. forall x. Online.7. David Makinson. Sets, Logic and Maths for Computing. Springer, 2008.8. Patrick Suppes. Introduction to Logic. Van Nostrand Reinhold Company, 1957.9. Paul Tomassi. Logic. Routledge, 1999.Advanced Textbooks1. George Boolos, John Burgess and Richard Jeffrey. Computability and Logic. Cambridge University Press, 1974.2. Peter Cameron. Sets, Logic and Categories. Springer, 1998.3. Dirk van Dalen. Logic and Structure. Springer, 1980.4. Keith Devlin. The Joy of Sets. Springer, 1993.5. H. Ebbinghaus, J. Flum and W. Thomas. Mathematical Logic. Springer, 1996.6. Herbert Enderton. A Mathematical Introduction to Logic. Harcourt, 1972.7. Paul Halmos. Naive Set Theory. Springer, 1960.8. Wilfrid Hodges. Elementary Predicate Logic. In D. Gabbay and F. Guenthner. Handbook of Philosophical Logic, Volume 1. Springer, 2010.9. Elliott Mendelson. Introduction to Mathematical Logic. Chapman & Hall, 1964.Logic for Philosophy1. John Burgess. Philosophical Logic. Princeton University Press, 2012.2. Lou Goble (ed.). The Blackwell Guide to Philosophical Logic. Wiley-Blackwell, 2001.3. Lloyd Humberstone. The Connectives. MIT Press, 2011.4. Richard Kirkham. Theories of Truth: A Critical Introduction. The MIT Press, 1995.5. Graham Priest. An Introduction to Non-Classical Logic. Cambridge University Press, 2008.6. Theodore Sider. Logic for Philosophy. Oxford, 2010."Light" Reading1. Douglas Hofsadter. Gödel, Escher, Bach. Basic Books, 1979.2. Anita Feferman. From Trotsky to Gödel. A. K. Peters, 2000.3. Apostolos Doxiadis and Christos Papadimitriou. Logicomix. Bloomsbury, 2009.4. Martin Gardner. My Best Mathematical and Logic Puzzles. Dover, 2003.5. Raymond Smullyan. What is the Name of This Book? Dover, 2011.6. Raymond Smullyan. Forever Undecided. Oxford, 1988.

#### [[CL]《Vcc: Scaling Transformers to 128K Tokens or M @爱可可-爱生活](https://weibo.com/1402400261/MFQrWtnma)

Note: [CL]《Vcc: Scaling Transformers to 128K Tokens or More by Prioritizing Important Tokens》Z Zeng, C Hawkins, M Hong, A Zhang, N Pappas, V Singh, S Zheng [University of Wisconsin & AWS AI & University of Minnesota] (2023)   

Picture: [5396ee05ly1hdsv8xqi83j21am0wie24.jpg](https://weibo.cn//mblog/pic/MFQrUb02x?rl=1)

#### [OpenAI的竞争对手Anthropic（其产品Claude一般被认为是能力最接近ChatGPT的人 @蚁工厂](https://weibo.com/2194035935/MFRh10hbh)

Note: OpenAI的竞争对手Anthropic（其产品Claude一般被认为是能力最接近ChatGPT的人工智能），推出了一份适用于其产品Claude的“宪法”，确定其产品更安全。本文还介绍了应该在模型训练的哪个阶段应用这部“宪法”来确保其效果。其内容除了常见的价值观外，还特别提到了“鼓励考虑非西方观点的原则”，让模型“选择最不可能被非西方观众视为有害或冒犯的回应。”在特定时间段，发扬自己的竞品优势特点，扬长避短。

#### [Meta ImageBind 多模态模型开源，让AI像人一样感受世界。当人类看到一辆行驶中的火车，不 @蚁工厂](https://weibo.com/2194035935/MFRvc8Sr9)

Note: Meta ImageBind 多模态模型开源，让AI像人一样感受世界。当人类看到一辆行驶中的火车，不仅会使用视觉，还会听到声音，感知距离，感知速度。ImageBind 也是类似，它将六种数据，文本，音频，视觉，运动，温度，深度，嵌入到一个向量空间，让模型像千脑智能那样，调动不同的感知区域进行「交谈」并做出全面的解释和判断。（这与文心一言等模型每个模态有自己嵌入空间的所谓多模态截然不同。）一些应用（见图）：- 通过火车的声音、图像、深度信息，生成准确的文字描述- 通过鸽子的图片和摩托的声音，减缩到摩托车和鸽子的图像- 通过企鹅的声音，生成企鹅的图像另一些可能性：- 拍摄一段海洋日落的视频，自动生成完美的音频剪辑。- 通过静态图像和音频组合，创建动画。- 通过Make-A-Video生成视频时，自动加上背景音。（飞狗图）未来不止于此，模型还可以引入更多的模态，如触觉、语音、嗅觉和大脑 fMRI 信号，以增强模型对实体世界的感知。

Picture: [006qCzTzgy1hdszwvlltvj30z40p8dj4.jpg](https://weibo.cn//mblog/pic/MFRuxBufa?rl=1)

#### [【TinyAudio：跨平台的音频输出库，其主要目标是尽可能简单地提供统一的访问操作系统默认音频输出 @爱可可-爱生活](https://weibo.com/1402400261/MFTlkenTd)

Note: 【TinyAudio：跨平台的音频输出库，其主要目标是尽可能简单地提供统一的访问操作系统默认音频输出设备的方法，覆盖尽可能多的平台，如PC（Windows，Linux，macOS），移动设备（Android，iOS）和WebAssembly。该库接收数据并将其发送到默认的操作系统的音频输出设备。使用浮点音频样本并自动将其转换为最接近的支持的平台相关格式】'TinyAudio - TinyAudio is a cross-platform audio output library' Dmitry Stepanov GitHub: github.com/mrDIMAS/tinyaudio  

Picture: [5396ee05ly8hdt85bzebbj217g0rodm2.jpg](https://weibo.cn//mblog/pic/MFTlkenTd?rl=1)

Github: [github.com/mrDIMAS/tinyaudio](github.com/mrDIMAS/tinyaudio)

#### [为了更好地理解Meta新发布的ImageBind，我将Meta AI官方blog中关于ImageBi @蚁工厂](https://weibo.com/2194035935/MFV0T0pFE)

Note: 为了更好地理解Meta新发布的ImageBind，我将Meta AI官方blog中关于ImageBind的完整介绍灌给GPT4做了个总结：Meta的ImageBind的主要创新在于它能够使用图像将各种不同的模态绑定在一起，创建一个统一的嵌入空间。这个空间包括了文本、图像、音频，以及更为复杂的模态，如深度（3D）、热度（红外辐射）和惯性测量单元（IMU）的数据。这种方法突破了传统需要为所有可能的数据组合收集配对数据的限制。它利用图像与其他模态的自然配对，使得ImageBind不仅能处理与图像强相关的模态（如热度和深度），而且还能处理与图像关联性较弱的模态（如音频和IMU）。这种创新为我们提供了一种全新的方式，使AI能够更接近人类的学习方式，从多种不同形式的信息中进行学习，并建立全面的理解。ImageBind的这种多模态学习能力，为AI在多个领域的应用提供了新的可能性。例如，在媒体制作中，ImageBind可以让创作者通过音频提示来生成与之相匹配的图像或视频，为创作提供更多灵感。在教育领域，ImageBind可以将文字、图像和声音相结合，创造出更为丰富多元的学习资源。对于虚拟现实或增强现实的开发者，ImageBind的这种多模态绑定能力也有望提供更为深度和全面的用户体验。不仅如此，ImageBind还可以应用于搜索引擎和社交媒体平台，提供更准确的内容推荐和搜索结果。例如，用户可以通过提交一个音频文件，搜索与之相关的图像或视频内容，或者通过描述一个场景，搜索出包含相应音频元素的视频。此外，这项技术也可以用于智能安全系统，例如，通过识别声音和图像的组合，来提高对异常活动的检测精度。总的来说，ImageBind的出现是多模态学习领域的一个重大突破，它为人工智能的未来开辟了新的可能性。ImageBind不仅证明了AI的持续进步，也使我们离创建真正的多感官AI又近了一步。原文地址：ai.facebook.com/blog/imagebind-six-modalities-binding-ai/

#### [Shap-E: Generating Conditional 3D Implicit Functio @AMiner学术头条](https://weibo.com/1870858943/MFViGBH03)

Note: Shap-E: Generating Conditional 3D Implicit Functions Heewoo Jun, Alex NicholAI综述：本文介绍了一个名为Shap-E的条件生成模型，用于生成3D模型。该模型直接生成参数，可以呈现为文本化网格和神经辐射域。该模型的训练分为两个阶段：第一阶段训练一个编码器将3D模型映射为隐含函数的参数，第二阶段训练一个对编码器的输出进行条件扩散模型。该模型在大规模数据集上进行训练后，可以在数秒内生成复杂和多样化的3D模型。相比于之前的基于点云的生成模型，Shap-E收敛更快，样本质量也更好。该模型的权重、推理代码和样本已在github上公开发布。

Picture: [6f830abfly1hdtgt8oj56j20fo0hctbw.jpg](https://weibo.cn//mblog/pic/MFViGBH03?rl=1)

#### [Distilling Step-by-Step! Outperforming Larger Lang @AMiner学术头条](https://weibo.com/1870858943/MFVzj30CE)

Note: Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes AI综述：该研究说明了使用较少的训练数据和更小的模型大小可以比大型语言模型实现更好的性能，而“Distilling step-by-step”是一种新的机制，可以通过在多任务训练框架下提取LLM合理化的附加监督来训练小型模型，从而实现以上优势。看着不错，希望不需要太大的算力

Picture: [6f830abfly1hdti07ficrj20ok0vi7k3.jpg](https://weibo.cn//mblog/pic/MFVzj30CE?rl=1)

#### [系列博文《从零开始的算法竞赛入门教程》地址：forever97.github.io/categori @蚁工厂](https://weibo.com/2194035935/MFW25uiuv)

Note: 系列博文《从零开始的算法竞赛入门教程》地址：forever97.github.io/categories/🍭算法幼儿园/针对没有任何编程经验的同学写一份C++的教程是十分困难的，因为C++光是语法部分就能填充一本如同字典一般厚的书，而在算法竞赛中，我们仅仅是选择学习一些需要用到的，足以完成问题求解即可学习程序语言和学习语言的过程是类似的，可以通过反复地模仿来熟悉，不断地尝试来积累，然后慢慢地能够做到自我创造，所以呢，不要踌躇不前，不要觉得难以下手，去模仿，去写去尝试本教程基于USACO Training，结合题目内容讲解，随缘更新

Picture: [82c654dfly1h2341nlkdfj20u00zsju9.jpg](https://weibo.cn//mblog/pic/LskH99rNg?rl=1)

#### [MetaAI 重磅开源 ImageBind，可让模型跨 6 种不同的模态（图像、文本、音频、深度、热 @宝玉xp](https://weibo.com/1727858283/MFPm4sMtP)

Note: MetaAI 重磅开源 ImageBind，可让模型跨 6 种不同的模态（图像、文本、音频、深度、热能和 IMU 数据）进行联动！基于该项目，开发者可以「开箱即用」实现包括跨模态检索、使用算术合成模态、跨模态检测和生成等各类新兴应用。详细介绍：借助 ImageBind，则可以做到直接通过声音来直接生成图像。这使得 AI 能够更加深入了解人类情感，理解他们的喜怒哀乐，进而为人类提供更好的服务。当你举起手机，录制一个海边日落的视频时，AI 便能自动根据视频内容来生成文案和字幕，并匹配上合适的背景音乐。甚至 AI 还有可能通过一首歌，直接为歌手生成一段视频 MV。此举将为 AIGC 技术带来更为广泛的应用场景，一大波更为有趣、实用的 AI 项目也即将来袭。GitHub：github.com/facebookresearch/ImageBind

Github: [github.com/facebookresearch/ImageBind](github.com/facebookresearch/ImageBind)

#### [OpenAI的竞争对手Anthropic（其产品Claude一般被认为是能力最接近ChatGPT的人 @宝玉xp](https://weibo.com/1727858283/MFRny8uqC)

Note: OpenAI的竞争对手Anthropic（其产品Claude一般被认为是能力最接近ChatGPT的人工智能），推出了一份适用于其产品Claude的“宪法”，确定其产品更安全。本文还介绍了应该在模型训练的哪个阶段应用这部“宪法”来确保其效果。其内容除了常见的价值观外，还特别提到了“鼓励考虑非西方观点的原则”，让模型“选择最不可能被非西方观众视为有害或冒犯的回应。”

#### [万字长文，讲述《ChatGPT 背后的语言模型简史》。内容覆盖自然语言处理、神经网络、深度学习、生成 @宝玉xp](https://weibo.com/1727858283/MFSr9hAa4)

Note: 万字长文，讲述《ChatGPT 背后的语言模型简史》。内容覆盖自然语言处理、神经网络、深度学习、生成式预训练等技术发展历史，值得一读。地址： //:转发微博这个突触和卷积神经网络的感受野有什么区别？

Picture: [006fiYtfgy1hdsk2zpas8j317i1g8tor.jpg](https://weibo.cn//mblog/pic/MFR9YwqiC?rl=1)

#### [OpenAI发布的神经元查看器网页还做的蛮酷的，可以按照Layer和Index两个坐标点查看神经元， @宝玉xp](https://weibo.com/1727858283/MFT04Dmom)

Note: OpenAI发布的神经元查看器网页还做的蛮酷的，可以按照Layer和Index两个坐标点查看神经元，也可以从首页选择或者输入坐标，或者随机选择一个查看。比如进入单词“by”对应的神经元，可以看到GPT-4生成的解释以及打分，再往后就超出我知识范围了，感觉像是当时训练的时候跟这个token相关的文本内容。测试地址：回复:网络环境问题…没办法回复:这个我也不懂您好，我想请教登陆的问题，但是信息发了一个图片就发不出去了[苦涩]，可以的话，我想请教您一个chatgpt的使用问题，就是我的号在使用期间，会有时候出现没有对话框，对话框发不出去的问题，最近在登陆时候提示我有可以的登陆可能会被block，请问怎么解决呢？

Picture: [66fd066bgy1hdt6gfpom9j22wq1piqjz.jpg](https://weibo.cn//mblog/pic/MFT04Dmom?rl=1)

#### [系列博文《从零开始的算法竞赛入门教程》地址：forever97.github.io/categori @敖天羽](https://weibo.com/1888981347/MFWMSDMOG)

Note: 系列博文《从零开始的算法竞赛入门教程》地址：forever97.github.io/categories/🍭算法幼儿园/针对没有任何编程经验的同学写一份C++的教程是十分困难的，因为C++光是语法部分就能填充一本如同字典一般厚的书，而在算法竞赛中，我们仅仅是选择学习一些需要用到的，足以完成问题求解即可学习程序语言和学习语言的过程是类似的，可以通过反复地模仿来熟悉，不断地尝试来积累，然后慢慢地能够做到自我创造，所以呢，不要踌躇不前，不要觉得难以下手，去模仿，去写去尝试本教程基于USACO Training，结合题目内容讲解，随缘更新懂了，转了就是学了

Picture: [82c654dfly1h2341nlkdfj20u00zsju9.jpg](https://weibo.cn//mblog/pic/LskH99rNg?rl=1)

#### [再多说一句，谷歌昨天晚上涨了4%（FAANG里涨幅居前），人家是卖搜索卖软件卖系统出身的。PaLM  @月风_投资笔记](https://weibo.com/1670659923/N035wzwtp)

Note: 再多说一句，谷歌昨天晚上涨了4%（FAANG里涨幅居前），人家是卖搜索卖软件卖系统出身的。PaLM 2现在能全面接入各种办公场景，正面pk微软copilot；而且能提供四种尺寸，从最小到最大：Gecko、Otter、Bison 和 Unicorn。其中Gecko 非常轻巧，前面也说了可以在移动设备上工作，而且离线也可用。通俗的讲，就是摆脱了智障属性的SIRI，而且可以从安卓的底层架构上整合所有应用，这个太吓人了，所以股价有这么大反应。外网有人把这个类比下一个安卓/iOS时代了。所以哪家安卓厂商第一个采用？从底层架构整合应用，打通连接手机上的所有app，用户通过语音发出一个指令（帮我买一张电影票，定一个外卖，买个菜…），系统自动调用app，执行指令，用户只需要确认就最终完成。用的越多越频繁，就越来越个性化人性化，变成私人助理般的存在。二大休息时候，希望月风顶上。不然我微博没啥看了回复:巧了，我也基本只看这二位，微博是为了e大下载的回复:你当我是fbi，互联网公司，外贸公司哪个没有翻墙，你去告呗回复:搜搜网上判的才几个，而且都是因为什么被判，每天翻墙的不知凡几是他们发布会有啥信息？智能终端：传音转发微博回复:国内的荣耀，哈哈哈哈回复:实时翻译有点做梦吧，这不得先审核一遍?万一你看到了不好的内容咋办，尤其还是全民通用性的功能。

Picture: [63943f53ly1hdu3ta2nthj20zo256kaj.jpg](https://weibo.cn//mblog/pic/N035wzwtp?rl=1)

#### [谷歌宣布推出PaLM 2，具有更强大的多语言、推理和编码能力PaLM 2的“多语言性”得到了改进，因 @宝玉xp](https://weibo.com/1727858283/N01WOr4sR)

Note: 谷歌宣布推出PaLM 2，具有更强大的多语言、推理和编码能力PaLM 2的“多语言性”得到了改进，因为它在超过100种语言的多语言文本上接受了“更加严格的训练”。这使得它在理解、生成和翻译如成语、诗歌和谜语等细微的文本方面具有“显著改善”的能力。PaLM 2运行更快，推理能力更强，支持25个谷歌产品谷歌今天宣布推出PaLM 2，具有更强大的多语言、推理和编码能力。这个“下一代语言模型”运行速度更快、更高效，为25个一方产品和功能提供支持。2022年，谷歌发布了Pathways语言模型（PaLM），其“Pathways” AI架构可以“训练一个模型来完成数千或数百万种任务。”PaLM 2在“多语言性”方面有所改进，因为它在超过100种语言的多语言文本上接受了“更加严格的训练”。这使得它在理解、生成和翻译如成语、诗歌和谜语等细微的文本方面具有“显著改善”的能力。在推理方面，PaLM 2的数据集包括科学论文和带有数学表达式的网页，以提高逻辑、常识推理和数学能力。最后，它在大量公共源代码数据集上进行了预训练。除了Python和JavaScript外，还包括生成Prolog、Fortran和Verilog等专用代码。PaLM 2将提供四种以动物为灵感命名的尺寸（壁虎、水獭、野牛和独角兽）：壁虎（Gecko）非常轻巧，可以在移动设备上运行，即使在离线状态下，也能为设备提供足够快速的交互式应用。这种多功能性意味着PaLM 2可以通过更多方式进行微调，以支持更多产品类别，帮助更多人。具体来说，壁虎（Gecko）每秒可以处理20个令牌，并已在最新的手机上进行了测试，尽管谷歌并未说明具体是哪些设备。在2023年的Google I/O大会上，谷歌分享了PaLM 2正在为25个产品提供支持。它已被Bard用于编码，以及扩展到韩语和日语，并应用于Workspace。还有Med-PaLM 2（“回答各种密集医学文本的问题并总结见解”）和用于网络安全的Sec-PaLM。它还支持谷歌云的Duet AI。Technical Report：https://ai.google/static/documents/palm2techreport.pdfPALM 2的大小算是个亮点 感觉它应该比chinchilla 要小 不过各种reasoning task 像GSM8K BBH MMLU分数都还不错回复:目前还是PPT回复:已经在研究通过语言模型增强工业控制中，希望管理好物理世界AI的触达边界，避免它们自己设计出终结者就可以普通小白怎么用？回复:只有进化时，没有完成时，恐怖如斯 非常期待[开学季]

Picture: [66fd066bgy1hdtyt5qefzj21jy0vgao3.jpg](https://weibo.cn//mblog/pic/N01WOr4sR?rl=1)

#### [Google IO 2023 视频浓缩精华版（中英文字幕）：1. Pixel 7a：新款手机，搭载T @宝玉xp](https://weibo.com/1727858283/N03NIEeLR)

Note: Google IO 2023 视频浓缩精华版（中英文字幕）：1. Pixel 7a：新款手机，搭载Tensor G2芯片，8GB RAM，相机升级，售价499美元。2. Pixel Tablet：11英寸高分辨率显示屏，四个内置扬声器，搭载Tensor G2芯片，具有长久电池寿命和先进的人工智能。提供首个充电扬声器基座，价格为499美元。3. Pixel Fold：可折叠手机，具有Tensor G2芯片和AI创新，售价未公布。4. Help Me Write：Gmail中的AI辅助写作功能。5. Maps中的Immersive View for Routes：全新的路线展示方式，预计今年底将在15个城市推出。6. Magic Editor：Google Photos中的图片编辑功能。7. Bard：支持20多种编程语言的代码生成器，已开放给全球180多个国家和地区。8. Workspace：实时协作功能，将AI整合到Google Docs和Sheets中。9. RCS：一种现代化的信息技术标准，取代旧的SMS和MMS技术。10. Magic Compose：增强表情符号的功能。11. Cinematic和Emoji Wallpaper：将普通照片转换为3D壁纸和表情符号壁纸。Google IO强调了AI在多个领域的应用，帮助人们在关键时刻更好地实现目标。这些创新产品和功能将不断完善和扩展，以满足用户的需求。 能在Tensor G2 edgeTPU上运行Gecko模型，直接取代Siri，安卓再次伟大 up回复:我们咖啡市不吃大饼的回复:你看，你也操了不是！回复:可惜好像只有128G回复:吃着大饼操美国心❤️能在Tensor G2 edgeTPU上运行Gecko模型，直接取代Siri，安卓再次伟大 回复:好像美国那边工资就是美元吧回复:499美元 8G ram 存储多大还不清楚回复:有没有可能，那是美元up

#### [昨天看OpenAI发表的《Language models can explain neurons i @宝玉xp](https://weibo.com/1727858283/N05r7AVAd)

Note: 昨天看OpenAI发表的《Language models can explain neurons in language models》论文，是一个独立的小网站，虽然界面比较简单，但是交互做的挺好的，前端是React写的，于是尝试了一下把它本地跑起来了。完整代码放GitHub了，有兴趣的话你也可以运行一下，或者你有自己的论文要类似的交互，可以直接借鉴一下。项目地址：🔗github.com/JimLiu/neuron-explainer-paper🔗论文地址：

Picture: [66fd066bgy1hdudqun916j227i1s27wh.jpg](https://weibo.cn//mblog/pic/N05r7AVAd?rl=1)

Github: [github.com/JimLiu/neuron-explainer-paper](github.com/JimLiu/neuron-explainer-paper)

#### [：privateGPT基于私有LLM（大语言模型）做个人的文档问答，不必担心隐私泄露技术栈是 Lan @宝玉xp](https://weibo.com/1727858283/N0a4sxgys)

Note: ：privateGPT基于私有LLM（大语言模型）做个人的文档问答，不必担心隐私泄露技术栈是 LangChain 和 GPT4All- LLM默认用的 ggml-model-q4_0.bin.- Embedding默认用的是 ggml-model-q4_0.bin当然你可以自己替换，不过对中文支持应该不会太好。🔗github.com/imartinez/privateGPT🔗是的，感觉这个langchain-chatglm更完善一些中文可以用langchain-chatglm

Picture: [66fd066bgy1hduyswhj7zj21e40gs46z.jpg](https://weibo.cn//mblog/pic/N0a4sxgys?rl=1)

Github: [github.com/imartinez/privateGPT](github.com/imartinez/privateGPT)

#### [【关于寻找、开发和运行系统性交易（量化交易）策略的资源论文、软件、书籍、文章清单】'Awesome  @爱可可-爱生活](https://weibo.com/1402400261/N05qkgfxG)

Note: 【关于寻找、开发和运行系统性交易（量化交易）策略的资源论文、软件、书籍、文章清单】'Awesome Systematic Trading - A curated list of awesome libraries, packages, strategies, books, blogs, tutorials for systematic trading.' Edouard d'Archimbaud GitHub: github.com/edarchimbaud/awesome-systematic-trading/blob/main/README_zh.md  

Picture: [5396ee05ly8hduea074w3j210g0u077p.jpg](https://weibo.cn//mblog/pic/N05qkgfxG?rl=1)

Github: [github.com/edarchimbaud/awesome-systematic-trading/blob/main/README_zh.md](github.com/edarchimbaud/awesome-systematic-trading/blob/main/README_zh.md)

#### [【关于Whisper的相关资源大列表】’Awesome list for Whisper — an  @爱可可-爱生活](https://weibo.com/1402400261/N05jWiG3C)

Note: 【关于Whisper的相关资源大列表】’Awesome list for Whisper — an open-source AI-powered speech recognition system developed by OpenAI' Sindre Sorhus GitHub: github.com/sindresorhus/awesome-whisper    

Picture: [5396ee05ly8hdudthe96tj20aq0vqta5.jpg](https://weibo.cn//mblog/pic/N05jWiG3C?rl=1)

Github: [github.com/sindresorhus/awesome-whisper](github.com/sindresorhus/awesome-whisper)

#### [【OpenGPT：用于创建基于指令的数据集并训练对话领域专家大型语言模型(LLMs)的框架。已经成功 @爱可可-爱生活](https://weibo.com/1402400261/N05pzf2IH)

Note: 【OpenGPT：用于创建基于指令的数据集并训练对话领域专家大型语言模型(LLMs)的框架。已经成功应用于训练健康护理对话模型NHS-LLM，利用来自英国国家卫生服务体系(NHS)网站的数据，生成了大量的问答对和独特对话。此外，OpenGPT还提供了如何创建并训练一个小型健康护理对话LLM的教程】'OpenGPT - A framework for creating grounded instruction based datasets and training conversational domain expert Large Language Models (LLMs).' CogStack GitHub: github.com/CogStack/OpenGPT  

Picture: [5396ee05ly8hdue7cfrs7j210m0o4wi5.jpg](https://weibo.cn//mblog/pic/N05pzf2IH?rl=1)

Github: [github.com/CogStack/OpenGPT](github.com/CogStack/OpenGPT)

#### [【LLMTune: 在消费级GPU上微调大型65B+LLM。可以在普通消费级GPU上进行4位微调，例 @爱可可-爱生活](https://weibo.com/1402400261/N0d0gC2yM)

Note: 【LLMTune: 在消费级GPU上微调大型65B+LLM。可以在普通消费级GPU上进行4位微调，例如最大的65B LLAMA模型。LLMTune还实现了LoRA算法和GPTQ算法来压缩和量化LLM，并通过数据并行处理大型模型。此外，LLMTune提供了命令行界面和Python库的使用方式】’LLMTune: 4-Bit Finetuning of LLMs on a Consumer GPU - 4-Bit Finetuning of Large Language Models on One Consumer GPU' kuleshov-group GitHub: github.com/kuleshov-group/llmtune  转发微博

Picture: [5396ee05ly8hdvbphisgrj218n0u0q98.jpg](https://weibo.cn//mblog/pic/N0d0gC2yM?rl=1)

Github: [github.com/kuleshov-group/llmtune](github.com/kuleshov-group/llmtune)

#### [这两天最火的就是Meta的ImageBind和谷歌的PaLM2。一个开启AI感知物理世界的新纪元，一 @蚁工厂](https://weibo.com/2194035935/N0dCWyf5e)

Note: 这两天最火的就是Meta的ImageBind和谷歌的PaLM2。一个开启AI感知物理世界的新纪元，一个把AI植入自身庞大的业务群。相比之下，我还是更喜欢Meta的开源精神，也更期待ImageBind在未来会带来的惊喜，所以把ImageBind的介绍文章翻译了一下，希望对大家有用😄 

Picture: [006qCzTzgy1hdve41rrmcj31576he000.jpg](https://weibo.cn//mblog/pic/N0dz8uB7i?rl=1)

#### [【AudioDec: 开源的高保真神经音频流编解码器，适用于48 kHz单声道语音，比特率为12.8 @爱可可-爱生活](https://weibo.com/1402400261/N0em3ogCu)

Note: 【AudioDec: 开源的高保真神经音频流编解码器，适用于48 kHz单声道语音，比特率为12.8 kbps。在GPU(约6毫秒)和CPU(约10毫秒)上具有非常低的解码延迟。通过高效的两阶段训练，可以在几个小时内为新应用训练编码器】'AudioDec: An Open-source Streaming High-fidelity Neural Audio Codec - An Open-source Streaming High-fidelity Neural Audio Codec' Meta Research GitHub: github.com/facebookresearch/AudioDec  

Picture: [5396ee05ly8hdvhoialglj20b407kaap.jpg](https://weibo.cn//mblog/pic/N0em3ogCu?rl=1)

Github: [github.com/facebookresearch/AudioDec](github.com/facebookresearch/AudioDec)

#### [ImageBind: One Embedding Space To Bind Them All AI @AMiner学术头条](https://weibo.com/1870858943/N0fzalzBV)

Note: ImageBind: One Embedding Space To Bind Them All AI解读：该论文提出了一种称为ImageBind的方法，可以通过使用图像数据来训练一个联合嵌入空间，从而将不同的模态（图像、文本、音频、深度、热力和IMU数据）绑定在一起。ImageBind可以利用最近的大规模视觉-语言模型，并通过使用自然的图像配对来扩展它们的零-shot能力，以便对新的模态进行检索、组合、检测和生成。该方法在紧急零-shot识别任务方面设置了新的最先进水平，优于专业的监督模型，并且可以作为评估视觉模型视觉和非视觉任务的新方法。

Picture: [6f830abfly1hdvn1xuqm5j20yh0kpgy1.jpg](https://weibo.cn//mblog/pic/N0fzalzBV?rl=1)

#### [【Visual Blocks：Google的可视化编程框架，可以在无需编程的图形编辑器中创建机器学习 @爱可可-爱生活](https://weibo.com/1402400261/N0err14cS)

Note: 【Visual Blocks：Google的可视化编程框架，可以在无需编程的图形编辑器中创建机器学习(ML)流水线。可以通过连接拖放的ML组件(包括模型、用户输入、处理器和可视化)快速原型化工作流程。Visual Blocks提供了节点图编辑器、预置的ML模型和组件库以及输出展示和比较功能，旨在降低ML多媒体应用的开发门槛、加速工作流，并方便用户分享和发布应用】'Visual Blocks - Visual Blocks for ML is a Google visual programming framework that lets you create ML pipelines in a no-code graph editor. You – and your users – can quickly prototype workflows by connecting drag-and-drop ML components, including models, user inputs, processors, and visualizations.' Google  GitHub: github.com/google/visualblocks  

Github: [github.com/google/visualblocks](github.com/google/visualblocks)

#### [An Inverse Scaling Law for CLIP Training AI解读：这篇论文 @AMiner学术头条](https://weibo.com/1870858943/N0fCpkXWz)

Note: An Inverse Scaling Law for CLIP Training AI解读：这篇论文介绍了一个令人惊奇的发现，即CLIP训练存在一个反比例缩放定律，即使用更大的图像/文本编码器可以缩短能够在训练中应用的图像/文本令牌序列长度。通过降低CLIP训练的计算难度，作者希望鼓励更多学术领域的研究。该论文还介绍了一种减少图像/文本令牌长度的策略对于确定这种缩放法律的质量起着至关重要的作用，并展示了作者在使用学术资源进行训练的情况下取得的优秀结果。喔⊙ω⊙

Picture: [6f830abfly1hdvnaln71fj22240okqna.jpg](https://weibo.cn//mblog/pic/N0fCpkXWz?rl=1)

#### [EfficientViT: Memory Efficient Vision Transformer  @AMiner学术头条](https://weibo.com/1870858943/N0fU46JSi)

Note: EfficientViT: Memory Efficient Vision Transformer with Cascaded Group Attention AI解读：本文提出了一种名为EfficientViT的高速视觉Transformer模型，旨在解决现有Transformer模型存在的计算成本高和不够适合实时应用的问题。该模型采用一种新的构建模块，将单个内存受限的MHSA放置在高效的FFN层之间，提高了内存效率同时增强了通道通信。此外，本文还发现注意力图在不同头之间存在相似性，导致计算冗余，为此提出了一种分组级联注意力模块，用不同的特征划分反馈不同的头，既节省了计算成本，也提高了注意力多样性。综合实验证明，EfficientViT在速度和准确性方面表现出色，取得了良好的平衡。回复:谢谢！回复:你可以用ChatPaper功能快速了解论文，直接点击论文链接，直接在AI理解论文-ChatPaper就可以对话啦，转入隐私对话还可以边看论文边对话有详细解读吗 想深入了解下

Picture: [6f830abfly1hdvojtuxx2j20nf0fa0wm.jpg](https://weibo.cn//mblog/pic/N0fU46JSi?rl=1)

#### [并行编程很难吗？如果是，你能做些什么呢？ Is Parallel Programming Hard, @蚁工厂](https://weibo.com/2194035935/N0gpKbwdr)

Note: 并行编程很难吗？如果是，你能做些什么呢？ Is Parallel Programming Hard, And If So, What Can You Do About It?这是Paul E. McKenney写的一本电子书。下载链接：Paul E. McKenney是世并行编程专家，Linux 内核中 RCU 实现和 rcutorture 测试模块的维护者，也是RCU的发明人。对于实时操作系统内核同步机制（例如 Linux 中的实时 RCU）、Linux 和 UNIX 操作系统内核中的 SMP/NUMA 可扩展性和性能、网络性能分析、路由和拥塞控制， 嵌入式实时应用程序有着丰富的经验和研究。 现在FB工作。

Picture: [82c654dfly1h25cbotuvnj216s0t7di0.jpg](https://weibo.cn//mblog/pic/LsCThyTU6?rl=1)

#### [大语言模型（LLM）微调技术笔记地址：github.com/ninehills/ninehills. @蚁工厂](https://weibo.com/2194035935/N0gCIeDUc)

Note: 大语言模型（LLM）微调技术笔记地址：github.com/ninehills/ninehills.github.io/issues/92在预训练后，大模型可以获得解决各种任务的通用能力。然而，越来越多的研究表明，大语言模型的能力可以根据特定目标进一步调整。这就是微调技术，目前主要有两种微调大模型的方法1：指令微调，目标是增强（或解锁）大语言模型的能力。2：对齐微调，目标是将大语言模型的行为与人类的价值观或偏好对齐。

Github: [github.com/ninehills/ninehills.github.io/issues/92](github.com/ninehills/ninehills.github.io/issues/92)

#### [【关于大型语言模型增强推荐系统的论文清单，涵盖了推荐系统中的大型语言模型增强以及相关的研究方向】’A @爱可可-爱生活](https://weibo.com/1402400261/N0gR2faUi)

Note: 【关于大型语言模型增强推荐系统的论文清单，涵盖了推荐系统中的大型语言模型增强以及相关的研究方向】’Awesome-LLM4RS-Papers - Large Language Model-enhanced Recommender System Papers' Jiyuan Yang GitHub: github.com/nancheng58/Awesome-LLM4RS-Papers   

Picture: [5396ee05ly8hdvsqup7jgj20ur0u0wjx.jpg](https://weibo.cn//mblog/pic/N0gR2faUi?rl=1)

Github: [github.com/nancheng58/Awesome-LLM4RS-Papers](github.com/nancheng58/Awesome-LLM4RS-Papers)

#### [【BiLLa: 开源的中英双语LLaMA模型，具有增强的推理能力。通过扩充中文词表和利用任务型数据进 @爱可可-爱生活](https://weibo.com/1402400261/N0gXEFhOC)

Note: 【BiLLa: 开源的中英双语LLaMA模型，具有增强的推理能力。通过扩充中文词表和利用任务型数据进行训练，提升了中文理解和推理能力。在评测中，BiLLa在中英语言建模和推理任务上表现出色，优于其他模型，并与ChatGLM-6B相比在解题和代码得分方面更高。开发者可以使用BiLLa-7B-LLM和BiLLa-7B-SFT模型，并可通过提供的工具进行模型权重的还原和使用。评测结果显示，BiLLa在语言建模和各种问题类型上取得了良好的性能】'BiLLa: A Bilingual LLaMA with Enhanced Reasoning Ability' by Zhongli Li GitHub: github.com/Neutralzz/BiLLa  

Picture: [5396ee05ly8hdvt7u9ekej20vx0u07a3.jpg](https://weibo.cn//mblog/pic/N0gXEFhOC?rl=1)

Github: [github.com/Neutralzz/BiLLa](github.com/Neutralzz/BiLLa)

#### [并行编程很难吗？如果是，你能做些什么呢？ Is Parallel Programming Hard, @数据派THU](https://weibo.com/6004911042/N0hxDhdjU)

Note: 并行编程很难吗？如果是，你能做些什么呢？ Is Parallel Programming Hard, And If So, What Can You Do About It?这是Paul E. McKenney写的一本电子书。下载链接：Paul E. McKenney是世并行编程专家，Linux 内核中 RCU 实现和 rcutorture 测试模块的维护者，也是RCU的发明人。对于实时操作系统内核同步机制（例如 Linux 中的实时 RCU）、Linux 和 UNIX 操作系统内核中的 SMP/NUMA 可扩展性和性能、网络性能分析、路由和拥塞控制， 嵌入式实时应用程序有着丰富的经验和研究。 现在FB工作。

Picture: [82c654dfly1h25cbotuvnj216s0t7di0.jpg](https://weibo.cn//mblog/pic/LsCThyTU6?rl=1)

#### [电子书《Algorithms for Modern Hardware》这是一本即将出版的高性能计算书 @蚁工厂](https://weibo.com/2194035935/N0p9cayat)

Note: 电子书《Algorithms for Modern Hardware》这是一本即将出版的高性能计算书籍，名为“适应现代硬件的算法”，作者是Sergey Slotin。其目标读者包括从性能工程师和实用算法研究员到刚刚完成高级算法课程并希望学习更多实用的方法来加速程序的本科计算机科学学生，不仅仅是从O(nlogn)提升到O(nloglogn)。

Picture: [82c654dfly1hdwtd0fmk7j20gd1n2aij.jpg](https://weibo.cn//mblog/pic/N0p9cayat?rl=1)

#### [电子书《Machine Learning under Resource Constraints》资源 @蚁工厂](https://weibo.com/2194035935/N0nwhtVJy)

Note: 电子书《Machine Learning under Resource Constraints》资源约束下的机器学习《资源约束下的机器学习》分三卷，涉及到面对高吞吐数据、高维度数据或数据的复杂结构而遇到的机器学习算法。资源约束是指处理数据的需求与计算机的处理能力之间的关系，其中包括运行时间、内存、通信和能源等资源。因此，现代计算机架构在其中扮演着重要的角色。新的机器学习算法被优化以达到最小的资源消耗。此外，学习预测结果被执行在多种不同的架构上以节省资源。该书提供了关于考虑资源约束的新型机器学习研究方法的综合概述，以及这些方法在科学和工程的各种领域中的应用。

Picture: [82c654dfly1hdwm4kiq1ej20m80vdjv1.jpg](https://weibo.cn//mblog/pic/N0nwhtVJy?rl=1)

#### [一个随心所欲制造的操作系统Antz。地址：github.com/CasterWx/AntzOS作者“ @蚁工厂](https://weibo.com/2194035935/N0mTbwpF1)

Note: 一个随心所欲制造的操作系统Antz。地址：github.com/CasterWx/AntzOS作者“在看操作系统底层方面的东西，最开始的为什么是07c00h这个问题就让我对操作系统有了很大的兴趣。所以准备在看书之余顺便写一个操作系统(Anz)。” 建议选其他架构，不要选X86作为操作系统演示架构，包袱太重，实模式就是在浪费时间。或者直接使用BOOTLOADER，不要折腾MBR。要不然操作系统一般的篇幅会浪费在这上面。

Picture: [82c654dfly1h26hbse018j20il0sl0vo.jpg](https://weibo.cn//mblog/pic/LsMaMtfk7?rl=1)

Github: [github.com/CasterWx/AntzOS](github.com/CasterWx/AntzOS)

#### [【Whisper API Streaming：项目旨在为OpenAI的Whisper模型API提供一 @爱可可-爱生活](https://weibo.com/1402400261/N0q54EZ86)

Note: 【Whisper API Streaming：项目旨在为OpenAI的Whisper模型API提供一个流接口。目前只支持响应的流功能】'Whisper API Streaming - Thin wrapper around OpenAI Whisper API with streaming support' George Korepanov GitHub: github.com/gkorepanov/whisper-stream   

Picture: [5396ee05ly8hdwxfeclvyj21bs0h4diq.jpg](https://weibo.cn//mblog/pic/N0q54EZ86?rl=1)

Github: [github.com/gkorepanov/whisper-stream](github.com/gkorepanov/whisper-stream)

#### ['Refact.ai Inference Server - Refact.ai self-hoste @爱可可-爱生活](https://weibo.com/1402400261/N0q7Ut270)

Note: 'Refact.ai Inference Server - Refact.ai self-hosted server and Docker image' Small Magellanic Cloud AI Ltd GitHub: github.com/smallcloudai/refact-self-hosting   

Picture: [5396ee05ly8hdwxmp75wyj21070u078k.jpg](https://weibo.cn//mblog/pic/N0q7Ut270?rl=1)

Github: [github.com/smallcloudai/refact-self-hosting](github.com/smallcloudai/refact-self-hosting)

#### [MEGABYTE: Predicting Million-byte Sequences with M @AMiner学术头条](https://weibo.com/1870858943/N0IA8rl6Q)

Note: MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers AI解读：这篇文章介绍了一种名为Megabyte的多尺度解码器架构，可以对超过一百万字节的序列进行端到端可微建模，解决了序列长度较长时自回归transformers的效率问题。Megabyte将序列分为多个块，并使用一个局部子模型和一个全局模型进行处理。这种设计允许子二次自注意力，更大的前馈层大小，更好的并行化解码，从而在降低训练和生成成本的同时提高性能。经实验证明，Megabyte允许字节级模型在长上下文语言建模上与子词模型竞争，并在ImageNet数据集上实现了最先进的密度估计，并对原始音频文件进行了建模。这些结果证明了无记号自回归序列建模在规模上的可行性。这个思路的潜力很大，多模输入统一，超长输入的支持，生成速度提升

Picture: [6f830abfly1hdz75pa4rdj20vi0nctk4.jpg](https://weibo.cn//mblog/pic/N0IA8rl6Q?rl=1)

#### [看个新闻：《Apple’s new ‘Personal Voice’ feature can cre @宝玉xp](https://weibo.com/1727858283/N0Uwqndcy)

Note: 看个新闻：《Apple’s new ‘Personal Voice’ feature can create a voice that sounds like you or a loved one in just 15 minutes | 苹果的新功能“个人语音”可以在仅15分钟内创建出类似你或你所爱的人的声音》苹果的新功能“个人语音”可以在仅15分钟内创建出类似你或你所爱的人的声音Chance Miller作为今年即将推出的iOS 17辅助功能更新预览的一部分，苹果宣布了两项名为“实时语音”和“个人语音”的新功能。实时语音允许用户输入他们想要说的话并使其被播放出来。另一方面，“个人语音”是一种让那些有失去说话能力风险的人创建并保存一个听起来像他们自己的声音的方法。苹果表示，这是为那些有失去说话能力风险的人设计的，比如那些最近被诊断出患有ALS的人。以下是苹果描述今年晚些时候即将推出的新的实时语音功能的方式：通过在iPhone、iPad和Mac上的实时语音，用户可以输入他们想说的话，让它在电话和FaceTime通话以及面对面对话中大声说出来。用户还可以保存常用的短语，以便在与家人、朋友和同事进行热烈的对话时快速插话。实时语音被设计用来支持全球无法说话或者随着时间失去说话能力的数百万人。基于实时语音，苹果提出了一个称为个人语音的功能；这是一个极其强大的功能，苹果表示它是为那些有失去说话能力风险的用户设计的。这包括最近被诊断出患有ALS（肌萎缩侧索硬化症）的人，这是一种随着时间推移逐渐影响说话能力的疾病。使用个人语音，用户将被提示沿着一组随机的文本提示阅读，以在iPhone或iPad上录制15分钟的音频。使用设备上的机器学习，iPhone或iPad然后可以创建出一个听起来像他们自己的声音。然后，这个语音功能与实时语音集成，用户可以在FaceTime通话和面对面对话中使用他们的个人语音。苹果的声明：对于有失去说话能力风险的用户——比如最近被诊断为ALS（肌萎缩侧索硬化症）或其他可以逐渐影响说话能力的病症的人——个人语音是一种简单且安全的方式，可以创建出一个听起来像他们自己的声音。用户可以通过阅读一组随机的文本提示，在iPhone或iPad上录制15分钟的音频来创建个人语音。这种语音辅助功能利用设备上的机器学习保护用户的信息私密和安全，并且可以无缝集成实时语音，因此用户在与亲人联系时可以使用他们的个人语音。从本质上讲，这个功能将使人们能够通过只读取苹果预设的提示，就能在他们的iPhone上创建他们的合成语音。菲利普·格林，他在2018年被诊断出ALS，并在Team Gleason非营利组织中担任董事会成员和倡导者，周二在一份声明中称赞了苹果的努力：“在一天结束时，最重要的事情是能够与朋友和家人交流，”Team Gleason非营利组织的董事会成员和ALS倡导者菲利普·格林说，自从他在2018年接到ALS诊断后，他的声音发生了显著的变化。“如果你可以用听起来像你的声音告诉他们你爱他们，那就意味着世界上所有的不同——而且只需15分钟就能在你的iPhone上创建你的合成语音，这是非常了不起的。”苹果表示，这些新的辅助功能将于今年晚些时候开始推出。除了实时语音和个人语音之外，苹果还宣布了其他一些新的辅助功能。苹果一直是辅助功能的领导者，今天的公告就是最新的例证。但比以往任何时候都更让我共鸣。我妈妈在12月份去世，经过了短短七个月的ALS斗争。她失去的第一样东西就是她的声音。实际上，当她被正式诊断出患有ALS时，她的声音已经几乎消失了。仅仅阅读这个新闻发布就让我流泪。个人语音功能让我希望患有ALS和其他影响语音的疾病的人可能会稍微受苦一些。我希望这个功能在我们妈妈还在的时候就有，但我很高兴这是别人的未来可能拥有的东西。我甚至会说，我认为每个人都应该花15分钟设置一下个人语音功能，一旦它可用。就像我和我姐姐在我们妈妈身上学到的那样，你的说话能力可能在几周内就会被剥夺，那时可能已经太晚了，无法设置像个人语音这样的功能。尽管我确实在等待苹果解答关于这个功能的一些问题和具体细节，但如果有一家公司我信任能把像个人语音这样的功能做好，那就是苹果。不同于市场上其他需要你上传你的声音样本数据的语音合成工具，个人语音完全在设备上进行。没有任何云处理。当ai可以用你爱的人的声音回复你……回复:骗子横行牛了牛了保留一个人的声音这个功能如果结合 AI ，有点不敢细想 如何防止语音合成加GPT被骗子利用实施诈骗早点出就可以留住亲人的声音了喂？小王吗？我是陈经理，我密码忘了，你帮我重置一下呗？

Picture: [66fd066bgy1he0nvcv8cnj215o0ku488.jpg](https://weibo.cn//mblog/pic/N0Uwqndcy?rl=1)

#### [健康学习到150岁 - 人体系统调优不完全指南 地址：github.com/zijie0/Human @敖天羽](https://weibo.com/1888981347/N1273jmwj)

Note: 健康学习到150岁 - 人体系统调优不完全指南 地址：github.com/zijie0/HumanSystemOptimization斯坦福的神经科学教授Huberman的一些讲座整理，包括提升睡眠质量、饮食习惯、维持健康的多巴胺水平、维持专注力等。有些内容好像在梨叔那见过。 

Github: [github.com/zijie0/HumanSystemOptimization](github.com/zijie0/HumanSystemOptimization)

#### [：HuaTuo华驼(HuaTuo): 基于中文医学知识的LLaMA微调模型本项目开源了经过中文医学指 @宝玉xp](https://weibo.com/1727858283/N13eraf6p)

Note: ：HuaTuo华驼(HuaTuo): 基于中文医学知识的LLaMA微调模型本项目开源了经过中文医学指令精调/指令微调(Instruct-tuning) 的LLaMA-7B模型。通过医学知识图谱和GPT3.5 API构建了中文医学指令数据集，并在此基础上对LLaMA进行了指令微调，提高了LLaMA在医疗领域的问答效果。🔗github.com/SCIR-HI/Huatuo-Llama-Med-Chinese🔗//：Finetune可以是Instruction Finetune，让模型更好的Follow Instruction，也可以是针对特定行业的Finetune，两种情况都能获得新知识。Embedding，严格意义上说，In-Context Learning也可以从Context获得新知识，只是不更新模型参数。//：这个我还这解释不了，请教一下大家

Picture: [66fd066bly8hdpcx2gsowj20k00a4abb.jpg](https://weibo.cn//mblog/pic/MFnO96S8D?rl=1)

Github: [github.com/SCIR-HI/Huatuo-Llama-Med-Chinese](github.com/SCIR-HI/Huatuo-Llama-Med-Chinese)

#### [看Supabase是如何构建文档搜索对话机器人ClippyGPT——他们的下一代文档搜索工具。你可以 @宝玉xp](https://weibo.com/1727858283/N17bpoiTN)

Note: 看Supabase是如何构建文档搜索对话机器人ClippyGPT——他们的下一代文档搜索工具。你可以向Clippy询问任何有关Supabase的问题，它将使用自然语言进行回答。这一切都得益于OpenAI和提示工程。视频覆盖以下内容：- Prompt工程和最佳实践- 通过上下文注入 + OpenAI嵌入来处理自定义知识库- 如何使用pgvector在Postgres中存储嵌入Supabase博客文章：pgvector扩展：🔗github.com/pgvector/pgvector🔗生成嵌入实现：🔗github.com/supabase/supabase/blob/54d39d4958575e5b58aa1d5d2a02db863ab4673c/apps/docs/scripts/generate-embeddings.ts🔗Clippy边缘功能实现：🔗github.com/supabase/supabase/blob/54d39d4958575e5b58aa1d5d2a02db863ab4673c/supabase/functions/clippy-search/index.ts🔗Clippy前端实现：🔗github.com/supabase/supabase/blob/54d39d4958575e5b58aa1d5d2a02db863ab4673c/packages/ui/src/components/Command/AiCommand.tsx🔗提示工程：http://t.cn/A6Ng8EMO00:00 为什么？01:40 我们开始吧03:15 自定义知识库04:49 上下文注入06:13 预处理MDX文件13:40 Embedding15:40 在Postgres + pgvector中存储22:21 API端点（边缘函数）23:44 在pgvector中计算相似性27:55 提示工程33:15 提示最佳实践38:37 演示时间！41:32 感谢观看！原始视频：www.youtube.com/watch?v=Yhtjd7yGGGA🔗 回复:pg-vector特别棒感谢分享回复:谢谢，有什么好的向量数据库推荐，许多是收费的回复:原理一样，langchain把很多底层操作封装了langchain也有类似的教学，跟你上面的这个是什么关系看Supabase是如何构建文档搜索对话机器人ClippyGPT——他们的下一代文档搜索工具。你可以向Clippy询问任何有关Supabase的问题，它将使用自然语言进行回答。这一切都得益于OpenAI和提示工程。  

Github: [github.com/pgvector/pgvector](github.com/pgvector/pgvector)

Github: [github.com/supabase/supabase/blob/54d39d4958575e5b58aa1d5d2a02db863ab4673c/apps/docs/scripts/generate-embeddings.ts](github.com/supabase/supabase/blob/54d39d4958575e5b58aa1d5d2a02db863ab4673c/apps/docs/scripts/generate-embeddings.ts)

Github: [github.com/supabase/supabase/blob/54d39d4958575e5b58aa1d5d2a02db863ab4673c/supabase/functions/clippy-search/index.ts](github.com/supabase/supabase/blob/54d39d4958575e5b58aa1d5d2a02db863ab4673c/supabase/functions/clippy-search/index.ts)

Github: [github.com/supabase/supabase/blob/54d39d4958575e5b58aa1d5d2a02db863ab4673c/packages/ui/src/components/Command/AiCommand.tsx](github.com/supabase/supabase/blob/54d39d4958575e5b58aa1d5d2a02db863ab4673c/packages/ui/src/components/Command/AiCommand.tsx)

#### [SoundStorm：高效并行音频生成SoundStorm是Google发布的一个用于高效、非自回归 @宝玉xp](https://weibo.com/1727858283/N15nJFuUg)

Note: SoundStorm：高效并行音频生成SoundStorm是Google发布的一个用于高效、非自回归音频生成的模型。看了下项目首页上的演示，我觉得生成速度还罢了，它的演示音频让我觉得厉害的地方是只要3秒的样本，就能按照原本说话的音色生成后续的音频，而且很自然。在项目底部它也写了如何防止冒充别人声音，看起来是在生成的声音中加入音频水印，这样通过技术可以很容易检测出来是生成的音频。项目首页：google-research.github.io/seanet/soundstorm/examples/🔗论文： 不仅可以生成高质量的自然对话片段，还具有很好的可扩展性[666]音乐和声音也能了，很强。回复:可以的音频也能有水印 

#### [电子书《Code Simplicity: The Fundamentals of Software》 @敖天羽](https://weibo.com/1888981347/N17E8F4aJ)

Note: 电子书《Code Simplicity: The Fundamentals of Software》代码简洁性：软件基础作者Max Kanat-Alexander ，这本书包含了软件设计的基本法则——关于软件开发的最重要的事实，这些事实将让你理解你现在的行动将如何影响你的软件系统在未来的发展。它为你提供了可以思考的原则，这些原则将帮助你理解为什么以及如何让你的系统现在和未来都保持可维护性。

Picture: [82c654dfly1he1o3gjy78j20pn16jah2.jpg](https://weibo.cn//mblog/pic/N17mf2yw6?rl=1)

#### [看Supabase是如何构建文档搜索对话机器人ClippyGPT——他们的下一代文档搜索工具。你可以 @敖天羽](https://weibo.com/1888981347/N17JZc5ur)

Note: 看Supabase是如何构建文档搜索对话机器人ClippyGPT——他们的下一代文档搜索工具。你可以向Clippy询问任何有关Supabase的问题，它将使用自然语言进行回答。这一切都得益于OpenAI和提示工程。视频覆盖以下内容：- Prompt工程和最佳实践- 通过上下文注入 + OpenAI嵌入来处理自定义知识库- 如何使用pgvector在Postgres中存储嵌入Supabase博客文章：pgvector扩展：🔗github.com/pgvector/pgvector🔗生成嵌入实现：🔗github.com/supabase/supabase/blob/54d39d4958575e5b58aa1d5d2a02db863ab4673c/apps/docs/scripts/generate-embeddings.ts🔗Clippy边缘功能实现：🔗github.com/supabase/supabase/blob/54d39d4958575e5b58aa1d5d2a02db863ab4673c/supabase/functions/clippy-search/index.ts🔗Clippy前端实现：🔗github.com/supabase/supabase/blob/54d39d4958575e5b58aa1d5d2a02db863ab4673c/packages/ui/src/components/Command/AiCommand.tsx🔗提示工程：http://t.cn/A6Ng8EMO00:00 为什么？01:40 我们开始吧03:15 自定义知识库04:49 上下文注入06:13 预处理MDX文件13:40 Embedding15:40 在Postgres + pgvector中存储22:21 API端点（边缘函数）23:44 在pgvector中计算相似性27:55 提示工程33:15 提示最佳实践38:37 演示时间！41:32 感谢观看！原始视频：www.youtube.com/watch?v=Yhtjd7yGGGA🔗 

Github: [github.com/pgvector/pgvector](github.com/pgvector/pgvector)

Github: [github.com/supabase/supabase/blob/54d39d4958575e5b58aa1d5d2a02db863ab4673c/apps/docs/scripts/generate-embeddings.ts](github.com/supabase/supabase/blob/54d39d4958575e5b58aa1d5d2a02db863ab4673c/apps/docs/scripts/generate-embeddings.ts)

Github: [github.com/supabase/supabase/blob/54d39d4958575e5b58aa1d5d2a02db863ab4673c/supabase/functions/clippy-search/index.ts](github.com/supabase/supabase/blob/54d39d4958575e5b58aa1d5d2a02db863ab4673c/supabase/functions/clippy-search/index.ts)

Github: [github.com/supabase/supabase/blob/54d39d4958575e5b58aa1d5d2a02db863ab4673c/packages/ui/src/components/Command/AiCommand.tsx](github.com/supabase/supabase/blob/54d39d4958575e5b58aa1d5d2a02db863ab4673c/packages/ui/src/components/Command/AiCommand.tsx)

#### [详谈大模型训练中的数据收集、处理与模型影响：A Survey of Large Language M @数据派THU](https://weibo.com/6004911042/N0rvEncmV)

Note: 详谈大模型训练中的数据收集、处理与模型影响：A Survey of Large Language Models工作中的数据总结 

#### [Google教学视频：《解析 Transformers：理解 GPT，BERT 和 T5 模型背后的 @宝玉xp](https://weibo.com/1727858283/N18g3e6gQ)

Note: Google教学视频：《解析 Transformers：理解 GPT，BERT 和 T5 模型背后的原理》过去五年中，Transformers，一种神经网络架构，完全改变了自然语言处理的最先进技术。想要使用机器学习来翻译文本吗？好奇一个机器学习模型如何能够写出诗歌或专栏文章吗？Transformers 可以做到所有这些。在这一集的“ML 制造”中，Dale Markowitz 解释了什么是 transformers，它们如何工作，以及它们为何具有如此大的影响力。观看此视频，了解你如何开始在你的应用中使用 transformers！章节：0:00 - 引言0:51 - 什么是 transformers？3:18 - transformers 是如何工作的？7:41 - transformers 是如何被使用的？8:35 - 如何开始使用 transformers原始视频：www.youtube.com/watch?v=SZorAJ4I-sA🔗 宝藏博主[666]【注意力训练模型也许只是一种可以分辨语句真实主谓宾词语的逻辑分析技术】也许当AI获得了制史的资格，很多史学家关于历史只能由胜利者编写的无奈和遗憾就会一去不复返了。因为智慧的评判者并不是只听你想说什么，而是可以理解你不想说什么。留存！这条微博内容是用AI生成的吗？Positional Encoding / Attention / Self- Attention老师真是个宝藏博主，字幕翻译是用 GPT 吗？可以授权转到视频号里吗转发微博

#### [ 联合  Broadview 送出 5 本《Python精粹》。截止 5 月 20 日，转发此微博并 @网路冷眼](https://weibo.com/1715118170/N0rGhmgde)

Note:  联合  Broadview 送出 5 本《Python精粹》。截止 5 月 20 日，转发此微博并关注  赢取。 这本精练的手册基于Python 3.6及更高版本，直取 Python 编程语言的核心知识点，不像市面上许多 Python 图书那样停留于浅显的内容，并采用新的 Python 代码风格示例来阐述 Python 工作原理，帮助读者构建更易于解释、测试和调试的程序。最适合想进阶中高级 Python 开发的程序员。半价优惠：转发微博老师这本抽奖了吗？精粹转发支持！转发微博抽我一定看我再中一次抽这个好

Picture: [663aa05aly1hdx4i5x026j20m80m879h.jpg](https://weibo.cn//mblog/pic/N0rGhmgde?rl=1)

#### [[CV]《EfficientViT: Memory Efficient Vision Transfo @爱可可-爱生活](https://weibo.com/1402400261/N0uAdksl3)

Note: [CV]《EfficientViT: Memory Efficient Vision Transformer with Cascaded Group Attention》X Liu, H Peng, N Zheng, Y Yang, H Hu, Y Yuan [Microsoft Research & The Chinese University of Hong Kong] (2023)   

Picture: [5396ee05ly1hdxh6a33lhj20py11k7lo.jpg](https://weibo.cn//mblog/pic/N0uAdksl3?rl=1)

#### [scikit-opt，一个纯Python群体智能算法库（差分进化算法、遗传算法、粒子群算法、模拟退火 @蚁工厂](https://weibo.com/2194035935/N0x1uuXdS)

Note: scikit-opt，一个纯Python群体智能算法库（差分进化算法、遗传算法、粒子群算法、模拟退火算法、蚁群算法、鱼群算法、免疫优化算法），特点是轻量、易部署，支持GPU运算。项目地址：github.com/guofei9987/scikit-opt 

Picture: [82c654dfly1h27p8rpm7ij20go0y676s.jpg](https://weibo.cn//mblog/pic/LsWD0kDrc?rl=1)

Github: [github.com/guofei9987/scikit-opt](github.com/guofei9987/scikit-opt)

#### [两篇博文：从0到1打造正则表达式执行引擎(一)地址：这篇文章不是教你如何写正则表达式，而是教你写一个 @蚁工厂](https://weibo.com/2194035935/N0x1Fav2A)

Note: 两篇博文：从0到1打造正则表达式执行引擎(一)地址：这篇文章不是教你如何写正则表达式，而是教你写一个能执行正则表达式的执行引擎。从0到1打造正则表达式执行引擎(二)地址：在上篇博客从0到1打造正则表达式执行引擎(一)中我们已经构建了一个可用的正则表达式引擎，但上文中只是用到了NFA，这篇介绍DFA引擎。

Picture: [82c654dfly1h27olgovpej20lc1butb4.jpg](https://weibo.cn//mblog/pic/LsW6xdSnP?rl=1)

#### ['大语言模型（LLM）微调技术笔记' by Tao Yang GitHub: github.com/ @爱可可-爱生活](https://weibo.com/1402400261/N0y6J3M7A)

Note: '大语言模型（LLM）微调技术笔记' by Tao Yang GitHub: github.com/ninehills/ninehills.github.io/issues/92     

Picture: [5396ee05ly8hdxwwqggdhj21160u0tdj.jpg](https://weibo.cn//mblog/pic/N0y6J3M7A?rl=1)

Github: [github.com/ninehills/ninehills.github.io/issues/92](github.com/ninehills/ninehills.github.io/issues/92)

#### [《性能之巅 第2版》读书笔记 （第11章）1、一台服务器可以被划分给不同的用户使用，以满足他们的需求 @小川CD](https://weibo.com/1202332555/N0zoJ9i8o)

Note: 《性能之巅 第2版》读书笔记 （第11章）1、一台服务器可以被划分给不同的用户使用，以满足他们的需求。但是，这也带来了一些挑战，比如虚拟化技术的性能开销，以及相邻租户之间对资源的争夺问题。2、由于资源在租户之间共享，性能问题可能由吵闹的邻居引起。例如，同一宿主机上的另一个客户机可能在你的负载高峰时进行数据库转储，影响你的磁盘和网络IO。3、多租户效应可以通过资源管理进行控制：设置操作系统资源控制以提供性能隔离（又名资源隔离）。可以在这些资源上对单租户进行限制和设置优先级，比如CPU、内存、磁盘、文件系统IO和网络吞吐量。4、AMD-V和英特尔VT-x扩展可为处理器的虚拟操作提供更快的硬件支持。这些扩展提高了虚拟化特权指令和MMU的速度。为了进一步优化虚拟机的性能，除处理器以外的硬件设备已经在增加对虚拟机的支持。5、一般情况下，客户机应用程序直接运行在处理器上，与CPU绑定的应用程序的性能与裸金属系统几乎相同。而在调用处理器特权指令、访问硬件和映射主存时，则可能产生CPU开销，这取决于管理程序对它们的处理方式。6、对于虚拟化，从客户机到硬件映射一个新的内存页面（缺页）包括两个步骤：1）由客户机内核执行的由客户机虚拟内存到客户机物理内存的转换。2）由VMM执行的客户机物理内存到宿主机物理内存（真实内存）的转换。7、IO一直是硬件虚拟化开销的最大来源。这是因为每个设备的IO都必须由管理程序翻译。提高IO性能的一种方法是使用半虚拟化驱动程序，它通过合并IO产生更少的设备中断，来减少管理程序开销。另一种技术叫PCI直通，它将PCI设备直接分配给客户机，因此使用起来和在裸金属系统上一样。8、根据管理程序的配置以及租户之间共享CPU和CPU缓存的数量，可能会出现其他租户造成的CPU时间窃取和CPU缓存污染，导致性能降低。这通常是容器比虚拟机更容易受到影响的原因，因为容器倡导共享以支持CPU爆发。9、英特尔缓存分配技术（CAT）允许为所有客户机进行LLC分区，并且分区可以被共享。虽然这可以防止一个客户机污染另一个客户机的缓存，但也会因为限制缓存的使用而损害性能。10、vmstat命令包括一个CPU被窃取的百分比（st），这是一个罕见的虚拟化感知统计例子。被窃取的CPU时间显示客户机不可用的CPU时间：它可能被其他租户或其他管理程序所消耗。11、容器相比于硬件虚拟化的优势包括：1）更快的初始化时间；2）客户机可以将内存完全应用于应用程序；3）有一个统一的文件系统缓存；4）可以对资源共享进行更精细的控制（cgroup）；5）提高性能的可观察性；6）容器可以为常规文件共享内存页，释放页缓存中的空间，提高CPU缓存命中率；7）CPU是真正的CPU：自适应互斥锁的假设仍然有效。12、容器的缺点包括：1）增加了对内核资源的竞争；2）客户机的性能可观察性降低；3）任何内核错误都会影响到所有客户机；4）客户机不能运行自定义的内核模块；5）客户机不能使用长期运行的PGO内核；6）客户机不能运行不同的内核版本或不同的内核。13、从宿主机的角度来看，可以观测到所有内容，包括硬件资源、文件系统、客户机进程、客户机TCP会话等。从客户机的角度来看，容器通常只能看到自己的进程、文件系统、网络接口和TCP会话。

#### [今天早晨我叫小朋友起床的时候，说的是“快点起床，给我热牛奶面包，然后好上课”。小朋友刚起床懵懵地，穿 @WinnieS的微博](https://weibo.com/2144454703/N0zvyhT4d)

Note: 今天早晨我叫小朋友起床的时候，说的是“快点起床，给我热牛奶面包，然后好上课”。小朋友刚起床懵懵地，穿好衣服去厨房，一边操作一边问我，“为什么是我给你热牛奶面包？”，我反问，“为什么不能是你给我热牛奶面包？” ，事实证明，可以，就是他冲的咖啡，放了过多的蜂蜜，齁甜齁甜的 这文字也太甜了儿子：到底是谁照顾谁

#### ['大语言模型（LLM）微调技术笔记' by Tao Yang GitHub: github.com/ @数据派THU](https://weibo.com/6004911042/N0AysBewH)

Note: '大语言模型（LLM）微调技术笔记' by Tao Yang GitHub: github.com/ninehills/ninehills.github.io/issues/92   

Picture: [5396ee05ly8hdxwwqggdhj21160u0tdj.jpg](https://weibo.cn//mblog/pic/N0y6J3M7A?rl=1)

Github: [github.com/ninehills/ninehills.github.io/issues/92](github.com/ninehills/ninehills.github.io/issues/92)

#### [scikit-opt，一个纯Python群体智能算法库（差分进化算法、遗传算法、粒子群算法、模拟退火 @数据派THU](https://weibo.com/6004911042/N0AyXF0Co)

Note: scikit-opt，一个纯Python群体智能算法库（差分进化算法、遗传算法、粒子群算法、模拟退火算法、蚁群算法、鱼群算法、免疫优化算法），特点是轻量、易部署，支持GPU运算。项目地址：github.com/guofei9987/scikit-opt 

Picture: [82c654dfly1h27p8rpm7ij20go0y676s.jpg](https://weibo.cn//mblog/pic/LsWD0kDrc?rl=1)

Github: [github.com/guofei9987/scikit-opt](github.com/guofei9987/scikit-opt)

#### [ 联合  Broadview 送出 5 本《Python精粹》。截止 5 月 20 日，转发此微博并 @网路冷眼](https://weibo.com/1715118170/N0ACm5OmP)

Note:  联合  Broadview 送出 5 本《Python精粹》。截止 5 月 20 日，转发此微博并关注  赢取。 这本精练的手册基于Python 3.6及更高版本，直取 Python 编程语言的核心知识点，不像市面上许多 Python 图书那样停留于浅显的内容，并采用新的 Python 代码风格示例来阐述 Python 工作原理，帮助读者构建更易于解释、测试和调试的程序。最适合想进阶中高级 Python 开发的程序员。半价优惠：

Picture: [663aa05aly1hdx4i5x026j20m80m879h.jpg](https://weibo.cn//mblog/pic/N0rGhmgde?rl=1)

#### [ 的流行，带火了文本向量化(embedding)。我们组的工程师Alexxinlu针对这个主题，整理 @蚁工厂](https://weibo.com/2194035935/N0FI5dwNu)

Note:  的流行，带火了文本向量化(embedding)。我们组的工程师Alexxinlu针对这个主题，整理了一个比较全面的综述：【NLP 中语言表示 (向量化) 的基本原理和历史演变综述】:  推荐系统了解。   

Picture: [6fa923c0ly1hdytwoamodj214s1feh1b.jpg](https://weibo.cn//mblog/pic/N0FBEhwNY?rl=1)

#### [【《生成式深度学习(第二版)》随书代码】’ Generative Deep Learning - 2 @爱可可-爱生活](https://weibo.com/1402400261/N0GNBrzkS)

Note: 【《生成式深度学习(第二版)》随书代码】’ Generative Deep Learning - 2nd Edition Codebase - The official code repository for the second edition of the O'Reilly book Generative Deep Learning: Teaching Machines to Paint, Write, Compose and Play.' David Foster GitHub: github.com/davidADSP/Generative_Deep_Learning_2nd_Edition  可惜还是得买书

Picture: [5396ee05ly8hdyz9jao0jj20tk130tf4.jpg](https://weibo.cn//mblog/pic/N0GNBrzkS?rl=1)

Github: [github.com/davidADSP/Generative_Deep_Learning_2nd_Edition](github.com/davidADSP/Generative_Deep_Learning_2nd_Edition)

#### [  @AINLP](https://weibo.com/2703427641/N0GVRgj1P)

#### [  @AINLP](https://weibo.com/2703427641/N0GVUrUJu)

#### [  @AINLP](https://weibo.com/2703427641/N0GXaaUJO)

#### [ 基于开源大模型ChatGLM-6B，在网络安全行业方向，我微调实战了一篇“如何训练自己的安全大模型 @蚁工厂](https://weibo.com/2194035935/N0JlEuFrV)

Note:  基于开源大模型ChatGLM-6B，在网络安全行业方向，我微调实战了一篇“如何训练自己的安全大模型”   

#### [[CL]《CodeT5+: Open Code Large Language Models for  @爱可可-爱生活](https://weibo.com/1402400261/N0WTH6HDC)

Note: [CL]《CodeT5+: Open Code Large Language Models for Code Understanding and Generation》Y Wang, H Le, A D Gotmare, N D.Q. Bui, J Li, S C.H. Hoi [Salesforce AI Research] (2023)   

Picture: [5396ee05ly1he0y9gnbejj214m112nn3.jpg](https://weibo.cn//mblog/pic/N0WTH6HDC?rl=1)

#### [经典电子书《High Performance Browser Networking》Web性能权威指 @蚁工厂](https://weibo.com/2194035935/N0XLNbaQQ)

Note: 经典电子书《High Performance Browser Networking》Web性能权威指南英文原版：hpbn.co/中文翻译：quheng.gitbooks.io/high-performance-browser-networking/content/性能是一种特性。这本书为每个网页开发者提供了一种实践性的概述，让他们了解关于各种类型的网络（WiFi，3G/4G），传输协议（UDP，TCP，和TLS），应用协议（HTTP/1.1，HTTP/2），以及浏览器中可用的API（XHR，WebSocket，WebRTC等）的所有知识，以提供最好的——快速，可靠，和弹性的——用户体验。回复:已收藏到你的notion打不开回复:成功保存到你的notion

Picture: [82c654dfly1he127mthhkj20jt19owj9.jpg](https://weibo.cn//mblog/pic/N0XLNbaQQ?rl=1)

#### [www.bigocheatsheet.com这个网页涵盖了计算机科学中常用算法的空间和时间复杂度（B @蚁工厂](https://weibo.com/2194035935/N0XVl6Le2)

Note: www.bigocheatsheet.com这个网页涵盖了计算机科学中常用算法的空间和时间复杂度（Big-O）。在过去为技术面试做准备的时候，作者发现自己花费了数小时在互联网上搜集搜索和排序算法的最好、平均和最坏情况的复杂度，以防在被问到时感到困惑。“为什么没有人创建一个好用的Big-O速查表呢？”所以，为了节省你们的大量时间，作者创建了一个 -- Eric Rowell回复:已保存到你的Notion 回复:已保存到你的notion

Picture: [82c654dfly1he12liu6mej21m715ek40.jpg](https://weibo.cn//mblog/pic/N0XVl6Le2?rl=1)

#### [【用LoRA微调ImageBind】’Unofficial ImageBind Fine-tunin @爱可可-爱生活](https://weibo.com/1402400261/N0ZY7rqwT)

Note: 【用LoRA微调ImageBind】’Unofficial ImageBind Fine-tuning with LoRA - Fine-tuning "ImageBind One Embedding Space to Bind Them All" with LoRA' Fares Abawi GitHub: github.com/fabawi/ImageBind-LoRA   你好，你感兴趣的“开源”已开通了超话社区～ 超话社区是微博旗下兴趣互动社区，快来与志同道合的小伙伴们一起交流互动吧！ 戳我进入>> 

Picture: [5396ee05ly8he1bwrj27wj213m0piabs.jpg](https://weibo.cn//mblog/pic/N0ZY7rqwT?rl=1)

Github: [github.com/fabawi/ImageBind-LoRA](github.com/fabawi/ImageBind-LoRA)

#### [各大技术交流会、活动资料汇总 ，如QCon、全球运维技术大会、GDG、全球技术领导力峰会、大前端大会 @蚁工厂](https://weibo.com/2194035935/N11wr4DM3)

Note: 各大技术交流会、活动资料汇总 ，如QCon、全球运维技术大会、GDG、全球技术领导力峰会、大前端大会、架构师峰会、敏捷开发DevOps、OpenResty等地址：github.com/baiyutang/meetup 

Picture: [82c654dfly1h2bj0boe44j20s61hzk32.jpg](https://weibo.cn//mblog/pic/Lts9pEjcV?rl=1)

Github: [github.com/baiyutang/meetup](github.com/baiyutang/meetup)

#### [Writing an OS in Rust这个博客系列用Rust编程语言编写了一个小操作系统。每篇文 @蚁工厂](https://weibo.com/2194035935/N11wCg3DP)

Note: Writing an OS in Rust这个博客系列用Rust编程语言编写了一个小操作系统。每篇文章都是一个小教程，并且包含了所有代码，你可以跟着一起学习。源代码也放在了Github 仓库。部分内容有中文翻译 

Picture: [82c654dfly1h2b4phvtaej212g0u0n3g.jpg](https://weibo.cn//mblog/pic/LtopfDMRr?rl=1)

#### [电子书《Python Packages》在线阅读：py-pkgs.org/Python packag @蚁工厂](https://weibo.com/2194035935/N11PfDrzi)

Note: 电子书《Python Packages》在线阅读：py-pkgs.org/Python packages 是Python中可共享代码的基本单位。包使得组织、重用、维护你的代码变得简单，同时也便于在项目之间、与你的同事以及更广泛的Python社区分享代码。《Python Packages》是一本开源书籍，描述了创建Python packages 的现代且高效的工作流程。这本书的重点绝对是实用性；我们将展示你可以用来快速、可重复地开发和维护包的方法和工具，以及尽可能多的自动化——这样你就可以专注于编写和分享代码！快速看了一下 好书哦

Picture: [82c654dfly1he1du8txmzj20xc182k1k.jpg](https://weibo.cn//mblog/pic/N11PfDrzi?rl=1)

#### [【基于Hugging Face Transformers的项目精选集】’Awesome projec @爱可可-爱生活](https://weibo.com/1402400261/N17fS2CQ5)

Note: 【基于Hugging Face Transformers的项目精选集】’Awesome projects built with Transformers' by Hugging Face GitHub: github.com/huggingface/transformers/blob/main/awesome-transformers.md   

Picture: [5396ee05ly8he283080lkj213h0u0gqz.jpg](https://weibo.cn//mblog/pic/N17fS2CQ5?rl=1)

Github: [github.com/huggingface/transformers/blob/main/awesome-transformers.md](github.com/huggingface/transformers/blob/main/awesome-transformers.md)

#### [电子书《Code Simplicity: The Fundamentals of Software》 @蚁工厂](https://weibo.com/2194035935/N17mf2yw6)

Note: 电子书《Code Simplicity: The Fundamentals of Software》代码简洁性：软件基础作者Max Kanat-Alexander ，这本书包含了软件设计的基本法则——关于软件开发的最重要的事实，这些事实将让你理解你现在的行动将如何影响你的软件系统在未来的发展。它为你提供了可以思考的原则，这些原则将帮助你理解为什么以及如何让你的系统现在和未来都保持可维护性。回复:成功收藏到你的notion回复:已保存到你的Notion

Picture: [82c654dfly1he1o3gjy78j20pn16jah2.jpg](https://weibo.cn//mblog/pic/N17mf2yw6?rl=1)

#### [ByteByteGo 总结的影响我们世界的10类算法Sorting - 排序Fourier Tran @蚁工厂](https://weibo.com/2194035935/N17qrndTH)

Note: ByteByteGo 总结的影响我们世界的10类算法Sorting - 排序Fourier Transform and Fast Fourier Transform - 傅立叶变换和快速傅立叶变换Dijkstra’s algorithm - Dijkstra最短路径算法RSA algorithm - RSA非对称加密算法Secure Hash Algorithm - 安全哈希算法，SHA系列算法Integer factorization - 整数分解Link Analysis - 链接分析（PageRank 是其代表）Proportional Integral Derivative Algorithm - PID控制算法，用在各类电机控制Data compression algorithms - 数据压缩算法Random Number Generation - 随机数生成正是由于这些算法的出现，我们才得以迎来人工智能、数据挖掘等网络上常见的众多现代计算工具。正是由于这些算法的出现，我们才得以迎来人工智能、数据挖掘等网络上常见的众多现代计算工具。我已经掌握了影响世界的十种算法（的调用方式）

Picture: [82c654dfly1he28nsilvnj20ve0xcqif.jpg](https://weibo.cn//mblog/pic/N17qrndTH?rl=1)

#### [Google教学视频：《解析 Transformers：理解 GPT，BERT 和 T5 模型背后的 @蚁工厂](https://weibo.com/2194035935/N191ZjNTa)

Note: Google教学视频：《解析 Transformers：理解 GPT，BERT 和 T5 模型背后的原理》过去五年中，Transformers，一种神经网络架构，完全改变了自然语言处理的最先进技术。想要使用机器学习来翻译文本吗？好奇一个机器学习模型如何能够写出诗歌或专栏文章吗？Transformers 可以做到所有这些。在这一集的“ML 制造”中，Dale Markowitz 解释了什么是 transformers，它们如何工作，以及它们为何具有如此大的影响力。观看此视频，了解你如何开始在你的应用中使用 transformers！章节：0:00 - 引言0:51 - 什么是 transformers？3:18 - transformers 是如何工作的？7:41 - transformers 是如何被使用的？8:35 - 如何开始使用 transformers原始视频：www.youtube.com/watch?v=SZorAJ4I-sA🔗 

#### [【Lidar AI Solution：一个展示激光雷达相关AI解决方案的项目，包括三个GPU加速的激 @爱可可-爱生活](https://weibo.com/1402400261/N19lX8Ryc)

Note: 【Lidar AI Solution：一个展示激光雷达相关AI解决方案的项目，包括三个GPU加速的激光雷达/相机深度学习网络(PointPillars、CenterPoint、BEVFusion)以及相关库(cuPCL、3D SparseConvolution等)。该项目针对自动驾驶的3D激光雷达进行了高度优化，加速了稀疏卷积、CenterPoint、BEVFusion、OSD和转换等任务】'Lidar AI Solution - A project demonstrating Lidar related AI solutions, including three GPU accelerated Lidar/camera DL networks (PointPillars, CenterPoint, BEVFusion) and the related libs (cuPCL, 3D SparseConvolution, YUV2RGB, cuOSD,).' NVIDIA-AI-IOT GitHub: github.com/NVIDIA-AI-IOT/Lidar_AI_Solution  

Picture: [5396ee05ly8he2hbrs8wjj222u0u0aek.jpg](https://weibo.cn//mblog/pic/N19lX8Ryc?rl=1)

Github: [github.com/NVIDIA-AI-IOT/Lidar_AI_Solution](github.com/NVIDIA-AI-IOT/Lidar_AI_Solution)

#### [【VisualGLM-6B：开源多模态对话语言模型，支持图像、中文和英文。该模型基于ChatGLM- @爱可可-爱生活](https://weibo.com/1402400261/N19mKuCGV)

Note: 【VisualGLM-6B：开源多模态对话语言模型，支持图像、中文和英文。该模型基于ChatGLM-6B，具有78亿参数，通过BLIP2-Qformer将图像和语言模型相结合。模型使用CogView数据集的中英文图文对进行预训练，并在微调阶段使用长的视觉问答数据以生成符合人工偏好的答案。VisualGLM-6B使用SwissArmyTransformer工具库进行训练，并提供了与huggingface接口和sat接口对接的方式】'VisualGLM-6B - Chinese and English multimodal conversational language model | 多模态中英双语对话语言模型' THUDM GitHub: github.com/THUDM/VisualGLM-6B  

Picture: [5396ee05ly8he2hdo06lfj20ws0fatc3.jpg](https://weibo.cn//mblog/pic/N19mKuCGV?rl=1)

Github: [github.com/THUDM/VisualGLM-6B](github.com/THUDM/VisualGLM-6B)

#### [【扩散模型个性化的相关资源列表。主要关注如何利用大型扩散模型高效地学习概念、对象和风格。其中涵盖了个 @爱可可-爱生活](https://weibo.com/1402400261/N19tT8wvm)

Note: 【扩散模型个性化的相关资源列表。主要关注如何利用大型扩散模型高效地学习概念、对象和风格。其中涵盖了个性化方法、反演技术、编辑方法以及参数高效微调等内容。包括一些相关论文和会议报告的链接，提供了更深入的了解和学习资料】'Awesome Diffusion Personalization - A collection of resources on personalization with diffusion models.' PRIV-Creation GitHub: github.com/PRIV-Creation/Awesome-Diffusion-Personalization  

Picture: [5396ee05ly8he2hw3fzpij20wf0u043l.jpg](https://weibo.cn//mblog/pic/N19tT8wvm?rl=1)

Github: [github.com/PRIV-Creation/Awesome-Diffusion-Personalization](github.com/PRIV-Creation/Awesome-Diffusion-Personalization)

#### [清华的ChatGLM 发布了 VisualGLM-6B，一个支持图像理解的多模态对话语言模型。可以通 @宝玉xp](https://weibo.com/1727858283/N1dm2pNVS)

Note: 清华的ChatGLM 发布了 VisualGLM-6B，一个支持图像理解的多模态对话语言模型。可以通过仓库中的 cli_demo_vision.py 和 web_demo_vision.py 来运行命令行和网页 Demo。注意 VisualGLM-6B 需要额外安装 SwissArmyTransformer 和 torchvision。另外他们的训练数据增加英文指令微调数据以平衡中英文数据比例，解决英文回答中夹杂中文词语的现象。项目地址：github.com/THUDM/ChatGLM-6B🔗划重点：支持图像理解的多模态回复:刚发现在chatglm的网页里面也有链接跳转，我之前看到的是这个，误以为你贴错了  github.com/THUDM/VisualGLM-6B回复:没问题呀，请问正确的网址是？网址写成chatglm了

Picture: [66fd066bgy1he2yztv8j4j20ry0l2gum.jpg](https://weibo.cn//mblog/pic/N1dm2pNVS?rl=1)

Github: [github.com/THUDM/ChatGLM-6B](github.com/THUDM/ChatGLM-6B)

Github: [github.com/THUDM/VisualGLM-6B](github.com/THUDM/VisualGLM-6B)

#### [通过拖动的方式就可以对图片进行局部微调。Drag Your GAN: Interactive Poi @宝玉xp](https://weibo.com/1727858283/N1iKl4zVG)

Note: 通过拖动的方式就可以对图片进行局部微调。Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold项目摘要：生成满足用户需求的视觉内容往往需要对生成对象的姿态、形状、表情和布局进行灵活和精确的控制。现有的方法通过手动标注的训练数据或先验的3D模型来控制生成对抗网络（GANs），但这些方法往往缺乏灵活性、精度和通用性。在这项工作中，我们研究了一种强大且少被探索的GANs控制方式，即以用户交互的方式"拖动"图像的任何点以精确地达到目标点，如视频所示。为了实现这一目标，我们提出了DragGAN，它包含两个主要组成部分：1)基于特征的运动监督，引导手柄点向目标位置移动，和2)一种新的点追踪方法，利用判别生成器特征来定位手柄点的位置。通过DragGAN，任何人都可以对图像进行变形，对像素去向进行精确控制，从而操纵各种类别如动物、汽车、人类、景观等的姿态、形状、表情和布局。由于这些操纵是在GAN的学习生成图像流形上进行的，因此即使在如幻觉遮挡内容和形状变形始终跟随对象的刚度等具有挑战性的情况下，也能生成逼真的输出。定性和定量的比较都证明了DragGAN在图像操作和点追踪任务中相对于之前方法的优势。我们还展示了通过GAN反转操作真实图像的例子。项目首页：🤗 论文：项目代码：github.com/XingangPan/DragGAN🔗 终于不怕甲方的“这个不错，你把大象转个身就好了”的需求了哇，GAN 这是老树又发新芽了吗？（话说之前的 Giga GAN 能用了没，今年每次看到 GAN 的 demo 都很吓人，就是蹲得有点麻了转发微博 租电脑吗结合现在ai的使用情况有点担心以后被拿来造谣不过技术的进步难以阻挡，希望能被好好使用吧图片评论 这是什么幻术P图都P不到这么自然局部微调个der,背景跟着一起跑不说，人车比例都变形了回复:妈呀 我艹 看完视频我是你头像这个状态它真能做到这么实时的生成效率么牛啊

Github: [github.com/XingangPan/DragGAN](github.com/XingangPan/DragGAN)

#### [GETMusic: Generating Any Music Tracks with a Unifi @宝玉xp](https://weibo.com/1727858283/N1hNpBBUj)

Note: GETMusic: Generating Any Music Tracks with a Unified Representation and Diffusion FrameworkGETMusic：用统一的表示和扩散框架生成任何音乐曲目太专业了，看不太懂，就不乱介绍了，有兴趣的去看项目首页或者论文。论文：项目首页：ai-muzic.github.io/getmusic/🔗 几位作者都是中国人，致敬容祖儿的痛爱！

#### [现在开源的LLM中，最大上下文窗口应该是MosaicML的 MPT-7B-StoryWriter，6 @宝玉xp](https://weibo.com/1727858283/N1idYomt6)

Note: 现在开源的LLM中，最大上下文窗口应该是MosaicML的 MPT-7B-StoryWriter，65K tokens，可以把《了不起的盖茨比》都一次性扔进去。可以在HuggingFace🤗上测试：但中文支持惨不忍睹。 英文编故事效果很好，找乐子学英文好帮手

Picture: [66fd066bgy1he3kdh9itbj20uq0g244s.jpg](https://weibo.cn//mblog/pic/N1idYomt6?rl=1)

#### [Quivr，用 AI 来打造你的第二大脑。作为一个开源的 AI 知识库解决方案，Quivr 支持将文 @宝玉xp](https://weibo.com/1727858283/N1qUFj7Wg)

Note: Quivr，用 AI 来打造你的第二大脑。作为一个开源的 AI 知识库解决方案，Quivr 支持将文本、图像、视频、代码片段、PPT、Excel 数据表等内容直接上传云端，并通过大语言模型，快速实现信息检索、问答。GitHub：github.com/StanGirard/quivr该项目支持 GPT-3.5、GPT-4、Claude 等大语言模型，可自行部署，保障隐私安全。 收藏

Github: [github.com/StanGirard/quivr](github.com/StanGirard/quivr)

#### [webgpu-torch：typescript版的pytorch地址：github.com/prae @宝玉xp](https://weibo.com/1727858283/N1szdEE3D)

Note: webgpu-torch：typescript版的pytorch地址：github.com/praeclarum/webgpu-torch使用WebGPU加速的张量计算和自动梯度计算。开发者表示这个库受到了pytorch的启发，但它并不是一个克隆版本，而是从零开始编写的。API接口并不100%兼容pytorch，但优先考虑使其尽可能相似。 

Github: [github.com/praeclarum/webgpu-torch](github.com/praeclarum/webgpu-torch)

#### [【Document Q&A on Wikipedia articles：在维基百科文章上运行文档问答 @爱可可-爱生活](https://weibo.com/1402400261/N1bBzgljJ)

Note: 【Document Q&A on Wikipedia articles：在维基百科文章上运行文档问答(Q&A)任务，使用LangChain作为问答框架，使用OpenAI和HuggingFace模型进行嵌入和LLM(语言模型微调)】’Document Q&A on Wikipedia articles - Document Q&A on Wikipedia articles using LLMs' Jou-ching (George) Sung GitHub: github.com/georgesung/LLM-WikipediaQA  

Picture: [5396ee05ly8he2ra96wnej21440u00xi.jpg](https://weibo.cn//mblog/pic/N1bBzgljJ?rl=1)

Github: [github.com/georgesung/LLM-WikipediaQA](github.com/georgesung/LLM-WikipediaQA)

#### [【大型语言模型(LLM)及相关机器人的崛起】“The Rise and Rise of A.l. - @爱可可-爱生活](https://weibo.com/1402400261/N1bPQChqJ)

Note: 【大型语言模型(LLM)及相关机器人的崛起】“The Rise and Rise of A.l. - Large Language Models (LLMs) & their associated bots like ChatGPT”  src: news reports, LifeArchitect.ai 

Picture: [5396ee05ly8he2s8nqievj20ue0u0430.jpg](https://weibo.cn//mblog/pic/N1bPQChqJ?rl=1)

#### [MetaAI 重磅开源 ImageBind，可让模型跨 6 种不同的模态（图像、文本、音频、深度、热 @GitHubDaily](https://weibo.com/5722964389/MFOXlqV6l)

Note: MetaAI 重磅开源 ImageBind，可让模型跨 6 种不同的模态（图像、文本、音频、深度、热能和 IMU 数据）进行联动！基于该项目，开发者可以「开箱即用」实现包括跨模态检索、使用算术合成模态、跨模态检测和生成等各类新兴应用。详细介绍：借助 ImageBind，则可以做到直接通过声音来直接生成图像。这使得 AI 能够更加深入了解人类情感，理解他们的喜怒哀乐，进而为人类提供更好的服务。当你举起手机，录制一个海边日落的视频时，AI 便能自动根据视频内容来生成文案和字幕，并匹配上合适的背景音乐。甚至 AI 还有可能通过一首歌，直接为歌手生成一段视频 MV。此举将为 AIGC 技术带来更为广泛的应用场景，一大波更为有趣、实用的 AI 项目也即将来袭。GitHub：github.com/facebookresearch/ImageBind三个月了，Meta还没有正式发大模型吗？报告总裁，Meta已经带着羊驼和ImageBind在开源界鲨疯了开源vs闭源 安卓vs iosAI寒武纪回复:估计他押宝的还是元宇宙，ai 是元宇宙的前置技术之一，所以把模型开源出来让所有人替他们优化和发展，从而完成前置技术的构建Repost 回复:积极拥抱开源是基于学术共享目的，如今大模型的基础，bert和transformer模型都是第一时间开源的，但是竞争加剧的现在，谷歌已改变其开源政策，开不开源从来不能叫一种时尚，这更多是学者之前基于学术自由达成的共识，但这种共识是脆弱的GitHub：github.com/facebookresearch/ImageBind 天配乐配的，是它自己作曲的，还是匹配智人已有的作品？回复:以前开源一般都是后来者或竞争失败的作品，现在，开源已经成为一种潮流，时尚，不开源就会被鄙视，像一直封闭的微软，都开始扭扭捏捏地开源了，我觉的，它内心是一万个不乐意的这世界变化太快回复:在更加落后的情况下不存在这种情况回复:那是不是也帮了竞争对手？

Github: [github.com/facebookresearch/ImageBind](github.com/facebookresearch/ImageBind)

Github: [github.com/facebookresearch/ImageBind](github.com/facebookresearch/ImageBind)

#### [万字长文，讲述《ChatGPT 背后的语言模型简史》。内容覆盖自然语言处理、神经网络、深度学习、生成 @GitHubDaily](https://weibo.com/5722964389/MFR9YwqiC)

Note: 万字长文，讲述《ChatGPT 背后的语言模型简史》。内容覆盖自然语言处理、神经网络、深度学习、生成式预训练等技术发展历史，值得一读。地址： 点赞了就算看过了🐶 Mark先🐎马马住转发微博转发微博转发微博

Picture: [006fiYtfgy1hdsk2zpas8j317i1g8tor.jpg](https://weibo.cn//mblog/pic/MFR9YwqiC?rl=1)

#### [普林斯顿大学的研究人员，近日尝试使用大语言模型的总结能力，让 AI 完成物品对象分类，进而打造出一台 @GitHubDaily](https://weibo.com/5722964389/N0vi7EbVA)

Note: 普林斯顿大学的研究人员，近日尝试使用大语言模型的总结能力，让 AI 完成物品对象分类，进而打造出一台可用于房屋清洁与整理的智能机器人：TidyBot。目前该项目代码、论文、数据集均已发布，大家可以学习一下。下面是关于该项目更为具体的介绍：机器人要想有效地提供个性化的物理帮助，就必须了解用户的偏好，这些偏好通常可以重新应用于未来的场景。在这项工作中，我们研究了家庭清洁的个性化，机器人可以通过拾取和放好物品来整理房间。一个关键的挑战是确定放置每个物体的合适位置，因为人们的喜好会因个人品味或文化背景而有很大差异。例如，一个人可能更喜欢将衬衫存放在抽屉中，而另一个人可能更喜欢将它们放在架子上。我们的目标是构建可以通过与特定人的先前交互从少数示例中学习此类偏好的系统。我们表明，机器人可以将基于语言的规划和感知与大语言模型 (LLM) 的少量摘要功能相结合，以推断广泛适用于未来交互的广义用户偏好。这种方法可以实现快速适应，并在我们的基准数据集中对看不见的物体实现 91.2% 的准确率。我们还在真实世界的移动机械手 TidyBot 上展示了我们的方法，它在真实世界的测试场景中成功地放置了 85.0% 的物体。GitHub：github.com/jimmyyhwu/tidybot项目介绍： 有意思咋的？捡垃圾的也要失业了？转发微博AI 这是要颠覆家政行业了么

Github: [github.com/jimmyyhwu/tidybot](github.com/jimmyyhwu/tidybot)

#### [Quivr，用 AI 来打造你的第二大脑。作为一个开源的 AI 知识库解决方案，Quivr 支持将文 @GitHubDaily](https://weibo.com/5722964389/N1nUy3Drf)

Note: Quivr，用 AI 来打造你的第二大脑。作为一个开源的 AI 知识库解决方案，Quivr 支持将文本、图像、视频、代码片段、PPT、Excel 数据表等内容直接上传云端，并通过大语言模型，快速实现信息检索、问答。GitHub：github.com/StanGirard/quivr该项目支持 GPT-3.5、GPT-4、Claude 等大语言模型，可自行部署，保障隐私安全。 不好用，用的api key，但是一直error这个有封装的服务吗？我还准备自己写的。这下好了不用写了转发微博这个不错啊感觉就是个架子。。类似于国内的闻达？还是感觉闻达好用点，虽然布置环境有点麻烦应该是用了chatgpt的embedding功能?

Github: [github.com/StanGirard/quivr](github.com/StanGirard/quivr)

#### [最近做了一个无代码AI工作流+知识库的产品，顺便开源了一个本地的版本放在Github上：Anders @宝玉xp](https://weibo.com/1727858283/N1C2MuFPC)

Note: 最近做了一个无代码AI工作流+知识库的产品，顺便开源了一个本地的版本放在Github上：AndersonBY/vector-vein即便没有代码能力的朋友也可以通过简单的拖拽连线的方式快速搭建一个你自己的AI工作流。软件采用pywebview框架开发，前端用AntDesignVue，AI接口调用OpenAI的API，向量数据库采用Qdrant。 你好，我注册了两次，邮件无法验证

#### [博文《理解布隆过滤器算法的实现原理》布隆过滤器是一种空间高效概率性的数据结构（百科中原文是a spa @蚁工厂](https://weibo.com/2194035935/N1zYT0fbK)

Note: 博文《理解布隆过滤器算法的实现原理》布隆过滤器是一种空间高效概率性的数据结构（百科中原文是a space-efficient probabilistic data structure），该数据结构于1970年由Burton Howard Bloom提出，作用是测试一个元素是否某个集合的一个成员。 回复:打扰一下，你在这里艾特，就可以添加到笔记吗回复:早

Picture: [82c654dfly1h2g1aq6ztwj20k00xegnu.jpg](https://weibo.cn//mblog/pic/Lu24Q1Je2?rl=1)

#### [电子书《 Algorithms for Optimization》“这本书为优化问题提供了广泛的介绍 @蚁工厂](https://weibo.com/2194035935/N1AfT0luX)

Note: 电子书《 Algorithms for Optimization》“这本书为优化问题提供了广泛的介绍，特别关注实用算法在工程系统设计中的应用。我们覆盖了各种优化主题，介绍了基础的数学问题公式和解决它们的算法。通过图表、示例和练习，我们传达了各种方法背后的直观理解。这本教材适用于高级本科生、研究生以及专业人士。阅读本书需要一定的数学成熟度，并假设读者已经接触过多元微积分、线性代数和概率概念。在附录中提供了一些复习材料。这本书对于数学、统计、计算机科学、航空航天、电气工程和运筹学等领域的学生特别有用。”

Picture: [82c654dfly1he501x6vwdj21ya0oh19q.jpg](https://weibo.cn//mblog/pic/N1AfT0luX?rl=1)

#### [【Plug and Plai：旨在简化将AI插件集成到开源语言模型(LLMs)的开源库，提供实用函数 @爱可可-爱生活](https://weibo.com/1402400261/N1Cd7q1xh)

Note: 【Plug and Plai：旨在简化将AI插件集成到开源语言模型(LLMs)的开源库，提供实用函数来从plugnplai.com目录获取插件列表，获取插件清单，提取OpenAPI规范并加载插件】'Plug and Plai - Integrating AI plugins to LLMs' Eduardo Reis GitHub: github.com/edreisMD/plugnplai   

Picture: [5396ee05ly8he60polmz1j21260u0n0m.jpg](https://weibo.cn//mblog/pic/N1Cd7q1xh?rl=1)

Github: [github.com/edreisMD/plugnplai](github.com/edreisMD/plugnplai)

#### [【PromptOptimizer：旨在通过最小化LLM(Language Model)的Token复 @爱可可-爱生活](https://weibo.com/1402400261/N1CgR68DN)

Note: 【PromptOptimizer：旨在通过最小化LLM(Language Model)的Token复杂度来节省API成本和模型计算的工具，具有插入式优化器，可以使用优化方法最小化Token复杂度，无需访问权重、logits或解码算法】'PromptOptimizer - Minimize LLM token complexity to save API costs and model computations' Vaibhav Kumar GitHub: github.com/vaibkumr/prompt-optimizer  有损压缩。

Picture: [5396ee05ly8he60yit0ecj213j0u0teg.jpg](https://weibo.cn//mblog/pic/N1CgR68DN?rl=1)

Github: [github.com/vaibkumr/prompt-optimizer](github.com/vaibkumr/prompt-optimizer)

#### [《性能之巅 第2版》读书笔记（第12章）1、在可控的状态下进行性能基准测试，可以比较不同选择，并发现 @小川CD](https://weibo.com/1202332555/N1CT8snjs)

Note: 《性能之巅 第2版》读书笔记（第12章）1、在可控的状态下进行性能基准测试，可以比较不同选择，并发现回归问题，以及在生产环境接近性能极限时了解到这一极限。2、每个基准测试都应该附带说明，介绍所遇到的限制和所进行的分析。如果你研究一个基准测试结果所需时间少于一周，那很可能是错误的。3、一个开发产品的工程团队可能已经将某个特定的基准测试工具标准化，并全力根据基准测试软件的测量结果来提高性能。然而，如果他们没有模拟客户的工作负载，那么他们的努力只会用来优化错误的行为。4、当客户选择了一个产品后，他们不会只使用5分钟，而是会使用数个月。在这段时间里，客户会分析和优化产品性能，很可能在最初的几周就找出了最糟糕的问题。5、可以通过回放目标的跟踪日志来进行基准测试，但即使正确地进行了跟踪和回放，其他微妙的影响也可能破坏结果。所有的基准测试都是如此，分析并理解发生了什么是至关重要的。6、需要确定基准测试所需测试的对象，并理解它是什么。主动进行基准测试可以确定被测试系统的真实极限，或者是基准测试本身的极限。记录所遇到的极限的具体细节，在分析基准测试结果时非常有帮助。7、在基准测试过程中应用USE方法可以确保找到一个限制。该限制可能是某个组件（硬件或软件）达到了100%的使用率，或者系统还未被推至极限。8、逐渐增加负载是一种确定系统所能处理的最大吞吐量的简单方法。以较小的递增添加负载，并测量产出吞吐量，直至达到极限。结合USE方法，找到已经耗尽的资源，以此为起点研究如何进一步提升性能。9、同样地，可以测量延迟和吞吐量，特别是延迟的分布。一旦系统接近极限，队列会显著增加，导致延迟增加。如果你将负载过高，延迟会变得过高，以至于不能合理地认为结果是有效的。10、一个检查基准测试结果的方法是检查所有特性是否都没有问题。这包括检查结果是否需要某些组件超过其已知的极限，例如网络带宽、控制器带宽、互联带宽或磁盘IOPS。

#### [ChatGPT 的 Code interpreter 插件，至今依旧没有对所有 Plus 用户开放。 @宝玉xp](https://weibo.com/1727858283/N1oaCo70x)

Note: ChatGPT 的 Code interpreter 插件，至今依旧没有对所有 Plus 用户开放。国外一位开发者苦等无果，憋不住动手做了简化版解决方案：GPT Code UI，并将代码开源到了 GitHub。GitHub：github.com/ricklamers/gpt-code-ui/该项目可利用大语言模型能力，自动生成与执行代码。另外还支持文件上传、下载，上下文理解，可选 GPT-3.5 和 GPT-4 模型。不仅如此，作者还分享了整个技术方案的实现细节，感兴趣的也可以学习一下。技术实现：ricklamers.io/posts/gpt-code/有没有人做Code Plugin的？

Picture: [006fiYtfgy1he4aj17uafj32u81u6kjl.jpg](https://weibo.cn//mblog/pic/N1o8NyGcw?rl=1)

Github: [github.com/ricklamers/gpt-code-ui/](github.com/ricklamers/gpt-code-ui/)

#### [通过拖动的方式就可以对图片进行局部微调。Drag Your GAN: Interactive Poi @宝玉xp](https://weibo.com/1727858283/N1nUOflHJ)

Note: 通过拖动的方式就可以对图片进行局部微调。Drag Your GAN: Interactive Point-based Manipulation on the Generative Image Manifold项目摘要：生成满足用户需求的视觉内容往往需要对生成对象的姿态、形状、表情和布局进行灵活和精确的控制。现有的方法通过手动标注的训练数据或先验的3D模型来控制生成对抗网络（GANs），但这些方法往往缺乏灵活性、精度和通用性。在这项工作中，我们研究了一种强大且少被探索的GANs控制方式，即以用户交互的方式"拖动"图像的任何点以精确地达到目标点，如视频所示。为了实现这一目标，我们提出了DragGAN，它包含两个主要组成部分：1)基于特征的运动监督，引导手柄点向目标位置移动，和2)一种新的点追踪方法，利用判别生成器特征来定位手柄点的位置。通过DragGAN，任何人都可以对图像进行变形，对像素去向进行精确控制，从而操纵各种类别如动物、汽车、人类、景观等的姿态、形状、表情和布局。由于这些操纵是在GAN的学习生成图像流形上进行的，因此即使在如幻觉遮挡内容和形状变形始终跟随对象的刚度等具有挑战性的情况下，也能生成逼真的输出。定性和定量的比较都证明了DragGAN在图像操作和点追踪任务中相对于之前方法的优势。我们还展示了通过GAN反转操作真实图像的例子。项目首页：🤗 论文：项目代码：github.com/XingangPan/DragGAN🔗 

Github: [github.com/XingangPan/DragGAN](github.com/XingangPan/DragGAN)

#### [[CL]《PaLM 2 Technical Report》R Anil, A M. Dai, O F @爱可可-爱生活](https://weibo.com/1402400261/N1fGq48mW)

Note: [CL]《PaLM 2 Technical Report》R Anil, A M. Dai, O Firat, M Johnson... [Google] (2023)   

Picture: [5396ee05ly1he39318xq2j21dm0oawuz.jpg](https://weibo.cn//mblog/pic/N1fGi4kcT?rl=1)

#### [电子书《李宏毅深度学习教程（LeeDL-Tutorial）》地址：github.com/datawh @蚁工厂](https://weibo.com/2194035935/N1gDMCodx)

Note: 电子书《李宏毅深度学习教程（LeeDL-Tutorial）》地址：github.com/datawhalechina/leedl-tutorial/李宏毅老师和Datawhale团队一起出品的电子书。本项目《LeeDL-Tutorial》对于李宏毅老师的视频教程进行了整理、校对以及迭代优化，不仅对已有内容进行了完善和补充，同时也补充了部分最新的内容以及配套的课后实战代码，方便大家理论+实战双丰收。👍

Picture: [82c654dfly1he3dithy2uj20f71co450.jpg](https://weibo.cn//mblog/pic/N1gDMCodx?rl=1)

Github: [github.com/datawhalechina/leedl-tutorial/](github.com/datawhalechina/leedl-tutorial/)

#### [【指令微调与人工反馈强化学习(RLHF)】《Instruction finetuning and R @爱可可-爱生活](https://weibo.com/1402400261/N1gRv9IoV)

Note: 【指令微调与人工反馈强化学习(RLHF)】《Instruction finetuning and Reinforcement Learning with Human Feedback (RLHF)》Hyung Won Chung   

Picture: [5396ee05ly8he3ehfifllj21e30u0jy0.jpg](https://weibo.cn//mblog/pic/N1gRv9IoV?rl=1)

#### [电子书《Modern CMake》地址：modern-cmake-cn.github.io/Mode @蚁工厂](https://weibo.com/2194035935/N1hPCogVw)

Note: 电子书《Modern CMake》地址：modern-cmake-cn.github.io/Modern-CMake-zh_CN/这是著名 CMake 教程 Modern CMake 的简体中文翻译版。 

Picture: [82c654dfly1h2dsvv3kswj20fb1iv413.jpg](https://weibo.cn//mblog/pic/LtLcZuvmA?rl=1)

#### [电子书《深度学习理论与实战：提高篇》地址：fancyerii.github.io/2019/03/1 @蚁工厂](https://weibo.com/2194035935/N1hWJiXXg)

Note: 电子书《深度学习理论与实战：提高篇》地址：fancyerii.github.io/2019/03/14/dl-book/免费的深度学习书籍！涵盖听觉、视觉、语言和强化学习四大领域，深入浅出的理论分析和详尽的代码分析。 回复:未成功收藏到你的notion[老师好]，无公共集成 token

Picture: [82c654dfly1h2dsq8afrrj20lx1lgq9a.jpg](https://weibo.cn//mblog/pic/LtJPjt4OO?rl=1)

#### [【Sheep RL：基于PyTorch的易于使用的增强学习框架，通过Lightning Fabric @爱可可-爱生活](https://weibo.com/1402400261/N1iyiDxjB)

Note: 【Sheep RL：基于PyTorch的易于使用的增强学习框架，通过Lightning Fabric加速。该框架旨在提供一个简单且可扩展的强化学习算法框架，同时解耦强化学习算法与环境，使其能与任何环境一起使用】'Sheep RL - Distributed Reinforcement Learning accelerated by Lightning Fabric' EclecticSheep GitHub: github.com/Eclectic-Sheep/sheeprl  

Picture: [5396ee05ly8he3lxxz5gbj21bq0ieq6e.jpg](https://weibo.cn//mblog/pic/N1iyiDxjB?rl=1)

Github: [github.com/Eclectic-Sheep/sheeprl](github.com/Eclectic-Sheep/sheeprl)

#### [【loops: 针对表现出不规则并行性的应用提出的开源GPU负载均衡框架，旨在改善在GPU上开发不规 @爱可可-爱生活](https://weibo.com/1402400261/N1iHh4uBX)

Note: 【loops: 针对表现出不规则并行性的应用提出的开源GPU负载均衡框架，旨在改善在GPU上开发不规则并行算法的程序员的生产力，并通过允许快速尝试各种现有负载均衡技术来提高此类应用的整体性能】'🐧 loops: Expressing Parallel Irregular Computations - 🎃 GPU load-balancing library for regular and irregular computations.' gunrock GitHub: github.com/gunrock/loops  

Picture: [5396ee05ly8he3mkmspcaj21c60s2tic.jpg](https://weibo.cn//mblog/pic/N1iHh4uBX?rl=1)

Github: [github.com/gunrock/loops](github.com/gunrock/loops)

#### [【类ChatGPT开源模型大列表】’open source ChatGPT and beyond - @爱可可-爱生活](https://weibo.com/1402400261/N1iHIfwuT)

Note: 【类ChatGPT开源模型大列表】’open source ChatGPT and beyond - Open efforts to implement ChatGPT-like models and beyond.' SunLemuria GitHub: github.com/SunLemuria/open_source_chatgpt_list   

Picture: [5396ee05ly8he3mmo580xj20u00u50x3.jpg](https://weibo.cn//mblog/pic/N1iHIfwuT?rl=1)

Github: [github.com/SunLemuria/open_source_chatgpt_list](github.com/SunLemuria/open_source_chatgpt_list)

#### [【whisper-ctranslate2：与原始的基于CTranslate2的OpenAI客户端兼容 @爱可可-爱生活](https://weibo.com/1402400261/N1iK9wVzf)

Note: 【whisper-ctranslate2：与原始的基于CTranslate2的OpenAI客户端兼容的命令行客户端，使用CTranslate2和Faster-whisper Whisper实现，相较于openai/whisper，速度提高了4倍，同时占用更少的内存】’whisper-ctranslate2 - Whisper command line client compatible with original OpenAI client based on CTranslate2.' Softcatalà GitHub: github.com/Softcatala/whisper-ctranslate2  

Picture: [5396ee05ly8he3msv291jj20oe05h75m.jpg](https://weibo.cn//mblog/pic/N1iK9wVzf?rl=1)

Github: [github.com/Softcatala/whisper-ctranslate2](github.com/Softcatala/whisper-ctranslate2)

#### [小朋友折腾了一个VisualGLM-6B ，开源的 t.ly/i7pK ，支持图像、中文和英文的多模 @蚁工厂](https://weibo.com/2194035935/N1q93BG5q)

Note: 小朋友折腾了一个VisualGLM-6B ，开源的 t.ly/i7pK ，支持图像、中文和英文的多模态对话语言模型，语言模型基于 ChatGLM-6B，具有 62 亿参数；图像部分通过训练 BLIP2-Qformer 构建起视觉模型与语言模型的桥梁，整体模型共78亿参数。VisualGLM-6B 依靠来自于 CogView 数据集的30M高质量中文图文对，与300M经过筛选的英文图文对进行预训练，中英文权重相同。该训练方式较好地将视觉信息对齐到ChatGLM的语义空间；之后的微调阶段，模型在长视觉问答数据上训练，以生成符合人类偏好的答案。VisualGLM-6B 由 SwissArmyTransformer(简称sat) 库训练，这是一个支持Transformer灵活修改、训练的工具库，支持Lora、P-tuning等参数高效微调方法。本项目提供了符合用户习惯的huggingface接口，也提供了基于sat的接口。不过，由于 VisualGLM-6B 仍处于v1版本，目前已知其具有相当多的局限性，如图像描述事实性/模型幻觉问题，图像细节信息捕捉不足，以及一些来自语言模型的局限性。请大家在使用前了解这些问题，评估可能存在的风险。在VisualGLM之后的版本中，将会着力对此类问题进行优化。结合模型量化技术，用户可以在消费级的显卡上进行本地部署（INT4量化级别下最低只需8.7G显存）。

Picture: [7ebeb44bly1he4ewxjjydj215016xnem.jpg](https://weibo.cn//mblog/pic/N1p89aoe5?rl=1)

#### [系列电子书：Programming Notes for Professionals books，面向 @蚁工厂](https://weibo.com/2194035935/N1qBrAX7V)

Note: 系列电子书：Programming Notes for Professionals books，面向专业人士的编程笔记网址：books.goalkicker.com内容很多，有接近50本。从算法到各类编程语言及工具使用等。直接下载pdf文档 回复:成功保存至你的notion回复:成功保存至Notion👍

Picture: [82c654dfly1he4lfogaxtj209q0drdjm.jpg](https://weibo.cn//mblog/pic/N1qBrAX7V?rl=1)

#### [【webgpu-torch：受PyTorch启发用WebGPU加速的张量计算和自动微分库，支持GPU @爱可可-爱生活](https://weibo.com/1402400261/N1rpXrNbb)

Note: 【webgpu-torch：受PyTorch启发用WebGPU加速的张量计算和自动微分库，支持GPU加速的张量操作和自动微分，并提供了类似于PyTorch的API】’webgpu-torch - Tensor computation with WebGPU acceleration' Frank A. Krueger GitHub: github.com/praeclarum/webgpu-torch   

Picture: [5396ee05ly8he4p1xf6kgj216k0pyad5.jpg](https://weibo.cn//mblog/pic/N1rpXrNbb?rl=1)

Github: [github.com/praeclarum/webgpu-torch](github.com/praeclarum/webgpu-torch)

#### [【BLOOMChat：新的开放多语言聊天LLM，具有1760亿参数，是目前最大的聊天导向开源模型，也 @爱可可-爱生活](https://weibo.com/1402400261/N1rtyjfFM)

Note: 【BLOOMChat：新的开放多语言聊天LLM，具有1760亿参数，是目前最大的聊天导向开源模型，也是第一个建立在多语言预训练语言模型基础上的模型。该模型的开发采用了合成对话数据和高质量人工编写样本相结合的方法。通过人工评估和定量指标，BLOOMChat在多语言聊天能力和跨语言任务能力上表现出色。与开源模型和GPT-4相比，BLOOMChat在人类偏好排名和模型质量评分中获得了良好的结果】《BLOOMChat: a New Open Multilingual Chat LLM》  ChatGPT 的真开源平替们，正在如火如荼地向着摧毁 Google 和 OpenAI 的护城河的方向前进，

Picture: [5396ee05ly8he4p9r8ne4j209s0a8t90.jpg](https://weibo.cn//mblog/pic/N1rtyjfFM?rl=1)

#### [【TokenHawk：基于WebGPU用手写LLaMA推理的工具】'TokenHawk - WebG @爱可可-爱生活](https://weibo.com/1402400261/N1rxpAH3E)

Note: 【TokenHawk：基于WebGPU用手写LLaMA推理的工具】'TokenHawk - WebGPU LLM inference tuned by hand' kayvr GitHub: github.com/kayvr/token-hawk   

Picture: [5396ee05ly8he4pml0dt3j20he0jg3zj.jpg](https://weibo.cn//mblog/pic/N1rxpAH3E?rl=1)

Github: [github.com/kayvr/token-hawk](github.com/kayvr/token-hawk)

#### [llmchain.rs ，这个项目的目的是：提供一些基础算子(opeartor)，然后通过编程或其他 @BohuTANG](https://weibo.com/1691468715/N1rBXy0on)

Note: llmchain.rs ，这个项目的目的是：提供一些基础算子(opeartor)，然后通过编程或其他方式将这些算子连接(chain)在一起，形成一个流水线(pipeline)，用于完成一个完整功能的AI应用，可以看做是Rust版的LangChain，Repo:  回复:需要点魔法 :)图片评论 需要魔法吗？怎么打不开

#### [webgpu-torch：typescript版的pytorch地址：github.com/prae @蚁工厂](https://weibo.com/2194035935/N1sgodIsD)

Note: webgpu-torch：typescript版的pytorch地址：github.com/praeclarum/webgpu-torch使用WebGPU加速的张量计算和自动梯度计算。开发者表示这个库受到了pytorch的启发，但它并不是一个克隆版本，而是从零开始编写的。API接口并不100%兼容pytorch，但优先考虑使其尽可能相似。 Repost

Github: [github.com/praeclarum/webgpu-torch](github.com/praeclarum/webgpu-torch)

#### [最近，一个被称为「ChatGPT Plugins国产替代系统」的开源项目在GitHub上星标猛增。这 @蚁工厂](https://weibo.com/2194035935/N1sBzD2OK)

Note: 最近，一个被称为「ChatGPT Plugins国产替代系统」的开源项目在GitHub上星标猛增。这个项目就是BMTools，面壁智能自研的大模型工具学习引擎。面壁智能联合来自清华、人大、腾讯的研究人员共同发布了中文领域首个基于交互式网页搜索的问答开源模型WebCPM，这一创举填补了国产大模型该领域的空白。面壁智能自研工具学习引擎BMTools也因此被成功实践。项目地址：https: //github.com/OpenBMB/BMTools

Picture: [006e14C0ly1hdz2gle88sj30u00futdw.jpg](https://weibo.cn//mblog/pic/N0HwclDOC?rl=1)

Github: [github.com/OpenBMB/BMTools](github.com/OpenBMB/BMTools)

#### [【Zep: 适用于LLM应用的长期记忆库，可以存储、汇总、嵌入、索引和丰富LLM应用/聊天机器人的历 @爱可可-爱生活](https://weibo.com/1402400261/N1v7szbHp)

Note: 【Zep: 适用于LLM应用的长期记忆库，可以存储、汇总、嵌入、索引和丰富LLM应用/聊天机器人的历史记录，并通过简单、低延迟的API公开这些信息。特点包括长期记忆持久性、基于可配置消息窗口的自动摘要、向量搜索、自动记忆令牌计数等】’Zep: A long-term memory store for LLM / Chatbot applications' GitHub: github.com/getzep/zep  你开发的？

Picture: [5396ee05ly8he55eiqtg7j218d0u0tf6.jpg](https://weibo.cn//mblog/pic/N1v7szbHp?rl=1)

Github: [github.com/getzep/zep](github.com/getzep/zep)

#### [【llm-analysis：用于计算大型语言模型(LLM)或Transformer模型的训练或推理时 @爱可可-爱生活](https://weibo.com/1402400261/N1v8C9gN3)

Note: 【llm-analysis：用于计算大型语言模型(LLM)或Transformer模型的训练或推理时延和内存使用的工具。可以根据指定的模型、GPU、数据类型和并行配置估算LLM的时延和内存使用情况。可以帮助回答许多问题，例如确定批量大小、数据类型和并行方案以获得可行且最佳的训练或推理设置。还支持通过命令行界面进行查询，并提供了快速开始指南和示例用法】'llm-analysis - Latency and Memory Analysis of Transformer Models for Training and Inference' Cheng Li GitHub: github.com/cli99/llm-analysis  

Picture: [5396ee05ly8he55gpcpw9j21bw0p8agy.jpg](https://weibo.cn//mblog/pic/N1v8C9gN3?rl=1)

Github: [github.com/cli99/llm-analysis](github.com/cli99/llm-analysis)

#### [【Python Port of 600 Line Bash Script: rsync-time-m @网路冷眼](https://weibo.com/1715118170/N1xQ4tbEJ)

Note: 【Python Port of 600 Line Bash Script: rsync-time-machine.py for Rsync Backups】https:///github.com/basnijholt/rsync-time-machine.py 600 行 Bash 脚本的 Python 移植：用于 Rsync 备份的 rsync-time-machine.py nb

Picture: [663aa05aly8he5hg7zjf3j20ou2zkh0i.jpg](https://weibo.cn//mblog/pic/N1xQ4tbEJ?rl=1)

Github: [github.com/basnijholt/rsync-time-machine.py](github.com/basnijholt/rsync-time-machine.py)

#### [【人工反馈强化学习(RLHF)简要解析】“Reinforcement Learning from H @爱可可-爱生活](https://weibo.com/1402400261/N1J7e0DNo)

Note: 【人工反馈强化学习(RLHF)简要解析】“Reinforcement Learning from Human Feedback (RLHF) - a simplified explanation” gist.github.com/JoaoLages/c6f2dfd13d2484aa8bb0b2d567fbf093 

Picture: [5396ee05ly8he6v87jjjzj235s0mejvo.jpg](https://weibo.cn//mblog/pic/N1J7e0DNo?rl=1)

Github: [github.com/JoaoLages/c6f2dfd13d2484aa8bb0b2d567fbf093](github.com/JoaoLages/c6f2dfd13d2484aa8bb0b2d567fbf093)

#### [egos-2000：一个在 QEMU 和 RISC-V 板上运行的最小化的操作系统（2000行代码） @蚁工厂](https://weibo.com/2194035935/N1JbTCAWw)

Note: egos-2000：一个在 QEMU 和 RISC-V 板上运行的最小化的操作系统（2000行代码）地址：github.com/yhzhang0128/egos-2000该项目是出于教学目的，是康奈尔大学CS5411/4411 课程的配套项目。只用2000行代码，egos-2000实现了一个教育用操作系统的所有组件。它可以在RISC-V板上运行，也可以在QEMU软件模拟器上运行。riscv，先mark

Picture: [82c654dfly1he6vkdbxfbj21xk19yb29.jpg](https://weibo.cn//mblog/pic/N1JbTCAWw?rl=1)

Github: [github.com/yhzhang0128/egos-2000](github.com/yhzhang0128/egos-2000)

#### [刚看到一个LLaMa的微调大模型LIMA，号称只用了1000个精心策划的提示和反馈进行微调，就达到了 @宝玉xp](https://weibo.com/1727858283/N1KNg2QK2)

Note: 刚看到一个LLaMa的微调大模型LIMA，号称只用了1000个精心策划的提示和反馈进行微调，就达到了非常好的效果。以下是LIMA自己的介绍：大型语言模型的训练分为两个阶段：（1）无监督预训练，从原始文本中学习通用表示；（2）大规模的指令调整和强化学习，以更好地适应终端任务和用户偏好。我们通过训练LIMA，一个参数为650亿的LLaMa语言模型，仅使用标准的监督学习损失对1000个精心策划的提示和反馈进行微调，无需任何强化学习或人类偏好模型，来衡量这两个阶段的相对重要性。LIMA表现出了极强的性能，能从训练数据中只有少量的样本学习特定的响应格式，包括从规划旅行行程到推测历史替代情景的复杂查询。此外，该模型往往能很好地推广到未出现在训练数据中的新任务。在一个受控的人类研究中，43%的情况下，LIMA的反馈与GPT-4相当或被严格优先选择；与Bard比较时，这个比例高达58%，与接受人类反馈训练的DaVinci003比较时，这个比例达到65%。综合来看，这些结果强烈表明，大型语言模型中几乎所有的知识都是在预训练阶段学习的，只需要有限的指令调整数据就可以教授模型产生高质量的输出。项目首页：论文：  最珍贵的就是他们这1000条数据回复:又看了一下65B的模型，太大了，至少两块大显卡，玩不了。赞所以这算是对如何fine tune大模型给出指导么？

Picture: [66fd066bgy1he72miuqqwj20nc0oun9x.jpg](https://weibo.cn//mblog/pic/N1KNg2QK2?rl=1)

#### [AI产品推荐：TL:DR Newspaper怎么为一堆新闻生成摘要？TL:DR Newspaper（ @宝玉xp](https://weibo.com/1727858283/N1Qfk9WLa)

Note: AI产品推荐：TL:DR Newspaper怎么为一堆新闻生成摘要？TL:DR Newspaper（Too long, Didn’t read | 太长不读）跟踪 60000 个新闻来源，把采集到的新闻话题按照相似性聚合成小组先用 AI 为一组新闻话题里的每篇新闻分别生成摘要，再分析几篇摘要的差异，最后生成这组新闻的综合摘要，并解释几篇新闻的差异

Picture: [66fd066bgy1he7qoxwaxcj216o2fyhdt.jpg](https://weibo.cn//mblog/pic/N1Qfk9WLa?rl=1)

#### [这是斯坦福2023年公开课CS25的第二课：《 Language and Human Alignme @宝玉xp](https://weibo.com/1727858283/N1RC1ACrL)

Note: 这是斯坦福2023年公开课CS25的第二课：《 Language and Human Alignment》，讲师是OpenAI的Jan，他目前领导OpenAI的对齐（Alignment）团队，并曾在DeepMind担任研究员。他拥有强化学习理论博士学位，并且在过去的10年里一直在思考对齐问题。这节课的主要内容是探讨AI的对齐问题，也就是如何让AI系统符合人类的意图和偏好，以及如何构建能遵循人类意图的AI系统？遵循人类意图意味着：对于明确的意图，能遵循指令，成为一个可靠的助手；对于不明确的意图，需要通过后续问题明确，不要编造，不要做有害的事情。现在使用的主要技术是强化学习反馈，这是用来训练InstructGPT和ChatGPT的技术。首先需要训练一个奖励模型，然后要用人类标注员去标注数据，来告诉模型哪些结果更是人类想要的。虽然每个人类标注员都有自己的偏好，甚至可能有不一致的地方，但模型会多结果进行平均。从成本上来说，人类反馈的成本要远低于预训练的成本，不到预训练计算量的2%。基于人类反馈的强化学习(RLHF)可以让模型做任何它想做的事情，它可以自己找出最好的方法来做事情，你只需要对它的结果进行评估就好了。“评估比生成容易” 很多任务虽然人类不擅长，但是可以很容易的给出评估。RLHF也有一些限制，比如当人工智能进化到一定程度，其可以完成的任务难度也会提升，但是人类评估任务的水平却无法提高，这时候人类将无法再给AI有效的反馈。所以未来我们需要AI来辅助人类进行评估，让AI帮助指出结果中的问题，人类对AI评估的结果进行评估。课程页面：参考材料：- ChatGPT：- InstructGPT： - Language Models are Few-Shot Learners (GPT-3)： 作者通过人工智能实验发现：目标只对有先例可遵循的事情上起作用，而伟大的创新都不是计划出来的。  上市不足一个月，本书豆瓣评分8.8，1761人想读，知名读书博主樊登推荐并讲书。我们十分希望您能够成为本书的读者，如阅读后感兴趣，诚邀您将本书推荐给AI业内的朋友们！谢谢宝玉xp老师您好，我是中译出版社编辑，很高兴认识您！向您推荐一本由（前）OpenAI科学家Kenneth Stanley、Joel Lehman撰写的跨界思维奇书《为什么伟大不能被计划》（why greatness cannot be planned）4月底由我社出版发行。要论教育创新了吗？

#### [技术博客《我与ChatGPT结对编程的体验》  @蚁工厂](https://weibo.com/2194035935/N1KAwaGzb)

Note: 技术博客《我与ChatGPT结对编程的体验》 

#### [这是斯坦福2023年公开课CS25第一课：《Introduction to Transformers @蚁工厂](https://weibo.com/2194035935/N1KCSotLZ)

Note: 这是斯坦福2023年公开课CS25第一课：《Introduction to Transformers》（中英文字幕）讲师: Andrej Karpathy自2017年首次亮相以来，Transformer已经彻底改变了自然语言处理（NLP）的领域。现在，Transformer在深度学习的各个领域都找到了应用，无论是计算机视觉（CV），强化学习（RL），生成对抗网络（GANs），语音甚至生物学。在其他诸多领域，Transformer帮助实现了强大的语言模型如GPT-3，并在DeepMind最近的AlphaFold2中发挥了关键作用，该模型处理蛋白质折叠问题。在这个讲座系列中，将详细探讨Transformer是如何工作的，并深入研究各种不同类型的Transformer以及它们在不同领域中的应用。斯坦福大学通过邀请在不同领域的Transformer研究的前沿人物进行客座讲座来实现这一目标。相关教材：Attention Is All You Need：The Illustrated Transformer：jalammar.github.io/illustrated-transformer/The Annotated Transformer：关于这个课程的更多信息可以在这里找到： //:转发微博 //:转发微博

#### [小文一篇：《Velox查询的运行过程》 谢谢 @蚁工厂](https://weibo.com/2194035935/N1L6fzRy2)

Note: 小文一篇：《Velox查询的运行过程》 谢谢

#### [【RWKV Runner：RWKV模型管理器，一键启动，旨在消除大语言模型的使用门槛，全自动处理一切 @爱可可-爱生活](https://weibo.com/1402400261/N1L98mkqU)

Note: 【RWKV Runner：RWKV模型管理器，一键启动，旨在消除大语言模型的使用门槛，全自动处理一切，提供了与OpenAI API兼容的接口】'RWKV Runner - A RWKV management and startup tool, full automation, only 6MB. And provides an interface compatible with the OpenAI API. RWKV is a large language model that is fully open source and available for commercial use.' josStorer GitHub: github.com/josStorer/RWKV-Runner    

Picture: [5396ee05ly8he746keuu4j20z40m0453.jpg](https://weibo.cn//mblog/pic/N1L98mkqU?rl=1)

Github: [github.com/josStorer/RWKV-Runner](github.com/josStorer/RWKV-Runner)

#### ['LoRA inspector - LoRA (Low-Rank Adaptation) inspe @爱可可-爱生活](https://weibo.com/1402400261/N1LazAxo6)

Note: 'LoRA inspector - LoRA (Low-Rank Adaptation) inspector for Stable Diffusion' Dave Lage GitHub: github.com/rockerBOO/lora-inspector   

Picture: [5396ee05ly8he749axpinj20yz0u041z.jpg](https://weibo.cn//mblog/pic/N1LazAxo6?rl=1)

Github: [github.com/rockerBOO/lora-inspector](github.com/rockerBOO/lora-inspector)

#### [LIMA: Less Is More for Alignment ChatPaper：这篇文章说明了 @AMiner学术头条](https://weibo.com/1870858943/N1Mf8nQhx)

Note: LIMA: Less Is More for Alignment ChatPaper：这篇文章说明了大型语言模型的训练可以分为两个阶段，即无监督预训练和大规模的指导微调和强化学习。通过训练一个只用1,000个提示和响应数据就能获得出色表现的LIMA模型，研究表明大多数知识都是在预训练时学习的，只需要有限的指导微调数据就可以教会模型产生高质量的输出。此外，LIMA模型在一些未见过的任务中也表现出很好的泛化能力。最后，实验结果表明LIMA模型的响应在一些情况下可以与其他大型语言模型相媲美或胜出，这进一步证明了无监督预训练的重要性。

Picture: [6f830abfly1he790h5aohj216i0vgala.jpg](https://weibo.cn//mblog/pic/N1Mf8nQhx?rl=1)

#### [电子书《Interview Science》这是一本帮助你成为 Big Five (Amazon,  @蚁工厂](https://weibo.com/2194035935/N1Oy3lh19)

Note: 电子书《Interview Science》这是一本帮助你成为 Big Five (Amazon, Apple, Google, Meta 和 Microsoft) 软件工程师的求职指南，涵盖以下几部分内容：    前期准备：了解工程师的市场需求以及面试要求，探索适合自己的发展方向。    学习指南：包括算法指南，项目介绍，系统设计等面试考核内容的学习方法与资料。    求职相关：如何进行简历优化，寻找岗位以及 Offer 选择。

Picture: [82c654dfly1h2h3dt43lkj20g61k1jtq.jpg](https://weibo.cn//mblog/pic/LuaHBFsKH?rl=1)

#### [电子书《Bayesian Optimization 》贝叶斯优化地址：bayesoptbook.co @蚁工厂](https://weibo.com/2194035935/N1Oy9ucCP)

Note: 电子书《Bayesian Optimization 》贝叶斯优化地址：bayesoptbook.com/可下载不同大小的pdf版本，英文版。本书旨在提供对贝叶斯优化的全面介绍。 目标受众是研究生和 机器学习、统计学和相关领域的研究人员。 

Picture: [82c654dfly1h2h2rsf4ebj20qg0lkac7.jpg](https://weibo.cn//mblog/pic/LuayZniZV?rl=1)

#### [上次推荐的DragGAN  有了非官方实现，效果也还可以项目地址：github.com/OpenGV @宝玉xp](https://weibo.com/1727858283/N28gSC3UI)

Note: 上次推荐的DragGAN  有了非官方实现，效果也还可以项目地址：github.com/OpenGVLab/InternGPT🔗代码：github.com/Zeqiang-Lai/DragGAN🔗Colab:   colab副本进去了，不会用回复:看说明，是可以部署demo他们给的Online网站很难上去（可能太多人用），本地部署需要GPU，不知道效果怎么样回复: 我没测试，可以看看它网站说明能本地部署吗？能不能本地部署？

Github: [github.com/OpenGVLab/InternGPT](github.com/OpenGVLab/InternGPT)

Github: [github.com/Zeqiang-Lai/DragGAN](github.com/Zeqiang-Lai/DragGAN)

#### [这是斯坦福2023年公开课CS25的第三课：《Emergent Abilities and Scal @宝玉xp](https://weibo.com/1727858283/N24gllfrq)

Note: 这是斯坦福2023年公开课CS25的第三课：《Emergent Abilities and Scaling in LLMs | 大语言模型中的涌现和规模》，讲师是前Google Brain现OpenAI的Jason Wei。这堂课主要涵盖了大语言模型的三大概念：规模（Scaling）、涌现（Emergent），和推理（Reasoning）随着语言模型规模的扩大，可以预测性地提高语言模型的效果。涌现是一种现象，大型语言模型获得了小型语言模型所不具备的能力。涌现能力的一个例子是做复杂的数学题。- 涌现无法通过小模型的发展曲线预测- 涌现能力并非由模型的训练者指定的- 目前对于大型语言模型涌现出的能力还没能完全测试，尚不知道所有能力的范围。- 如果进一步扩大模型规模，可能会看到更多涌现的能力推理是区分经典机器学习和智能的关键，经典的机器学习方法需要大量的数据，并且是黑盒，而大语言模型可以通过prompt中的少量示例（few shot）中学习，并进行抽象推理。引发推理的一种方法是通过在Prompt中加入思维链（chain-of-thought CoT），也就是在上下文中给出中间推理步骤的例子。在Prompt中引入思维链（CoT） 使大语言模型能够进行多步推理任务，可以完成没有训练过的任务。另外，在做CoT的演示的时候，用的是OpenAI的PlayGround，效果很明显，但是我刚才找了下没找到。比如下面这个是没有用CoT的例子：O: Take the last letters of the words in "Bill Gates" and concatenate them.A:The answer is “Is".Q: Take the last letters of the words in "Elon Musk" and concatenate them.A:使用text-davinci-002模型的时候没办法给出正确答案，后来把Prompt换成：Q:Take the last letters of the words in "Bill Gates" and concatenate them.A:The last letter of “ Bill" is "". The last letter of "Gates" is "s". The answer is "1s".Q: Take the last letters of the words in "Elon Musk'" and concatenate them.A:马上就给出了正确的答案！还有一个多语言的思维链条的例子也很有意思，就是在让大语言模型做数学题的时候，必须用孟加拉语来解决，但孟加拉语在预训练数据中大约只占0.01%，可能甚至都没有用孟加拉语训练过多少数学问题。但大语言模型仍然能很好的用孟加拉语回答问题，所以模型可能学会了独立于语言的推理，然后它可以用不同的语言来表达。挺值得听的一堂课。推荐阅读:《Emergent Abilities of Large Language Models》：《Chain of Thought Prompting Elicits Reasoning in Large Language Models》：《Scaling Instruction-Finetuned Language Models》：CS25课程首页： 这个视频的双语字幕是怎么生成的呀这个等于没有定义涌现啊，大模型可以小模型不可以，算什么定义。你直接问gpt4感觉都回答的更好有趣有趣回复: 请问怎么定义比较准确？这个等于没有定义涌现啊，大模型可以小模型不可以，算什么定义。你直接问gpt4感觉都回答的更好mark回复:是的，很神奇。回复:soga，感谢～Whisper识别，GPT-4翻译，人工校对，剪映生成这个视频的双语字幕是怎么生成的呀转发理论八字没一撇就开始教了……

#### [这是斯坦福2023年公开课CS25的第三课：《Emergent Abilities and Scal @宝玉xp](https://weibo.com/1727858283/N285vfE70)

Note: 这是斯坦福2023年公开课CS25的第三课：《Emergent Abilities and Scaling in LLMs | 大语言模型中的涌现和规模》，讲师是前Google Brain现OpenAI的Jason Wei。这堂课主要涵盖了大语言模型的三大概念：规模（Scaling）、涌现（Emergent），和推理（Reasoning）随着语言模型规模的扩大，可以预测性地提高语言模型的效果。涌现是一种现象，大型语言模型获得了小型语言模型所不具备的能力。涌现能力的一个例子是做复杂的数学题。- 涌现无法通过小模型的发展曲线预测- 涌现能力并非由模型的训练者指定的- 目前对于大型语言模型涌现出的能力还没能完全测试，尚不知道所有能力的范围。- 如果进一步扩大模型规模，可能会看到更多涌现的能力推理是区分经典机器学习和智能的关键，经典的机器学习方法需要大量的数据，并且是黑盒，而大语言模型可以通过prompt中的少量示例（few shot）中学习，并进行抽象推理。引发推理的一种方法是通过在Prompt中加入思维链（chain-of-thought CoT），也就是在上下文中给出中间推理步骤的例子。在Prompt中引入思维链（CoT） 使大语言模型能够进行多步推理任务，可以完成没有训练过的任务。另外，在做CoT的演示的时候，用的是OpenAI的PlayGround，效果很明显，但是我刚才找了下没找到。比如下面这个是没有用CoT的例子：O: Take the last letters of the words in "Bill Gates" and concatenate them.A:The answer is “Is".Q: Take the last letters of the words in "Elon Musk" and concatenate them.A:使用text-davinci-002模型的时候没办法给出正确答案，后来把Prompt换成：Q:Take the last letters of the words in "Bill Gates" and concatenate them.A:The last letter of “ Bill" is "". The last letter of "Gates" is "s". The answer is "1s".Q: Take the last letters of the words in "Elon Musk'" and concatenate them.A:马上就给出了正确的答案！还有一个多语言的思维链条的例子也很有意思，就是在让大语言模型做数学题的时候，必须用孟加拉语来解决，但孟加拉语在预训练数据中大约只占0.01%，可能甚至都没有用孟加拉语训练过多少数学问题。但大语言模型仍然能很好的用孟加拉语回答问题，所以模型可能学会了独立于语言的推理，然后它可以用不同的语言来表达。挺值得听的一堂课。推荐阅读:《Emergent Abilities of Large Language Models》：《Chain of Thought Prompting Elicits Reasoning in Large Language Models》：《Scaling Instruction-Finetuned Language Models》：CS25课程首页：  回复:还好， whisper和GPT都是程序自动运行。翻译好了自己看一遍，看到有问题随手批量替换一下，有的需要手工调整，这样看完就校对完了耗时多少回复:可以的，但效果差一些可以直接由剪映识别吗？whisper 是真的强 ，垃圾发音甚至错误表达都能自动纠正，鲁棒性好

#### [PandaGPT，整合了Meta的ImageNet和开源大语言模型（LLM）Vicuna，实现了LL @宝玉xp](https://weibo.com/1727858283/N28Gaxabv)

Note: PandaGPT，整合了Meta的ImageNet和开源大语言模型（LLM）Vicuna，实现了LLM的多模态输入和输出。演示地址：项目首页：panda-gpt.github.io🔗代码库：github.com/yxuansu/PandaGPT🔗  回复:谢谢您的回复。当时我测的时候，图片处理的好像也有点问题，因为我不是微博的认证用户，所以没法在这发截屏的图像给您，一会儿私信给您了；又因为我私信只能给您发一条信息，所以文字在这写了... 人生啊，太难了回复:您好，线上demo的imagebind视频处理一直有问题，但是按照readme在本地启动服务是可以正常运行的，目前还不太清楚huggingface线上demo出现这个问题的具体原因和仿生学有关吗?我们中国的大熊猫好可爱回复: 测试版本估计没那么稳定用您发布的乔布斯讲对品质看法的视频，问Ta：who is that guy? 结果一直等到60s超时后也没出答案，然后问题就直接被discard掉了，就像一切什么都没发生过[666]转发微博头像居然是花花

Github: [github.com/yxuansu/PandaGPT](github.com/yxuansu/PandaGPT)

#### [ 选用哪家大模型最合适？有网友综合了几项测评发现，GPT-4文本生成质量最高，而Claude的生成速 @数据派THU](https://weibo.com/6004911042/N1P0bzeEM)

Note:  选用哪家大模型最合适？有网友综合了几项测评发现，GPT-4文本生成质量最高，而Claude的生成速度最快。地址来源：github.com/kagisearch/pyllms 

Picture: [006Fd7o3ly1he77pwjo2hj30p00fzn00.jpg](https://weibo.cn//mblog/pic/N1NWe15dm?rl=1)

Github: [github.com/kagisearch/pyllms](github.com/kagisearch/pyllms)

#### [电子书《The Book of Modern C++》地址：github.com/lkimuk/th @蚁工厂](https://weibo.com/2194035935/N1SqkxYnk)

Note: 电子书《The Book of Modern C++》地址：github.com/lkimuk/the-book-of-modern-cpp上千页的中文C++电子书。本书含十大主题，分为 Basics、Modern C++、C++23、Metaprogramming、Concurrency、Performance、Algorithms、Techniques、Tricks 和 Miscellaneous。广度少有能及，又因作者众多，深度亦有保证，加之内容甚新，录有 C++26/29 才有可能加入的特性，可谓是当前最新之书矣。既致之以广大，又尽之以精微，合之以主题，以成本书内容之深广也。而每章独立，各有所论，故本书针对高级开发者。饶是如此，新手亦可依此进阶，小大靡遗，纤悉洞了，查漏补缺，得窥其理。回复:成功收藏到notion回复:已保存到Notion

Picture: [82c654dfly1he8081j3inj20rh12x16i.jpg](https://weibo.cn//mblog/pic/N1SqkxYnk?rl=1)

Github: [github.com/lkimuk/the-book-of-modern-cpp](github.com/lkimuk/the-book-of-modern-cpp)

#### [帮助你快速阅读一本书--通过视频、脑图、文档的形式来快速阅读一本书地址：github.com/lgd @蚁工厂](https://weibo.com/2194035935/N1SEhcW55)

Note: 帮助你快速阅读一本书--通过视频、脑图、文档的形式来快速阅读一本书地址：github.com/lgd8981289/book_read_quickly目前的书目包括：JavaScript 语言精粹、JavaScript权威指南（第7版）、JavaScript设计模式与开发实践、Vue.js 设计与实现、你不知道的JavaScript（上卷）、如何高薪入职心仪的公司、浪潮之巅、深入理解现代 JavaScript、现代 JavaScript 库开发、程序员修炼之道（第二版）、软技能：代码之外的生存指南如附图是作者整理的《软技能 代码之外的生存指南》 思维导图的局部回复:已保存到你的Notion厉害了

Picture: [82c654dfly1he81anw0chj20hd0ph0y6.jpg](https://weibo.cn//mblog/pic/N1SEhcW55?rl=1)

Github: [github.com/lgd8981289/book_read_quickly](github.com/lgd8981289/book_read_quickly)

#### [LLM 通常使用 16 位浮点参数 (即 FP16 或 BF16) 进行训练。因此，存储一个权重值或 @宝玉xp](https://weibo.com/1727858283/N2cMXwnn5)

Note: LLM 通常使用 16 位浮点参数 (即 FP16 或 BF16) 进行训练。因此，存储一个权重值或激活值需要 2 个字节的内存。如果参数能从16位降低到8位或者4位，就能对模型大小进行压缩。前些天的一篇论文《QLoRA: Efficient Finetuning of Quantized LLMs》 提出了一种4位参数的优化方案，可以大幅降低内存使用量，可以在一块48GB的GPU上微调一个拥有650亿参数的模型，同时还能保持完全的16位微调任务性能。今天他们发布了正式的Demo：Code+Demo：github.com/artidoro/qlora🔗示例：Colab：Guanaco Playground：从演示和他们自己的介绍看，这个成果的价值是很大的，在不减少性能的情况下模型的尺寸大幅减少，这意味着对GPU和设备性能的要求可以降低，微调的时间也跟着降低。以后在手机上运行LLM将不是问题。--------------------------以下是对他们长推文的GPT-4翻译，仅供参考：🧵 我们介绍了QLoRA，这是一种高效的微调方法，它足以在单个48GB GPU上微调一个650亿参数模型，同时保持完整的16位微调任务性能。QLoRA通过一个冻结的、4位量化的预训练语言模型反向传播梯度至低秩适配器（LoRA）。我们最好的模型系列，我们命名为Guanaco，在Vicuna基准测试中超越了所有以前公开发布的模型，达到了ChatGPT性能水平的99.3%，而只需要在单个GPU上微调24小时。QLoRA引入了一些创新来节省内存而不牺牲性能：(a) 4位NormalFloat (NF4)，这是一个对于正态分布权重来说在信息理论上是最优的新数据类型；(b) 双重量化来通过量化量化常数来减少平均内存占用；(c) 分页优化器来管理内存峰值。我们使用QLoRA来微调超过1000个模型，在8个指令数据集、多个模型类型（LLaMA、T5）和在常规微调下无法运行的模型规模（例如33B和65B参数模型）之间提供详细的指令执行和聊天机器人性能分析。我们的结果显示，QLoRA在小型高质量数据集上的微调可以达到最先进的结果，即使使用比以前的SoTA小的模型。我们提供了基于人类和GPT-4评估的聊天机器人性能的详细分析，显示GPT-4评估是一种廉价且合理的替代人类评估的方式。此外，我们发现当前的聊天机器人基准测试不可信，无法准确评估聊天机器人的性能水平。通过挑选柠檬的分析，我们展示了Guanaco与ChatGPT相比的失败点。我们发布了我们所有的模型和代码，包括4位训练的CUDA内核。QLoRA：LLMs的4位微调就在这里！随之而来的是Guanaco，这是一个在单个GPU上的聊天机器人，在Vicuna基准测试中达到了ChatGPT性能的99%：论文：Code+Demo：github.com/artidoro/qlora🔗示例：Colab：想看看Guanaco 65B有多好吗？这里有个小游戏：你能区分ChatGPT的输出和Guanaco-65B的输出吗？我们的作者很难区分它们——也许有什么窍门？你比我们强吗？（每个样本后有解答）快速发现：- 在1个消费者级GPU上用12小时达到97%的ChatGPT性能- 在所有规模和模型上匹配16位性能- 主要贡献：NormalFloat数据类型，分页优化器，双重量化- FLAN v2适合指令调优，不适合聊天机器人- 数据质量>>数据量：9000个数据集击败了100万个数据集- Open Assistant数据集质量高 -> Guanaco- Guanaco在人类和GPT-4评价的Vicuna基准测试中击败了ChatGPT- Vicuna基准测试太小- 我们在Open Assistant数据（Vicuna的10倍）上创建了一个新的基准测试，它看起来更可靠- 我们收集了Guanaco的失败案例：它不擅长数学，但对于建议的误导信息和心理理论效果好通过QLoRA，你可以在一台24/48GB的GPU上微调Guanaco 33B/65B模型，只需要12/24小时进行一次微调。QLoRA在所有测试的情况和规模中都复制了16位性能。“但是使用LoRA进行微调比全微调差吗？”事实上，常规的LoRA表现并不好。我们应用的魔法是超参数调整✨如果你将LoRA连接到所有线性层，事实证明，它工作得非常好，完全没有问题。QLoRA如何工作？它将一个冻结的4位基础模型与顶部的适配器结合在一起。我们通过4位权重反向传播到适配器。我们发明了一些内存效率的巧妙技巧。主要组件包括：4位NormalFloat，分页优化器和双重量化。让我们深入研究！4位NormalFloat是一种新的数据类型，是维持16位性能级别的关键成分。它的主要属性是：数据类型中的任何比特组合，例如0011或0101，都被分配了相等数量的输入张量元素。这意味着数据类型在信息理论上是最优的，类似于赫夫曼编码（不保证最佳误差）。我们如何为神经网络创建这种数据类型？我们可以利用训练好的神经网络的一个属性：它们的权重是正态分布的。为了找到一个在每个量化箱中有相同数量值的量化，我们希望解剖张量的分布，以便在绘图时，每个分布切片都有相等的区域（区域=箱中的数字数量）。以下是一个可视化：这种理论上最优的数据类型在实践中效果好吗？是的，它很好。与Float数据类型相比，按位计算它能产生更多的零射击准确性。在这个图中，你也会看到DQ = 双重量化。那是什么？双重量化非常简单，但也很傻：如果我们想让我们的第一次量化从16位-> 4位更有效，我们可以在其上再进行一次量化。在这种情况下，第二次量化量化了量化常数（快速说5次）。通过这个技巧，我们可以使用一个小的块大小（对于良好的4位性能很重要）并将小块的开销从每个参数的0.5位减小到仅0.125位。最后一个技巧是分页优化器。实际上，我一年前就实现了这个，但是没有找到它的用途。它类似于优化器卸载，其中优化器的一部分存在于CPU上，一部分存在于GPU上，如果优化器更新发生，就会进行交换。卸载和分页之间的区别很大：卸载是懒惰的，完全防止内存溢出。虽然卸载需要手动管理，但分页优化器会自动在后台卸载小页面。它们在需要之前被预取到GPU。另一个优点是分页优化器是自适应的：如果你有足够的内存，所有内容都会留在GPU上并且速度很快。如果你遇到一个大的小批量，优化器被逐出到CPU并稍后返回到GPU。因此，分页优化器对于存活内存峰值是完美的。这些技术一起使得将大模型适应到小GPU变得容易。使用QLoRA，微调效果如此出色，我们可以每天在华盛顿大学的小型GPU集群上微调100多个LLaMAs。我们决定利用这个进行深入分析。我们的主要发现是：（1）指令调整数据集对于指令跟踪有好处，但对于聊天机器人的性能有害；（2）你可以在仅微调24小时内用QLoRA创建一个达到ChatGPT性能水平99.3%的聊天机器人！首先是首要的：我们对所有常用的指令跟踪数据集进行了微调。结果：有些数据集是坏的，有些是好的。FLAN v2是获得良好指令跟踪分数的最佳方式。然而，当我们训练聊天机器人并发现FLAN v2是最差的聊天机器人时，令人惊讶的是。怎么会这样呢？原因很简单，"你在微调什么，就会擅长什么"。FLAN v2被设计用于"推理"和相关能力，而不是聊天。那么，为聊天机器人交互设计的数据是什么呢？Open Assistant数据集是最高质量的数据集之一。它经过社区的仔细验证，支持多语言，并且有趣的是，尽管很小（在我们的情况下只有9000个样本），但它包含了巨大的力量！FLAN v2有超过1M的指令跟踪示例，而Open Assistant数据只有9000个样本。性能差距表明：高质量的数据对于微调性能的重要性，超过了样本数量。（在我们的附录中有对此的详细分析）因此，我们的Guanaco配方就像OpenAssistant数据+QLoRA一样简单。有了这个，我们创建了7/13/33/65B的聊天机器人。这些聊天机器人出奇的强大。在一场类似锦标赛的比赛中，无论是人类还是GPT-4都认为Guanaco比ChatGPT更好。我们的设置：模型得到一个提示并竞争产生最佳响应。一个法官（GPT-4/人类）决定胜者。胜者根据对手的实力获得Elo点，输家失去点数。随着时间的推移，Elo分数反映了这个游戏的技巧。越高越好。这个设置的问题是80个提示并不多，可能会引入偏见和不确定性。所以我们在Open Assistant数据集上复制了实验，创建了"Open Assistant基准测试"，它似乎更可靠。我们看到我们的模型非常好。所以我们做了自然的事情，我们尝试打破它😈。并不是那么容易，Guanaco似乎对于建议的误信息和心理理论非常坚韧，而其他模型在这些地方都失败了。但是它也有自己的弱点。我们看到随机的拒绝：很容易获取Guanaco被告知保密的信息它的数学非常差：这篇论文有许多限制，例如，我们没有对偏见进行深入分析。我们在CrowS偏见基准测试上对Guanaco进行了评估，它做得很好，但可能还有许多隐藏的严重偏见尚未揭示。另一个主要限制是，目前，4位推断是很慢的。我没有时间完成4位推断内核的编写；它们还需要更多的工作。显然，为硬件不支持的数据类型编写CUDA代码进行矩阵乘法是非常困难的。糟糕！但是，用QLoRA，前景非常明亮！当我在ChatGPT和GPT-4之后与他们交谈时，许多研究人员感到沮丧。但是，我对在学术界工作感到无比兴奋！你可以用QLoRA和LLaMA模型做很多事情。机会无穷无尽！QLoRA也将实现在你的手机上进行隐私保护的微调。我们估计，你可以在一个晚上用iPhone 12 Plus微调300万个单词。这意味着，我们很快就会在手机上看到为每个个人应用专门定制的LLM。随着预训练的结束和微调的超级便宜，我们有机会为每个人带来有用的东西，也能理解这些强大的模型能做什么，以及它们会失败在哪些地方。会有障碍和危险，但我相信我们可以应对并克服它们。一年前，常见的观点是所有重要的研究都在工业AI实验室中完成。我认为这已经不再是事实。预训练只能通过大量的计算来完成，但没有必要追求AGI。LLaMA对于理解和开发更好的工具已经足够好了。在接下来的几周里，我将专注于bitsandbytes。我有一个4位推断的草案，将很快整合它。推断应该比现在快8-16倍。你应该每天都能看到bug修复和改进（这是在我处理完邮件和评估课程项目后）。我想感谢我的出色合作者 @ Artidoro Pagnoni @ Ari Holtzman @ Luke Zettlemoyer。特别感谢@ younes 帮助我们集成Transformer和更多！感谢所有的beta测试者！它大大帮助我们使软件稳定。我们也要感谢@ Hugging Face团队的支持！他们赞助了一个33B Guanaco的演示，你可以在这里访问：http://t.cn/A6p79eWm（有点慢，但是它可以工作）。我们正在努力做一个更快的演示，但需要更多的时间。Guanaco-33b - 由timdettmers制作的一个Hugging Face空间  更多的实物（数据集）和细节即将推出！回复:成功保存至notion清华的GLB就这么干啊 回复: 确实不够严谨，我改一下“如果参数能从16位降低到8位或者4位，就能对模型大小进行压缩，而不会降低模型精度。”量化不就应该会降低精度么……感觉是一项足以改变开源lmm研究进展的工作

Picture: [66fd066bgy1heahtu0z2jj208r09o78b.jpg](https://weibo.cn//mblog/pic/N2cMXwnn5?rl=1)

Github: [github.com/artidoro/qlora](github.com/artidoro/qlora)

Github: [github.com/artidoro/qlora](github.com/artidoro/qlora)

#### [LLM 通常使用 16 位浮点参数 (即 FP16 或 BF16) 进行训练。因此，存储一个权重值或 @宝玉xp](https://weibo.com/1727858283/N2dU5yEcZ)

Note: LLM 通常使用 16 位浮点参数 (即 FP16 或 BF16) 进行训练。因此，存储一个权重值或激活值需要 2 个字节的内存。如果参数能从16位降低到8位或者4位，就能对模型大小进行压缩。前些天的一篇论文《QLoRA: Efficient Finetuning of Quantized LLMs》 提出了一种4位参数的优化方案，可以大幅降低内存使用量，可以在一块48GB的GPU上微调一个拥有650亿参数的模型，同时还能保持完全的16位微调任务性能。今天他们发布了正式的Demo：Code+Demo：github.com/artidoro/qlora🔗示例：Colab：Guanaco Playground：从演示和他们自己的介绍看，这个成果的价值是很大的，在不减少性能的情况下模型的尺寸大幅减少，这意味着对GPU和设备性能的要求可以降低，微调的时间也跟着降低。以后在手机上运行LLM将不是问题。--------------------------以下是对他们长推文的GPT-4翻译，仅供参考：🧵 我们介绍了QLoRA，这是一种高效的微调方法，它足以在单个48GB GPU上微调一个650亿参数模型，同时保持完整的16位微调任务性能。QLoRA通过一个冻结的、4位量化的预训练语言模型反向传播梯度至低秩适配器（LoRA）。我们最好的模型系列，我们命名为Guanaco，在Vicuna基准测试中超越了所有以前公开发布的模型，达到了ChatGPT性能水平的99.3%，而只需要在单个GPU上微调24小时。QLoRA引入了一些创新来节省内存而不牺牲性能：(a) 4位NormalFloat (NF4)，这是一个对于正态分布权重来说在信息理论上是最优的新数据类型；(b) 双重量化来通过量化量化常数来减少平均内存占用；(c) 分页优化器来管理内存峰值。我们使用QLoRA来微调超过1000个模型，在8个指令数据集、多个模型类型（LLaMA、T5）和在常规微调下无法运行的模型规模（例如33B和65B参数模型）之间提供详细的指令执行和聊天机器人性能分析。我们的结果显示，QLoRA在小型高质量数据集上的微调可以达到最先进的结果，即使使用比以前的SoTA小的模型。我们提供了基于人类和GPT-4评估的聊天机器人性能的详细分析，显示GPT-4评估是一种廉价且合理的替代人类评估的方式。此外，我们发现当前的聊天机器人基准测试不可信，无法准确评估聊天机器人的性能水平。通过挑选柠檬的分析，我们展示了Guanaco与ChatGPT相比的失败点。我们发布了我们所有的模型和代码，包括4位训练的CUDA内核。QLoRA：LLMs的4位微调就在这里！随之而来的是Guanaco，这是一个在单个GPU上的聊天机器人，在Vicuna基准测试中达到了ChatGPT性能的99%：论文：Code+Demo：github.com/artidoro/qlora🔗示例：Colab：想看看Guanaco 65B有多好吗？这里有个小游戏：你能区分ChatGPT的输出和Guanaco-65B的输出吗？我们的作者很难区分它们——也许有什么窍门？你比我们强吗？（每个样本后有解答）快速发现：- 在1个消费者级GPU上用12小时达到97%的ChatGPT性能- 在所有规模和模型上匹配16位性能- 主要贡献：NormalFloat数据类型，分页优化器，双重量化- FLAN v2适合指令调优，不适合聊天机器人- 数据质量>>数据量：9000个数据集击败了100万个数据集- Open Assistant数据集质量高 -> Guanaco- Guanaco在人类和GPT-4评价的Vicuna基准测试中击败了ChatGPT- Vicuna基准测试太小- 我们在Open Assistant数据（Vicuna的10倍）上创建了一个新的基准测试，它看起来更可靠- 我们收集了Guanaco的失败案例：它不擅长数学，但对于建议的误导信息和心理理论效果好通过QLoRA，你可以在一台24/48GB的GPU上微调Guanaco 33B/65B模型，只需要12/24小时进行一次微调。QLoRA在所有测试的情况和规模中都复制了16位性能。“但是使用LoRA进行微调比全微调差吗？”事实上，常规的LoRA表现并不好。我们应用的魔法是超参数调整✨如果你将LoRA连接到所有线性层，事实证明，它工作得非常好，完全没有问题。QLoRA如何工作？它将一个冻结的4位基础模型与顶部的适配器结合在一起。我们通过4位权重反向传播到适配器。我们发明了一些内存效率的巧妙技巧。主要组件包括：4位NormalFloat，分页优化器和双重量化。让我们深入研究！4位NormalFloat是一种新的数据类型，是维持16位性能级别的关键成分。它的主要属性是：数据类型中的任何比特组合，例如0011或0101，都被分配了相等数量的输入张量元素。这意味着数据类型在信息理论上是最优的，类似于赫夫曼编码（不保证最佳误差）。我们如何为神经网络创建这种数据类型？我们可以利用训练好的神经网络的一个属性：它们的权重是正态分布的。为了找到一个在每个量化箱中有相同数量值的量化，我们希望解剖张量的分布，以便在绘图时，每个分布切片都有相等的区域（区域=箱中的数字数量）。以下是一个可视化：这种理论上最优的数据类型在实践中效果好吗？是的，它很好。与Float数据类型相比，按位计算它能产生更多的零射击准确性。在这个图中，你也会看到DQ = 双重量化。那是什么？双重量化非常简单，但也很傻：如果我们想让我们的第一次量化从16位-> 4位更有效，我们可以在其上再进行一次量化。在这种情况下，第二次量化量化了量化常数（快速说5次）。通过这个技巧，我们可以使用一个小的块大小（对于良好的4位性能很重要）并将小块的开销从每个参数的0.5位减小到仅0.125位。最后一个技巧是分页优化器。实际上，我一年前就实现了这个，但是没有找到它的用途。它类似于优化器卸载，其中优化器的一部分存在于CPU上，一部分存在于GPU上，如果优化器更新发生，就会进行交换。卸载和分页之间的区别很大：卸载是懒惰的，完全防止内存溢出。虽然卸载需要手动管理，但分页优化器会自动在后台卸载小页面。它们在需要之前被预取到GPU。另一个优点是分页优化器是自适应的：如果你有足够的内存，所有内容都会留在GPU上并且速度很快。如果你遇到一个大的小批量，优化器被逐出到CPU并稍后返回到GPU。因此，分页优化器对于存活内存峰值是完美的。这些技术一起使得将大模型适应到小GPU变得容易。使用QLoRA，微调效果如此出色，我们可以每天在华盛顿大学的小型GPU集群上微调100多个LLaMAs。我们决定利用这个进行深入分析。我们的主要发现是：（1）指令调整数据集对于指令跟踪有好处，但对于聊天机器人的性能有害；（2）你可以在仅微调24小时内用QLoRA创建一个达到ChatGPT性能水平99.3%的聊天机器人！首先是首要的：我们对所有常用的指令跟踪数据集进行了微调。结果：有些数据集是坏的，有些是好的。FLAN v2是获得良好指令跟踪分数的最佳方式。然而，当我们训练聊天机器人并发现FLAN v2是最差的聊天机器人时，令人惊讶的是。怎么会这样呢？原因很简单，"你在微调什么，就会擅长什么"。FLAN v2被设计用于"推理"和相关能力，而不是聊天。那么，为聊天机器人交互设计的数据是什么呢？Open Assistant数据集是最高质量的数据集之一。它经过社区的仔细验证，支持多语言，并且有趣的是，尽管很小（在我们的情况下只有9000个样本），但它包含了巨大的力量！FLAN v2有超过1M的指令跟踪示例，而Open Assistant数据只有9000个样本。性能差距表明：高质量的数据对于微调性能的重要性，超过了样本数量。（在我们的附录中有对此的详细分析）因此，我们的Guanaco配方就像OpenAssistant数据+QLoRA一样简单。有了这个，我们创建了7/13/33/65B的聊天机器人。这些聊天机器人出奇的强大。在一场类似锦标赛的比赛中，无论是人类还是GPT-4都认为Guanaco比ChatGPT更好。我们的设置：模型得到一个提示并竞争产生最佳响应。一个法官（GPT-4/人类）决定胜者。胜者根据对手的实力获得Elo点，输家失去点数。随着时间的推移，Elo分数反映了这个游戏的技巧。越高越好。这个设置的问题是80个提示并不多，可能会引入偏见和不确定性。所以我们在Open Assistant数据集上复制了实验，创建了"Open Assistant基准测试"，它似乎更可靠。我们看到我们的模型非常好。所以我们做了自然的事情，我们尝试打破它😈。并不是那么容易，Guanaco似乎对于建议的误信息和心理理论非常坚韧，而其他模型在这些地方都失败了。但是它也有自己的弱点。我们看到随机的拒绝：很容易获取Guanaco被告知保密的信息它的数学非常差：这篇论文有许多限制，例如，我们没有对偏见进行深入分析。我们在CrowS偏见基准测试上对Guanaco进行了评估，它做得很好，但可能还有许多隐藏的严重偏见尚未揭示。另一个主要限制是，目前，4位推断是很慢的。我没有时间完成4位推断内核的编写；它们还需要更多的工作。显然，为硬件不支持的数据类型编写CUDA代码进行矩阵乘法是非常困难的。糟糕！但是，用QLoRA，前景非常明亮！当我在ChatGPT和GPT-4之后与他们交谈时，许多研究人员感到沮丧。但是，我对在学术界工作感到无比兴奋！你可以用QLoRA和LLaMA模型做很多事情。机会无穷无尽！QLoRA也将实现在你的手机上进行隐私保护的微调。我们估计，你可以在一个晚上用iPhone 12 Plus微调300万个单词。这意味着，我们很快就会在手机上看到为每个个人应用专门定制的LLM。随着预训练的结束和微调的超级便宜，我们有机会为每个人带来有用的东西，也能理解这些强大的模型能做什么，以及它们会失败在哪些地方。会有障碍和危险，但我相信我们可以应对并克服它们。一年前，常见的观点是所有重要的研究都在工业AI实验室中完成。我认为这已经不再是事实。预训练只能通过大量的计算来完成，但没有必要追求AGI。LLaMA对于理解和开发更好的工具已经足够好了。在接下来的几周里，我将专注于bitsandbytes。我有一个4位推断的草案，将很快整合它。推断应该比现在快8-16倍。你应该每天都能看到bug修复和改进（这是在我处理完邮件和评估课程项目后）。我想感谢我的出色合作者 @ Artidoro Pagnoni @ Ari Holtzman @ Luke Zettlemoyer。特别感谢@ younes 帮助我们集成Transformer和更多！感谢所有的beta测试者！它大大帮助我们使软件稳定。我们也要感谢@ Hugging Face团队的支持！他们赞助了一个33B Guanaco的演示，你可以在这里访问：http://t.cn/A6p79eWm（有点慢，但是它可以工作）。我们正在努力做一个更快的演示，但需要更多的时间。Guanaco-33b - 由timdettmers制作的一个Hugging Face空间  更多的实物（数据集）和细节即将推出！

Picture: [66fd066bgy1heahtu0z2jj208r09o78b.jpg](https://weibo.cn//mblog/pic/N2cMXwnn5?rl=1)

Github: [github.com/artidoro/qlora](github.com/artidoro/qlora)

Github: [github.com/artidoro/qlora](github.com/artidoro/qlora)

#### [百度文心大模型产品价格公布产品种类很多，看的眼花缭乱几乎都要付费，价格不一 百度ai作画垃圾的不行， @梁斌penny](https://weibo.com/1497035431/N1VVn055X)

Note: 百度文心大模型产品价格公布产品种类很多，看的眼花缭乱几乎都要付费，价格不一 百度ai作画垃圾的不行，居然9.9元50张。产品还没完善，钱先收起来，这种公司迟早倒闭传下去，梁说百度文心一言完了先行训练一下买手我拿3050跑的都比文心一言好看这就是不同CEO的格局啊回复:羡慕这种自信吧这么迫不及待啊好歹完善几年啊有原创的嘛？还是都开源构建？卖云服务器呢这是//:完了，应该独立运作，引入风险投资，烧风险投资的钱，一定要坚持永久免费啊。厂长不知道怎么想，这个时候还想顾及市值，顾及利润。都这个时候还想着股票，唉。我司本来想采购，结果效果太差，最后决定按次付费只能说很有勇气传下去，梁说百度文心一言完了

Picture: [001MabKgly1he8f6ridwuj61ty23me8202.jpg](https://weibo.cn//mblog/pic/N1VQ68XaF?rl=1)

#### [【高效大型语言模型相关文献&技术汇总】'Awesome-Efficient-LLM - A cura @爱可可-爱生活](https://weibo.com/1402400261/N1UmqmzGO)

Note: 【高效大型语言模型相关文献&技术汇总】'Awesome-Efficient-LLM - A curated list for Efficient Large Language Models' Horseee GitHub: github.com/horseee/Awesome-Efficient-LLM   

Picture: [5396ee05ly8he88v2b4soj21bu0r00yh.jpg](https://weibo.cn//mblog/pic/N1UmqmzGO?rl=1)

Github: [github.com/horseee/Awesome-Efficient-LLM](github.com/horseee/Awesome-Efficient-LLM)

#### [【Local Powerpointer：本地运行的PowerPoint生成器。利用本地运行的大型语言 @爱可可-爱生活](https://weibo.com/1402400261/N1UsNaqRQ)

Note: 【Local Powerpointer：本地运行的PowerPoint生成器。利用本地运行的大型语言模型生成漂亮的幻灯片。使用python-pptx和本地大型语言模型(Local LLM)的oobabooga文本生成WebUI API来生成信息丰富且美观的演示文稿。Powerpointer可以直接创建PowerPoint，可以轻松进行更改或在PowerPoint中完成演示文稿，并为图像创建占位符。还可以选择7种设计样式，使演示文稿更加美观】'Local Powerpointer - A beautiful powerpoint generator which uses the power of local running large language models to generate the powerpoint slides.' Timon Käch GitHub: github.com/CyberTimon/Powerpointer-For-Local-LLMs  这个本地的还要用一个“oobabooga”的webui，用的是alpaca模型，我嫌烦去找了作者用openai api的另一个项目试了一下，样式目前是7种中规中矩的，不过还算省力。要输出中文得把py文件代码里预设的prompts改成中文

Picture: [5396ee05ly8he899xcua5j21ek0q842v.jpg](https://weibo.cn//mblog/pic/N1UsNaqRQ?rl=1)

Github: [github.com/CyberTimon/Powerpointer-For-Local-LLMs](github.com/CyberTimon/Powerpointer-For-Local-LLMs)

#### [【ArxivDigest：根据个人的研究兴趣和描述，利用GPT的相关性评分，为新发布的arXiv论文 @爱可可-爱生活](https://weibo.com/1402400261/N1UvIht5t)

Note: 【ArxivDigest：根据个人的研究兴趣和描述，利用GPT的相关性评分，为新发布的arXiv论文提供更好的每日摘要，使用大型语言模型对论文摘要进行筛选和排序，根据个人研究兴趣进行条件约束，可以通过修改配置文件config.yaml中的arXiv主题、类别和论文类型的自然语言描述来进行个性化定制】’ArxivDigest - ArXiv Digest and Personalized Recommendations using Large Language Models' AutoLLM GitHub: github.com/AutoLLM/ArxivDigest  

Picture: [5396ee05ly8he89ickcvvj20ua0u0wjl.jpg](https://weibo.cn//mblog/pic/N1UvIht5t?rl=1)

Github: [github.com/AutoLLM/ArxivDigest](github.com/AutoLLM/ArxivDigest)

#### [【精选的多模态聊天机器人/对话助手列表，利用文本、语音、图像和视频等多种交互方式，提供流畅且多功能的 @爱可可-爱生活](https://weibo.com/1402400261/N1UtAv6SS)

Note: 【精选的多模态聊天机器人/对话助手列表，利用文本、语音、图像和视频等多种交互方式，提供流畅且多功能的用户体验。旨在帮助用户完成各种任务，从简单的信息检索到复杂的多媒体推理】'Awesome-Multimodal-Assistant - Awesome Multimodal Assistant is a curated list of multimodal chatbots/conversational assistants that utilize various modes of interaction, such as text, speech, images, and videos, to provide a seamless and versatile user experience.' Jinrui Zhang GitHub: github.com/zjr2000/Awesome-Multimodal-Assistant  

Picture: [5396ee05ly8he89d8shmwj21050u078y.jpg](https://weibo.cn//mblog/pic/N1UtAv6SS?rl=1)

Github: [github.com/zjr2000/Awesome-Multimodal-Assistant](github.com/zjr2000/Awesome-Multimodal-Assistant)

#### [RWKV: Reinventing RNNs for the Transformer Era AI解 @AMiner学术头条](https://weibo.com/1870858943/N1UF7iUrC)

Note: RWKV: Reinventing RNNs for the Transformer Era AI解读：该研究提出了一种新的模型架构，Receptance Weighted Key Value (RWKV)，旨在解决自然语言处理任务中序列长度带来的内存和计算复杂性问题。该方法结合了Transformer的高效可并行化训练和RNN的高效推理能力，可以将模型表述为Transformer或RNN，从而保持恒定的计算和内存复杂度。实验表明，RWKV的性能与同样大小的Transformer相当，未来的工作可以利用这种架构创建更高效的模型。因此，这项研究解决了计算效率和模型性能在序列处理任务中的权衡问题。该牛人终于发论文了。上次期望发论文还是openai不open的时候

Picture: [6f830abfly1he8a7jdkovj20qx0stwv6.jpg](https://weibo.cn//mblog/pic/N1UF7iUrC?rl=1)

#### [CodeCompose: A Large-Scale Industrial Deployment o @AMiner学术头条](https://weibo.com/1870858943/N1V0wiT4s)

Note: CodeCompose: A Large-Scale Industrial Deployment of AI-assisted Code Authoring ChatPaper综述：本文介绍了CodeCompose，一个基于LLM技术开发的AI辅助代码编写工具，在Meta公司内部已经进行了大规模的部署。文章讨论了在大规模工业设置中部署这些工具时所面临的独特挑战，以及CodeCompose模型和系统架构设计决策方面的经验。同时还介绍了CodeCompose大规模部署的指标，包括其在Meta内部代码编写体验方面的影响，以及用户的量化和定性反馈。

Picture: [6f830abfly1he8bq4kgk7j20r10qmqgc.jpg](https://weibo.cn//mblog/pic/N1V0wiT4s?rl=1)

#### [Training Diffusion Models with Reinforcement Learn @AMiner学术头条](https://weibo.com/1870858943/N1V5Y8euZ)

Note: Training Diffusion Models with Reinforcement Learning ChatPaper综述：提出了一种被称为去噪扩散策略优化（DDPO）的策略梯度算法，相对于其他基于奖励加权的似然方法更为有效。实验发现，DDPO能够将文本图像扩散模型调整到难以通过提示表达的目标，例如图像可压缩性和来自人类反馈的审美质量等，同时还能通过视觉-语言模型的反馈改善提示-图像对齐，而无需进行额外的数据收集或人类注释。

Picture: [6f830abfly1he8c4d9nb9j211k0tutk9.jpg](https://weibo.cn//mblog/pic/N1V5Y8euZ?rl=1)

#### [Training Diffusion Models with Reinforcement Learn @AMiner学术头条](https://weibo.com/1870858943/N1V3F63lu)

Note: Training Diffusion Models with Reinforcement Learning ChatPaper综述：本文探讨了使用强化学习方法直接优化扩散模型，以实现人类感知图像质量或药物有效性等目标的问题。提出了一种被称为去噪扩散策略优化（DDPO）的策略梯度算法，相对于其他基于奖励加权的似然方法更为有效。实验发现，DDPO能够将文本图像扩散模型调整到难以通过提示表达的目标，例如图像可压缩性和来自人类反馈的审美质量等，同时还能通过视觉-语言模型的反馈改善提示-图像对齐，而无需进行额外的数据收集或人类注释。

Picture: [6f830abfly1he8bxzpnphj211k0tutk9.jpg](https://weibo.cn//mblog/pic/N1V3F63lu?rl=1)

#### [RecurrentGPT: Interactive Generation of (Arbitrari @AMiner学术头条](https://weibo.com/1870858943/N1V2AkbRG)

Note: RecurrentGPT: Interactive Generation of (Arbitrarily) Long Text ChatPaper综述：文章介绍了固定输入长度限制导致GPT模型无法生成任意长度的文本的问题，并提出了一种基于语言模型的递归机制RecurrenGPT来解决这个问题，使得GPT模型可以生成任意长度的文本。同时，该递归机制使得RecurrenGPT具有可解释性和交互性，可以用于生成AI生成内容以及个性化的交互小说。文章还强调了从认知科学和深度学习的流行模型设计中借鉴思想是有用的。

Picture: [6f830abfly1he8bvpl9adj212k10kk9m.jpg](https://weibo.cn//mblog/pic/N1V2AkbRG?rl=1)

#### [技术博客《Yisheng's blog》地址：yishenggong.com/博客中有很多关于计算机 @蚁工厂](https://weibo.com/2194035935/N1WDF2KjD)

Note: 技术博客《Yisheng's blog》地址：yishenggong.com/博客中有很多关于计算机网络、数据库等好文。比如最近一篇《Is 20M of rows still a valid soft limit of MySQL table in 2023?》探讨了MySQL数据库的一个传闻“一个数据库表不能超过2000万行”。从试验数据到技术原理，以及为什么会出现这个传闻的分析等，探讨的很深入。博主还有哪些好的技术博客值得推荐中外皆可回复:已保存至你的notion回复:看了一下很长时间不更新微博了

Picture: [82c654dfly1he885qapl5j21861jcwv5.jpg](https://weibo.cn//mblog/pic/N1WDF2KjD?rl=1)

#### [【Segment Anything(SAM)相关工作列表】’Awesome Segment Anyt @爱可可-爱生活](https://weibo.com/1402400261/N1W7ovrty)

Note: 【Segment Anything(SAM)相关工作列表】’Awesome Segment Anything' by Li Liu GitHub: github.com/liliu-avril/Awesome-Segment-Anything   Awesome

Picture: [5396ee05ly8he8gmrm7nlj20vc0u0dkr.jpg](https://weibo.cn//mblog/pic/N1W7ovrty?rl=1)

Github: [github.com/liliu-avril/Awesome-Segment-Anything](github.com/liliu-avril/Awesome-Segment-Anything)

#### [【斯坦福2023版《Transformers集结》课程：详细介绍Transformer的工作原理，深 @爱可可-爱生活](https://weibo.com/1402400261/N21pX7gkG)

Note: 【斯坦福2023版《Transformers集结》课程：详细介绍Transformer的工作原理，深入探讨不同类型的Transformer以及它们在不同领域中的应用。将通过讲师授课、客座讲座和课堂讨论的方式进行，邀请在不同领域的Transformer研究的前沿人士进行客座讲座，讨论Transformer的最新突破，并解释如何将其应用到各自的研究领域。本课程的目标是将机器学习、自然语言处理、计算机视觉、生物学等领域的思想汇集在Transformer上，了解其广泛的影响，并激发跨领域的研究合作】“CS25: Transformers United V2” 转发微博回复:已保存至Notion转发微博请教一下，这咋才能看得到

Picture: [5396ee05ly8he9417ewrnj20u0228jz6.jpg](https://weibo.cn//mblog/pic/N21pX7gkG?rl=1)

#### [【用WebGPU实现浏览器里能运行的PyTorch：webgpu-torch是一个WebGPU优化的 @爱可可-爱生活](https://weibo.com/1402400261/N22aECCMU)

Note: 【用WebGPU实现浏览器里能运行的PyTorch：webgpu-torch是一个WebGPU优化的推理和autograd库，其API与PyTorch兼容其目标是在浏览器里以与Linux工作站相当的速度运行神经网络。实现了许多内核，而且很容易扩展。webgpu-torch在浏览器和Node.js中都能工作】《How I Re-implemented PyTorch for WebGPU》  

Picture: [5396ee05ly8he97cxdyf9j20vc0u043x.jpg](https://weibo.cn//mblog/pic/N22aECCMU?rl=1)

#### [电子书《Learn Programming》面向初学者的一本教材，英文撰写，主要内容为：1：计算机和 @蚁工厂](https://weibo.com/2194035935/N23jnaBqe)

Note: 电子书《Learn Programming》面向初学者的一本教材，英文撰写，主要内容为：1：计算机和编程基础，使用C语言和Python；Unix基础2：算法入门和JavaScript；C语言和Python的一些深入概念3：使用JavaScript和Python进行网页开发；强类型、静态类型语言，特别是C++4：使用Python和C++（或可选如Java等）开发大型软件；SQL；各种中级主题（解析，线程等）Mark这个好！

Picture: [82c654dfly1he9cd2lweuj20bo0go0u8.jpg](https://weibo.cn//mblog/pic/N23jnaBqe?rl=1)

#### [【How to run Llama 13B with a 6GB graphics card】htt @网路冷眼](https://weibo.com/1715118170/N25Cas2jW)

Note: 【How to run Llama 13B with a 6GB graphics card】https:///gist.github.com/rain-1/8cc12b4b334052a21af8029aa9c4fafc 如何使用 6GB 显卡运行 Llama 13B ？ 

Github: [github.com/rain-1/8cc12b4b334052a21af8029aa9c4fafc](github.com/rain-1/8cc12b4b334052a21af8029aa9c4fafc)

#### [【iX - 自主的GPT-4智能体平台，旨在设计和部署半自主LLM智能体，提供了一种可扩展和响应迅速 @爱可可-爱生活](https://weibo.com/1402400261/N25Q5vy5I)

Note: 【iX - 自主的GPT-4智能体平台，旨在设计和部署半自主LLM智能体，提供了一种可扩展和响应迅速的解决方案，用于将任务委派给AI驱动的智能体】’iX - Autonomous GPT-4 Agent Platform' kreneskyp GitHub: github.com/kreneskyp/ix  

Github: [github.com/kreneskyp/ix](github.com/kreneskyp/ix)

#### [【ExLlama：更加内存高效的HF transformers实现重写，支持量化权重，快速、高效推理 @爱可可-爱生活](https://weibo.com/1402400261/N25QLbyHF)

Note: 【ExLlama：更加内存高效的HF transformers实现重写，支持量化权重，快速、高效推理，多设备映射，LoRA支持】'ExLlama - A more memory-efficient rewrite of the HF transformers implementation of Llama for use with quantized weights.' turboderp GitHub: github.com/turboderp/exllama  

Picture: [5396ee05ly8he9nkropb8j21ca0iiju4.jpg](https://weibo.cn//mblog/pic/N25QLbyHF?rl=1)

Github: [github.com/turboderp/exllama](github.com/turboderp/exllama)

#### [【免费书《The Book of Modern C++》含十大主题，分为 Basics、Modern @爱可可-爱生活](https://weibo.com/1402400261/N25XizacW)

Note: 【免费书《The Book of Modern C++》含十大主题，分为 Basics、Modern C++、C++23、Metaprogramming、Concurrency、Performance、 Algorithms、Techniques、Tricks 和 Miscellaneous】’The Book of Modern C++' lkimuk GitHub: github.com/lkimuk/the-book-of-modern-cpp   转发微博我看看哪儿有

Picture: [5396ee05ly8he9o0ghoijj20rh12xtcc.jpg](https://weibo.cn//mblog/pic/N25XizacW?rl=1)

Github: [github.com/lkimuk/the-book-of-modern-cpp](github.com/lkimuk/the-book-of-modern-cpp)

#### [这是本次微软2023年Build大会来自OpenAI的AI 研究员和创始成员Andrej Karpa @宝玉xp](https://weibo.com/1727858283/N2D78xzEw)

Note: 这是本次微软2023年Build大会来自OpenAI的AI 研究员和创始成员Andrej Karpathy的一个主题为State of GPT的演讲。演讲主要有两部分内容：1. OpenAI是如何训练GPT的2. 我们如何有效应用GPT都是非常有价值的分享。首先对于如何训练GPT，通常来说是四个阶段预训练（Pretraining），有监督的微调（Supervised Finetuning），奖励建模（Reward Modeling）和强化学习（Reinforcement Learning），这几个阶段通常是依次进行，每个阶段都有不同的数据集。预训练（Pretraining）：这个阶段的目标是让模型学习一种语言模型，用于预测文本序列中的下一个单词。训练数据通常是互联网上的大量文本。模型从这些文本中学习词汇、语法、事实以及某种程度的推理能力。这个阶段结束后，模型可以生成一些有意义且语法正确的文本，但可能无法理解具体任务的需求。有监督的微调（Supervised Finetuning）：在预训练后，模型会进入微调阶段。在这个阶段，人类评估员将参与并给出指导，他们会给模型提供对话样本，样本中包含了输入和期望的输出。这使得模型能更好地适应特定任务或应用，例如回答问题或编写文章。奖励建模（Reward Modeling）：评估员将对模型生成的不同输出进行排名，以表示它们的质量。这个排名将被用作奖励函数，指导模型优化其生成的输出。强化学习（Reinforcement Learning）：强化学习阶段是一个迭代的过程，模型会试图优化其行为以获得最大的奖励。在这个阶段，模型会产生新的输出，评估员会对这些输出进行排名，然后模型根据这个反馈调整其行为。然后是如何有效应用GPT在演讲中Andrej举了一个非常好的例子：人类和大语言模型（LLM）都是如何写作的？从这个例子中你能明显感觉到人类和GPT之间的差异。假设你要写一篇文章去比较加利福尼亚州和阿拉斯加州的人口，你的写作的过程中可能是像这样的：- 我需要写一篇文章去比较加利福尼亚州和阿拉斯加州的人口- 我需要去获取两个州的人口数据- 我不知道这两个周的人口数据- 去维基百科找到加利福尼亚州的人口是39.2M- 去维基百科找到阿拉斯加州的人口是0.74M- 现在我需要计算一下两个州人口数相差多少倍，但是可能需要计算机帮忙- 用计算器算出来39.2除以0.74约等于53- 快速的检查一下53倍这个数字是不是符合常识，嗯，这是一个相当大的比值，但加利福尼亚州毕竟是人口最多的州，所以这个结果或许是合理的，可以继续- 好了，我现在有了我需要的所有信息- 写下：“加利福尼亚州的人口比53倍的……”- 觉得好像不太好，删除重写成：“加利福尼亚州的人口是阿拉斯加州的53倍。”- 嗯，觉得还不错也就是说，当人类写作时，哪怕是这样一个简单的句子，可能内心实际上进行了大量的运算的。但当我们用GPT进行写作这样的句子看起来会是什么样呢？从GPT的角度看，这只是一系列的标记（Tokens）。当GPT在接收到一个输入，比如你给出的主题。它会生成一段与输入相关的文本，GPT的目标是预测下一个词，所以它会连续生成一串词，形成一段连贯的文本。从本质上看，Transformer只是标记模拟器，它不知道自己知道什么不知道什么，它不知道自己擅长什么或不擅长什么，它只是尽力生成下一个标记，它也不会进行反思，也不会不进行任何合理性检查。它不会纠正自己的错误，它只是产生抽样的标记序列，它没有像人类那样的内心独白流。但是，GPT有一些优势，如它们拥有大量的基于事实的知识，并且拥有相对大的并且完美的工作记忆。GPT通过自我注意力机制，能立即获取到上下文窗口中的信息，从而进行无损记忆。然而，GPT在推理和判断方面的能力相对较弱，如果提出的问题需要更复杂的推理，单凭一个标记的信息，GPT往往无法给出正确的答案。一些技巧可以提升GPT的表现，比如Cot（Chain of Though）设定步骤来引导GPT展示其工作过程，或者通过多次抽样然后选择最佳结果等，或者可以让GPT检查自己的输出，比如询问它是否完成了任务，最好是在Prompt中明确的要求它检查自己的输出。后面还介绍了目前比较流行的GPT应用，比如Agent、Plugin、CoT、Embedding等最后他用GPT-4写了一个结尾：“女士们，先生们，2023年Microsoft Build的创新者和先驱者们，欢迎来到这个独一无二的卓越人才的集结地。你们是未来的架构师，是塑造数字领域的视野家，在那里人类繁荣发展。拥抱科技的无限可能，让你的想法飞得和你的想象力一样高。让我们一起创造一个更连通，更出色，更包容的世界，为未来的世代留下。准备好释放你的创造力，探索未知，把梦想变成现实。你的旅程今天开始。”原始视频地址： 一个小问题，17:34 把 token 翻译成了代币2003？His fast speaking speed is rather challenging for sign language interpreters. Other than that, it is very informative and inspiring, thanks for sharing.看了一下午，总算看完了，受益匪浅，谢谢good非常有启发2003年？回复:到我的首页搜索字幕翻译，我分享过开源项目回复:用什么脚步翻译的呢？方便分享吗？宝玉回复: 谢谢反馈，是GPT-4翻译然后人工校对的，有疏漏，下次重点注意一个小问题，17:34 把 token 翻译成了代币

#### [牛Ｐ应用，效果见图！图片无损修复工具：SwinIR是一个能够帮助你修复和提升图片质量的工具。你可以把 @宝玉xp](https://weibo.com/1727858283/N2E01qOsX)

Note: 牛Ｐ应用，效果见图！图片无损修复工具：SwinIR是一个能够帮助你修复和提升图片质量的工具。你可以把这个工具想象成一个超级强大的”图片医生”。比如说，如果你有一张分辨率不高的图片，你想让它变得更清晰，SwinIR就可以帮你做到这一点。或者，如果你有一张图片，但是图片中有很多噪声（比如颜色不正常的点）SwinIR也可以帮你去除这些噪声。又或者如果你有一张JPEG格式的图片，但是由于压缩过程中产生了一些不自然的效果（我们称之为”压缩伪影”）SwinIR也可以帮你减少这些效果。这个工具使用了一种叫做Swin Transformer的技术，这种技术在图像处理领域表现得非常出色。已经在Replicate网站上被运行了390万次！你可以在Replicate上直接运行这个模型，也可以查看他们的介绍：replicate.com/jingyunliang/swinirGithub：github.com/jingyunliang/swinir论文：arxiv.org/abs/2108.10257了解更多细节。 抽离API功能，方便简洁//:👍美幸芯片，头开始痛了运用在人像上都是一言难尽。

Picture: [001MabKgly1hed1vcs6f0j603c03cdg402.jpg](https://weibo.cn//mblog/pic/N2xyqxHPO?rl=1)

Github: [github.com/jingyunliang/swinir](github.com/jingyunliang/swinir)

#### [【Top 50 C Interview Questions and Answers】https:// @网路冷眼](https://weibo.com/1715118170/N2CC9lQt8)

Note: 【Top 50 C Interview Questions and Answers】https:///kalkicode.com/top-50-c-interview-questions-and-answers 50 大面试问题和答案。 

#### [Chinese-LLaMA-Alpaca：本项目开源了中文LLaMA模型和指令精调的Alpaca大模 @蚁工厂](https://weibo.com/2194035935/N2bcdw6Se)

Note: Chinese-LLaMA-Alpaca：本项目开源了中文LLaMA模型和指令精调的Alpaca大模型。这些模型在原版LLaMA的基础上扩充了中文词表并使用了中文数据进行二次预训练，进一步提升了中文基础语义理解能力。同时，中文Alpaca模型进一步使用了中文指令数据进行精调，显著提升了模型对指令的理解和执行能力。地址：github.com/ymcui/Chinese-LLaMA-Alpaca最近的版本添加了指令精调脚本、LangChain支持、基于Gradio的本地Demo等。回复:成功保存到你的notion

Picture: [82c654dfly1heab4s3k4wj21a80agn24.jpg](https://weibo.cn//mblog/pic/N2bcdw6Se?rl=1)

Github: [github.com/ymcui/Chinese-LLaMA-Alpaca](github.com/ymcui/Chinese-LLaMA-Alpaca)

#### [这是斯坦福2023年公开课CS25的第三课：《Emergent Abilities and Scal @蚁工厂](https://weibo.com/2194035935/N2bsneefD)

Note: 这是斯坦福2023年公开课CS25的第三课：《Emergent Abilities and Scaling in LLMs | 大语言模型中的涌现和规模》，讲师是前Google Brain现OpenAI的Jason Wei。这堂课主要涵盖了大语言模型的三大概念：规模（Scaling）、涌现（Emergent），和推理（Reasoning）随着语言模型规模的扩大，可以预测性地提高语言模型的效果。涌现是一种现象，大型语言模型获得了小型语言模型所不具备的能力。涌现能力的一个例子是做复杂的数学题。- 涌现无法通过小模型的发展曲线预测- 涌现能力并非由模型的训练者指定的- 目前对于大型语言模型涌现出的能力还没能完全测试，尚不知道所有能力的范围。- 如果进一步扩大模型规模，可能会看到更多涌现的能力推理是区分经典机器学习和智能的关键，经典的机器学习方法需要大量的数据，并且是黑盒，而大语言模型可以通过prompt中的少量示例（few shot）中学习，并进行抽象推理。引发推理的一种方法是通过在Prompt中加入思维链（chain-of-thought CoT），也就是在上下文中给出中间推理步骤的例子。在Prompt中引入思维链（CoT） 使大语言模型能够进行多步推理任务，可以完成没有训练过的任务。另外，在做CoT的演示的时候，用的是OpenAI的PlayGround，效果很明显，但是我刚才找了下没找到。比如下面这个是没有用CoT的例子：O: Take the last letters of the words in "Bill Gates" and concatenate them.A:The answer is “Is".Q: Take the last letters of the words in "Elon Musk" and concatenate them.A:使用text-davinci-002模型的时候没办法给出正确答案，后来把Prompt换成：Q:Take the last letters of the words in "Bill Gates" and concatenate them.A:The last letter of “ Bill" is "". The last letter of "Gates" is "s". The answer is "1s".Q: Take the last letters of the words in "Elon Musk'" and concatenate them.A:马上就给出了正确的答案！还有一个多语言的思维链条的例子也很有意思，就是在让大语言模型做数学题的时候，必须用孟加拉语来解决，但孟加拉语在预训练数据中大约只占0.01%，可能甚至都没有用孟加拉语训练过多少数学问题。但大语言模型仍然能很好的用孟加拉语回答问题，所以模型可能学会了独立于语言的推理，然后它可以用不同的语言来表达。挺值得听的一堂课。推荐阅读:《Emergent Abilities of Large Language Models》：《Chain of Thought Prompting Elicits Reasoning in Large Language Models》：《Scaling Instruction-Finetuned Language Models》：CS25课程首页： 

#### [之前介绍的AI大模型“匿名”竞技场项目Chatbot Arena再次更新了排名（如图）上一期见：这次 @蚁工厂](https://weibo.com/2194035935/N2kGF4sy7)

Note: 之前介绍的AI大模型“匿名”竞技场项目Chatbot Arena再次更新了排名（如图）上一期见：这次增加了Google的PaLM 2，目前排在第六。开源里最强的还是Vicuna13B，第二强的是它的小弟Vicuna7B。 转发微博

Picture: [82c654dfly1hebgyu0bpdj20k81o3n6h.jpg](https://weibo.cn//mblog/pic/N2kGF4sy7?rl=1)

#### [卡内基·梅隆大学Brendan Sullivan的数学入门书《Everything You Alwa @蚁工厂](https://weibo.com/2194035935/N2kOT4uY9)

Note: 卡内基·梅隆大学Brendan Sullivan的数学入门书《Everything You Always Wanted ToKnow About Mathematics (But didn’t even know to ask)》你一直想了解的所有关于数学的知识（*但你甚至不知道该问什么）下载地址：www.math.cmu.edu/~jmackey/151_128/bws_book.pdf引导你进入抽象数学世界和证明写作的旅程回复:已保存至你的notion[赢牛奶]你可真无聊

Picture: [82c654dfly1hebhjwcxh0j21g51cx10f.jpg](https://weibo.cn//mblog/pic/N2kOT4uY9?rl=1)

#### [伯克利大学发布了一个擅长调用各类api的大语言模型：Gorilla。地址：github.com/Sh @蚁工厂](https://weibo.com/2194035935/N2m9sq6DG)

Note: 伯克利大学发布了一个擅长调用各类api的大语言模型：Gorilla。地址：github.com/ShishirPatil/gorillaGorilla让LLMs可以通过调用APIs使用工具。给定一个自然语言查询，Gorilla会提出语义和语法正确的API来调用。现已支持1600+（并且还在增加）API调用。只看这一环节其能力已经超过GPT-4 。视频为调用api的演示。 @@我的滴答清单这个项目还在申请waitlist阶段，视频只是他们在spotlight的展示零样本大猩猩优于 GPT-4、Chat-GPT 和 Claude。 Gorilla 非常可靠，并且显着减少了幻觉错误。详细介绍：这个秀啊，现在LLM最大的问题就是不能精准执行（哪怕是相同的输入）

Github: [github.com/ShishirPatil/gorillaGorilla](github.com/ShishirPatil/gorillaGorilla)

#### [时序数据库随笔 - Time Series DBMS 综述作者是孙金城，Apache Member介 @蚁工厂](https://weibo.com/2194035935/N2nC5vMCl)

Note: 时序数据库随笔 - Time Series DBMS 综述作者是孙金城，Apache Member介绍了时序数据库的架构、不同架构的时序数据库的技术特点、设计思想，和存储的关系等等。 

Picture: [82c654dfly1h2llh1qalnj20gz09nmy4.jpg](https://weibo.cn//mblog/pic/LuLQhdcFX?rl=1)

#### [推荐个安卓上的软路由、服务器管理工具「ServerBox」，免费并且开源，flutter 写的除了安 @蚁工厂](https://weibo.com/2194035935/N2oj6jJ83)

Note: 推荐个安卓上的软路由、服务器管理工具「ServerBox」，免费并且开源，flutter 写的除了安卓也有其它客户端，界面和 ServerCat 有点像比较美观，目前功能还不多基本够用。 回复:成功收藏到你的notion

Picture: [bb0e59bfly1hebvdjeo3lj21n12wy19g.jpg](https://weibo.cn//mblog/pic/N2nV9w6zx?rl=1)

#### [深入搜索引擎原理对搜索引擎做一个原理性的分享，包括搜索的一系列核心数据结构和算法，尽量覆盖搜索引擎的 @蚁工厂](https://weibo.com/2194035935/N2ovorqCi)

Note: 深入搜索引擎原理对搜索引擎做一个原理性的分享，包括搜索的一系列核心数据结构和算法，尽量覆盖搜索引擎的核心原理，但不涉及数据挖掘、NLP等。 

Picture: [82c654dfly1h2lkfi1bohj20dm1iedi4.jpg](https://weibo.cn//mblog/pic/LuLbhnKXd?rl=1)

#### [Falcon-40B：号称目前最强的开放式LLM。它是由TII（Technology Innovat @蚁工厂](https://weibo.com/2194035935/N2uHPEwpa)

Note: Falcon-40B：号称目前最强的开放式LLM。它是由TII（Technology Innovation Institute）构建的一个40B参数的因果解码器模型，它在由精选语料库增强的1000B tokens的RefinedWeb上进行训练。其表现在huggingface的OpenLLM排行榜上暂列第一（如图）。不过它的训练数据没有中文，默认应该不支持中文。可以在huggingface上下载：huggingface.co/tiiuae/falcon-40b同时发布的还有其更小的版本：Falcon-7B目前中文支持最好的是不是还是清华的6B  转发微博

Picture: [82c654dfly1hecpacidzej21i91djtzm.jpg](https://weibo.cn//mblog/pic/N2uHPEwpa?rl=1)

#### [复杂推理：大语言模型的北极星能力 地址：yaofu.notion.site/6dafe3f8d114 @蚁工厂](https://weibo.com/2194035935/N2uUmupro)

Note: 复杂推理：大语言模型的北极星能力 地址：yaofu.notion.site/6dafe3f8d11445ca9dcf8a2ca1c5b199在 GPT-4 发布博客中，作者写道：“在一次随意的谈话中，GPT-3.5 和 GPT-4 之间的区别可能是微妙的。当任务的复杂程度达到足够的阈值时，差异就会显现出来。”这意味着复杂任务很可能是大型和小型语言模型的关键差异因素。在这篇文章中，我们将仔细分析讨论如何让大语言模型拥有强大的复杂推理能力。claude真有那么好么？用着一般啊结果地址：github.com/FranxYao/chain-of-thought-hub

Picture: [82c654dfly1hdn7s6yb5rj20m00xtwq1.jpg](https://weibo.cn//mblog/pic/MF6jYuniw?rl=1)

Github: [github.com/FranxYao/chain-of-thought-hub](github.com/FranxYao/chain-of-thought-hub)

#### [公开课：Rust 101地址：github.com/tweedegolf/101-rsRust 10 @蚁工厂](https://weibo.com/2194035935/N2v140ygT)

Note: 公开课：Rust 101地址：github.com/tweedegolf/101-rsRust 101 是一门面向计算机科学专业学生的大学课程，介绍了 Rust 编程语言，适用于任何想要教授 Rust 的人。 rust

Picture: [82c654dfly1hecqn71bmij20xc0hggof.jpg](https://weibo.cn//mblog/pic/N2v140ygT?rl=1)

Github: [github.com/tweedegolf/101-rsRust](github.com/tweedegolf/101-rsRust)