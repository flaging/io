<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>深度学习模型与算法 - 福来鸽的剪报库</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body>
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="01.intro.html">简要介绍</a></li><li class="chapter-item expanded affix "><li class="part-title">深度学习</li><li class="chapter-item expanded "><a href="02.deep-models.html" class="active"><strong aria-hidden="true">1.</strong> 深度学习模型与算法</a></li><li class="chapter-item expanded "><a href="03.deep-modules.html"><strong aria-hidden="true">2.</strong> 深度学习结构与组件</a></li><li class="chapter-item expanded "><a href="04.deep-accelate.html"><strong aria-hidden="true">3.</strong> 深度学习加速方法</a></li><li class="chapter-item expanded "><a href="05.deep-hardware.html"><strong aria-hidden="true">4.</strong> 深度学习硬件</a></li><li class="chapter-item expanded affix "><li class="part-title">系统与应用</li><li class="chapter-item expanded "><a href="06.systems.html"><strong aria-hidden="true">5.</strong> 操作系统与系统软件</a></li><li class="chapter-item expanded "><a href="07.tools.html"><strong aria-hidden="true">6.</strong> 实用工具</a></li><li class="chapter-item expanded "><a href="09.languages.html"><strong aria-hidden="true">7.</strong> 编程语言</a></li><li class="chapter-item expanded affix "><li class="part-title">未整理链接</li><li class="chapter-item expanded "><a href="11.links.html"><strong aria-hidden="true">8.</strong> 技术链接</a></li><li class="chapter-item expanded "><a href="12.weibo.html"><strong aria-hidden="true">9.</strong> 微博链接</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">福来鸽的剪报库</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="深度学习模型与算法"><a class="header" href="#深度学习模型与算法">深度学习模型与算法</a></h1>
<p>模型, 应用和解决方案.</p>
<h2 id="cv"><a class="header" href="#cv">CV</a></h2>
<p>dinov2</p>
<ul>
<li>图像子监督对比训练模型</li>
<li><a href="https://github.com/facebookresearch/dinov2">github</a>, <a href="https://hub.baai.ac.cn/view/25489">haai</a>, <a href="https://aijishu.com/a/1060000000398895">aijishu</a></li>
</ul>
<p>dino</p>
<ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzU1MzY0MDI2NA==&amp;mid=2247499393&amp;idx=1&amp;sn=83e6eecb11e4dc03dde296d06d689e3c&amp;chksm=fbed76a6cc9affb0095fa04452a111fd483720980208fc6edd09c0bd8f207e7f94d6c151a1cb&amp;scene=21#wechat_redirect">wechat</a>, <a href="https://github.com/facebookresearch/dino">github</a>, <a href="https://arxiv.org/abs/2104.14294">arxiv</a></li>
</ul>
<h2 id="nlp"><a class="header" href="#nlp">NLP</a></h2>
<p><a href="https://hazyresearch.stanford.edu/blog/2023-03-27-long-learning">From deep to long learning ?</a></p>
<ul>
<li><a href="https://news.ycombinator.com/item?id=35502187">hacker news</a>对此进行了详细的讨论</li>
</ul>
<p><a href="https://aijishu.com/a/1060000000408210">深度学习进阶篇-预训练模型[1]：预训练分词Subword、ELMo、Transformer模型原理</a></p>
<p><a href="https://aijishu.com/a/1060000000408421">深度学习进阶篇-预训练模型[2]：Transformer-XL、GPT原理、模型结构等详细讲解</a></p>
<p><a href="https://aijishu.com/a/1060000000408630">深度学习进阶篇-预训练模型[3]：XLNet、BERT、GPT,ELMO的区别优缺点等原理详解</a></p>
<p><a href="https://aijishu.com/a/1060000000408669">深度学习进阶篇-预训练模型[4]：RoBERTa、ALBERT、ELECTRA算法原理应用等详解</a></p>
<p><a href="https://aijishu.com/a/1060000000408803">深度学习进阶篇-国内预训练模型[5]：ERINE、ERNIE 3.0、ERNIE-的设计思路等详解</a></p>
<h2 id="audio"><a class="header" href="#audio">AUDIO</a></h2>
<p><a href="https://github.com/openai/whisper">whisper</a></p>
<ul>
<li><a href="https://github.com/ggerganov/whisper.cpp">whisper.cpp</a>: whisper模型的C++实现</li>
<li><a href="https://github.com/sanchit-gandhi/whisper-jax">Whisper JAX</a>: jax版本实现和加速
<ul>
<li>加速内容: 音频分段批处理(7倍), 使用jax jit(2倍), 使用TPU替换GPU(5倍), 共70倍</li>
</ul>
</li>
<li><a href="https://github.com/Const-me/Whisper">Whisper</a>: whisper模型的Windows客户端, 支持GPU, <a href="https://www.appinn.com/const-me-whisper/">小众软件</a>推荐</li>
<li><a href="https://github.com/MiscellaneousStuff/openai-whisper-cpu">openai-whisper-cpu</a>: CPU量化提升吞吐</li>
<li><a href="https://github.com/m-bain/whisperX">whisperX</a>: 提升时间戳精准度</li>
<li><a href="https://github.com/davabase/whisper_real_time">whisper_real_time</a>: 实时调用音频转换成字符的demo</li>
<li><a href="https://github.com/schibsted/WAAS">WAAS</a>: whisper as a service</li>
<li><a href="https://github.com/zhuzilin/whisper-openvino">whisper openvino</a>: whisper openvino优化版本</li>
<li><a href="https://github.com/guillaumekln/faster-whisper">faster-whisper</a>: 基于CTranslate2的whisper实现</li>
<li><a href="https://github.com/huggingface/blog/blob/main/fine-tune-whisper.md">huggingface finetune whisper</a>: huggingface官方的whisper finetune博客</li>
<li><a href="https://aws.amazon.com/cn/blogs/china/fine-tuning-and-deploying-whisper-models-with-sagemaker/">AWS finetune whisper</a>: AWS finetune博客, 示例在<a href="https://github.com/aws-samples/amazon-sagemaker-fine-tune-and-deploy-wav2vec2-huggingface">github</a></li>
<li><a href="https://github.com/SociallyIneptWeeb/LanguageLeapAI">LanguageLeapAI</a>: 基于whisper的翻译助理</li>
</ul>
<p><a href="https://www.aminer.cn/pub/6448967c71ac66d2cbd88151/audiogpt-understanding-and-generating-speech-music-sound-and-talking-head?f=wb">AudioGPT</a>: 论文<a href="https://www.aminer.cn/pub/6448967c71ac66d2cbd88151/audiogpt-understanding-and-generating-speech-music-sound-and-talking-head?f=wb">AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head</a>, 代码在<a href="https://github.com/AIGC-Audio/AudioGPT">github</a></p>
<h2 id="reco"><a class="header" href="#reco">RECO</a></h2>
<p><a href="https://arxiv.org/abs/2303.13835">Where to Go Next for Recommender Systems? ID- vs. Modality-based Recommender Models Revisited</a></p>
<ul>
<li>推荐系统能不能将ID细化</li>
</ul>
<p><a href="https://tech.meituan.com/2023/08/11/meituan-kdd-2023.html">KDD 2023 | 美团技术团队精选论文解读</a>: 美团23年推荐相关论文简介</p>
<p><a href="https://tech.meituan.com/2023/11/09/how-to-model-context-information-in-deep-interest-network.html">如何利用「深度上下文兴趣网络」提升点击率？</a>: 美团推荐网络</p>
<h2 id="llms"><a class="header" href="#llms">LLMs</a></h2>
<p><a href="https://huggingface.co/blog/AviSoori1x/makemoe-from-scratch">makeMoE: Implement a Sparse Mixture of Experts Language Model from Scratch</a>: 博客, MoE LLM的一种实现, <a href="https://github.com/AviSoori1x/makeMoE">github</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/638514540">AWQ vs SpQR: 量化又见量化</a>: 知乎解析, AWQ和SoQR, 保护关键的1%参数不变</p>
<p><a href="https://github.com/mit-han-lab/llm-awq">AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration</a>: llama, int3/4量化推理工具</p>
<p><a href="https://arxiv.org/abs/2401.02385">TinyLlama: An Open-Source Small Language Model</a>: 小型化llama</p>
<p><a href="https://github.com/dzhulgakov/llama-mistral">llama-mistral</a>: mistral实现代码</p>
<p><a href="https://www.ai-contentlab.com/2023/11/how-to-fine-tune-clip-model-with-custom.html">How to Fine-Tune CLIP Model with Custom Data</a>: finetune示例代码</p>
<p><a href="https://www.ai-contentlab.com/2023/11/implementation-of-q-learning-with-python.html">Implementation of Q-Learning with Python</a>: Q-learning示例代码</p>
<p><a href="https://magazine.sebastianraschka.com/p/practical-tips-for-finetuning-llms">Practical Tips for Finetuning LLMs Using LoRA (Low-Rank Adaptation)</a>: finetune建议</p>
<p><a href="https://github.com/togethercomputer/stripedhyena">StripedHyena-Nous-7B</a>: 7B模型的高效实现</p>
<p><a href="https://arxiv.org/abs/2305.14292">论文: WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia</a>: 减少模型的幻觉</p>
<p><a href="https://huggingface.co/mlabonne/phixtral-2x2_8">phi-2x2_8</a>: phi-2的2x8的MoE模型</p>
<p><a href="https://huggingface.co/mlabonne/phixtral-4x2_8">phi-4x2_8</a>: phi-2的4x8 MoE模型</p>
<p><a href="https://huggingface.co/microsoft/phi-2">phi-2</a>: 微软用教科书训练的2.7B模型</p>
<p><a href="https://github.com/lyogavin/Anima/tree/main/air_llm">air-llm</a>: 层级推理/flash attention, 实现4GB跑70B模型</p>
<p><a href="https://github.com/hpcaitech/SwiftInfer">SwiftInfer</a>: streaming-llm的框架, streaming的意思是将首token和滑动窗口结合,实现超长上下文.</p>
<p><a href="https://blog.llamaindex.ai/a-cheat-sheet-and-some-recipes-for-building-advanced-rag-803a9d94c41b">RAG方法介绍</a>: 其中RAG介绍的图在<a href="https://d3ddy8balm3goa.cloudfront.net/llamaindex/rag-cheat-sheet-final.svg">medium</a>上</p>
<p><a href="https://arxiv.org/abs/2312.12705">论文:Optimizing Distributed Training on Frontier for Large Language Models</a>: 基于AMD MI250X的大模型训练优化论文</p>
<p><a href="https://qwu28uf3j5.feishu.cn/docx/Ofp1dBDp2oH1nGxTmk9cRZDvnQe">涓海录AIGC学习文档</a>: AIGC飞书文档</p>
<p><a href="https://github.com/zeux/calm/tree/main">calm</a>:基于C的推理框架</p>
<p><a href="https://arxiv.org/abs/2401.04088">Mixtral of Experts</a>: SMoE, <a href="https://mistral.ai/news/mixtral-of-experts/">news</a></p>
<p><a href="https://github.com/dvmazur/mixtral-offloading">mixtral-offloading</a>: mixtral加速框架</p>
<p><a href="https://huggingface.co/ahxt/LiteLlama-460M-1T">LiteLlama-460M-1T</a>: 使用460M参数和1Ttoken训练的小型LLama</p>
<p><a href="https://llava-vl.github.io/">LLaVA</a></p>
<ul>
<li>多模态大模型,开源了数据集,模型和性能</li>
<li><a href="https://github.com/haotian-liu/LLaVA">github</a>, <a href="https://arxiv.org/abs/2304.08485">arxiv</a>, <a href="https://hub.baai.ac.cn/view/25839">haai</a></li>
</ul>
<p><a href="https://github.com/Vision-CAIR/MiniGPT-4">minGPT-4</a></p>
<ul>
<li><a href="https://minigpt-4.github.io/">github.io</a>, <a href="https://githubdaily.gitee.io/posts/2023-04-17-minigpt-4/">githubdaily</a>, <a href="https://hub.baai.ac.cn/view/25493">haai</a>, <a href="https://cuijiahua.com/blog/2023/04/ai-32.html">jack cui</a>, <a href="https://paperswithcode.com/paper/minigpt-4-enhancing-vision-language">paper with code</a>, <a href="https://arxiv.org/abs/2304.10592">arxiv</a></li>
<li><a href="https://mp.weixin.qq.com/s/riPR6dAvhlJD0Gp4Rtbw1w">MiniGPT-4实现原理及其核心BLIP2模型实践：从代表性图文对数据集、BLIP2模型结构到调用实践</a></li>
<li><a href="https://weibo.com/1497035431/MCXq5BmDe">weibo分析</a>
<ul>
<li>CV 部分采用了 EVA、BEIT、timm 和 DeiT</li>
<li>NLP 部分采用了 LLaMA</li>
<li>框架主体使用了 PyTorch</li>
<li>分布式部分，用了Salesforce.com的一个基于 PyTorch 分布式的简单封装和加强库</li>
</ul>
</li>
</ul>
<p><a href="https://arxiv.org/abs/2303.18223">A Survey of Large Language Models</a></p>
<ul>
<li>大语言模型综述, <a href="https://github.com/RUCAIBox/LLMSurvey/blob/main/assets/LLM_Survey_Chinese_0418.pdf">github</a>上有中文版</li>
</ul>
<p><a href="https://github.com/IBM/Dromedary">Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision</a></p>
<ul>
<li>IBM对模型产生内容进行无害化过滤</li>
</ul>
<p><a href="https://github.com/s-JoL/Open-Llama">Open-Llama</a></p>
<ul>
<li>开源训练llama流程, <a href="http://home.ustc.edu.cn/~sl9292/">这里</a>还部署了一个demo.</li>
</ul>
<p><a href="https://github.com/EniasCailliau/GirlfriendGPT">GrilfriendGPT</a></p>
<ul>
<li>一个小应用,生成一个会发照片,语音,文字的虚拟女友</li>
</ul>
<p><a href="https://ai.facebook.com/blog/multilingual-model-speech-recognition/">multilingual-model-speech-recognition</a></p>
<ul>
<li>META开源的ASR模型,特点是支持1000多种语言,对小语种友好</li>
<li><a href="https://github.com/facebookresearch/fairseq/tree/main/examples/mms">github</a>, <a href="https://scontent-cgk1-1.xx.fbcdn.net/v/t39.8562-6/348836647_265923086001014_6878005808275791319_n.pdf?_nc_cat=104&amp;ccb=1-7&amp;_nc_sid=ae5e01&amp;_nc_ohc=hjR-6nxcdOYAX-rEdBF&amp;_nc_ht=scontent-cgk1-1.xx&amp;oh=00_AfDmuOFfAUiIzeJ9TG0faxUXs_x6M81aj4GW3fhxjoOx3Q&amp;oe=6475A14F">paper</a></li>
</ul>
<h2 id="train"><a class="header" href="#train">train</a></h2>
<p><a href="https://learn.deeplearning.ai/chatgpt-building-system/lesson/1/introduction">Building Systems with the ChatGPT API</a></p>
<ul>
<li>吴恩达DLAI的prompt课程, <a href="https://www.youtube.com/watch?v=1SZOGp1D17E&amp;list=PLiuLMb-dLdWKjX8ib9PhlCIx1jKMNxMpy">youtube</a>有宝玉的翻译版本</li>
</ul>
<p><a href="https://blog.eleuther.ai/transformer-math/">Transformer Math 101</a></p>
<ul>
<li>transformer训练的一些数字知识, 可用于进行性能预估</li>
</ul>
<p><a href="https://kipp.ly/blog/transformer-inference-arithmetic/">Transformer Inference Arithmetic</a></p>
<ul>
<li>推理部分详细计算</li>
</ul>
<p><a href="https://github.com/XingangPan/DragGAN">Drag Your GAN</a></p>
<ul>
<li>使用GAN实现图像修改,只需要拖动图片</li>
</ul>
<p><a href="https://github.com/0nutation/SpeechGPT">SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities</a></p>
<ul>
<li>使用GPT实现多模态对话, 能实现语音对话</li>
</ul>
<p><a href="https://mp.weixin.qq.com/s/kqBROBbXIeu5Zu1luNpitw?v_p=90&amp;WBAPIAnalysisOriUICodes=10000001&amp;wm=3333_2001&amp;aid=01A2GUVvCiJ0bN45VH0AOVftc20OVPaYUZmVa1h1s_8-8xrdg.&amp;from=10D5193010">【LLM系列之底座模型对比】LLaMA、Palm、GLM、BLOOM、GPT模型结构对比</a></p>
<ul>
<li>GPT: decoder只保留一个Masked-Multi-Head Attention</li>
<li>LLaMA: RMSNorm,SwiGLU,Rotary Embedding, AdamW+Cosine learning rate schedule,因果多头注意力</li>
<li>Palm:swiGLU,Parallel layers, Multi-Query Attention, RoPE, shared Input-Output Embedding</li>
<li>GLM: layer norm的顺序和残差重新排列, 用于输出标记的单个线性层, Gelu, 二维位置编码</li>
<li>BLOOM:ALiBi位置嵌入, Embedding LayerNorm再第一嵌入层后直接使用, 250K词汇表,字节BPE,两个全连接层</li>
</ul>
<p><a href="https://mp.weixin.qq.com/s/fF1jci5l65opO1YPMOUuaw?v_p=90&amp;WBAPIAnalysisOriUICodes=10000001&amp;wm=3333_2001&amp;aid=01A2GUVvCiJ0bN45VH0AOVftc20OVPaYUZmVa1h1s_8-8xrdg.&amp;from=10D5193010">chatglm_tuning: 基于 LoRA 和 P-Tuning v2 的 ChatGLM-6B 高效参数微调</a></p>
<ul>
<li><a href="https://github.com/zejunwang1/chatglm_tuning">Github 代码</a></li>
</ul>
<p><a href="https://arxiv.org/abs/2306.09782">Full Parameter Fine-tuning for Large Language Models with Limited Resources</a></p>
<ul>
<li>全参数finetune大模型,最少使用8卡3090(24GB*8)即可</li>
<li>使用SGD能减少显存用量</li>
<li>提出LOMO的优化器及配套归一缩放规则</li>
</ul>
<p><a href="https://github.com/zejunwang1/LLMTuner">LLMTuner</a></p>
<ul>
<li>大模型调优,支持全参数/LoRA/QLoRA</li>
</ul>
<p><a href="https://github.com/eugeneyan/open-llms">Open LLMs</a></p>
<ul>
<li>大模型列表</li>
</ul>
<p><a href="https://inflection.ai/inflection-1">Inflection-1:Pi’s Best-in-Class LLM</a></p>
<ul>
<li>新的大模型,用于对话效果很好, 使用见<a href="https://heypi.com/talk">hey pi</a></li>
</ul>
<p><a href="https://huggingface.co/spaces/mosaicml/mpt-30b-chat">MPT-30B</a></p>
<ul>
<li>来自<a href="https://twitter.com/MosaicML">@mosaicML</a>, <a href="https://huggingface.co/spaces/lmsys/mt-bench">benchmark</a></li>
</ul>
<p><a href="https://zhuanlan.zhihu.com/p/637154782">LLM 全景图（The Landscape of LLM）</a></p>
<ul>
<li>大模型介绍, 文件包再<a href="https://drive.google.com/file/d/1-n7ZN6wXzgWWlv9kF5DT1QrvPOoguDCT/view?usp=sharing">google drive</a></li>
</ul>
<p><a href="https://gofurther.feishu.cn/docx/Enofdl25BotoVrxth8ec4rNBn5c">GPT/AIGC/LLM/NLP/ChatGPT 学习</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/620631150">【VALSE 2023】走向计算机视觉的通用人工智能：GPT和大语言模型带来的启发</a></p>
<ul>
<li>通用人工智能发展方向</li>
</ul>
<p><a href="https://www.sequoiacap.com/article/llm-stack-perspective/">The New Language Model Stack</a></p>
<ul>
<li>红衫资本对大模型未来的调研和判断</li>
</ul>
<p><a href="https://zhaozhiming.github.io/">Hacker and Geeker's Way</a>:ChatGLM3的部署应用等</p>
<h2 id="dataset"><a class="header" href="#dataset">dataset</a></h2>
<p><a href="github.com/GAIR-NLP/MathPile">MathPile</a>:一个多样化且高质量的以数学为中心的语料库, 包含约 95 亿个tokens。其数据包括教科书（包括讲义）、arXiv、维基百科、ProofWiki、StackExchange 和网页。它包含适合 K-12、大学、研究生水平和数学竞赛的数学内容</p>
<p><a href="https://labs.criteo.com/2013/12/download-terabyte-click-logs-2/">Download Terabyte Click Logs</a>: CTR数据集,推荐数据集</p>
<p><a href="https://mlbook.explained.ai/">The Mechanics of Machine Learning</a>: 深度学习的原理,图书</p>
<p><a href="https://whjlnspmd6.feishu.cn/wiki/DBnWwik1piTB6Iki02CcXoVQn3S?continueFlag=15c65df5e495a04816b3bfb2a052bc03">大模型赛道的技术分析</a>:飞书文档,随时失效</p>
<h2 id="gpu"><a class="header" href="#gpu">GPU</a></h2>
<p><a href="https://www.anandtech.com/show/20001/nvidia-unveils-gh200-grace-hopper-gpu-with-hbm3e-memory">NVIDIA Unveils Updated GH200 'Grace Hopper' Superchip with HBM3e Memory, Shipping in Q2'2024</a>: GH200在24年使用HBM3e</p>
<p><a href="https://gpus.llm-utils.org/nvidia-h100-gpus-supply-and-demand/">Nvidia H100 GPUs: Supply and Demand</a>: H100的供需问题, 介绍了一些细节</p>
<p><a href="https://www.zhihu.com/question/376875425/answer/3170169345?utm_medium=social&amp;utm_oi=49336847171584&amp;utm_psn=1675675386296467456&amp;utm_source=ZHShareTargetIDMore">使用什么工具可以监控GPU使用情况?@知乎</a>: nvidia-smi/gpustat/<a href="https://www.cyberciti.biz/hardware/nvtop-command-in-linux-to-monitor-nvidia-amd-intel-gpus/">nvtop</a>/<a href="https://github.com/XuehaiPan/nvitop/blob/main/README.md">nvitop</a></p>
<p><a href="https://gpuopen.com/learn/amd-lab-notes/amd-lab-notes-register-pressure-readme/">Register pressure in AMD CDNA2™ GPUs</a>: AMD GPU中降低寄存器的压力</p>
<p><a href="https://s2023.siggraph.org/">芯片会议:SIGGRAPH</a>: 需要注册</p>
<p><a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2016/EECS-2016-143.pdf">论文:Understanding Latency Hiding on GPUs</a>: GPU性能提升的方法论文/指南</p>
<p><a href="https://lore.kernel.org/lkml/20230515113537.1052146-1-muralimk@amd.com/T/#t">[PATCH 0/5] AMD64 EDAC GPU Updates</a>: AMD MI200系列的GPU patch</p>
<p><a href="https://face2ai.com/program-blog/#GPU%E7%BC%96%E7%A8%8B%EF%BC%88CUDA%EF%BC%89">GPU编程（CUDA）</a>: CUDA编程博客</p>
<p><a href="https://wccftech.com/nvidia-launches-a2-tensor-core-gpu-an-entry-level-design-powered-by-ampere-ga107-gpu-16-gb-gddr6-memory/">NVIDIA Launches A2 Tensor Core GPU, An Entry-Level Design Powered By Ampere GA107 GPU &amp; 16 GB GDDR6 Memory</a>:性能较差,未实际上市</p>
<p><a href="https://www.tomshardware.com/news/nvidia-hopper-h100-gpu-revealed-gtc-2022">Nvidia Reveals Hopper H100 GPU With 80 Billion Transistors</a>: 22年旧闻,有H100的PPT和老黄的视频</p>
<p><a href="https://gpuopen.com/learn/amd-lab-notes/amd-lab-notes-profilers-readme/">Introduction to profiling tools for AMD hardware</a>: AMD profiling工具介绍</p>
<p><a href="https://gpuopen.com/learn/matrix-compendium/matrix-compendium-intro/">matrix-compendium</a>: AMD GPU矩阵运算</p>
<p><a href="https://gpuopen.com/learn/amd-lab-notes/amd-lab-notes-mi200-memory-space-overview/">AMD Instinct™ MI200 GPU memory space overview</a>: AMD GPU显存</p>
<p><a href="https://developer.download.nvidia.com/GPU_Programming_Guide/GPU_Programming_Guide_G80.pdf">GPU Programming Guide GeForce 8 and 9 Series</a>: Nvidia GPU编程指南</p>
<p><a href="https://gpuopen.com/learn/wmma_on_rdna3/">How to accelerate AI applications on RDNA 3 using WMMA</a>: AMD GPU矩阵编程</p>
<p><a href="https://mp.weixin.qq.com/s/ZZfUdjplMVV0lk8tAf7QeQ">详解AMD RDNA2 GPU架构</a>: RDNA2</p>
<p><a href="https://www.semianalysis.com/p/amd-mi300-taming-the-hype-ai-performance">AMD MI300 – Taming The Hype – AI Performance, Volume Ramp, Customers, Cost, IO, Networking, Software</a>: MI300的简单介绍</p>
<p><a href="https://mp.weixin.qq.com/s/AGZU66wZll36o9_Ri01OSw">GPU巨头，拼什么？</a>: Nvidia Ada, AMD Navi 31和Intel ACM-G10的对比</p>
<p><a href="https://www.ece.lsu.edu/koppel/gp/notes/set-nv-org.pdf">NVIDIA GPU Microarchitecture</a>: Nvidia架构课件</p>
<p><a href="https://on-demand.gputechconf.com/gtc/2014/presentations/S4158-cuda-streams-best-practices-common-pitfalls.pdf">CUDA STREAMS</a>: Stream课件</p>
<p><a href="https://zhuanlan.zhihu.com/p/644124799?utm_campaign=&amp;utm_medium=social&amp;utm_oi=49336847171584&amp;utm_psn=1668775304565837824&amp;utm_source=com.microsoft.todos">学习设计GPU：3.执行单元之LSU（load store unit）</a>: Load store单元, 代码在<a href="https://github.com/OpenGPGPU/opengpgpu">opengpgpu@github</a>, <a href="https://zhuanlan.zhihu.com/p/643184661?utm_medium=social&amp;utm_oi=49336847171584&amp;utm_psn=1664435410360201216&amp;utm_source=ZHShareTargetIDMore">学习设计GPU：2.后端流水线设计和VectorALU</a></p>
<p><a href="https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/">Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning</a>: 通过对GPU的量化分析选择合适的型号</p>
<p><a href="https://gpuopen.com/learn/amd-lab-notes/amd-lab-notes-finite-difference-docs-laplacian_part4/">Finite difference method – Laplacian part 4</a>: AMD GPU差分算法实现</p>
<p><a href="http://gpgpu-sim.org/manual/index.php/Main_Page">GPGPU-Sim 3.1.1</a>: GPU cycle level的性能模拟器, <a href="https://www.zhihu.com/question/610069168/answer/3101615269?utm_medium=social&amp;utm_oi=49336847171584&amp;utm_psn=1665507212742049792&amp;utm_source=ZHShareTargetIDMore">拜月神使-曌鵷鶵@知乎</a>有一些解析</p>
<p><a href="https://developer.nvidia.com/gpu-accelerated-libraries">NVIDIA CUDA-X GPU-Accelerated Libraries</a>: Nvidia GPU库合集</p>
<p><a href="https://gpuopen.com/learn/amd-lab-notes/amd-lab-notes-gpu-aware-mpi-readme/">GPU-aware MPI with ROCm</a>: ROCm MPI</p>
<p><a href="https://frankdenneman.nl/2023/05/16/vsphere-ml-accelerator-spectrum-deep-dive-gpu-device-differentiators/">vSphere ML Accelerator Spectrum Deep Dive – GPU Device Differentiators</a>: Nvidia GPU 显存/Nvlink/Encoder/Decoder等都有些图表</p>
<p><a href="https://frankdenneman.nl/2023/05/12/vsphere-ml-accelerator-spectrum-deep-dive-for-distributed-training-multi-gpu/">vSphere ML Accelerator Spectrum Deep Dive for Distributed Training – Multi-GPU</a>: GPU多卡训练分析</p>
<p><a href="https://frankdenneman.nl/2023/05/10/vsphere-ml-accelerator-deep-dive-fractional-and-full-gpus/">vSphere ML Accelerator Deep Dive – Fractional and Full GPUs</a>: 单GPU分析, 是有整个系列</p>
<p><a href="https://github.com/OpenImageDenoise/oidn">oidn@github</a>: Intel的GPU denoise库,还支持Nvidia和AMD GPU</p>
<p><a href="https://gpuopen.com/amd-microsoft-directml-stable-diffusion/">AMD support for Microsoft® DirectML optimization of Stable Diffusion </a>: 使用AMD GPU做SD</p>
<p><a href="https://cohost.org/mcc/post/1406157-i-want-to-talk-about-webgpu">I want to talk about WebGPU</a>: WebGPU的简介</p>
<p><a href="https://sebastianraschka.com/blog/2023/llm-grad-accumulation.html">Finetuning Large Language Models On A Single GPU Using Gradient Accumulation</a>: Finetune</p>
<p><a href="https://github.com/GPUOpen-Drivers/AMDVLK">AMDVLK@github</a>: AMD的开源vulkan驱动</p>
<p><a href="https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html">NVIDIA Magnum IO GPUDirect Storage Overview Guide</a>: Nvidia GDR官方文档, <a href="https://developer.nvidia.com/gpudirect-storage">GDR官网</a></p>
<p><a href="https://yurichev.org/GPU/">CPU vs (GP)GPU: the difference</a>: CPU和GPU区别,以及SIMT的解释</p>
<p><a href="https://github.com/scutan90/DeepLearning-500-questions">DeepLearning-500-questions@github</a>: GPU问题</p>
<p><a href="https://mp.weixin.qq.com/s/0mvtj7s3FdYXPx-oJjrRgA">快速认识英伟达的GPU-CPU超级芯片Grace Hopper</a>: GH介绍</p>
<p><a href="https://mp.weixin.qq.com/s/q1SLsLlet2pQ7q0CJZtykA">GPU 利用率低常见原因分析及优化</a> </p>
<p><a href="https://mp.weixin.qq.com/s/sD8--wbpJPb46D3AXkmkFQ">深入浅出扩散模型(Diffusion Model)系列</a>:<a href="https://mp.weixin.qq.com/s?__biz=Mzg2NjcwNjcxNQ==&amp;mid=2247485029&amp;idx=1&amp;sn=1cc60284430cef628b2704936fa0c530&amp;chksm=ce47f211f9307b0745a757cf9bb02430fed5cb04491766afb63733c62b79d9ee403e137fe724&amp;scene=21#wechat_redirect">第一篇</a>, <a href="https://mp.weixin.qq.com/s?__biz=Mzg2NjcwNjcxNQ==&amp;mid=2247485206&amp;idx=1&amp;sn=716b8cd4a67d130a55dd18d7e9a9bbf8&amp;chksm=ce47f362f9307a74ff19b154dac3990b387452c81f1912988acddd53853b8c45feae3e5c387f&amp;scene=21#wechat_redirect">第二篇</a>, <a href="https://mp.weixin.qq.com/s/sD8--wbpJPb46D3AXkmkFQ">第三篇</a>, 从原理,数学推导和代码实现分别讲解SD</p>
<p><a href="https://arxiv.org/abs/2309.05463">Textbooks Are All You Need II: phi-1.5 technical report</a>: phi-1.3,从教科书训练的模型,但泛化性存在争议</p>
<p><a href="https://allenai.org/olmo/olmo-paper.pdf">paper: OLM</a>: 开源Open Language Model, 预计会开源训练/推理框架和代码, 训练log, 数据集等,还在AMD的超算中运行了.</p>
<p><a href="https://medium.com/@fareedkhandev/create-gpt-from-scratch-using-python-part-1-bd89ccf6206a">Create GPT from scratch using Python — Part 1</a>: 学习GPT</p>
<p><a href="https://github.com/nomic-ai/contrastors">contrastors</a>: train and evaluate contrastive models efficiently</p>
<p><a href="https://github.com/QwenLM/Qwen1.5">Qwen1.5</a>: 通义千问1.5模型</p>
<p><a href="https://arxiv.org/abs/2402.05964">A Survey on Transformer Compression</a>: 华为transformer压缩综述, 剪枝,量化,蒸馏,NAS</p>
<p><a href="https://github.com/kyo-takano/chinchilla">chinchilla</a>: 工具包,用来测算或评估scaling law</p>
<p><a href="https://github.com/HMUNACHI/nanodl">nanodl</a>: transformer的JAX实现</p>
<p><a href="https://christophm.github.io/interpretable-ml-book/">Interpretable Machine Learning</a>: 可解释的机器学习</p>
<p><a href="https://waytoagi.feishu.cn/wiki/QPe5w5g7UisbEkkow8XcDmOpn8e?continueFlag=dfef32ee7e6e88ed0e5fd659a6b1fb1f&amp;mark_id=999_reallog_mark_ad%3A999%7CWeiboADNatural">通往AGI之路</a>: AGI整理</p>
<p><a href="https://mp.weixin.qq.com/s/jgqs1eNiIOowK53IeB-k5A">语言大模型的浮点运算分配</a>: 计算量分配</p>
<p><a href="https://github.com/LouisShark/chatgpt_system_prompt">ChatGPT_system_prompt</a>: prompt整理</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="01.intro.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next" href="03.deep-modules.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="01.intro.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next" href="03.deep-modules.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
